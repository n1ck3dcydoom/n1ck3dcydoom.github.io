<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>(三)redis 持久化机制</title>
    <link href="/2022/11/10/(%E4%B8%89)redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/10/(%E4%B8%89)redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-的持久化机制"><a href="#redis-的持久化机制" class="headerlink" title="redis 的持久化机制"></a>redis 的持久化机制</h3><p>由于 redis 是内存型数据库,当 redis 实例发生异常宕机时,其内存里面的数据将会全部丢失; 所以 redis 也需要通过持久化操作来避免异常宕机导致的数据丢失问题发生</p><p>redis 提供了 3 种持久化方式:</p><ol><li>AOF 日志</li><li>RDB 内存快照</li><li>MIX 两者的混合模式</li></ol><h3 id="AOF-日志"><a href="#AOF-日志" class="headerlink" title="AOF 日志"></a>AOF 日志</h3><p>mysql 也有写日志,而且 mysql 的特性是写 <code>前日志</code> 也就是说在实际的数据写入之前,先写日志</p><p>而 redis 则恰恰相反,redis 是写 <code>后日志</code> 也就是当数据写入内存之后,才会记录日志; 要弄清楚为什么 redis 写 <code>后日志</code> 需要先了解 <code>AOF</code> 日志究竟保存了什么内容</p><p>相比于 mysql 的 <code>redo log</code>,记录的是修改后的数据,也就是哪个库那张表那个数据行多少偏移量上修改了什么</p><p>而 redis 的 <code>AOF</code> 日志也是类似于 <code>redo log</code> 记录的是什么 <code>key</code> 发生了什么修改,其组成部分如下:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-number">*3</span><br><span class="hljs-variable">$3</span><br><span class="hljs-built_in">set</span><br><span class="hljs-variable">$7</span><br>testkey<br><span class="hljs-variable">$9</span><br>testvalue<br></code></pre></td></tr></table></figure><p><code>*3</code> 表示当前操作命令有 3 个部分组成,每个部分都是由 <code>$+数字</code> 开头,后面紧跟跟具体的命令或者操作数; <code>$</code> 后面的 <code>数字</code> 表示当前命令或者操作数占用的字节数</p><p><code>$3 set</code> 表示 <code>set</code> 指令占用了 3 个字节, <code>$7 testkey</code> 表示操作数 <code>testkey</code> 占用了 7 个字节</p><p>为什么 redis 采用写 <code>后日志</code> 的方式,说到底还是为了快,为了性能</p><p>如果 redis 已经将命令成功执行了,则表示命令本身的语法和操作并没有问题,无需进行额外的校验,可以直接写到日志里面</p><p>如果说是写 <code>前日志</code> 的话,还需要对命令进行语法检查,或者一致性检查; 例如 mysql 的唯一键冲突,或者记录不存在等等检查,可以节约系统资源</p><p>如果不进行前置检查,直接将命令写入日志的话,如果命令本身是错误的在使用日志做数据恢复的时候,就会发生报错</p><p><code>AOF</code> 日志的缺点</p><ol><li>如果写入内存后,还没来得及写入 <code>AOF</code> 日志,此时宕机会导致数据丢; 如果 redis 用于缓存,还能从数据库里面恢复数据; 如果 redis 用作数据库的话,丢失的数据将无法恢复</li><li><code>AOF</code> 写日志不阻塞当前命令执行,但是写 <code>AOF</code> 日志也是在主线程中执行的,如果写盘的 IO 压力过大,将会严重影响后续命令的执行</li></ol><h4 id="AOF-的回写策略"><a href="#AOF-的回写策略" class="headerlink" title="AOF 的回写策略"></a>AOF 的回写策略</h4><p>为了解决主线程写 <code>AOF</code> 日志导致的阻塞问题,redis 提供了 3 种写 <code>AOF</code> 日志的策略</p><ol><li>Always 实时写:类似于 mysql 的同步刷盘,每次命令执行后,都立即写入 <code>AOF</code> 日志; 这样做数据可靠性最强,但是性能较低</li><li>Everysec 每秒写回:类似于 mysql 的实时写延时刷,每次命令执行后,先写入 <code>AOF</code> 的内存缓冲区,依靠其他后台线程每 1s 将 <code>AOF</code> 内存缓冲区内的数据刷入磁盘</li><li>No 操作系统控制刷盘时机:类似于 mysql 的延时写,每次命令执行后,只写入 <code>AOF</code> 内存缓冲区; 至于什么时候刷盘,由操作系统决定; 性能最高但是数据可靠性最低</li></ol><p>对于第 2 点,如果发生异常宕机,仍然会丢失 1s 之前的数据</p><h4 id="AOF-重写机制"><a href="#AOF-重写机制" class="headerlink" title="AOF 重写机制"></a>AOF 重写机制</h4><p>由于 <code>AOF</code> 是以文件的形式记录所有接收到的 <strong>写请求</strong>, 必不可免会导致 <code>AOF</code> 日志文件过大的情况; 即使是顺序写,对于一个大文件来说起磁盘写入的性能仍然低下</p><p>而且如果要使用 <code>AOF</code> 日志来做数据恢复的话,一个巨大的 <code>AOF</code> 日志势必导致数据恢复的时间非常缓慢,也会影响到 redis 的正常使用</p><p>redis 为了避免 <code>AOF</code> 日志文件越写越大,引入了 <code>AOF</code> 重写机制,其具体过程如下: 进行 <code>AOF</code> 重写时,会基于当前 redis 数据库现状创建一个新的 <code>AOF</code> 日志文件,会遍历所有的键值对,使用 <code>一条</code> 命令来记录写入</p><p>为什么说重写的 <code>AOF</code> 日志可以减小日志文件的大小呢?</p><p>因为 <code>AOF</code> 日志是追加写入的方式,也就是说 redis 对于每一条写记录,都会记录对应的 <code>AOF</code> 日志,对于一个 <code>key</code> 的重复</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fmi1e2yj332a0u017w.jpg" alt="img.png"></p><p>对于写入一个 <code>list</code> 来说, <code>AOF</code> 日志会记录完整的所有写操作,而重写的 <code>AOF</code> 日志则是只会记录当前最新状态的记录</p><p>即无论对 <code>list</code> 有多少次操作,重写 <code>AOF</code> 时的状态只有确切的一条,就只用记录这一条日志就够了</p><p>为了避免重写 <code>AOF</code> 日志对主线程的阻塞,redis 实际上有专门的后台线程 <code>bgrewriteaof</code> 去处理重写 <code>AOF</code> 日志</p><p><strong>一处拷贝,两处日志</strong></p><ul><li>一处拷贝是指: 当需要进行 <code>AOF</code> 日志重写时,此时的主线程会 <code>fork</code> 一个子线程出来,<code>fork</code> 出来的子线程拥有与重写时主线程完全一致的内存数据; 这样子线程就可以在不阻塞主线程的情况下,在后台异步的重写 <code>AOF</code> 日志</li></ul><p>之前提到过,为了避免写 <code>AOF</code> 日志时写盘速率影响到主线程,此时主线程实际上写入的是 <code>AOF</code> 日志缓冲区,然后按照配置的刷盘策略去将日志缓冲区的记录刷到磁盘上的 <code>AOF</code> 文件里</p><p>由于重写 <code>AOF</code> 时是 <code>fork</code> 的子线程,而在 <code>fork</code> 之后还会有新的写请求进来,这样子线程的内存数据和主线程的内存数据就会产生不一致</p><ul><li>两处日志就是为了解决上述的不一致问题: 当主线程 <code>fork</code> 之后继续处理新的写请求时,此时不仅仅会将新的写请求写入 <code>AOF</code> 日志缓冲区,还会继续写入 <code>AOF</code> 重写日志缓冲区; 这样当子线程完成 <code>AOF</code> 重写之后,再把 <code>AOF</code> 重写缓冲区内的增量写请求继续重写后与当前结果合并,这样一个完整的 <code>AOF</code> 重写日志就完成了,而且 <code>fork</code> 之后的写请求也不会丢失</li></ul><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fn02t77j30j108xdib.jpg" alt="img_1.png"></p><h4 id="AOF-重写时的性能问题"><a href="#AOF-重写时的性能问题" class="headerlink" title="AOF 重写时的性能问题"></a>AOF 重写时的性能问题</h4><p>重写 <code>AOF</code> 日志时,虽然使用了子线程在后台操作,但是仍然有阻塞主线程的场景</p><ol><li>主线程 <code>fork</code> 子线程时,需要拷贝虚拟页表,可能会阻塞</li><li>当有 <code>bigkey</code> 写入时,根据写时复制优化,需要拷贝 <code>key</code> 的全量数据到新的内存页里面,可能会阻塞</li><li>当重写 <code>AOF</code> 日志完成后,应用重写 <code>AOF</code> 缓冲区时,可能会阻塞</li></ol><h4 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h4><p>什么是写时复制</p><p>如果 <code>fork</code> 子线程时全量拷贝主线程的内存数据,此时很有可能导致内存不够,为了避免全量拷贝主线程内存,操作系统在做 <code>fork</code> 时引入了写时复制的概念</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fn62qwej30hd0fhtar.jpg" alt="img_2.png"></p><p>当主线程需要写入数据的时候,如果此时数据页正好在内存当中,则会在内存上单独分配一块内存出来将原有的内存页复制到新页里面,主线程的数据全部写入新的数据页</p><p>这样原来 <code>fork</code> 的子线程仍然访问原来的老数据页,使得在做 <code>AOF</code> 重写时,主线程和子线程的读写互不影响</p><p>且写时复制对于 redis 这种读多写少的数据库,能够减少数据页的分配,提高内存的使用率,减少 <code>fork</code> 子线程的阻塞时间</p><h3 id="RDB-内存快照"><a href="#RDB-内存快照" class="headerlink" title="RDB 内存快照"></a>RDB 内存快照</h3><p>由于 <code>AOF</code> 日志记录的是每一条操作指令和操作数,并不是实际的数据; 所以在使用 <code>AOF</code> 日志进行数据恢复的时候,需要 redis 把这些指令和操作数全部拿出来重新执行一遍</p><p>且 <code>AOF</code> 日志记录所有写指令,如果日志文件过大,在做数据恢复的时候将严重影响 redis 性能</p><p>redis 的另一种持久化方式: <code>RDB</code> 内存快照</p><p><code>RDB</code> 就是在某一时刻,记录了 redis 瞬间的所有数据和状态,并且以文件的形式持久化到磁盘上</p><p>与 <code>AOF</code> 相比, <code>RDB</code> 记录的是某一时刻的全量数据,而 <code>AOF</code> 则是记录的数据的操作; 所以在做数据恢复的时候,可以很方便的把 <code>RDB</code> 文件直接导入到 redis 当中</p><h4 id="RDB-快照的范围"><a href="#RDB-快照的范围" class="headerlink" title="RDB 快照的范围"></a>RDB 快照的范围</h4><p>要明确一点 <code>RDB</code> 做的是 <code>全量</code> 数据快照; 如果 redis 里面的数据量非常多,那么 <code>全量</code> 快照很有可能阻塞主线程的工作; 类比于 <code>AOF</code> 日志, redis 也提供了后台线程执行快照</p><p><code>bgsave</code> 命令可以创建一条后台子线程专门处理当前时刻的 <code>RDB</code> 快照数据,避免阻塞主线程</p><h4 id="RDB-快照时-写请求如何处理"><a href="#RDB-快照时-写请求如何处理" class="headerlink" title="RDB 快照时,写请求如何处理"></a>RDB 快照时,写请求如何处理</h4><p>对于业务系统来说,如果为了处理一次 <code>RDB</code> 快照,而让整个 redis 进入只读状态,这是不允许接收的; 然而如果在做 <code>RDB</code> 快照时仍然有写请求进入,此时就可能导致 <code>RDB</code> 快照数据和 redis 本身保存的数据不一致问题</p><p>对于写请求, <code>RDB</code> 类似于 <code>AOF</code> 仍然采用 <code>写时复制</code> 技术,保证数据的一致性; 当主线程需要写入数据时,会将这份数据的内存页复制出一个新的内存页; 主线程的写入操作全部放到新的内存页上; 同时子线程的 <code>RDB</code> 快照也会读取新的内存页,保证数据的一致性不被破坏</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fnb7r21j30i709qtao.jpg" alt="img_3.png"></p><h4 id="RDB-快照的频率"><a href="#RDB-快照的频率" class="headerlink" title="RDB 快照的频率"></a>RDB 快照的频率</h4><p>为了保证数据尽可能的最新,<code>RDB</code> 快照的频率必然也要变得更加频繁; 这样可以减少两次快照之间异常宕机导致的改动丢失; 但是 <code>RDB</code> 快照的频率也不是越快越好</p><ol><li>虽然 <code>bgsave</code> 子线程做快照时不阻塞主线程,但是每次子线程都要从主线程 <code>fork</code> 出来,而 <code>fork</code> 操作会把主线程的虚拟内存映射表全部赋值给子线程; 如果 redis 里面的数据量非常大,这里的 <code>fork</code> 操作也会影响到主线程的处理</li><li>由于 <code>RDB</code> 快照每次都记录全量的数据,而频繁地将全量数据写入磁盘; 也会导致 redis 整体性能下降</li></ol><h4 id="增量-RDB"><a href="#增量-RDB" class="headerlink" title="增量 RDB"></a>增量 RDB</h4><p>由于每次全量 <code>RDB</code> 需要记录的数据太多了,而放慢 <code>RDB</code> 频率又会导致宕机时丢失更多的数据; redis 引入了增量 <code>RDB</code> 技术</p><p>即在一次全量 <code>RDB</code> 之后,后面仅仅记录发生改动的数据,即只做增量 <code>RDB</code> 操作</p><p>增量 <code>RDB</code> 看起来很美好,但实际上并不是如此,因为 redis 要为每条记录维护元数据,而这些元数据大小是固定的; 如果说大量很小的字段被增量写入 <code>RDB</code> 可能一条记录也就 2,3 个字节; 但是其元数据可能固定高达 8 个字节; 这样 redis 就不得不为这些小字段去维护大量的元数据; 浪费大量内存,显得有点得不偿失</p><h4 id="混合-AOF-和-RDB-持久化"><a href="#混合-AOF-和-RDB-持久化" class="headerlink" title="混合 AOF 和 RDB 持久化"></a>混合 AOF 和 RDB 持久化</h4><p>在 redis 4.0 以后引入了混合模式: 即以一定的间隔做全量 <code>RDB</code> 快照; 同时在快照期间通过记录 <code>AOF</code> 日志的形式保存增量数据</p><p>这样即保证了有 <code>RDB</code> 快照可以快速恢复到上一时刻,也保证了快照期间的写请求不会丢失,还保证了 <code>AOF</code> 日志文件不会变得过于庞大,因为它只记录每次快照期间的增量数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fngtx5rj30iu0blmzs.jpg" alt="img_4.png"></p><p>在下一次发生全量快照的时候,直接清空 <code>AOF</code> 日志即可,因为下一次全量快照已经包含了这部分 <code>AOF</code> 日志记录的数据,这样进一步减小了 <code>AOF</code> 日志文件的大小</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(二)redis 为什么快</title>
    <link href="/2022/11/10/(%E4%BA%8C)redis%20%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB/"/>
    <url>/2022/11/10/(%E4%BA%8C)redis%20%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-使用单线程"><a href="#redis-使用单线程" class="headerlink" title="redis 使用单线程"></a>redis 使用单线程</h3><ol><li>完全基于内存,绝大部分请求都是在内存中计算处理,少量需要持久化的操作才会涉及到写磁盘</li><li>数据结构是专门设计的,操作简单</li><li>单线程,省去了线程间的上下文切换和 CPU 消耗,不存在资源竞争,不涉及加锁和释放的操作</li></ol><p>这里的单线程指的是 <strong>处理网络 IO 请求和键值对读写(核心工作线程)</strong> 是单线程的,而对于那些需要持久化的操作,例如写日志,异步删除,集群间节点数据同步等是有额外线程执行的</p><h3 id="IO-多路复用"><a href="#IO-多路复用" class="headerlink" title="IO 多路复用"></a>IO 多路复用</h3><h4 id="select-模型"><a href="#select-模型" class="headerlink" title="select 模型"></a>select 模型</h4><p>将所有已连接的 <code>socket</code> 都放入一个 <strong>文件描述符集合</strong> 当中,调用 <code>select</code> 函数把这个集合拷贝给内核,让内核轮训集合检测是否有网络事件</p><p>而内核检测是否有网络事件产生的方式则是通过遍历每个文件描述符,如果有网络事件产生,则将此 <code>socket</code> 标记为可读或者可写,遍历完成后把这个集合再拷贝回用户态交给 <code>select</code> 函数处理</p><p>此时用户态还需要做 <strong>第二次</strong> 遍历,才能找到就绪的 <code>socket</code> 并且进行处理</p><p>可以看到 <code>select</code> 模型有如下特点:</p><ol><li>需要遍历 2 次文件描述符集合</li><li>发生 2 次用户态到内核态,内核态到用户态的拷贝</li></ol><p>而且操作系统在不修改配置的情况下,默认只允许一个进程最大操作 <code>1024</code> 个文件描述符</p><h4 id="poll-模型"><a href="#poll-模型" class="headerlink" title="poll 模型"></a>poll 模型</h4><p>几乎与 <code>select</code> 一样,仅仅是使用链表来组织 <strong>文件描述符集合</strong> ,突破了 <code>select</code> 最大监听数量而已</p><h4 id="epoll-模型"><a href="#epoll-模型" class="headerlink" title="epoll 模型"></a>epoll 模型</h4><ol><li>使用 <strong>红黑树</strong> 存储文件描述符集合</li><li>使用 <strong>就绪队列</strong> 存储就绪的文件描述符</li><li>每个文件描述符只需要在添加时传入一次,通过事件更改描述符状态</li></ol><p><code>select, poll</code> 都只有一个相关函数,而 <code>epoll</code> 有 3 个相关函数 </p><p><code>epoll_create()</code></p><p>创建一个 <code>epoll</code> 实例,其内部主要有两个结构:</p><ul><li>监听列表: 所有需要监听的文件描述符集合,使用 <strong>红黑树</strong> 存储</li><li>就绪列表: 监听列表里面已经就绪的文件描述符结合,使用 <strong>队列</strong> 存储</li></ul><p><code>epoll_ctl()</code> </p><p>监听文件描述符 <code>fd</code> 上发生的 <code>event</code> 事件</p><p>调用 <code>epoll_ctl()</code> 函数会将当前文件描述符 <code>fd</code> 添加到 <code>epoll</code> 实例的监听列表里面,同时为 <code>fd</code> 设置一个回调函数,并且监听指定的 <code>event</code> 事件; 当 <code>fd</code> 上发生指定事件 <code>event</code> 之后,就会调用回调函数将 <code>fd</code> 放入 <code>epoll</code> 实例的就绪列表里面</p><p><code>epoll_wati()</code></p><p><code>epoll</code> 模型的主要处理函数,起作用相当于 <code>select</code>,当调用 <code>epoll_wait()</code> 时,会返回 <code>epoll</code> 实例的就绪列表里面的描述符个数,避免 <code>select, poll</code> 每次遍历所有集合元素</p><h4 id="水平触发"><a href="#水平触发" class="headerlink" title="水平触发"></a>水平触发</h4><p>当监听到文件描述符就绪后,就会触发通知,如果当前文件描述符缓冲区内的数据没有处理完,下次遍历到的时候还会继续发出通知</p><h4 id="边缘触发"><a href="#边缘触发" class="headerlink" title="边缘触发"></a>边缘触发</h4><p>仅当文件描述符从未就绪变更为就绪时,触发一次通知,且之后不会再次通知; 这要求处理函数必须在通知到来时,将缓冲区内的数据通过循环全部处理完成</p><p>边缘触发可以减少 <code>select</code> 的调用次数,只不过在一次调用当中需要反复调用多次 <code>read</code> </p><p><code>epoll</code> 采用边缘触发的方式,保证每次调用 <code>epoll_wait()</code> 都是有效的,因为一次调用必须把缓冲区内的所有数据全部处理完才能返回,否则内核会认为就绪的文件描述符的状态没有发生改变(还有数据没处理完,仍然是就绪状态),从而不再发出后续的通知导致内容丢失</p><h4 id="redis-的-IO-多路复用"><a href="#redis-的-IO-多路复用" class="headerlink" title="redis 的 IO 多路复用"></a>redis 的 IO 多路复用</h4><p>redis 将监听套接字的工作交给内核完成,而内核采用 <code>epoll</code> 的机制同事监听多个套接字和管理已就绪的套接字; 一旦有请求到来,通过就绪队列可以快速的找到文件描述符,交给 redis 的 IO 进程处理</p><p>这样 redis 就实现了一个 IO 进程复用,处理多个网络请求的效果</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zrs431btj30io0chq61.jpg" alt="img.png"></p><p>可以看到,redis 的 IO 进程其实就是在不断的处理 <code>epoll_create</code> 创建的 <code>epoll</code> 实例的就绪队列,每个就绪的文件描述符因为有 <code>epoll_wati</code> 的调用,都记录了监听的事件和对应的回调函数</p><p>当 redis 的 IO 进程拿到就绪的文件描述符之后,可以直接调用对应的回调函数进行请求的处理; 并且不会阻塞在某一个请求上,而是可以继续处理队列里下一个就绪的请求</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(一)redis 底层数据结构</title>
    <link href="/2022/11/09/(%E4%B8%80)redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <url>/2022/11/09/(%E4%B8%80)redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-对外提供的上层数据结构"><a href="#redis-对外提供的上层数据结构" class="headerlink" title="redis 对外提供的上层数据结构"></a>redis 对外提供的上层数据结构</h3><ol><li>String</li><li>List</li><li>Hash</li><li>Set</li><li>Sorted Set</li></ol><p>这五大基本类型是 redis 对外提供的数据结构,在底层 redis 分别有自己实现的底层数据结构去对应这些基本类型,分别是:</p><ol><li>简单动态字符串</li><li>压缩列表</li><li>双向链表</li><li>哈希表</li><li>跳表</li><li>整数数组</li></ol><h4 id="简单动态字符串-SDS"><a href="#简单动态字符串-SDS" class="headerlink" title="简单动态字符串 (SDS)"></a>简单动态字符串 (SDS)</h4><p><code>SDS</code> 并不是一个简单的以 <code>\0</code> 结尾的字符数组,而是一个有着相对复杂结构的抽象类型,并且支持动态扩展</p><p>一个 <code>SDS</code> 的结构如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sdshdr</span> &#123;</span><br>    <span class="hljs-comment">// 记录buf数组中已使用字节的数量，即SDS所保存字符串的长度</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> len;<br>    <span class="hljs-comment">// 记录buf数据中未使用的字节数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-built_in">free</span>;<br>    <span class="hljs-comment">// 字节数组，用于保存字符串</span><br>    <span class="hljs-type">char</span> buf[];<br>&#125;;<br></code></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqevfpm1j30jv0dvgp1.jpg" alt="img_6.png"></p><p><code>raw</code> 类型的 <code>redisObj</code> 和 <code>SDS</code> 内存不连续,需要两次内存分配</p><p><code>EMBSTR</code> 的 <code>redisObj</code> 和 <code>SDS</code> 内存连续,只需要一次内存分配</p><p>但是 <code>EMBSTR</code> 用来保存短字符的优化,如果字符串长度增加需要重新分配时,整个 <code>redisObj</code> 和 <code>SDS</code> 都需要重新分配</p><ol><li>获取字符串长度的时候,不用遍历底层的字符数组,只需要取出 <code>len</code> 属性即可</li><li>杜绝缓冲区溢出,在做字符串拼接的时候,首先会检查 <code>len</code> 和 <code>free</code> 判断内存是否满足需要;如果内存不足,则会对 <code>SDS</code> 做扩展后在才做</li><li>减少字符串的重新分配次数; 字符串扩展时,实际的内存分配会比对应的长度更多,减少连续扩展的内存分配次数; 字符串缩短时,已经分配的内存空间不会立即回收,以免下次需要用的时候再次分配内存</li><li>保证二进制文件安全,不通过 <code>\0</code> 判断是否达到末位,而是通过 <code>len</code> 和 <code>free</code> 属性计算末尾</li></ol><p>在实际做字符串扩展的时候,如果新字符串长度小于 <code>1M</code> 时,扩展会分配一倍大小的空间,如果超过了 <code>1M</code> 则每次多分配 <code>1M</code> 的空间</p><h4 id="压缩列表-zlist"><a href="#压缩列表-zlist" class="headerlink" title="压缩列表 zlist"></a>压缩列表 zlist</h4><p>一个 <code>zlist</code> 的结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqf2b902j30f102nabh.jpg" alt="img_1.png"></p><ul><li>zlbytes: 记录了整个压缩列表占用的字节数</li><li>zltail: 记录了压缩列表最后一个元素的偏移量,用于快速定位列表尾部</li><li>zllen: 记录了压缩列表实际保存的元素 <code>entry</code> 个数 (类似于 <code>SDS</code> 的 <code>len</code> 属性)</li><li>entry…: 压缩列表实际存储每个元素</li><li>zlend: 压缩列表尾部的终止符 (类似于 <code>\0</code> 的作用),标记一个压缩列表结束</li></ul><p><code>entry</code> 的结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqf7rasoj30fe03sta9.jpg" alt="img_2.png"></p><ol><li>一般情况下</li></ol><ul><li>prevlen: 上一个 <code>entry</code> 的大小</li><li>encoding: 当前 <code>entry</code> 的编码格式</li><li>entry-data: 当前 <code>entry</code> 实际存储的内容</li></ul><ol start="2"><li>如果保存的是整数类型<ul><li><code>encoding</code> 和 <code>entry-data</code> 会合并在 <code>encoding</code> 里面,通过前几位判断整型长度,用于节约空间</li><li>且会尝试把 <code>int</code> 转化为 <code>string</code> 类型</li></ul></li></ol><p>压缩列表的设计就是为了节省内存,顺序数组由于每个元素的类型和大小都是固定的,会导致内存使用率低</p><p>而压缩列表的每个节点 <code>entry</code> 通过保存编码让节点刚好分配够用的长度,来达到提高内存使用率的效果;同时由于每个 <code>entry</code> 的长度不一样,就必须记录上一个 <code>entry</code> 的偏移量,这样才能在链表里面完成寻址遍历</p><p>压缩列表的缺点:</p><ol><li>在做缩容的时候,会直接回收对应的内存空间,而不是类似 <code>SDS</code> 会保留; 这样每次新添加元素的时候都会产生一次内存分配</li><li>如果上一个节点的长度超过了 254 个字节,将会导致扩容,而扩容后的 <code>entry</code> 长度由于超过了 254 字节,下一个节点的 <code>prevlen</code> 属性无法保存 254 字节的信息,就只能跟着扩容; 这样容易引起一整条链路上的所有节点都对 <code>prevlen</code> 属性进行扩容操作</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfdaf2tj30u70gbq89.jpg" alt="img_7.png"></p><h4 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h4><p>在压缩列表 <code>zlist</code> 的基础上,每个节点都有维护指向上一个节点 <code>*prev</code> 和下一个节点 <code>*next</code> 的指针,构成一个双向链表</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfhppbkj30m20b7mzk.jpg" alt="img_3.png"></p><p>可以看到,在双向链表的每个节点 <code>quicklistEntry</code> 上,其实保存的实质性内容就是一个 <code>zlist</code> 压缩列表</p><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>字典的结构如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictht</span>&#123;</span><br>    <span class="hljs-comment">//哈希表数组</span><br>    dictEntry **table;<br>    <span class="hljs-comment">//哈希表大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> size;<br>    <span class="hljs-comment">//哈希表大小掩码，用于计算索引值</span><br>    <span class="hljs-comment">//总是等于 size-1</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> sizemask;<br>    <span class="hljs-comment">//该哈希表已有节点的数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> used;<br> <br>&#125;dictht<br></code></pre></td></tr></table></figure><p>可以看到字典其实是由 <code>dictEntry</code> 组成的数组构成,而 <code>dictEntry</code> 的结构如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span>&#123;</span><br>     <span class="hljs-comment">//键</span><br>     <span class="hljs-type">void</span> *key;<br>     <span class="hljs-comment">//值</span><br>     <span class="hljs-class"><span class="hljs-keyword">union</span>&#123;</span><br>          <span class="hljs-type">void</span> *val;<br>          uint64_tu64;<br>          int64_ts64;<br>     &#125;v;<br> <br>     <span class="hljs-comment">//指向下一个哈希表节点，形成链表</span><br>     <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> *<span class="hljs-title">next</span>;</span><br>&#125;dictEntry<br></code></pre></td></tr></table></figure><p>每个 <code>dictEntry</code> 都包含一个 <code>kv</code> 对,还包含一个指向下一个节点的 <code>*next</code> 指针,这说明 redis 在解决哈希冲突的问题上,采取的是 <code>拉链法</code> </p><p>当 <code>dictEntry</code> 节点个数在不停地增加时,哈希碰撞的概率也会加大,最严重的时候会导致字典退化为一个单链表,所以 redis 通过 <code>rehash</code> 操作来扩展字典的大小,将原来集中的 <code>kv</code> 再次分散到不同的 <code>dictEntry</code> 上,减小哈希碰撞的发生</p><p>redis 内部维护了两个全局的 <code>hash table</code> 起作用类似于 <code>AB</code> 表,当发生 <code>rehash</code> 时,就对新 <code>table</code> 做扩容操作,然后把旧 <code>table</code> 的数据全部拷贝过去,再释放旧 <code>table</code> 的空间</p><p>对于少量数据,这个操作可以瞬间完成; 对于大量数据的全量拷贝,势必造成 redis 的阻塞; 所以 redis 引入了 <code>渐进式 rehash</code></p><ol><li>对新 <code>table</code> 进行扩容操作,但是并不立即拷贝旧的数据</li><li>对旧 <code>table</code> 做读取操作时,每次读出的 <code>hash</code> 桶就会拷贝到新 <code>table</code> 上尽行 <code>rehash</code></li></ol><p>这样每次写都是写旧的 <code>table</code>  而读可能新旧 <code>table</code> 都能提供服务; 减少了一次性全量数据拷贝阻塞 redis 的风险</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfn2s4oj30x10jkqa6.jpg" alt="img_8.png"></p><h4 id="整数数组"><a href="#整数数组" class="headerlink" title="整数数组"></a>整数数组</h4><p>数组的结构很简单:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">intset</span> &#123;</span><br>    <span class="hljs-type">uint32_t</span> encoding;<br>    <span class="hljs-type">uint32_t</span> length;<br>    <span class="hljs-type">int8_t</span> contents[];<br>&#125; intset;<br></code></pre></td></tr></table></figure><p>一个记录长度的变量 <code>len</code> 一个记录编码的变量 <code>encoding</code> 一个实际保存变量的整型数组 <code>contents</code> </p><h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>跳表可以说是 redis 最复杂的数据结构了,要好好理解下</p><p>考虑压缩列表或者双端列表的场景,由于这两者都不支持随机访问,如果要查找某个元素的话,只能从头到尾依次遍历</p><p>而作为有序集合,其性质本身保证了有序,对于有序的查找,使用二分查找能加快查找进度</p><p>跳表在原来一层链表的基础上,引入了多层索引结构,每次从最高层最左端开始查找,其查找过程类似于二分查找</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfs56nnj30k60cqq53.jpg" alt="img_5.png"></p><p>在 redis 的实际运用当中,跳表 <code>zskiplist</code> 由指向头部的指针 <code>*header</code>, 指向尾部的指针 <code>*tail</code>, 当前跳表内最高的节点层数(表头节点不算), 当前跳表的长度(即节点个数,表头节点不算) </p><p>每个跳表节点 <code>zskiplistNode</code> 的结构组成如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> &#123;</span><br>    <span class="hljs-comment">// 后退指针</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">backward</span>;</span><br>    <span class="hljs-comment">// 分值</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-comment">// 成员对象</span><br>    obj *obj;<br>    <span class="hljs-comment">// 层</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistLevel</span> &#123;</span><br>        <span class="hljs-comment">// 前进指针</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">forward</span>;</span><br>        <span class="hljs-comment">// 跨度</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br></code></pre></td></tr></table></figure><p><code>level[]</code> 表示当前节点在哪些层里面出现,例如上图的节点 <code>o1</code> 就出现在 <code>L1,L2,L3,L4</code> 当中,而节点 <code>o2</code> 自出现在 <code>L1,L2</code> 当中</p><p><code>obj</code> 跳表节点存储的实际数据</p><p><code>*backward</code> 后退指针,当检索跳表节点时,若发现当前节点大于检索值,则需要后退并且进入下一层检索</p><p><code>score</code> 跳表的节点按照分值从小到大有序排列</p><p>对于层 <code>level</code>:</p><p><code>*forward</code> 前进指针用于检索下一个节点</p><p><code>span</code> 跨度,表示当前节点在当前层的下一个节点与当前节点之间有多少步长,例如对于节点 <code>o1</code> 在 <code>L4</code> 的节点来说,其跨度就是 <code>2</code> (走两步到当前层的下一个节点); 所有指向 <code>NULL</code> 的节点跨度为 <code>0</code></p><p>跳表插入节点时,如果数据比较几种,可能会退化成一条单链表; 所以必须在插入时更新节点的层数,redis 通过一个随机函数来决定插入节点在下一层是否应该继续插入,每次进入下一层的概率大概为 <code>1/4</code></p><p>为何 redis 选用跳表而不是红黑树</p><p>因为红黑树在做插入和删除时,涉及到树的旋转,其效率并不如跳表操作指针高; 而且在查询效率上分布均匀的跳表和红黑树几乎没有区别</p><h3 id="redis-所有的-kv-通过什么形式组织"><a href="#redis-所有的-kv-通过什么形式组织" class="headerlink" title="redis 所有的 kv 通过什么形式组织"></a>redis 所有的 kv 通过什么形式组织</h3><p>redis 内部维护了一个巨大的 <code>hash</code> 表,这个 <code>hash</code> 表记录了实例里面的所有键值对</p><p>这个巨大的 <code>hash</code> 表其实就是一个数组,而数组每个元素都是一个 <code>hash</code> 桶,每个 <code>hash</code> 桶里面才保存了键值对数据</p><p>每个 <code>hash</code> 桶内其实也不是保存的真正的键值对,而是维护的指向键值对的指针,即 <code>*key</code> 和 <code>*value</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfxowfbj30j609dgnk.jpg" alt="img.png"></p><p>全局哈希表可以在 <code>O(1)</code> 的时间内快速查找到对应的键值对,只需要由 <code>hash</code> 函数计算出 <code>key</code> 的位置就能找到 <code>hash</code> 桶的位置,然后访问 <code>hash</code> 桶内的 <code>*value</code> 指针即可找到对应的值</p><p>跳表的结构定义如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* ZSETs use a specialized version of Skiplists */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> &#123;</span><br>    sds ele;  <span class="hljs-comment">// 跳表节点保存的数据,一个 SDS 简单动态字符串</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">backward</span>;</span>  <span class="hljs-comment">// 当前节点的前驱节点</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistLevel</span> &#123;</span>  <span class="hljs-comment">// 当前节点所属的层级</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">forward</span>;</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplist</span> &#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">header</span>, *<span class="hljs-title">tail</span>;</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> length;<br>    <span class="hljs-type">int</span> level;<br>&#125; zskiplist;<br></code></pre></td></tr></table></figure><p><code>zskiplist</code> 跳表定义了两个指针,分别指向跳表的头部 <code>*header</code> 和尾部 <code>*tail</code> ,类型是跳表节点 <code>zskiplistNode</code></p><p><code>zskiplistNode</code> 跳表节点由一下</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十六)mysql 读写分离</title>
    <link href="/2022/11/08/mysql/(%E5%8D%81%E5%85%AD)mysql%20%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    <url>/2022/11/08/mysql/(%E5%8D%81%E5%85%AD)mysql%20%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/</url>
    
    <content type="html"><![CDATA[<h3 id="一主多从架构下的读写分离"><a href="#一主多从架构下的读写分离" class="headerlink" title="一主多从架构下的读写分离"></a>一主多从架构下的读写分离</h3><p>先回顾下一主多从的结构图</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y196hmklj30j00cttan.jpg" alt="img.png"></p><p>读写分离的主要目的就是为了 <strong>分摊主库上的请求压力</strong> ,上面的架构主要是在 <code>client</code> 客户端主动做负载均衡; 在这种模式下,会把数据库的配置信息放到客户端的连接层,由客户端主动选择处理写请求和读请求的数据库实例</p><p>还有一种就是在客户端和数据库之间新增一个代理网关(正向代理:发送方不知道实际处理方是谁,只知道一个处理方代理),这样客户端就不用区分读写请求,只需要把请求全部发送给代理即可; 具体的读写请求分发到主库还是从库全部由代理判断</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19d7bvhj30hb0dvq4f.jpg" alt="img_1.png"></p><p>无论是那种架构,都存在一个问题: <strong>由于存在主从延迟,客户端刚刚写入一条数据后马上发起查询请求,此时处理读请求的从库很可能还没来得及完成主从同步,导致数据不一致</strong></p><p>读写分离解决数据不一致的方案主要有以下几种:</p><ol><li>强制查主库</li><li><code>sleep</code> 等待</li><li>判断是否存在主从延迟</li><li><code>semi-sync</code></li><li>等待主库位点</li><li>等待主库 <code>GTID</code></li></ol><h4 id="强制查主库"><a href="#强制查主库" class="headerlink" title="强制查主库"></a>强制查主库</h4><p>业务方将请求分为以下两类:</p><ol><li>有强一致性要求的请求,强制把这部分读请求打到主库上,保证数据一致性</li><li>接受一定时间内数据不一致的请求,把这部分读请求打到从库上,由主从同步保证一定时间内的最终一致性即可</li></ol><p>考虑一种极端场景,所有的请求都有强一致性要求; 这样一主多从的读写分离结构就退化为只有一个主库的单节点结构; 失去了读写分离的意义</p><h4 id="sleep-等待"><a href="#sleep-等待" class="headerlink" title="sleep 等待"></a>sleep 等待</h4><p>在主库完成写请求之后,下一个强一致性读请求到达业务方,在发送到从库之前先 <code>sleep(x)</code> 等待一段时间 <code>x</code></p><p>假设当前的主从延迟在 <code>2s</code> 以内,这样 <code>sleep(2)</code> 之后就可以认为从库已经同步了刚刚最新的写请求,此时业务方再把读请求发送到从库上,有很大概率能拿到最新的数据</p><p>这个方案仍然是不可靠的,假如主从延迟并不稳定在固定值之内</p><ol><li>如果主从延迟只有 <code>0.5s</code> 了,此时等待 <code>2s</code> 显然时间过长</li><li>如果主从延迟超过了 <code>2s</code>, 即使有等待的时间,还是会读取到历史脏数据,导致数据不一致的问题</li></ol><h4 id="判断是否存在主从延迟"><a href="#判断是否存在主从延迟" class="headerlink" title="判断是否存在主从延迟"></a>判断是否存在主从延迟</h4><ol><li>通过主从延迟时间判断是否存在主从延迟,每次查询前,先获取 <code>seconds_behind_master</code> 值,判断主从延迟的时间是否等于 0; 如果等于 0 就发起读请求,否则就等待主从延迟的时间变为 0 后才执行查询</li><li>通过位点判断是否存在主从延迟,查询主库上的最新位点和从库上的最新位点,如果两个位点相同,则认为没有主从延迟可以执行查请求;否则就等待直到位点相同后才执行查询</li><li>通过 <code>GTID</code> 判断是否存在主从延迟,查询主库的 <code>GTID</code> 集合与从库的 <code>GTID</code> 集合是否相同; 若相同则执行查询请求;否则就等待直到相同后才执行查询</li></ol><p>每次判断是否存在主从延迟,无论选用那种方式判断,也都还是会发生数据不一致的问题</p><p>考虑如下场景,主库 A 已经写入 2 个事务到 <code>binlog</code> ,并且发送了前两个事务到从库 B 里面,且从库 <code>B</code> 也已经同步完成; 此时主库 A 上一个新事务 3 刚刚写入完成,还没来得及发送</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19iv59mj30bq0a6wfe.jpg" alt="img_2.png"></p><p>此时无论是位点还是 <code>GTID</code> 都会认为没有发生主从延迟,但严格上来说此时的读请求,在从库上仍然是查询不到事务 3 的</p><h4 id="semi-sync-半同步"><a href="#semi-sync-半同步" class="headerlink" title="semi-sync 半同步"></a>semi-sync 半同步</h4><p><code>semi-sync</code> 半同步的设计如下:</p><ol><li>事务提交后,主库把 <code>binlog</code> 发送给从库</li><li>从库收到 <code>binlog</code> 在消费 <code>relay log</code> 并完成从库 <code>binlog</code> 的写入后,会给主库发送一个 <code>ack</code> 表示完成当前事务的同步</li><li>主库收到 <code>ack</code> 之后,才会返回给客户端表示当前事务已经完成</li></ol><p>也就是说 <code>semi-sync</code> 半同步机制保证了所有返回给客户端的事务请求,都是在从库上完成了同步的</p><p>在一主多从结构下,<code>semi-sync</code> 也可能会犯错</p><p>如果一个从库收到同步 <code>binlog</code> 的请求后,完成同步并向主库回复了 <code>ack</code>; 此时主库认为这个事务的同步已经完成,则向客户端回复成功; 假如针对这个事务数据的读请求进来,被代理分配到一个还没有完成同步的从库上,此时又产生了数据不一致的问题</p><p>而且如果是基于位点或者 <code>GTID</code> 的半同步,如果主库压力很大其不停地在推进位点或者 <code>GTID</code> 而从库可能会一直在追赶主库的同步进度</p><p>由于主从延迟加上 <code>semi-sync</code> 半同步机制,对于一个事务来说,从库迟迟不会向主库回复 <code>ack</code> ,从而主库不会向客户端回复成功; 导致整个业务阻塞</p><p>对于一笔刚写入完成的事务,并不需要完全等待从库完成同步后,才回复 <code>ack</code> 可以看一下主从同步之间的中间状态</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19r2wa6j30oe0ixdk3.jpg" alt="img_3.png"></p><p>对于等待位点检测主从延迟的方案来说,上面的请求中,从库和主库的位点一直都不相同; 如果一个查询必须要等待同步完成才能响应的话,上面的步骤将会导致整个查询不可用</p><p>其实当一个事务已经同步写入从库的 <code>binlog</code> 当中并完成刷盘,此时就可以认为这个事务的同步已经完成了; 至于其他事务导致的主从延迟,其实和当前已同步完成的事务无关</p><p>总结,使用 <code>semi-sync</code> 且检测主从延迟的方案,存在两个问题</p><ol><li>一主多从,从某些还未来得及同步主库的从库查询时,可能查到没有更新的历史数据</li><li>如果出从延迟持续存在,从库等延迟结束,主库等从库回复 <code>ack</code> ,这里可能导致长时间的等待</li></ol><h4 id="等待主库位点的操作"><a href="#等待主库位点的操作" class="headerlink" title="等待主库位点的操作"></a>等待主库位点的操作</h4><p>从库上有一条指令,可以用于主动检测与主库之间位点的差异</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> master_pos_wait(file, pos, timeout)<br></code></pre></td></tr></table></figure><ol><li><code>file</code> 指定了检测主库的 <code>binlog</code> 文件, <code>pos</code> 指定了检测事务的位置</li><li><code>timeout</code> 制定这个函数检测时的超时时间</li></ol><p>这条命令的返回值如下:</p><ol><li>正常返回一个正整数 <code>M</code> 表示从命令开始执行,到同步 <code>file</code> 的 <code>pos</code> 位置时,执行了多少个事务</li><li>如果主从同步发生异常,返回 NULL</li><li>如果超时,返回 <code>-1</code></li><li>如果开始执行的时候,就已经超过 <code>pos</code> 位置,返回 0</li></ol><p>对于上面 <code>semi-sync</code> 产生的问题,看看等待主库位点如何解决</p><ol><li>主库事务 <code>trx1</code> 执行完成之后,立马查询当前主库的 <code>binlog</code> 文件 <code>file</code> 和最新的位点 <code>pos</code></li><li>随机选择一个从库进行查询</li><li>从库查询前先执行上述语句,检测主从同步之间的位点差异</li><li>如果返回值 <code>&gt;=0</code> 则表示当前从库对于主库刚刚执行的事务 <code>trx1</code> 已经执行过了,可以由从库返回读请求</li><li>否则说明当前从库还未来得及同步刚刚主库的事务,此时读请求交给主库响应</li></ol><ul><li><p>假设检测主从延迟的等待时长为 <code>1s</code> ,如果这 <code>1s</code> 内,返回了大于 0 的整数 <code>M</code> ,则说明在这 <code>1s</code> 内,从库从某个之前的位置同步到 <code>pos</code> 时,应用了 <code>M</code> 个事务; 虽然等待了一些时间,但是好歹追上了主从延迟,所以从库可以相应对应的读请求</p></li><li><p>如果返回值等于 0,则表示从库当前同步主库的位点已经领先于主库执行事务 <code>trx1</code> 时的位点,此时从库肯定也是完成了事务 <code>trx1</code> 的同步,可以响应读请求</p></li><li><p>如果返回值等于 <code>-1</code> 或者 <code>NULL</code> 则说明在等待时间内从库都没能追上主从延迟,此时记录的肯定是历史数据,必须交给主库响应当前查询请求</p></li></ul><p>图例如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19xa2l8j30mh0g5n2i.jpg" alt="img_4.png"></p><p>退化到主库查询是一种通用的兜底方案,因为读请求不可能无限等待从库去追赶主从延迟;超时后就必须要由主库响应请求</p><h4 id="等待-GTID-的操作"><a href="#等待-GTID-的操作" class="headerlink" title="等待 GTID 的操作"></a>等待 GTID 的操作</h4><p>同理,从库通过主库发送过来的事务 <code>GTID</code> ,判断自己当前的 <code>GTID</code> 集合是否包含对应事务的 <code>GTID</code> </p><p>同样,超时后结束等待; 或者在等待时事务的 <code>GTID</code> 加入当前集合; 或者在检测时当前集合就已经包含了 <code>GTID</code> </p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十五)mysql 一主多从如何进行主从切换</title>
    <link href="/2022/11/07/mysql/(%E5%8D%81%E4%BA%94)mysql%20%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/"/>
    <url>/2022/11/07/mysql/(%E5%8D%81%E4%BA%94)mysql%20%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h3 id="一主多从的结构"><a href="#一主多从的结构" class="headerlink" title="一主多从的结构"></a>一主多从的结构</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7xg26tow1j30il0dxq6q.jpg" alt="img.png"></p><p>其中 A 和 A’ 互为主备关系(即双 M 结构),BCD 三个从库同步主库 A 的数据,只提供读服务</p><p>当发生主从切换的时候,从库 A’ 当选新的主库,此时 BCD 三个库需要重新连接到新的主库 A’ 上</p><h3 id="基于位点的朴素主从切换"><a href="#基于位点的朴素主从切换" class="headerlink" title="基于位点的朴素主从切换"></a>基于位点的朴素主从切换</h3><p>以从库 B 为例,当需要把 B 的主库切换到 A’ 时,需要执行 <code>change master</code> 指令,然后需要指定新主库的 <code>ip,端口,用户名,密码,binlog 日志,以及 binlog 日志位点</code> 这 6 个值</p><p>其中 <code>binlog</code> 日志位点是比较关键的信息,包含了从库 B 应该从新的主库的 <code>binlog</code> 日志的那个位置开始同步</p><p>如果这个位置选早了,会导致重复的事务再次被同步; 如果选晚了,会导致有些事务丢失</p><p>一种同步方式为:</p><ol><li>等待新主库 A’ 完成 <code>relay log</code> 的消费</li><li>通过工具解析原主库的最后一条事务记录,得到发生主从切换时的 <code>binlog</code> 日志和对应的位点</li><li>新主库 A’ 将这个位点发给从库 B 告知从库从这里开始往后解析 <code>binlog</code></li></ol><p>这种统计方式并不准确:</p><p>假如在原来的主库在执行事务 R 之后,已经将 <code>binlog</code> 发送给从库 A’ 和从库 B,在这个 T 时刻发生了主从切换</p><p>此时 A’ 还在继续消费 A 的中转日志,从库 B 已经把刚刚接收到的事务 R 同步到自己的实例当中; 当发生主从切换时,新的主库 A’ 告知从库 B 应当从最新的位点,即原来主库的最后一条事务 R 开始执行; 这样因为从库 B<br>已经执行过事务 R 了,会产生主键重复的错误</p><p>在主从切换遇到主键冲突一般有两种解决方案:</p><ol><li>手动跳过一个事务</li><li>设置跳过指定类型的错误:例如唯一键冲突,或者删除行不存在</li></ol><p>对于第二种方案,在主从切换稳定下来之后需要再次关闭,避免真正产生数据不一致后被跳过</p><h3 id="GTID-全局事务-id"><a href="#GTID-全局事务-id" class="headerlink" title="GTID 全局事务 id"></a>GTID 全局事务 id</h3><p>根据前面事务的介绍,InnoDB 会在每个事务创建的时候,为其分配一个自增的 <code>long</code> 类型的事务 <code>trx_id</code>, 在配合上当前数据库实例的唯一 <code>server_id</code> 就构成了 <code>GTID</code><br>其定义为: <code>GTID=server_id:trx_id</code></p><p>在启动 <code>GTID</code> 之后,每个事务都有一个唯一确定的 <code>GTID</code>,有两种分配方式:</p><ol><li><code>gtid_next=automatic</code> 自增分配</li><li><code>gtid_next=&#39;current_gtid</code> 手动指定一个事务的 <code>GTID</code> 值<ul><li>若这个 <code>current_gtid</code> 已经存在于当前实例的 <code>GTID</code> 集合里面,则当前实例在拿到这条事务后会跳过不执行</li><li>若不存在于当前实例的 <code>GTID</code> 集合,则把这个 <code>GTID</code> 分配给当前即将执行的事务,然后在分配下一个 <code>GTID</code> 给下一个事务</li></ul></li></ol><p>每个实力都维护了一个 <code>GTID</code> 集合,用来记录 <strong>当前实例已经执行过的所有事务</strong></p><p>举个简单的例子:</p><p>假设实例 X 已经插入了数据 <code>(1,1)</code> 且 <code>binlog</code> 里面记录的实例 X 的 <code>insert</code> 语句之前有一条 <code>SET</code> 语句,为这个事务设置了 <code>GTID=xxx</code></p><p>实例 X 是实例 Y 的从库,而且主库 Y 也插入了一条记录 <code>(1,1)</code> 且 <code>binlog</code> 里面 <code>insert</code> 语句之前也有一条 <code>SET</code> 语句,为这个事务设置了 <code>GTID=yyy</code></p><p>若此时主库 Y 将自己的 <code>binlog</code> 发送给从库 X 进行同步,显然从库 X 会发生主键冲突的错误,导致主从同步停止</p><p>根据上面 <code>GTID</code> 分配方式的,第二种,可以手动为从库 X 将产生主键冲突的事务 <code>GTID</code> 加入到实例 X 维护的 <code>GTID</code> 集合里面,来达到跳过这条主键冲突的事务</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> gtid_next<span class="hljs-operator">=</span>yyy;<br><span class="hljs-keyword">begin</span>;<br><span class="hljs-keyword">commit</span>;<br><span class="hljs-keyword">set</span> gtid_next<span class="hljs-operator">=</span>automatic;<br></code></pre></td></tr></table></figure><p>这样通过提交一个 <strong>空事务</strong> 来把产生冲突的 <code>GTID</code> 加入到实例 X 维护的 <code>GTID</code> 集合里面,这样同步实例 Y 的语句时,就会跳过这条事务,也就不会再出现主键冲突; 并且在手动 <code>SET</code> 之后,还将 <code>GTID</code> 更新设置自增,这样 mysql 就可以继续按照原有的序号分配新的 <code>GTID</code> 给新的事务</p><h3 id="基于-GTID-的主从切换"><a href="#基于-GTID-的主从切换" class="headerlink" title="基于 GTID 的主从切换"></a>基于 GTID 的主从切换</h3><p>当启动了 <code>GTID</code> 后,假设新主库 A’ 的 <code>GTID</code> 集合为 <code>set_a</code>, 从库 B 的 <code>GTID</code> 集合为 <code>set_b</code></p><p>此时主从切换的过程如下:</p><ol><li>从库 B 指定新的主库 A’</li><li>从库 B 把自己的 <code>set_b</code> 发送给主库 A’</li><li>主库 A’ 计算出 <code>set_a</code> 和 <code>set_b</code> 之前的差异,找到所有存在于 <code>set_a</code> 但是不存在于 <code>set_b</code> 的集合 <code>set_a&#39;</code> ,并且判断主库 A’ 上面的 <code>binlog</code> 里面是否包含 <code>set_a&#39;</code><ul><li>如果 <code>binlog</code> 包含所有 <code>set_a&#39;</code>,就找到 <code>set_b</code> 第一个不存在的事务,并把这个事务的 <code>GTID</code> 发送给 B</li><li>如果 <code>binlog</code> 不包含,则认为 <code>binlog</code> 数据不完整,直接报错</li></ul></li><li>主库 A 从 <code>set_a&#39;</code> 里面第一个不存在于 <code>set_b</code> 的事务开始,顺序读取 <code>binlog</code> 发送给从库 B 进行主从同步</li></ol><p>这里有个大前提保证: <strong>只要产生主从关系,就必须保证主库发送给从库的 <code>binlog</code> 是完整的,否则会导致主从数据不一致</strong></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十四)mysql 如何保证高可用</title>
    <link href="/2022/11/07/mysql/(%E5%8D%81%E5%9B%9B)mysql%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <url>/2022/11/07/mysql/(%E5%8D%81%E5%9B%9B)mysql%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="双-M-结构"><a href="#双-M-结构" class="headerlink" title="双 M 结构"></a>双 M 结构</h3><p>双 M 主从切换是目前比较常用的结构,这种结构使得数据库之间互相进行同步,通过属性 <code>readonly</code> 来决定逻辑上的主库</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbhy4xwmj30g6065jsl.jpg" alt="img.png"></p><h3 id="主从延迟"><a href="#主从延迟" class="headerlink" title="主从延迟"></a>主从延迟</h3><p>mysql 在做主从同步的时候,有几个关键的时间点如下:</p><ol><li>主库执行完成一个事务,写入 <code>binlog</code> 这个时间点记为 <code>T1</code></li><li>主库通过 <code>dump_thread</code> 将 <code>binlog</code> 发送给备库,备库通过 <code>io_thread</code> 将接收到的 <code>binlog</code> 写入中转日志 <code>relay log</code> 这个时间点记为 <code>T2</code></li><li>备库通过 <code>sql_thread</code> 线程消费中转日志 <code>relay log</code> 完成当前事务的时间点记为 <code>T3</code></li></ol><p>那么一个事务从主库到备库的 <strong>主从延迟</strong> 可以通过 <code>T1-T3</code> 得到</p><p><code>binlog</code> 里每个事务有个时间段字段,这是主库执行事务写入 <code>binlog</code> 的时间,备库在做同步的时候取出这个字段和自己的服务器本地时间作对比,计算出主从延迟的具体值即为 <code>T3-T1</code></p><p>如果主从库之间的系统时间不一致,备库每次同步的时候,都会向主库执行 <code>select unix_timesatmp()</code> 来获取主库的系统时间,在计算主从延迟的时候也会把这个时间加入一起计算</p><p>通常来说,在网络正常的情况下, <code>T2-T1</code> 的值非常小; 即主从延迟通常体现在备库太慢上,最主要的原因就是 <strong>备库消费中转日志的速率小于主库生产 binlog 的速率</strong> </p><h3 id="主从延迟的原因"><a href="#主从延迟的原因" class="headerlink" title="主从延迟的原因"></a>主从延迟的原因</h3><h4 id="备库的机器性能比主库差"><a href="#备库的机器性能比主库差" class="headerlink" title="备库的机器性能比主库差"></a>备库的机器性能比主库差</h4><p>相同的 sql 语句可能因为备库的机器性能较差从而导致备库执行的时间长于主库执行的时间,最终引发主从延迟</p><p>现在几乎都是主从的机器配置保持一样,采用对称配置,避免发生主从切换时,备库的性能问题拖垮整个服务</p><h4 id="备库压力过大"><a href="#备库压力过大" class="headerlink" title="备库压力过大"></a>备库压力过大</h4><p>在对称部署之后,仍然有主从延迟,还有个很常见的原因就是,备库有很多离线的计算任务</p><p>通常主库对外提供服务,而备库只读,所以很多时候会把一些分析任务放到备库里面跑,结果反而占用了备库大量的 CPU 资源,最终影响到主从同步,导致主从延迟发生</p><p>解决方案可以分为以下几种:</p><ol><li>一主多从: 使用多个备库一起分担这种需要耗费大量 CPU 资源的离线读任务</li><li>将 <code>binlog</code> 直接输出到外部系统,让外部系统直接提供解析 <code>binlog</code> 的能力</li></ol><h4 id="大事务"><a href="#大事务" class="headerlink" title="大事务"></a>大事务</h4><p>即使配置了一主多从,保证备库的压力不会超过主库,仍然还是可能发生主从延迟</p><p>如果说主库上运行了一个大事务,长达 <code>10min</code> ,那么备库在同步执行这个大事务的时候很有可能会导致主从延迟 <code>10min</code> 以上</p><p>最常见的场景就是一次性使用 <code>delete</code> 语句删除大量数据,这是个典型的大事务; 包括一次性归档大量数据等</p><p>最好是控制单次删除数据的量,分成多批次删除,降低事务的处理时间</p><p>另一种常见的大事务场景就是对一张大表做 <code>DDL</code> 操作</p><h4 id="从库的并行复制能力"><a href="#从库的并行复制能力" class="headerlink" title="从库的并行复制能力"></a>从库的并行复制能力</h4><p>如果一个从库消费中转日志 <code>relay log</code> 的速率小于主库生产 <code>binlog</code> 的速率,很有可能永远都追不上主库,导致长时间的主从延迟,如下图所示</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbi9bictj30ul0jjdnk.jpg" alt="img_4.png"></p><p>在 mysql 5.6 版本之前,从库的 <code>sql_thread</code> 只支持单线程,因此在主库并发高的情况下,会导致严重的主从延迟问题</p><p>5.6 之后引入了多线程模型,用于解决单线程消费中转日志 <code>relay log</code> 过慢的场景</p><p>类似于 <code>Netty</code> 或者 <code>Redis</code> 的网络模型,通常都是将接受网络请求的线程设为 1 个,而处理网络请求的线程设为若干个; 如果直接由若干个处理请求并发消费 <code>relay log</code> 每个线程之间都无法知道哪些日志是被消费过的,哪些日志是没有消费过的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbih0idbj30rs0jaju0.jpg" alt="img_5.png"></p><p>这里面的 <code>worker</code> 数量也不能过大,因为在读写分离场景下,从库还需要提供查询能力,如果仅仅由主从同步就将全部 CPU 资源占用了的话,从库的读取能力将大幅下降</p><p>mysql 在将 <code>relay log</code> 分发给不同的 <code>worker</code> 时需要满足以下两个要求</p><ol><li>不能造成覆盖更新,也就是更新同一行数据的多个事务,必须由一个 <code>worker</code> 顺序执行,否则将会出现其他 <code>worker</code> 的更新丢失或者覆盖当前数据</li><li>同一个事务不能再拆分</li></ol><h4 id="按表分发策略"><a href="#按表分发策略" class="headerlink" title="按表分发策略"></a>按表分发策略</h4><p>如果说一个两个事物分别更新两个不同的表,那么可以认为是这两个事务互不影响,可以由两个 <code>worker</code> 并行执行; 但是如果事务涉及到了跨表操作,还是需要把涉及到的多张表放到一个 <code>worker</code> 执行</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbin3yf4j30dl0edabx.jpg" alt="img_6.png"></p><p>可以看到每个 <code>workder</code> 都维护了一个 hash 表,里面维护的是当前 <code>worker</code> 的队列里面的事务所涉及到的表, <code>key</code> 是表名, <code>value</code> 是有多少个事务涉及到</p><p>当有新的事务被分配给 <code>worker</code> 时,事务里面涉及到的表就会被添加到对应的 hash 表里面, <code>worker</code> 执行完成之后就会把对应的 hash 记录移除掉</p><p>图中 <code>hash_table 1</code> 表示当前 <code>worker</code> 的工作队列里面有 4 个事务涉及到 <code>db1.t1</code> 表; 有 1 个事务涉及到 <code>db1.t2</code> 表</p><p><code>hash_table 2</code> 表示当前 <code>worker</code> 的工作队列里面有 1 个事务涉及到 <code>db1.t3</code> 表</p><p>假设分发者从 <code>relay log</code> 日志里面消费到一个新的事务 T,这个事务的修改涉及到 <code>t1 和 t3</code> 表</p><ol><li>根据第一个要求,这个事务涉及到的两个表 <code>t1 和 t3</code> 需要检查这两张表上是否有其他事务正在执行</li><li><code>t1</code> 表由 <code>worker1</code> 正在执行,检查 <code>t3</code> 发现正在由 <code>worker2</code> 执行,由于涉及到多表的事务只能由 1 个 <code>worker</code> 执行,所以分发者不能将 T 单独分配给 <code>worker1 或者 worker2</code> 只能等待下一次轮训</li><li>假设 <code>worker2</code> 的工作先结束,从 hash 表里面移除了 <code>t3</code> 的相关记录,此时分发者发现这个多表事务只有 <code>worker1</code> 有涉及到到,就把事务 T 分发给 <code>worker1</code></li><li>分发者继续处理中转日志当中的其他事务</li></ol><p>对于分发者来说,他的选择策略如下:</p><ol><li>如果当前事务跟所有 <code>worker</code> 都不冲突,则把它分给最闲的一个 <code>worker</code> 处理, 即 hash 表里面的字段最少的</li><li>如果当前事务跟多个 <code>worker</code> 冲突,则等待下一次轮训,直到有且只有 1 个 <code>workder</code> 冲突时,把事务分给当前 <code>worker</code></li><li>如果当前事务只有 1 个 <code>worker</code> 跟他冲突,则直接分给那个 <code>worker</code></li></ol><p>很明显,对于表请求负载均衡的场景,这个策略可以很好的胜任工作; 但是如果遇到一张热点表,即大量事务的更新都涉及到这一张表,此时就会把所有事务分配给同一个 <code>worker</code> ,这个模型就退化成单线程模型</p><h4 id="按行分发策略"><a href="#按行分发策略" class="headerlink" title="按行分发策略"></a>按行分发策略</h4><p>按行分发策略要求如果两个事务没有更新到相同的行,则他们可以并发执行; 由于要检测事务里面的更新涉及到的具体行信息,显然 <code>binlog</code> 只能设置为 <code>row</code> 模式,因为 <code>statement</code> 模式记录的原始 sql 不会涉及到具体的行</p><p>因此 <code>worker</code> 维护的 hash 表里面,就必须保存数据行的唯一性特征,这里的唯一性特征,不仅仅是主键 id,还要把表里面的唯一性索引全都考虑进去,避免出现唯一性校验不通过的情况</p><p>可以看到按行分发在解析 <code>binlog</code> 时,会耗费更多的 cpu 资源,且要求表必须有主键,不得有外键,因为外键上的级联更新不会记录到 <code>binlog</code> 里面,会导致冲突检测不准确,还要求 <code>binlog</code> 格式必须是 <code>row</code></p><h4 id="按库分发策略"><a href="#按库分发策略" class="headerlink" title="按库分发策略"></a>按库分发策略</h4><p>实际上,mysql 既没有采用按行分发,也没有采用按表分发,而是 <strong>按库分发</strong></p><ul><li><p>这样在构造 hash 表的时候就会非常快,而且占用的资源少,因为一个 db 实例上的库毕竟不会太多</p></li><li><p>对于 <code>binlog</code> 的格式也没有具体要求</p></li></ul><h3 id="由于主从延迟-主从切换时应当选择什么样的策略"><a href="#由于主从延迟-主从切换时应当选择什么样的策略" class="headerlink" title="由于主从延迟,主从切换时应当选择什么样的策略"></a>由于主从延迟,主从切换时应当选择什么样的策略</h3><h4 id="可靠性优先策略"><a href="#可靠性优先策略" class="headerlink" title="可靠性优先策略"></a>可靠性优先策略</h4><p>双 M 部署的结构,具体的主从切换过程如下</p><ol><li>从库判断当前与主库的主从延迟时间,如果超过某个值,则不进行出从切换,循环执行当前步骤直到小于某个可以接受的时间值</li><li>将主库改为只读状态 <code>readonly=true</code></li><li>由于停止了对主库的写入操作,此时主从同步会慢慢地赶上进度,直到完全同步,即主从延迟时间等于 0</li><li>将从库的状态改为读写 <code>readonly=false</code>,将请求切换到从库上,完成主从切换</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbivgw6dj30nr079wgm.jpg" alt="img_1.png"></p><p>可以看到在 <strong>可靠性优先策略</strong> 的前提下,会有一个不可用的阶段,其长度等于设定的某个可以接受的主从延迟时间值</p><h4 id="可用性优先策略"><a href="#可用性优先策略" class="headerlink" title="可用性优先策略"></a>可用性优先策略</h4><p>如果非要把这个不可用时间降低到 0,那只能把第 4 步提前执行; 也就是不等待主从完成同步,直接让从库状态变为读写,然后把请求切到从库</p><p>这虽然避免了不可用的情况发生,但是会出现比较严重的数据不一致问题</p><p>假如表 <code>t (id, c)</code> 有两个字段,且主从库里面同时记录了 3 条数据 <code>(1,1)(2,2)(3,3)</code></p><p>此时业务正在往主库里面写入两条数据分别是 <code>insert c=4, insert c=5</code></p><p>如果此时已经有 <code>5s</code> 的主从延迟,当业务对主库写入 <code>c=4</code> 之后,发生主从切换,根据可用性优先策略,此时请求会立马切换到从库,即 <code>c=5</code> 的数据是向从库写入的</p><p>如果此时的 <code>binlog_format=STATEMENT</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbj1adzyj30og0j6q8r.jpg" alt="img_2.png"></p><p>根据主键自增的特性,在 <code>c=4</code> 写入主库时,插入的主键 <code>id=4</code> 实际写入数据 <code>(4,4)</code>, 而发生主从切换之后 <code>c=5</code> 写入从库时,插入的主键 <code>id=4</code> 也等于 4,实际写入的数据是 <code>(4,5)</code> </p><p><code>STATEMENT</code> 格式的 <code>binlog</code> 记录了原始 sql 语句,即 <code>insert id=4</code></p><p>那么在做出从同步时,新的主库接收到 <code>insert id=4</code> 由于主键 id 自增的特性,实际写入的数据是 <code>(5,4)</code></p><p>而新的从库接收到 <code>insert id=5</code> 由于主键 id 自增的特性,实际写入的数据是 <code>(5,5)</code> </p><p>可以看到,在 <code>id=4</code> 这条数据上,主从切换后产生了数据不一致</p><p>如果说将 <code>binlog</code> 格式改为 <code>ROW</code> 呢,由于 <code>ROW</code> 格式的 <code>binlog</code> 会记录插入行的所有字段值,那么在最后的同步过程当中,会报错 <strong>主键重复</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbj6jomqj30gg08vmzj.jpg" alt="img_3.png"></p><p>因为新主库发送的 sql 里面,包含了主键信息,可以理解为 <code>insert (id,c) value (4,5)</code></p><p>新从库发送的 sql 也包含了主键信息,可以理解为 <code>insert (id,c) value (4,4)</code></p><p>这样两个库都会因为重复的主键 <code>id=4</code> 而报错</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><code>row</code> 格式的 <code>binlog</code> 在做主从切换的时候,如果有数据不一致的问题很快就能通过报错发现</p><p>而 <code>statement</code> 格式的 <code>binlog</code> 在上述情况下是可以完成主从切换的,数据不一致的问题悄悄地发生了,严重的话可能要很久之后才会发现</p><p>所以 <code>binlog</code> 配置大多数时候还是以 <code>row</code> 格式为主</p><p>而且大多数时候数据的可靠性是优先于服务的可用性的,除非有特殊场景基本上都使用 <strong>可靠性优先策略</strong></p><h3 id="mysql-如何检测一个库是否可用"><a href="#mysql-如何检测一个库是否可用" class="headerlink" title="mysql 如何检测一个库是否可用"></a>mysql 如何检测一个库是否可用</h3><h4 id="select-1"><a href="#select-1" class="headerlink" title="select 1"></a>select 1</h4><p>如何判断一个库是否可用,最容易想到的办法就是 <code>select 1</code> 这样类似的心跳包</p><p>如果通过参数设置 mysql 的 <code>并发查询</code> 数最大只能为 3,那么下面的 <code>select 1</code> 语句将失去作用</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y2ezbvi8j30mg075wf8.jpg" alt="img_4.png"></p><p>可以看到会话 ABC 分别开启了查询的事务,但是没有提交结束事务; 此时会话 D 的心跳语句 <code>select 1</code> 是可以正常返回的,因为 <code>select 1</code> 不是一条查询语句,mysql 直接返回 1 就结束了; 而真正的查询语句会被阻塞掉</p><p>此时通过 <code>select 1</code> 判断主库是否可用的手段就失效了, <code>select 1</code> 只能检测进程是否存在,对于主库是否健康起不到检测作用</p><h4 id="select-查表语句"><a href="#select-查表语句" class="headerlink" title="select 查表语句"></a>select 查表语句</h4><p>如果执行一条真正的查表语句呢? 通常在数据库里面多放一张检测心跳的表,里面就一行记录; 这样心跳包就通过对这条记录反复执行 <code>select</code> 操作,即可检测数据库实例是否健康</p><p>考虑如下场景,所有的更新操作都会写 <code>redo log</code> 和 <code>binlog</code> 那如果磁盘被日志文件写满了,此时所有的更新操作都会被阻塞; 但查询语句不需要写盘,查询仍然是可用的</p><p>所以通过普通的 <code>select</code> 语句也不能真正检测出一个数据库是否可用</p><h4 id="update-更新语句"><a href="#update-更新语句" class="headerlink" title="update 更新语句"></a>update 更新语句</h4><p>如果执行一条更新语句呢? 在心跳检测表放一条数据,每次心跳检测都去更新这条记录,通常以写入时间戳 <code>timestamp</code> 来达到更新的操作</p><p>由于一主多从结构下,主库通常有一个双 <code>M</code> 结构的从库与之进行互相同步; 写入主库 A 的 <code>binlog</code> 会发送给从库 <code>A&#39;</code>, 而写入从库 <code>A&#39;</code> 的 <code>binlog</code> 也会发送给主库 <code>A&#39;</code> 如果只有一行记录的话,很有可能产生行冲突</p><p>由此可见,需要更新多行记录</p><p>在心跳检测表里面插入两行记录,分别以主库和从库的 <code>server_id</code> 作为主键; 由于主从关系 mysql 保证了其 <code>server_id</code> 一定不一样; 这样各自写自己的主键 id 即可避免主键冲突</p><p>多行更新仍然存在一个问题,就是判定主库不可用的时间可能会很慢</p><p>正常来说当一个主库正在经历非常大压力是,其 CPU 资源几乎被大量复杂业务查询占用完; 而心跳检测只需要一条简简单单的 <code>update</code> 语句,其占用的 CPU 资源是非常少的</p><p>如果心跳检测在得到一个 CPU 时间片后立马就执行成功了,此时外部仍然是认为主库可用的; 然而实际上此时主库正在经历前所未有的压力呢</p><h4 id="mysql-内部的检测方法"><a href="#mysql-内部的检测方法" class="headerlink" title="mysql 内部的检测方法"></a>mysql 内部的检测方法</h4><p>上面几种都是通过外部系统去检测 mysql 是否可用,而引入外部系统必将导致系统的复杂度和不可靠度</p><p>mysql 提供了内置的用于检测数据库是否可用的能力: <code>performance_schema</code> 性能检测表</p><p>这张表里面记录了 IO 操作的平均耗时,最大耗时,最小耗时等等性能指标; 这样可以通过外部系统去定时采集这张表的指标数据,来检测是否可用; 避免了通过外部手段检测带来的不确定性</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十三)mysql 主备同步</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%B8%89)mysql%20%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%B8%89)mysql%20%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h3 id="mysql-主备同步的过程"><a href="#mysql-主备同步的过程" class="headerlink" title="mysql 主备同步的过程"></a>mysql 主备同步的过程</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vlun7uysj30rm0h5dlk.jpg" alt="img.png"></p><p>对于主节点 A 来说,记录一个事务的过程依然符合两阶段提交,只不过多了一个 <code>dump_thread</code> 线程将 <code>binlog</code> 定时同步给从库 B</p><p>从库 B 通过 <code>io_thread</code> 与主库维持一个长连接接收从主库发过来的 <code>binlog</code>, 然后有多个 <code>sql_thread</code> 线程同步 <code>binlog</code> 里面的内容到数据库当中 </p><h3 id="binlog-的存储格式"><a href="#binlog-的存储格式" class="headerlink" title="binlog 的存储格式"></a>binlog 的存储格式</h3><ol><li>statement</li><li>row</li><li>mixed</li></ol><h4 id="statement"><a href="#statement" class="headerlink" title="statement"></a>statement</h4><p><code>statement</code> 模式会如实的记录每一条执行的 sql,例如</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vlutt4h1j314q05vjxi.jpg" alt="img_1.png"></p><p>注意一个问题,使用 <code>statement</code> 格式的时候,如果 <code>delte</code> 语句带有 <code>limit</code> 的话,很可能会导致主备不一致</p><p>因为 <code>delete</code> 后面如果有多个 <code>where</code> 条件,在主库和从库上分别执行这条 sql 语句是,很有可能两个库选择的索引不一致</p><p>这是因为 <code>statement</code> 记录的是原始 sql,当主库执行时,走索引 <code>a</code>,当从库执行时走索引 <code>t_modified</code>, 这是完全可能发生的情况</p><h4 id="row"><a href="#row" class="headerlink" title="row"></a>row</h4><p><code>row</code> 模式不会记录原始 sql 语句,而是记录每条 sql 语句实际操作的行</p><p><strong>这里因为我的 Mac 是 M1 arm64 架构的,而 docker 支持 arm64 架构的 image 都不带 mysqlbinlog 工具,唯一支持 mysqlbinlog 工具的镜像是 mysql-debian,然而 mysql-debian 仅支持 amd64 架构</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vluz1purj30sg09sn5a.jpg" alt="img_2.png"></p><p>实际上可以看到最终执行的语句里面其实是删除 <code>id=4</code> 的记录</p><h3 id="循环复制"><a href="#循环复制" class="headerlink" title="循环复制"></a>循环复制</h3><p>如果说主从之间互为主备关系,即 <code>binlog</code> 文件会互相发给对方用于同步</p><p>对于同一行更新语句生成的 <code>binlog</code> 记录,如何解决循环复制的问题</p><ol><li>规定两个库的 <code>server id</code> 必须不同</li><li>从库收到日志后,重放过程记录 <code>binlog</code> 时生成与原 <code>server id</code> 相同的日志</li><li>收到从库发过来的日志后,判断日志里面记录的 <code>server id</code> 是否是自己的; 如果是自己生成的则丢弃日志;否则进行同步</li></ol>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十二)mysql 日志写入时机</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%BA%8C)mysql%20%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E6%97%B6%E6%9C%BA/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%BA%8C)mysql%20%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E6%97%B6%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>mysql 操作日志的步骤当中,几乎都有为日志文件添加对应的缓存,由此可见 mysql 最大程度上在利用缓存来平衡内存和磁盘间写入速率的差距</p><p>同样的 <code>binlog</code> 也有自己的 <code>binlog buffer</code>, mysql 为每个事务都分配了对应的 <code>binlog buffer</code> 当事务执行时,都是先写入 <code>binlog buffer</code>, 当事务提交的时候才把 <code>binlog buffer</code> 写入 <code>binlog</code></p><p>根据以前的知识,这里写入的 <code>binlog file</code> 其实也还没有真正写入磁盘</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5h2r8mj30ca0a4tau.jpg" alt="img.png"></p><p>与这张图类似,都是将用户态的 <code>buffer</code> 写入 <code>os buffer</code> 然后调用 <code>fsync()</code> 刷入磁盘</p><p>同样的,有三种写入机制</p><ol><li>延时写,事务提交后,只写入 <code>os buffer</code>,不调用 <code>fsync()</code> 数据可靠性最低</li><li>实时写,实时刷,事务提交后,写入 <code>os buffer</code>,立即调用 <code>fsync()</code> 数据可靠性最高</li><li>实时写,延时刷,事务提交后,写入 <code>os buffer</code> ,积攒 <code>N</code> 个事务后一次性刷盘, 可能会丢失 <code>N</code> 个事务的记录</li></ol><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>同样的, <code>redo log</code> 也由两个部分组成 <code>redo log buffer</code> 和 <code>redo log file</code>,与 <code>binlog</code> 差不多,每次都是先写入 <code>buffer</code> 然后写入 <code>os buffer</code> 再调用 <code>fsync()</code> 刷盘</p><p><code>redo log</code> 也有三种写入机制:</p><ol><li>延时写,只写入 <code>redo log buffer</code>,由后台进程每秒写入 <code>os buffer</code> 然后再刷盘,可能丢失 1s 以内的数据</li><li>实时写,实时刷,每次写入 <code>redo log buffer</code> 后立即写入 <code>os buffer</code> 并且刷盘,数据可靠性最高</li><li>实时写,延时刷,每次写入 <code>redo log buffer</code> 后立即写入 <code>os buffer</code> 但是并不立即刷盘,由后台进程每 1s 进行刷盘操作,可能丢失 1s 以内的数据</li></ol><p>根据 <strong>两阶段提交</strong> 的原则,实际上在事务提交的过程中,需要先将 <code>redo log</code> 写为 <code>prepare</code> 状态,再写 <code>binlog</code> 最后将 <code>redo log</code> 写为 <code>commit</code> 状态</p><p>所以在实际的写盘时,在 <code>prepare</code> 阶段就要进行一次持久化操作</p><p>mysql 数据最可靠的配置,就是 <code>binlog</code> 每次提交事物前刷盘, <code>redo log</code> 的 <code>prepare</code> 也刷盘</p><h3 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h3><p>由于 mysql 最可靠的刷盘配置会在一次事务过程当中进行两次刷盘,为了尽可能提高写磁盘的性能,会将多次写盘操作合并为一次进行组提交</p><p><code>LSN</code> 日志逻辑序号,例如 3 个并发事务都提交了 <code>prepare</code> 的日志,需要完成刷盘操作,根据先后顺序分别是 <code>LSN=50</code> 的事务 1, <code>LSN=120</code> 的事务 2, <code>LSN=160</code> 的事务 3</p><p>当 InnoDB 刷新 <code>redo log</code> 的后台进程开始刷盘时,发现需要刷入的日志尾序号是 <code>LSN=160</code>, 头部是 <code>LSN=50</code> 那么这一次刷盘就会把三个事务的请求合并一起刷入磁盘,尽可能的减少了刷盘的次数</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vjetd1mdj30gq0bfdho.jpg" alt="img.png"></p><p>mysql 为了尽可能的提高一次刷盘的组大小,采用最简单的办法 <code>拖时间</code>, 只要尽可能的晚调用 <code>fsync()</code> 那么一次刷盘的组成员就会越大,所以在事务的两阶段提交过程,也采取了对应的优化措施</p><p>两阶段提交: 存储引擎更新 <code>buffer pool</code> 里面的数据,写入 <code>redo log</code> 为 <code>prepare</code> 状态, 返回 <code>Server</code> 将记录写入 <code>binlog</code> 后提交事务, 存储引擎写入 <code>redo log</code> 为 <code>commit</code></p><p>为了尽可能的利用组提交,mysql 实际上将 <code>binlog</code> 写入 <code>os buffer</code> 这一步提前,放到 <code>热到 log</code> 刷入 <code>prepare</code> 之后</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vjf05oe6j30g50i9wiv.jpg" alt="img_1.png"></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十一)mysql 幻读和 next-key lock</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%B8%80)mysql%20%E5%B9%BB%E8%AF%BB%E5%92%8C%20next-key%20lock/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%B8%80)mysql%20%E5%B9%BB%E8%AF%BB%E5%92%8C%20next-key%20lock/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是幻读"><a href="#什么是幻读" class="headerlink" title="什么是幻读"></a>什么是幻读</h2><p>幻读的定义: 事务在执行过程前后两次查询同一个范围内的数据时,后一次读到了前一次没有读到的结果</p><p>在可重复度级别下,普通的查询时 <strong>快照读</strong> 是不会观测到其他事务在其中插入的数据的,因此 <strong>幻读</strong> 仅发生在 <strong>当前读</strong> 的操作下</p><h3 id="幻读带了什么问题"><a href="#幻读带了什么问题" class="headerlink" title="幻读带了什么问题"></a>幻读带了什么问题</h3><p>假设有如下三个会话,并且没有针对幻读采取任何措施</p><p>且表里面只有 2 条记录 <code>id = 5, d = 5</code>, <code>id = 0, d = 0</code>, 执行顺序如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vflq7ab8j30rz0f1grs.jpg" alt="img.png"></p><p>从语义上来说,会话 A 开启了 <strong>当前读</strong> ,所以三次 <code>select</code> 查询得到不同的结果,在这个场景下看起来是符合语义的,当前读就是能看到其他未提交会话的更新操作</p><p>如果会话 A 在 T1 时刻查询后执行了一次 <code>update</code> 操作 <code>update t set d = 100 where d = 5</code></p><p>由于会话 B 和 C 都是执行一条 sql 语句,会在执行完成后立马提交事务,而会话 A 因为是通过 <code>begin</code> 开启的事务,所以必须在显式声明 <code>commit</code> 后才会提交事务,那么 <code>binlog</code> 的记录会是什么样的呢</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 会话 B</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id <span class="hljs-operator">=</span> <span class="hljs-number">0</span>    <span class="hljs-comment">-- (0,0,5)</span><br><br><span class="hljs-comment">-- 会话 C</span><br>inserst <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>)       <span class="hljs-comment">-- (1,1,5)</span><br><br><span class="hljs-comment">-- 会话 A</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span>   <span class="hljs-comment">-- (5,5,100) (0,0,100) (1,1,100)</span><br></code></pre></td></tr></table></figure><p>如果使用这份 <code>binlog</code> 去做主备同步或者备份数据库的话,会导致 <code>id = 0 和 id = 1</code> 的数据发生不一致的现象</p><p>很明显,会话 A 的 <strong>当前读</strong> 语义上是要对所有 <code>d = 5</code> 的数据加上锁,但是后来发现会话 B 将原来 <code>d != 5 的 id = 0</code> 的记录给更新为 <code>d = 5</code>,而且会话 C 更是插入了一条 <code>id = 1 且 d = 5</code> 的数据,这根原来会话 A 给 <code>d = 5</code> 加锁的语义发生了冲突</p><p>显然会话 A 并没有为所有 <code>d = 5</code> 的记录加上行锁,仅仅是锁住了 <code>id = 5, d = 5</code> 这一行数据; 如果进一步假设锁的范围变得更加严格,让所有被扫描过的 <code>d = 5</code> 的记录加上行锁</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vflvnhywj30lb0990vu.jpg" alt="img_1.png"></p><p>但是对于会话 C 呢,由于 <code>id = 1</code> 的记录之前并不存在所以自然而言也没有对 <code>id = </code> 的记录加锁,所以会话 C 仍然能够执行,此时 <code>binlog</code> 日志记录如下:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 会话 B 被阻塞,</span><br><span class="hljs-comment">-- update t set d = 5 where id = 0    -- (0,0,5)</span><br><br><span class="hljs-comment">-- 会话 C 因为 id = 0 的记录不存在,自然也没有锁,能够正常插入</span><br>inserst <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>)       <span class="hljs-comment">-- (1,1,5)</span><br><br><span class="hljs-comment">-- 会话 A</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span>   <span class="hljs-comment">-- (5,5,100) (0,0,0) (1,1,100)</span><br><br><span class="hljs-comment">-- 会话 B 在会话 A 提交后才能得以更新</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id <span class="hljs-operator">=</span> <span class="hljs-number">0</span>    <span class="hljs-comment">-- (0,0,5)</span><br></code></pre></td></tr></table></figure><p>显然,会话 B 的问题解决了,但是会话 C 的问题还没有解决</p><p>可以看到给单独的行加上行锁,或者给扫描过行加上行锁,在 <strong>当前读</strong> 的场景下都无法解决幻读的问题</p><h3 id="如何解决幻读"><a href="#如何解决幻读" class="headerlink" title="如何解决幻读"></a>如何解决幻读</h3><p>InnoDB 引入 <code>间隙锁</code> 的概念来解决行锁,先说下 <code>间隙</code> 是什么</p><p>对于上面的表,只有两条记录的时候 <code>id = 0, d = 0</code> 和 <code>id = 5, d = 5</code>, 此时把主键 id 放到一条数轴上,有如下表示:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfm2gsxnj30fa03cjrd.jpg" alt="img_2.png"></p><p>InnoDB 规定 <code>间隙</code> 的区间端点为 <code>左开右闭</code> ,对于正无穷为了让右区间为闭区间,InnoDB 约定了一个固定的最大值</p><p>对于 <code>间隙</code> 上面的加锁,就叫做 <code>间隙锁</code></p><p>在有了 <code>间隙锁</code> 之后,会话 A ,就会为数据两边的 <code>间隙</code> 都加上 <code>间隙锁</code>,如下图所示</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfm95entj30om08awfj.jpg" alt="img_3.png"></p><p>可以看到当会话 A 查询 <code>id = 3</code> 的记录时 <code>for update</code> 不仅仅为当前记录加锁,还把周围的间隙也加上了锁; 这样会话 B 在这个间隙里插入记录的时候会被阻塞掉</p><h3 id="间隙锁和死锁问题"><a href="#间隙锁和死锁问题" class="headerlink" title="间隙锁和死锁问题"></a>间隙锁和死锁问题</h3><p>考虑如下场景</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfme14t9j30rl0ah76b.jpg" alt="img_4.png"></p><p>对于会话 A,锁住的间隙是 <code>(5,max]</code>, 对于会话 B,锁住的间隙也是 <code>(5,max]</code>,可以看到同一个间隙锁可以被多个会话同时加锁,它们之间并不互斥,与间隙锁发生互斥的条件仅仅是 <strong>往间隙当中插入新数据</strong> </p><p>紧接着会话 B 插入数据,由于会话 A 持有了间隙锁,所以会话 B 被阻塞</p><p>同理会话 A 插入数据时也因为间隙锁导致阻塞,这里 mysql 的主动死锁检测立马就会返回报错</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>InnoDB 如何解决幻读问题</p><ul><li>对于快照读, <code>MVCC</code> 可以保证幻读不会产生</li><li>对于当前读, <code>间隙锁</code> 保证幻读不会产生</li></ul><h3 id="next-key-lock-加锁机制"><a href="#next-key-lock-加锁机制" class="headerlink" title="next-key lock 加锁机制"></a>next-key lock 加锁机制</h3><p>对于行锁和间隙锁,结合起来称为 <code>next-key lock</code></p><p>对于 <code>next-key lock</code> 的加锁规则,遵循一下 5 个原则</p><ol><li>加锁的基本单位是 <code>next-key lock</code>,符合 <strong>前开后闭</strong> 原则</li><li>在查询过程当中只对访问到的记录加锁,没有访问的记录不会加锁</li><li>等值查询下,如果是唯一索引加锁, <code>next-key lock</code> 退化为 <code>行锁</code></li><li>等值查询下,向右遍历到第一个不满足条件的记录时, <code>next-key lock</code> 退化为 <code>间隙锁</code></li><li>唯一索引上的范围查询会遍历到第一个不满足条件的记录为止</li></ol><p>假设表有 <code>id,c,d</code> 三个记录,主键 <code>id</code> 和 普通索引 <code>c</code></p><p>并且有记录 <code>(0,0,0)(5,5,5)(10,10,10)(15,15,15)(20,20,20)(25,25,25)</code></p><h4 id="1-唯一索引的等值查询"><a href="#1-唯一索引的等值查询" class="headerlink" title="1. 唯一索引的等值查询"></a>1. 唯一索引的等值查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh481j86j30p008gdgu.jpg" alt="img.png"></p><ol><li>会话 A 的对 <code>(5,10]</code> 加上 <code>next-key lock</code></li><li><code>id=7</code> 是一个等值查询,且主键 <code>id</code> 是一个唯一索引,所以 <code>next-key lock</code> 退化为 <code>行锁</code>,由于不存在 <code>id=7</code> 的记录,所以往右查找到第一个不满足条件的位置 <code>id=10</code> 退化为 <code>间隙锁</code> ,即 <code>(5,10)</code> </li><li>最终的加锁范围 <code>(5,10)</code></li></ol><p>由此可见会话 B 插入 <code>id=8</code> 会被阻塞,会话 C 更新 <code>id=10</code> 可以成功</p><h4 id="2-非唯一索引的等值查询"><a href="#2-非唯一索引的等值查询" class="headerlink" title="2. 非唯一索引的等值查询"></a>2. 非唯一索引的等值查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4fk7w1j30ou099wfo.jpg" alt="img_1.png"></p><ol><li>会话 A 对 <code>(0,5]</code> 加上 <code>next-key lock</code></li><li><code>c=5</code> 是一个等值查询,且 <code>c=5</code> 是非唯一索引,向右查找到第一个不满足条件的记录 <code>(10,10,10)</code> 这个查找过程中都会加上间隙锁 <code>(5,10]</code> ,而且 <code>c=10</code> 的记录会退化为 <code>间隙锁</code> ,即 <code>(5,10)</code></li><li>最终的加锁范围 <code>(0,10)</code></li></ol><p>为什么 B 更新 <code>id=5</code> 的记录能够成功,不是已经有 <code>(0,10)</code> 的间隙锁吗</p><p>需要注意的是,根据第 2 条原则,只对访问过的记录才加锁; 由于绘画 A 的 sql 是 <code>select id xxx</code> 可以看到通过索引 <code>c</code> 是覆盖索引的,此时不需要回表查询主键索引</p><p>相当于会话 A 的查找记录只使用索引 <code>c</code> 而没有用到主键索引,所以会话 A 的加锁仅仅在索引 <code>c</code> 上生效,而会话 B 通过主键 id 更新时,是没有 <code>next-key lock</code> 存在的,所以会话 B 能够成功执行</p><p>同理,会话 C 因为插入 <code>c=7</code> 的记录,会被会话 A 创建的 <code>next-key lock</code> 锁住,所以会话 C 被阻塞</p><p>这个例子说明两点:</p><ul><li><code>lock in share mode</code> 只会锁定覆盖索引,而 <code>lock for update</code> 会把涉及到的主键索引一起加锁</li><li>如果要避免 <code>lock in share mode</code> 加读锁但是数据被更新的话,就必须绕开覆盖索引,重新回表让主键索引一起加锁</li></ul><h4 id="3-主键索引的范围查询"><a href="#3-主键索引的范围查询" class="headerlink" title="3. 主键索引的范围查询"></a>3. 主键索引的范围查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4letudj30ou0ebq4k.jpg" alt="img_2.png"></p><ol><li>会话 A 对 <code>(5,10]</code> 加上 <code>next-key lock</code> ,由于 <code>id=10</code> 是等值查询, 且是唯一索引,所以退化成 <code>行锁</code> ,即 <code>[10,10]</code> 这一行</li><li>会话 A 对 <code>(10,15]</code> 加上 <code>next-key lock</code> ,由于 <code>id&lt;11</code> 是范围查询,所以会遍历到第一个不满足条件的记录位置,即 <code>(15,15,15)</code> ,此时 <code>next-key lock</code> 为 <code>(10,15]</code> </li><li>最终的加锁范围 <code>[10,15]</code></li></ol><p>会话 B 插入 <code>id=8</code> 的记录不在 <code>next-key lock</code> 当中,操作成功,更新 <code>id=13</code> 的记录被锁住,失败阻塞</p><p>会话 C 更新 <code>id=15</code> 的记录被锁住,失败阻塞</p><h4 id="4-非唯一索引的范围查询"><a href="#4-非唯一索引的范围查询" class="headerlink" title="4. 非唯一索引的范围查询"></a>4. 非唯一索引的范围查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4rrlerj30ou0b2mya.jpg" alt="img_3.png"></p><ol><li><code>c&gt;=10</code> 是范围查询, 会话 A 对 <code>(5,10]</code> 加上 <code>next-key lock</code>, 因为 <code>c</code> 是非唯一索引,不会退化为 <code>间隙锁</code></li><li><code>c&lt;11</code> 也是范围查询,会话 A 对 <code>(10,15]</code> 加上 <code>next-key lock</code>, 同样因为 <code>c</code> 是非唯一索引,不会退化为 <code>间隙锁</code></li><li>最终的加锁范围 <code>(5,10]∪(10,15] = (5,15]</code></li></ol><p>会话 B 插入 <code>c=8</code> 的记录被锁住,失败阻塞</p><p>会话 C 更新 <code>c=15</code> 的记录被锁住,失败阻塞</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十)mysql 索引失效的场景</title>
    <link href="/2022/11/05/mysql/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/"/>
    <url>/2022/11/05/mysql/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-当中索引失效的场景"><a href="#mysql-当中索引失效的场景" class="headerlink" title="mysql 当中索引失效的场景"></a>mysql 当中索引失效的场景</h2><h3 id="索引字段使用函数"><a href="#索引字段使用函数" class="headerlink" title="索引字段使用函数"></a>索引字段使用函数</h3><p>思考下 mysql 为何能够通过索引快速定位数据,是因为 <code>B+</code> 同层节点的有序性</p><p>如果说某些操作打破了这种有序性,那么就无法利用索引树来检索数据了,只能走全表扫描</p><p>例如 <code>select a from t where sum(a) &gt; 5</code> 这种对索引列做函数操作的,很有可能破坏索引的有序性</p><p>其实并不是说 mysql 对于这种函数操作完全放弃了索引,即使走全表扫描,仍然可以优化具体使用什么索引树来做全盘扫描</p><p>如果字段 <code>a</code> 上建立了索引,那么扫描索引 <code>a</code> 显然比扫描主键索引更快,这是因为 <code>索引覆盖</code> 带来的优化,不用取出整行数据,索引 <code>a</code> 已经包含了列 <code>a</code> 所需要的所有数据</p><p>同样的,还有更加隐蔽的操作也会导致索引失效</p><p>例如 <code>select * from t where id + 1 = 10000</code> 这里 <code>+1</code> 不会破坏有效性,但是仍然无法通过 id 定位到 <code>9999</code> 这一行 因为 mysql 无法计算 <code>多少 id +1 才能等于 10000</code><br>,还是需要全表扫描</p><p>如果改为 <code>where id = 10000 -1</code> 那么即可快速通过索引定位到 <code>9999</code> 行</p><h3 id="隐式类型转换会导致索引失效"><a href="#隐式类型转换会导致索引失效" class="headerlink" title="隐式类型转换会导致索引失效"></a>隐式类型转换会导致索引失效</h3><p>假如存在一个 <code>varchar()</code> 类型的列 <code>order_id</code> 上建有索引, 以下 sql 会让索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> order_id <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>注意到 <code>order_id</code> 本身是 <code>varchar()</code> 类型,但是 sql 语句里面却是用 <code>int</code> 整型变量在做比较,这会导致发生 <strong>隐形类型转换</strong> 从而导致索引失效</p><p><strong>mysql 将数字和字符串作为比较的话,会把字符串转换为数字</strong></p><p>为何隐式类型转换会导致索引失效</p><p>在了解到字符串如果和数字作对比,会把字符串转换为数字之后,上面 sql 的本质就发生了改变</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> <span class="hljs-built_in">CAST</span>(order_id <span class="hljs-keyword">AS</span> <span class="hljs-type">int</span>) <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>可以看到这里的隐式类型转换实际上是对字符串调用了 <code>CAST()</code> 函数,而之前说过,如果在索引列上有函数操作的话,可能会破坏索引树的有序性,从而 mysql 不使用索引改用全表扫描</p><p>同样的,如果在做关联查询的时候,两个连接的字段的字符编码不相同,也会触发隐式类型转换,从而导致索引失效</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>如果存在联合索引,则查询列里面的索引必须从最左侧开始且不允许跳过中间的索引列</p><p>例如存在联合索引 <code>a,b,c</code> ,如下 sql 语句属于 <strong>全值匹配</strong> 可以命中索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>这里跟查询列的顺序无关,只要在逻辑上满足索引列从左到右的匹配顺序即可,myslq 优化器会在内部自动调整索引的顺序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>非全值匹配</strong> 只要满足从左到右的前缀即可</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>但是不能出现缺少或者跳过,这样会导致最左前缀原则失效,从而导致索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 从左往右缺少 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <br><span class="hljs-comment">-- 跳过 b</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>同样对于模糊查找也必须满足最左前缀原则</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 模糊检索最左前缀 a 是确定的,后面 % 才是通配符,符合最左前缀原则,可以命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;a%&#x27;</span><br><br><span class="hljs-comment">-- 最左前缀 % 是通配符,属于不确定的,破坏了最左前缀原则,不能命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;%a&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="使用-OR-关键字"><a href="#使用-OR-关键字" class="headerlink" title="使用 OR 关键字"></a>使用 OR 关键字</h3><p>例如只有列 <code>a</code> 有索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>此时会导致索引失效,假设只有 <code>where b = 2</code> 此时肯定是全表扫描,已经得到 <code>a,b</code> 的值,就不用再遍历 <code>a</code> 的索引了; 否则使用 <code>a</code> 的索引后还需要一次全表扫描才能判断 <code>b</code> 的条件</p><p>使用 <code>or</code> 关键字的时候,必须保证两边都有索引才可以</p><h3 id="负向查询"><a href="#负向查询" class="headerlink" title="负向查询"></a>负向查询</h3><p>常见的负向查询有 <code>NOT, IS NOT NULL, !=, NOT IN, NOT LIKE</code> 等</p><p>这些查询不一定会导致索引失效,mysql 在实际执行的过程当中,根据优化器的判断决定是否选择索引,亦或者是全表扫描</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(九)mysql order by 原理细节</title>
    <link href="/2022/11/05/mysql/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/"/>
    <url>/2022/11/05/mysql/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<h2 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h2><p>假设有一张城市表,记录了城市里面每个人的名字,你年龄的信息</p><p>现在需要对城市是 <code>杭州</code> 的所有人,按照年龄排序后返回前 1000 人</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> city,name,age <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> city<span class="hljs-operator">=</span><span class="hljs-string">&#x27;杭州&#x27;</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> name limit <span class="hljs-number">999</span>;<br></code></pre></td></tr></table></figure><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>为了避免扫描全表,很自然的在 <code>where</code> 语句查询的字段 <code>city</code> 上加上索引</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsbrl2wj30th0fbjuw.jpg" alt="img.png"></p><p>使用 <code>explain</code> 指令查看执行情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsiczttj31bh041jxx.jpg" alt="img_1.png"></p><p>在 <code>extra</code> 一列里面可以看到 <code>using filesort</code> 表示进行了排序,实际 mysql 会为每个需要排序的线程分配一块内存区域专门用来加速排序,称为 <code>sort_buffer</code></p><p>一个完整的查询流程如下:</p><ol><li>初始化 <code>sort_buffer</code> ,里面有 3 个字段分别是 <code>city,name,age</code> </li><li>从 <code>city</code> 索引开始查找,找到第一个满足条件的主键 id ,即 <code>id_x</code></li><li>回表得到 <code>id_x</code> 对应的完整数据,取出 <code>name,age</code> 和 <code>city</code> 一起放入 <code>sort_buffer</code></li><li>从 <code>city</code> 索引继续取出下一个满足条件的主键 id,重复 34 过程,直到 <code>city</code> 不再满足条件</li><li>对 <code>sort_buffer</code> 里面的所有数据做快速排序</li><li>将排序结果前 1000 条返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsnhzo9j30m60gbtd4.jpg" alt="img_2.png"></p><p>需要注意的是,由于每次分配的 <code>sourt_buffer</code> 大小是固定的,其不一定能够完全放下所有需要排序的记录; 所以 mysql 会根据实际情况,在内存中完成排序,或者在磁盘上完成排序; 如果在磁盘上进行排序,就不得不依赖磁盘创建临时文件辅助排序</p><p>打开 msyql 的 <code>optimizer_trace</code> 查看优化器的输出</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt1fzvoj30mt05twgy.jpg" alt="img_3.png"></p><p>可以看到在磁盘排序时,使用了 12 个临时文件,这是因为在磁盘上排序一般使用 <strong>归并排序</strong> ,将整个数据集分为若干个子文件,对子文件进行排序后再合并为一个有序的大文件</p><h3 id="rowid-排序"><a href="#rowid-排序" class="headerlink" title="rowid 排序"></a>rowid 排序</h3><p>上面的全字段排序会将所有需要排序的字段取出放到 <code>sort_buffer</code> 里面,如果字段多,数据行多的话,就会导致 <code>sort_buffer</code> 里面要保存的数据太多,由于内存是有限制的,所以很快 <code>sort_buffer</code> 就会被占满,这样就需要把数据分散到多个临时文件里面做归并排序,其性能会差很多</p><p>可以通过修改 mysql 控制排序数据行长度的参数,让 myslq 选择另一种排序方式 <code>rowid</code> 排序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> max_length_for_sort_date<span class="hljs-operator">=</span><span class="hljs-number">16</span><br></code></pre></td></tr></table></figure><p>如果单行总长度超过这个值,就该用 <code>rowid</code> 排序</p><p><code>rowid</code> 排序不把单行所有字段放入 <code>sort_buffer</code> 里面,仅仅把主键 id 和需要排序的列放入 <code>sort_buffer</code>, 由于 <code>sort_buffer</code> 里面缺少了单行的所有信息,所以不能够在完成排序后直接返回,需要多添加一步回表查询的过程</p><p>当 <code>sort_buffer</code> 完成排序后,遍历前 1000 条记录,通过主键 id 再次回表查询得到所有的数据行返回</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugst18g8j30n10hhtf6.jpg" alt="img_4.png"></p><h3 id="全字段排序和-rowid-排序"><a href="#全字段排序和-rowid-排序" class="headerlink" title="全字段排序和 rowid 排序"></a>全字段排序和 rowid 排序</h3><p>如果 mysql 检测到内存足够,就会使用全字段排序,因为这样能够节省一次回表的查询开销</p><p>如果内存不足,则会改用 <code>rowid</code> 排序,这样可以提高一次性排序的行数,但是对应的代价就是多了一次回表查询</p><p>总的来说,mysql 体现了一个原则就是: 内存够用就要尽可能利用内存,减少磁盘的访问</p><h3 id="使用索引覆盖来加速排序过程"><a href="#使用索引覆盖来加速排序过程" class="headerlink" title="使用索引覆盖来加速排序过程"></a>使用索引覆盖来加速排序过程</h3><p>如果查询的列天然有序,则可以进一步提高 <code>order by</code> 语句的效率</p><p>对于仍然是查询 <code>city</code>, <code>name</code>, <code>age</code> 的 sql,如果在 <code>city</code> 和 <code>name</code> 上建立联合索引</p><p>这样 <code>where</code> 语句使用 <code>city</code> 索引检索的时候, <code>name</code> 也是自然有序的,这样可以节省排序的步骤,只需要一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt8teb7j30lq08xacf.jpg" alt="img_5.png"></p><p>如果在 <code>city</code>, <code>name</code>, <code>age</code> 三个字段上建立联合索引,这样检索的时候,索引树里面就已经全部包含了所有需要查询的数据,而且自然有序,这样的索引覆盖还能再减少一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugtf3quvj30he09cmyt.jpg" alt="img_6.png"></p><h3 id="随机排序"><a href="#随机排序" class="headerlink" title="随机排序"></a>随机排序</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand()<br></code></pre></td></tr></table></figure><p>当添加上 <code>rand()</code> 随机函数之后,如果再使用 <code>explain</code> 查看执行过程的话,会发现 <code>extra</code> 列上多了个 <code>using temporary</code> 表示当前查询会使用 <strong>临时表</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsdqh5nj307w01yq3k.jpg" alt="img_7.png"></p><p>对于带有临时内存表的排序,mysql 应当选择何种排序算法:</p><ol><li>如果是 <code>InnoDB</code> 为了减少磁盘访问,优先选择全字段排序</li><li>如果是带有临时内存表的排序,回表相当于访问内存,其性能几乎不会受到影响,此时会选择 <code>rowid</code> 排序</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> word <span class="hljs-keyword">from</span> t <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand() limit3<br></code></pre></td></tr></table></figure><p>其排序的查询过程如下:</p><ol><li>创建一张临时内存表,表里面保存两个字段 浮点数 <code>R</code> 和 字符串 <code>W</code></li><li>从主表中按照主键顺序取出 <code>word</code>,并且调用 <code>rand()</code> 函数生成一个随机浮点数,将这个随机浮点数和 <code>word</code> 放入内存表的 <code>R</code> 和 <code>W</code> 字段</li><li>在内存表上排序,初始化 <code>sort_buffer</code>, 其包含两个字段 浮点数和字符串</li><li>从内存表中一行一行地取出 <code>R</code> 和 <code>位置信息</code> 将其放入 <code>sort_buffer</code>,然后在 <code>sort_buffer</code> 里面完成排序</li><li>排序完成后,取前 3 个数据返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhskxbg6j30o30hrjvf.jpg" alt="img_8.png"></p><p>其中内存表的 <code>内存信息</code> 就是 mysql 为我们隐式生成的 <code>rowid</code>, 其实如果一张表没有显式指出主键的话,mysql 就会隐式的创建 <code>rowid</code> 当做主键 id 使用</p><p>如果单行数据超过了 mysql 配置的最大单行数据长度,则全字段排序会被转换为 <code>rowid</code> 排序,会导致在磁盘上通过临时文件进行归并排序</p><p>对于 <strong>随机排序</strong> 且还带有 <code>limit</code> 关键字的情况,归并排序完成后所有的数据都是有序的,此时只用取前 <code>limit</code> 个,但是实际上除了前 <code>limit</code> 个以外的数据,并不关系其是否有序,所以 mysql 在 5.6 版本引入了 <code>堆排序</code> </p><p>构造最大堆或者最小堆,初始化容量为 <code>limit</code> 个元素,将后续的元素依次添加到堆里,完成遍历后,堆里就保留了 <strong>最大</strong> 或者 <strong>最小</strong> 的前 <code>limit</code> 个元素,而后面的则无需关心是否有序</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsquhy8j30o00dqagy.jpg" alt="img_9.png"></p><p>无论如何,使用 <code>order by rand()</code> 都会导致复杂的排序计算</p><p>优雅的随机排序应当使用如下操作</p><ol><li>统计表的总行数 <code>C</code></li><li>计算随机数 <code>R = floor(C*rand())</code> 其中 <code>floor()</code> 函数负责向下取整</li><li><code>select xxxx limit Y,1</code> 表示从 <code>Y</code> 开始取出 <code>offer = </code> 即 <code>Y+1</code> 行</li></ol><p>若要得到 <code>X</code> 个随机记录,则将上述操作重复 <code>X</code> 次,这样可以避免主键空洞导致的伪随机</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(八)mysql count 函数机制</title>
    <link href="/2022/11/05/mysql/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/mysql/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="count-的实现原理"><a href="#count-的实现原理" class="headerlink" title="count(*) 的实现原理"></a>count(*) 的实现原理</h3><ol><li>在 <code>Myisam</code> 上,每个表的总行数保存在了磁盘上,因此 <code>count(*)</code> 可以在 O(1) 的时间复杂度之内得到,效率非常高</li><li>在 <code>InnoDB</code> 上,不会单独保存表的总行数,因此只能通过遍历所有数据,完成统计得到</li></ol><p>为什么 <code>InnoDB</code> 不保存总记录数,因为 <code>MVCC</code> 多版本并发控制导致,即使每次执行 <code>count(*)</code> 语句时,快照读返回的行数都不一定是准确的</p><p>例如事务 A 快照读的时候得到行数 10000,在这个过程中事务 B 插入了 1 行,因为快照读的原因事务 A 并不能观察到这 1 行,所以返回的行数并不准确</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubro5pldj30ne08yjuu.jpg" alt="img.png"></p><p>具体 mysql 是怎么实现 <code>count(*)</code> 的计算过程呢</p><p>由于只能一行一行地遍历所有数据,那么就需要从索引树的叶子节点的链表开始遍历; 前面说过,聚簇索引的叶子节点保存的是 <code>主键 id 和完整数据行</code>; 而非聚簇索引的叶子节点保存的是 <code>索引列和主键 id</code>; 这样对于相同大小的页,后者能够放下更多的节点</p><p>因此 myslq 实际上在做 <code>count(*)</code> 的时候,会选择最小的索引树进行遍历,加快遍历的速度</p><h3 id="使用缓存系统保存总数"><a href="#使用缓存系统保存总数" class="headerlink" title="使用缓存系统保存总数"></a>使用缓存系统保存总数</h3><p>如果有个业务需要频繁的访问表的总记录数,而数据又非常多,那么 <code>count(*)</code> 势必导致性能问题</p><p>考虑设计一个缓存系统来保存总数,每次增删记录的时候,同时更新缓存里面的总数</p><p>实际上并不能通过 redis 来完成这个缓存系统,因为总是存在数据不一致,有点类似幻读的感觉,例如下面两个例子</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubru7q69j30nc08yaay.jpg" alt="img_1.png"></p><p>实际上会话 B 在查询最近 100 条记录的时候,会把会话 A 插入的新数据查询出来,但是会话 B 访问 redis 的时候总计数却不包含这一条,因为此时会话 A 还没来得及更新 redis</p><p>如果反过来</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubrzdpldj30n809pt9j.jpg" alt="img_2.png"></p><p>会导致会话 B 从 redis 里面已经得到的总数已经新增了一条,但是最近 100 条记录里面却不包含这新增的一条,再次发生数据不一致的问题</p><p>这些都是因为缓存系统无法完全保证数据实时一致性,考虑使用数据库当做缓存系统使用</p><p>将对 redis 的操作更换为数据库操作,同时为其加上事务</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubs4hin0j30n50ci0ts.jpg" alt="img_3.png"></p><p>根据 <code>MVCC</code> 会话 B 读到的总数并不包含会话 A 新增的总数,而且前 100 条记录也不包含回话 A 新增的数据; 这是由 <code>MVCC</code> 的快照读保证的一致性</p><h3 id="不同的-count-函数使用方式"><a href="#不同的-count-函数使用方式" class="headerlink" title="不同的 count 函数使用方式"></a>不同的 count 函数使用方式</h3><p>不仅仅有 <code>count(*)</code> 能够统计行数,还有 <code>count(1)</code>, <code>count(主键)</code>, <code>count(字段)</code> 等等</p><p>其原理都差不多,<code>count()</code> 本身是一个聚合函数,起作用就是对于返回的结果集进行遍历,如果参数不是 <code>NULL</code> 就将结果值+1,所以上面那么多不同的 <code>count()</code> 操作,其本质就是在计算返回的结果集对应的参数不是 <code>NULL</code> 的总数</p><p>记住以下原则 <code>Server</code> 层要什么,存储引擎就给什么</p><ul><li><code>count(主键)</code> 存储引擎遍历整张表,把每一行的主键 <code>id</code> 取出来返回给 <code>Server</code> 层将,然后 <code>Server</code> 判断是否为 <code>NULL</code> 并计数</li><li><code>count(1)</code> 存储引擎遍历整张表,但是不取具体值,而是对每一行返回一个 1,由 <code>Server</code> 层判断是否为 <code>NULL</code> 并计数</li><li><code>count(字段)</code> 如果这个字段定义为 <code>NOT NULL</code> 非空的话,原理同 <code>count(主键)</code>; 如果定义允许 <code>NULL</code>,则需要对每一行判断是否为 <code>NULL</code> 后计数</li><li><code>count(*)</code> 优化器做了专门的优化,不会取所有值</li></ul><p>从性能层面来说 : <code>count(*) ≈ count(1) &gt; count(主键) &gt; count(字段)</code></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(七)mysql 表空间回收</title>
    <link href="/2022/11/05/mysql/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/"/>
    <url>/2022/11/05/mysql/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="表空间的存储设置"><a href="#表空间的存储设置" class="headerlink" title="表空间的存储设置"></a>表空间的存储设置</h3><p>首先有个设置 <code>innodb_file_per_table</code> 表示是否把表数据存储为单个文件,否则的话就放在共享表空间里</p><p>明确一点,单独存放为一个文件更好,因为这样更便于管理; 而且 <code>drop</code> 命令执行时会删除对应的表文件,如果放在共享空间里, <code>drop</code> 命令不会回收表空间</p><h3 id="delete-语句为何不会回收表空间"><a href="#delete-语句为何不会回收表空间" class="headerlink" title="delete 语句为何不会回收表空间"></a>delete 语句为何不会回收表空间</h3><p><strong>可以结合前面讲的索引复习</strong>, 都知道 mysql 的索引是用 <code>B+</code> 树实现的,由于 <code>B+</code> 树也是一种自平衡的树,所以在对某些索引进行删除或者插入的时候,由于单个节点存储的索引有限,势必会导致单个节点的分裂或者多个节点的重组</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatmc03pj30ex0bjjt2.jpg" alt="img.png"></p><p>假设需要删除 <code>R4</code> 这条记录,此时并不会实际操作磁盘,而是把页里面的 <code>R4</code> 标记为删除,这是一种 <strong>软删除</strong> 或者叫做 <strong>逻辑删除</strong></p><p>后面如果插入 <code>300</code> 到 <code>600</code> 的记录,是完全可以继续复用这个位置的</p><p>同理当插入一条记录的时候,如果此时页里面已经放满了数据,就会导致当前节点分裂为多个节点,将原先的页按照一定规则重新放到多个节点上</p><p>这里需要注意一点:</p><p>记录的删除仅仅是在页里面将当前数据的位置标记为可复用,而页的删除则是将里面所有的数据标记为可复用</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uattc0hej30oc0fjdk8.jpg" alt="img_1.png"></p><p>例如插入 <code>550</code> 的记录,此时由于页里面已经放满了索引此时需要把原来的页 A 一部分索引数据拆分到一个新的页 B 里面去;这里的拆分和重组由 <code>B+</code> 树的插入和删除性质计算的到</p><p>此时会导致原来完整的 A 出现了 <strong>数据空洞</strong>, 同时新页 B 也产生了 <strong>数据空洞</strong> ; 当一张表经过大量的增删改操作之后,很有可能存在不少的 <strong>数据空洞</strong> </p><p>总结来说,<code>delete</code> 语句仅仅是将页里面的记录位置标记为可以复用,而不是真正的删除页释放空间; 所以执行 <code>delete</code> 语句是无法回收表空间的</p><h3 id="重建表解决表空间空洞的问题"><a href="#重建表解决表空间空洞的问题" class="headerlink" title="重建表解决表空间空洞的问题"></a>重建表解决表空间空洞的问题</h3><p>利用 AB 表的思想,创建一张结构与 A 表相同的 B 表,依次扫描 A 表并顺序插入在 B 表当中, 这样处理过后 B 表的主键就是紧凑没有数据空洞的,数据页的利用率也更高; 操作完成后把流量切到 B 表,然后再删除 A 表即可</p><p>或者直接用 myslq 提供的指令 <code>alter table A engin = InnoDB</code> 进行表的重建</p><p>重建过程当中,如果有新数据写入旧表的话,是不会同步到新表的,此时会导致数据丢失,更新也一样; 所以整个重建过程,必须保证旧表处于只读状态</p><p>如果说保持表 A 的只读状态,那么此时的 <code>DDL</code> 操作就不是 <code>Online</code> 的</p><p>在 mysql 5.6 开始引入 <code>Online DDL</code> ,即重建过程当中,也支持对表 A 的写操作</p><p>基本原理如下:</p><ol><li>扫描表 A 的所有数据页,重新生成对应的 B+ 树,存储到临时文件当中</li><li>生成临时文件的过程中,如果有对表 A 的写操作,则记录在 <code>row log</code> 的日志文件当中</li><li>临时文件生成后,与 <code>row log</code> 的记录进行 <code>merge</code> 操作,得到最终的临时文件</li><li>将最终的临时文件应用到表 A 上</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatzz998j30o70ehdmc.jpg" alt="img_2.png"></p><p>前面说过表级锁有表锁和 <code>MDL</code> 锁,其中 <code>MDL</code> 写锁就是为了防止在查询过程当中表结构发生变化</p><p>而此时的 <code>DDL</code> 重建表操作就会申请到 <code>MDL</code> 写锁,按照其定义,后续对表 A 的读写请求应该都被阻塞了才对</p><p>其实实际重建表的过程当中,这里的 <code>MDL</code> 写锁在 <code>alter</code> 语句开始执行后,真正拷贝数据之前就已经退化成 <code>MDL</code> 读锁了,这样做重建的时候不会阻塞其他的增删改查操作</p><p>此时也不能直接释放 <code>MDL</code> 锁,这样是为了保护不受其他后面的 <code>DDL</code> 影响</p><p>在整个重建过程中,最耗时的是数据拷贝到临时表的过程,这里退化成读锁也不会阻塞其他正常请求,而到了真正需要拷贝数据的时候,相对于整个过程, <code>MDL</code> 写锁的持有过程相对来说并不长,可以近似认为是 <code>Online</code> 的</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(六)mysql 刷盘机制</title>
    <link href="/2022/11/05/mysql/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/mysql/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="mysql-的抖动"><a href="#mysql-的抖动" class="headerlink" title="mysql 的抖动"></a>mysql 的抖动</h3><p>在日常工作当中,监控 mysql 的 cpu 状况一般可以发现几个特征</p><ol><li>随着流量高峰导致的使用率上升,这种随着业务的频繁访问而上升,随着业务冷却的下降,属于正常波动</li><li>在平滑的曲线当中,经常会出现 <code>突刺</code> 般的抖动</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37pk9brj30me05s3yx.jpg" alt="img.png"></p><p>这种短暂的 <code>突刺</code> 抖动,一般情况都是因为 mysql 在做 <strong>刷盘</strong> 操作引起的</p><h3 id="结合日志系统理解刷盘"><a href="#结合日志系统理解刷盘" class="headerlink" title="结合日志系统理解刷盘"></a>结合日志系统理解刷盘</h3><p>对于前面提到的 mysql 的日志系统,以 <code>redo log</code> 为例,前面介绍过分为两个部分 <code>redo log buffer</code> 和 <code>redo log file</code></p><p><code>buffer</code> 保存在内存里, <code>file</code> 保存在磁盘上,这也是为了平衡内存和磁盘访问速率不统一的问题</p><p>但是保存在内存里的数据终究是不可靠的,会随着断电而丢失,所以必须在适当的时机将内存里的数据写入磁盘完成持久化操作,保证数据的安全</p><h4 id="脏页和干净页"><a href="#脏页和干净页" class="headerlink" title="脏页和干净页"></a>脏页和干净页</h4><p>当内存里面的数据页和磁盘里面的对应数据页内容不一致的时候,这个内存页就被称为 <code>脏页</code></p><p>反之若保持一致,则称内存页为 <code>干净页</code></p><p>回顾一下之前的数据写入过程,首先记录 <code>redo log</code> 这是由 mysql 写前日志的特性保证,然后将改动在 <code>buffer pool</code> 里面写入,这里可以结合缓存相关的东西一起复习,最后 mysql<br>找一个合适的时机,将 <code>redo log</code> 里面记录的操作写入磁盘完成持久化</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37w4jo6j30mt0d976q.jpg" alt="img_1.png"></p><h3 id="什么时候触发刷盘操作"><a href="#什么时候触发刷盘操作" class="headerlink" title="什么时候触发刷盘操作"></a>什么时候触发刷盘操作</h3><ol><li>当 <code>redo log</code> 的 <code>write_pos</code> 已经追上 <code>check_point</code> 的时候,表明 <code>redo log</code> 已经写满了无法再继续写入新数据,此时整个数据库的写操作都将被阻塞,必须要将 <code>check_point</code> 后面的数据刷入磁盘,以腾出空间让 <code>redo log</code> 恢复继续写入</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u38318laj30gb0fkace.jpg" alt="img_2.png"></p><p>当 <code>check_point</code> 的位置从 <code>cp</code> 推进到 <code>cp&#39;</code> 的时候,就必须把这个区间内的所有的日志(浅绿色部分)都刷入磁盘,当完成刷盘操作后,<code>check_point</code>的位置推进到 <code>cp&#39;</code> 这样就空出来新的位置给 <code>write_pos</code> 继续推进</p><ol start="2"><li>当缓冲池内存不足的时候,此时就必须要淘汰掉里面的部分数据页(对应可以结合 mysql 的缓存机制复习),如果从 <code>LRU</code> 里面淘汰的是干净页那还好说,直接移出 <code>LRU</code> 即可; 如果淘汰的是脏页,就必须要刷盘</li></ol><p>为何不考虑直接丢弃脏页,下次从磁盘读取旧的内存页,然后和 <code>redo log</code> 里面的操作结合返回呢</p><p>从性能角度上来说, 这里的 <code>merge</code> 操作对于读取页来说相对复杂了</p><p>而且刷盘能够保证一致性:</p><ul><li>若内存页里有数据,无论是脏页还是干净页,一定是最新的正确数据,命中缓存后直接返回</li><li>若内存页里没有数据,那么磁盘里面的一定是正确数据,从磁盘读入内存后直接返回即可,也不需要额外的 <code>merge</code> 操作</li></ul><ol start="3"><li><p>当 mysql 检测到系统负载不高的时候,也会进行刷盘操作; 即使系统的负载很高,也要见缝插针的刷脏页,避免造成内存不够或者 <code>redo log</code> 写满的情况发生(这个频率是每秒 1 次)</p></li><li><p>最后,当 mysql 需要停机的时候,关闭 mysql 进程之前,会将内存里面的所有脏页一次性全部刷入磁盘,避免内存里面的数据丢失</p></li></ol><h3 id="着重考虑下第-2-点的刷盘情况"><a href="#着重考虑下第-2-点的刷盘情况" class="headerlink" title="着重考虑下第 2 点的刷盘情况"></a>着重考虑下第 2 点的刷盘情况</h3><p>结合之前的缓存技术一起复习,当需要访问数据的时候,先检查缓存池里是否已有对应的页,若命中缓存则快速返回; 否则从磁盘里面读取对应的内存页</p><p>如果此时缓存池还没有写满,那么直接放入 <code>LRU</code> 即可</p><p>如果缓存池已经写满,就需要根据 <code>LRU</code> 淘汰页; 淘汰的是脏页,必须刷盘; 淘汰的是干净页,无需刷盘</p><p>mysql 通过两个参数来控制刷脏页的速率</p><ol><li>当前 <code>buffer pool</code> 里面的脏页比例 M</li><li>当前 <code>redo log</code> 的写盘速度 N</li></ol><p>简单来说就是取 <code>R = max(M, N)</code>,然后 mysql 就以 <code>R% * 磁盘写入能力</code> 的速率刷新脏页</p><h3 id="连坐刷新"><a href="#连坐刷新" class="headerlink" title="连坐刷新"></a>连坐刷新</h3><p>若一次请求需要刷新一个脏页,根据局部性原理,mysql 会判断当前页旁边的数据页是否也是脏页,如果也是脏页,就一起刷新掉; 而且这个判断机制会蔓延下去,也就是说如果邻居是脏页,还要继续判断邻居的邻居</p><p>这样最终可能导致一次简单的请求,原本刷新一个脏页就可完成,最后刷新的大批量的脏页,反而拖慢了整体查询的性能</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(五)mysql 锁</title>
    <link href="/2022/11/04/mysql/(%E4%BA%94)mysql%20%E9%94%81/"/>
    <url>/2022/11/04/mysql/(%E4%BA%94)mysql%20%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>锁是用来保证事务并发,数据安全的一种手段</p><p>mysql 有三种类型(注意:是 <strong>三种类型</strong> 而非 <strong>三种</strong>):</p><ol><li>全局锁</li><li>表级锁</li><li>行级锁</li></ol><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>全局锁就是对 <strong>整个数据库实例</strong> 加锁,在此期间,整个数据库处于 <strong>只读</strong> 状态,除了读其他所有操作都会被拒绝</p><p>全局锁的作用几乎都是用来做 <strong>整库备份</strong>, 如果在做整库备份的时候,没有加上全局锁,这个时候表仍然可以写,就会出现备份前后数据不一致的情况</p><p>在事务里面,mysql 通过 <code>MVCC</code> 多版本并发控制来保证事务的隔离性,用到的数据结构是 <code>视图</code>,这个视图保证了在启动事务的时候,是处于一个 <strong>静止状态的逻辑时间点</strong></p><p>参考事务,在做全局备份的时候,也生成一张视图,这样后续的读写请求都不会因为全局锁而阻塞; 既然有视图的存在,为何备份的时候还需要全局锁呢</p><p>考虑到有些存储引擎, 例如 <code>Myisam</code>, 它不支持事务; 这样在备份的时候仍然能取到最新的数据,破坏了数据的一致性</p><p>还有一种方式也能够实现类似于 <strong>全局锁</strong> 的能力,那就是 <strong>将数据库设置为只读状态</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span> readonly <span class="hljs-operator">=</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>但是仍然不建议使用将数据库设置为只读状态来进行整库备份</p><ol><li>客户端连接数据库实例后,加上全局锁进行备份,如果中间发生异常导致客户端断开连接,这个时候数据库也能将全局锁自动恢复,以保证数据库实例能够继续对外提供服务</li><li>如果是通过设置只读的状态,如果连接在中途断开后,数据库是不会从只读状态中恢复的,此时会导致整个数据库对外停止服务</li><li>有些数据库框架可能会用 <code>readonly</code> 字段做业务逻辑,例如判断是否是主库,是否是从库; 改变这个值可能会引起主从判断的逻辑</li></ol><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>表级锁有两种:</p><ol><li>表锁</li><li>元数据锁</li></ol><h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>表锁的使用限制非常严格,例如</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">lock tables t1 read, t2 write<br></code></pre></td></tr></table></figure><p>如果线程 A 在某个时刻执行上述语句后, 其他线程写 t1 ,读写 t2 的请求都会被阻塞,这个很好理解</p><p>但是对于线程 A 来说,就更加严格,它只能够读取 t1,连写 t1 都不行; 对于 t2 来说,线程 A 能够读写; 而且线程 A 也不能访问其他表</p><h4 id="MDL-元数据锁"><a href="#MDL-元数据锁" class="headerlink" title="MDL 元数据锁"></a>MDL 元数据锁</h4><p><code>MDL</code> 锁是不需要显式声明的,在访问一张表的时候,数据库会自动为这张表加上 <code>MDL</code> 锁</p><p>简单来说, <code>MDL</code> 锁是为了保障表结构的完整性不受到影响</p><p>例如当一个线程正在查询表 A 里面的 c1,c2,c3 三列数据列,此时另外一个线程却对表 A 执行了一条 <code>alter</code> 语句,结果是删掉了 c3 列</p><p>这就导致原来的线程在获取道德数据跟原来的表结构不一致了</p><p>mysql 引入了 <code>MDL</code> 锁,分为 <code>MDL</code>读和写两种子类型:</p><ul><li>读锁之间互不影响,也就是说对于同一张表, 每个线程都可以持有对应的 <code>MDL</code> 读锁,所以每个线程之间的读请求互不受到影响</li><li>写锁之间和读写锁之间互斥, 一旦有一个线程正在修改表结构,此时其他所有的读请求和写请求都会被阻塞掉,只有等待写锁释放后,才能进行后面的操作</li></ul><p>介绍一个由 <code>MDL</code> 锁导致的故障问题,假设有如下 4 个会话执行顺序如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgl1480lj30j30bvdih.jpg" alt="img.png"></p><p>会话 A,B 分别执行查询语句,申请 <code>MDL</code> 读锁,这没问题; 会话 C 执行 <code>alert</code> 语句申请 <code>MDL</code> 写锁,此时阻塞</p><p>问题来了,如果仅仅是会话 C 阻塞还好,可如果后面还有其他请求进来访问表,都会被会话 C 阻塞掉</p><p>为什么说会话 C 申请写锁被阻塞之后,还会继续阻塞其他读写锁的申请呢</p><p>mysql 在内部使用 <strong>优先队列</strong> 来维护所有的 <code>MDL</code> 锁申请,而且,而且 <strong>写锁的申请优先级高于读锁</strong></p><p>这就解释了为什么会话 C 的写锁申请阻塞,会导致后续的读写锁申请都被阻塞: <strong>因为有一个高优先级的申请在前面,所以队列后面的请求只能一直等待即使有相同的优先级</strong></p><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><p><code>MDL</code> 锁是有 <code>Server</code> 层提供的能力,而行级锁是由存储引擎提供的能力,有些例如 <code>Myisa</code> 就不支持行级锁</p><h4 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h4><p><strong>先说结论: 在 InnoDB 事务当中,行锁是在需要的时候才加上,而要等到事务提交后才释放锁, 这个叫做两阶段锁协议</strong></p><p>起作用就是,当事务需要持有多把锁时,要尽可能把最可能影响并发度的锁放到后面</p><p>举个简单的例子:</p><ol><li>客户使用账户 A 购买商家的东西,要在账户 A 上扣款</li><li>商家使用账户 B 进行收款</li><li>商家记录一笔交易记录</li></ol><p>可以看到上面的三步操作肯定是在一个事务里面执行,其中 1,2 分别是 <code>update</code> 操作,3 是 <code>insert</code> 操作,且 3 和 1,2 之前没有先后依赖关系</p><p>如果这个时候有另外一个客户也在商家这里购买东西,那么这也是 <code>update</code> 操作,且和前面的 1,2 步骤 <code>update</code> 的是同一个账户</p><p>为了使都操作账户 B 带来的并发等待最小,第一个客户应当对步骤进行重新排序,例如 3,1,2 这样把存在锁竞争的步骤 2 放到了最后面,这样第一个客户持有账户 B 的锁时间被降低到了最短,尽可能地降低锁导致的并发问题的影响</p><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>什么是死锁: 当并发系统中几个线程出现 <strong>循环等待</strong> 资源,涉及到的线程都在等待别人释放自己需要的资源,且 <strong>一直等待</strong> 下去的现象,称为死锁</p><p>死锁发生的 3 个必要条件:</p><ol><li>互斥条件:一个资源只能被一个线程使用,其他线程只能等待释放</li><li>请求和保持:一个线程请求其他互斥资源时,不会释放自己手里的资源</li><li>不可抢占:线程不能强行从其他线程那里获取自己需要的资源,只能等待其释放</li><li>循环等待:存在循环链,使得每个线程都在等待别人释放自己需要的资源</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgkpg18ij30jh0c6juh.jpg" alt="img_1.png"></p><p>可以看到事务 A 启动后申请对 id&#x3D;1 的资源的锁,事务 B 启动后申请对 id&#x3D;2 的资源的锁</p><p>然后事务 A 申请 id&#x3D;2 的锁,发现被事务 B 持有,此时事务 A 阻塞等待事务 B 释放 id&#x3D;2 的锁</p><p>接着事务 B 申请 id&#x3D;1 的锁,发现被事务 A 持有,此时事务 B 阻塞等待事务 A 释放 id&#x3D;1 的锁</p><p>这样两个事务都在等待对方释放自己的资源,进入死锁状态</p><h4 id="mysql-如何解决死锁"><a href="#mysql-如何解决死锁" class="headerlink" title="mysql 如何解决死锁"></a>mysql 如何解决死锁</h4><ol><li>超时等待</li></ol><p>mysql 有个超时等待时间,默认值为 50s,意味着一个线程进入等待后 50s 没有拿到资源,就放弃等待</p><p>50s 的等待时长一般难以接受,太小的话容易误伤正常的锁等待,所以这个策略很少使用</p><ol start="2"><li>主动死锁检测</li></ol><p>当一个事务发生等待时,会主动检测事务所依赖的所有线程是否有被其他线程锁住,以此循环下去最后判断是否出现了死锁</p><p>主动死锁检测虽然可以发现死锁,但是也存在性能问题</p><p>假如有 100 个线程同时更新 1 个资源,第一个拿到锁的线程开始处理,后面每个进来的新线程都要等待第一个线程释放锁,每个线程都要做一次死锁检测,而每次都会循环检查其他的线程,相当于最后产生了 10000 次死锁检查</p><p>最终的检测结果是没有发生死锁,但是这个过程却是相当耗费 cpu 资源的</p><h4 id="如何减少主动死锁检测带来的-cpu-性能消耗问题"><a href="#如何减少主动死锁检测带来的-cpu-性能消耗问题" class="headerlink" title="如何减少主动死锁检测带来的 cpu 性能消耗问题"></a>如何减少主动死锁检测带来的 cpu 性能消耗问题</h4><p>对于这种 <strong>热点数据</strong> 的并发更新,死锁检测往往会占用大量的 cpu 资源</p><ol><li>从源头上控制,假如能够限制客户端的并发,例如一个客户端发起 5 个链接,那么死锁检测的成本就很低能够接受</li></ol><p>但是难以避免出现大量客户端发起连接更新热点数据,即使单个客户端的并发数很小,但是客户端数量过多仍然会导致死锁检测耗费大量 cpu 资源</p><ol start="2"><li>在业务上做出拆分,将原来一整块的并发资源,拆分为多个子集</li></ol><p>例如原来的一个账户,拆分为 100 个账户的总和,每次更新总账户的时候,实际上是随机更新一个子账户</p><p>这样可以将一个资源面临的大量访问均分到多个资源上,减少单个资源的并发度,降低死锁检测的 cpu 消耗</p><p>但是这样要考虑如何汇总零散的资源,以及单个资源的上出现的特殊情况,这样的做法会导致业务的复杂程度变高</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(四)mysql 的各种缓存技术</title>
    <link href="/2022/11/03/mysql/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/"/>
    <url>/2022/11/03/mysql/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="预读-局部性原理"><a href="#预读-局部性原理" class="headerlink" title="预读 局部性原理"></a>预读 局部性原理</h3><p>操作系统有个很经典的理论,叫做 <strong>局部性原理</strong> ,意思就是说如果使用了一些数据,那么大概率接下来还会使用这些数据附近的其他数据</p><p>同时,磁盘的读写并不是按需读取,也就是说并不是需要什么数据就读取什么数据; 而是按照一定大小的页,一次性读取到内存当中,通常这个页的大小默认为 <code>4K</code></p><p>因为根据局部性原理,访问了数据 x 之后,大概率还会访问 x 附近的其他数据; 而如果是按需读取的话,在访问 x 之后,继续访问 y 和 z 又要进行磁盘操作,这无疑增大了 io 的消耗</p><p>对于按页读取 ,可以一次性将 x 所在的那一页都放到内存里,这样以后再访问 y 或者 z,就可以直接从内存里读取,无需磁盘操作</p><p>可能有疑问就是,如果 x 正好在当前页的最后一条记录,那么访问 y 或者 z 必然要再读取下一页; 实际上这种情况发生的概率非常小,即使如此,再读取下一页也比每次都访问磁盘的效率高得多,是值得接受的必要 io 消耗</p><p>mysql 为了利用磁盘按页读取的能力,在其内存缓存池里面,也是按照页为单位来加载磁盘上的数据</p><h3 id="mysql-如何管理缓存-读缓存-buffer-pool"><a href="#mysql-如何管理缓存-读缓存-buffer-pool" class="headerlink" title="mysql 如何管理缓存 读缓存(buffer pool)"></a>mysql 如何管理缓存 读缓存(buffer pool)</h3><p>管理缓存有个非常经典的算法, <code>LRU</code> 最近最少使用算法</p><p>最常见的实现就是通过一个固定大小的双向链表,将最近一次访问的页放到链表头,这样链尾上的最长时间没有使用的页就会被淘汰置换出链表</p><p><code>LRU</code> 在更新内存页的时候,又分为两种情况</p><ul><li>当前命中的页已经在缓存里面了,这时只需要把命中页置换到头部即可</li><li>当前命中的页还不在缓存里面,这时需要通过一次磁盘 io 把磁盘页读取出来放到缓存头部</li></ul><p>对于一个已经装满的缓存,第一种情况只会发生置换页的操作,不会有页被淘汰;第二种情况则是会淘汰尾部的最后一页</p><p>朴素 <code>LRU</code> 在很多内存缓存里面,例如 <code>MemoryCache</code> 运用的很多,但是 mysql 并没有选择朴素 <code>LRU</code> 算法,这是因为有以下两个问题</p><ol><li>预读失效</li><li>缓存污染</li></ol><h4 id="预读失效"><a href="#预读失效" class="headerlink" title="预读失效"></a>预读失效</h4><p>由于 mysql 预读将部分磁盘页放到缓存里面,但是因为某些原因,这些预读出来的页并没有实际访问到,导致预读失效</p><p>假设缓存大小等于 <code>10 ,且磁盘页 </code>50&#96; 被预读放入缓存,考虑如下情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6j8tn3ij30an02maa7.jpg" alt="img.png"></p><p>此时预读出来的页 <code>50</code> 被放到缓存头部,但是后续再也没有发生过对 <code>50</code> 的访问,这导致预读出来的数据 <code>50</code> 需要被置换 10 次后才能够被淘汰掉</p><p>这使得这些未命中的预读页,在缓存里面的停留时间过长</p><p>mysql 采用 <strong>改良的 LRU 算法</strong> ,将普通缓存改为 <strong>分代</strong> 设计,分为 <strong>新生代</strong> 和 <strong>老年代</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6jirxpjj30b504lmxj.jpg" alt="img_1.png"></p><ul><li>缓存被分为两个部分 <strong>新生代</strong> 和 <strong>老年代</strong></li><li>实际上是通过 4 个指针,分别维护新生代头尾和老年代头尾</li><li>新页在放入缓存的时候,首先放入 <strong>老年代</strong></li><li>如果 <strong>老年代</strong> 里面的页发生了命中,才会加入 <strong>新生代</strong></li><li>如果 <strong>老年代</strong> 里面的页没有发生命中,那么在 <strong>更短的时间内</strong> 它将被移除缓存</li></ul><p>这样使得那些被预读放入缓存,但是又长时间没被使用过的页,能够尽快的从老年代里面淘汰出去</p><h4 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h4><p>什么是缓存污染: <strong>当 mysql 发生大面积扫描数据行的时候,会将大量数据页放入缓存后,立马又再次换入新的数据页; 导致每页只在缓存里面停留非常短的时间就被置换出去</strong></p><p>缓存污染将会显著导致 mysql 的性能下降</p><p>例如一次全表扫描时:</p><ol><li>将预读页放入老年代</li><li>从老年代里面访问页加入新生代</li><li>下一次预读又会将全新的页刷入老年代</li><li>重复 123 步骤,直到完成全表扫描</li></ol><p>可以看到在这样的场景下,所有的页都被放入缓存 1 次后,立马又被新的页置换掉; 从而导致原本缓存里面真正的 <strong>热数据</strong> 被大量新页挤出缓存,从而导致 mysql 的性能下降</p><p>mysql 为了解决缓存污染问题,引入了 <strong>老年代停留窗口</strong> 的概念</p><p>放入老年代后,如果再次命中,并不会立即放入新生代,而是要求在老年代待满多少时间后才允许进入新生代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6joyl78j30ci082js4.jpg" alt="img_2.png"></p><p>假设有大量需要扫描的页需要进入缓存,此时首先进入的是老年代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6k1gfkzj30hw05fq47.jpg" alt="img_3.png"></p><p>如果老年代里面装不下,即使页被访问了,也会被缓存淘汰掉</p><p>这个时候缓存头部的那些高频命中的新生代热点数据,不会立马被这种大批量扫描的页给置换出去</p><p>对于能够命中新生代的查询来说,此时缓存依然能够提供服务,并且性能依旧高效</p><p>而对于老年代里面的页,命中后需要判断是否满足 <strong>老年代停留窗口</strong> 的时长 <code>T</code></p><ul><li>如果 <code>停留时长 &gt;= T</code>,则将其置换到新生代的头部,此时新生代的尾部页面会进入老年代作为的老年代的头部</li><li>如果 <code>停留时长 &lt; T</code>,则只会将其置换到老年代的头部,不会进入新生代</li></ul><h3 id="mysql-如何管理写缓存-change-buffer"><a href="#mysql-如何管理写缓存-change-buffer" class="headerlink" title="mysql 如何管理写缓存 (change buffer)"></a>mysql 如何管理写缓存 (change buffer)</h3><p>简单回顾下读缓存在 mysql 保存了什么内容</p><ol><li>索引页</li><li>索引页对应的数据页</li></ol><p>对于读请求,<code>buffer pool</code> 通过改进后的 <code>LRU</code> 算法实现缓存管理,解决 <code>预读失效</code> 和 <code>缓存污染</code> 的问题</p><p>对于写请求,究竟该如何管理缓存呢,以几个例子分别分析下</p><h4 id="写的页正好在-buffer-pool-里"><a href="#写的页正好在-buffer-pool-里" class="headerlink" title="写的页正好在 buffer pool 里"></a>写的页正好在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6ju3go6j308p072gmf.jpg" alt="img_4.png"></p><ol><li>直接在页上写入数据</li><li>然后写入 <code>redo log</code></li></ol><p>是否会出现一致性问题呢: <strong>不会</strong></p><ol><li>读取,会命中缓存池的页</li><li>缓存池 <code>LRU</code> 数据淘汰,会将 <code>脏页</code> 刷回磁盘</li><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li></ol><h4 id="写的页不在-buffer-pool-里"><a href="#写的页不在-buffer-pool-里" class="headerlink" title="写的页不在 buffer pool 里"></a>写的页不在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kjgoolj308j06vaaw.jpg" alt="img_5.png"></p><ol><li>一次随机磁盘访问,将需要写入的页加载到缓存池里</li><li>在缓存池里写入数据</li><li>写入 <code>redo log</code></li></ol><p>由于写入页不在缓存池里,多了一次从磁盘读取对应页的操作,mysql 为了减少这一次磁盘操作,引入了写缓存 <code>change buffer</code> 的概念</p><p><strong>定义:当对一张不在缓存池里且 <code>非唯一索引</code> 的页进行写入操作是时,并不会立即从磁盘里加载对应的页,而是通过在写缓存 <code>change buffer</code> 里 <code>记录</code> 当前操作,直到后面需要访问这张页的时候,在进行合并 <code>merge</code> 操作</strong></p><p>这样对流程上来说带来的改变如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kq2mdfj30bf06xmya.jpg" alt="img_6.png"></p><ol><li>没有立即从磁盘里面加载对应的数据页,而是在 <code>change buffer</code> 里面记录了一次操作</li><li>写入 <code>redo log</code></li></ol><p>可以看到因为有写缓存的存在,其性能与读请求几乎一致</p><p>同样可以分析下是否会产生一致性问题: <strong>同样也不会</strong></p><ol><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li><li>读取刚刚写入的数据,会有其他机制保证从磁盘里面取出旧的数据页,并和 <code>change buffer</code> 里面的记录完成合并</li><li>会有机制保证 <code>change buffer</code> 里面的改动在适当的实际刷入磁盘</li></ol><p>如果此时发生读取操作,会发生什么呢</p><ol><li>发现缓存里没有对应的页,从磁盘里面随机读取一次拿到对应的页放入缓存</li><li>将磁盘里面读出来的页和写缓存 <code>change buffer</code> 里面的操作进行合并 <code>merge</code> </li><li>将 <code>merge</code> 后的页根据 <code>LRU</code> 算法放入缓存池的对应位置 (老年代)</li></ol><p>可以看到: 再写操作发生时,并不会从磁盘里面加载页到缓存里面; 实际上是在读操作到来时,才会从磁盘里面真正加载到缓存里面然后进行 <code>merge</code> 操作</p><h4 id="为什么说写缓存只能用于-“非唯一索引”"><a href="#为什么说写缓存只能用于-“非唯一索引”" class="headerlink" title="为什么说写缓存只能用于 “非唯一索引”"></a>为什么说写缓存只能用于 “非唯一索引”</h4><p>这是由 <strong>一致性</strong> 决定</p><p>什么是一致性? 简单回顾下: 数据库保证数据能够从一个正确的状态转换为另一个正确的状态</p><p>为什么说 <code>change buffer</code> 写缓存在对于 <strong>唯一索引</strong> 的写操作时,没法保证一致性</p><p>由于 <strong>唯一索引</strong> 在写入数据时,需要保证数据的 <strong>唯一性</strong>, 而 <code>change buffer</code> 在记录写入操作时,并没有去校验这条记录 <strong>是否已经存在</strong></p><p>要校验数据的唯一性,必须要从磁盘里面读取出对应的索引页,以检查数据是否存在</p><p>既然这次磁盘操作必不可免,那为什么不直接从磁盘里面读出放到 <code>buffer pool</code> 里,然后直接对页进行修改</p><p>这样看来在中间添加一个 <code>change buffer</code> 写缓存,对于校验索引的唯一性来说,就显得毫无作用了</p><h3 id="什么场景适合开启写缓存"><a href="#什么场景适合开启写缓存" class="headerlink" title="什么场景适合开启写缓存"></a>什么场景适合开启写缓存</h3><p>根据上面的分析,有以下场景适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>非唯一索引</strong></li><li>写多读少</li></ol><p>什么时候不适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>唯一索引</strong></li><li>读多写少 或者说 写入一个数据后,立马读它(因为写缓存没有实际写页,缓存池里面也没有页,只能从磁盘里面加载,这就导致写缓存失效)</li></ol>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(三)mysql 索引深入浅出</title>
    <link href="/2022/11/03/mysql/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/"/>
    <url>/2022/11/03/mysql/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-的索引"><a href="#mysql-的索引" class="headerlink" title="mysql 的索引"></a>mysql 的索引</h2><h3 id="索引数据结构的发展"><a href="#索引数据结构的发展" class="headerlink" title="索引数据结构的发展"></a>索引数据结构的发展</h3><p>索引是一种数据结构,用来提高查询效率,常见的用于提高查询效率的数据结构大致可分为以下三种</p><ol><li>hash</li><li>有序数组</li><li>搜索树</li></ol><h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><p>hash 表提供一种 <code>k-v</code> 的关系,当输入 <code>key</code> 值,可以在 <code>O(1)</code> 的时间复杂度内返回对应的 <code>value</code> 值</p><p>但是 hash 表本身是无序的,也就是说对于确定的 <strong>等值</strong> 查询,即检索在不在,有没有这种情况来说,hash 表能够胜任</p><p>但是对于范围查询,hash 表的性能表现就会非常差,因为 hash 表无法确定数据的范围,所以在对范围查询时,需要遍历整个 hash 表</p><h4 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h4><p>有序数组的结构本身也很简单,他对范围查询提供很好的性能表现,对于等值查询,则可以借助有序的特点,使用 <code>二分查找</code> 提高查找效率</p><p>但是数组的问题就在于对于元素的删除和增加操作非常麻烦,通常需要大批量连续移动若干个节点,才能保证数组的数据结构不被破坏</p><p>如果采用有序链表,虽然能够提高插入和删除操作,但代价就是失去了随机访问的能力,对于 <strong>等值查询</strong> 链表则需要遍历所有节点</p><h4 id="搜索树"><a href="#搜索树" class="headerlink" title="搜索树"></a>搜索树</h4><p>对于二叉搜索树来说,每个左孩子都小于父节点,每个右孩子都大于父节点,可以看做是二分查找的运用,其搜索一个节点是否存在的时间复杂度是 <code>O(logn)</code></p><p>考虑最极端的情况,如果所有节点都只有左孩子,那么整棵树将退化成一条链表,此时时间复杂度退化为 <code>O(n)</code></p><p>所以为了平衡这些极端情况,维持 <code>O(logn)</code> 的时间复杂度,需要树能够做出自平衡,所谓平衡就是说树中每个节点的左子树和右子树的深度之差不超过 1</p><p>这种具有自平衡的二叉搜索树叫做 <code>AVL</code> 树</p><p>但是数据库也放弃使用 <code>AVL</code> 树当做索引,原因如下:</p><p><code>AVL</code> 树是一棵 <strong>二叉树</strong> ,每个节点只能保存两个孩子节点,如果说数据量过大,那么二叉树的深度将会变得非常深</p><p>索引数据并非只存在于内存里,还需要保存到磁盘上;每个节点在磁盘上的位置并不是连续的,如果对于非常靠近叶子节点的位置,其搜索次数能够轻松达到几十上百次</p><p>这样就会导致几十上百次磁盘的访问,整体的检索性能会严重被树深影响</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B 树"></a>B 树</h4><p>为了解决 <code>AVL</code> 树二叉导致磁盘访问频繁的问题,引入 <strong>N 叉树</strong> 的概念</p><p>根据经验, innoDB 里面的 <code>N</code> 大概在 1200 左右,对于一棵树深高度为 3 的 N 叉树,其能够保存接近 17 亿的数据</p><p>这样查询一个节点,其最多也就访问 3 次磁盘而已,极大地减少了对磁盘的访问</p><p>B 树在普通 N 叉树的基础上,会在节点里面同时保存数据,也就是说一个 B 树的节点不仅仅会保存索引值,还会保存对应的数据</p><p>这就导致了空间的浪费,也会拖慢检索速度,举个简单的例子说明,假说一个节点值保存 8k 的内容</p><p>如果节点里面的数据占用了 3k,那么剩下的索引值就只有 5k,如果本可以通过一次查询得到的索引值,由于节点上保存了数据,导致需要多次查询才能得到对应的索引值</p><p>至此 mysql 索引的终极解决方案 B+ 树横空出世</p><h4 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B+ 树"></a>B+ 树</h4><p>B+ 树在 B 树的基础上,将中间节点保存的数据全部移除,这样中间节点就只负责保存索引值</p><p>所有的数据都落到叶子节点上,这样每次查询的次数都是相同的,提高了查询的稳定性</p><p>对于 B 树来说,有些数据可能在根节点,有些数据可能在叶子节点,不同的查询可能根据位置不同有较大的差异</p><p>B+ 树的叶子节点按照关键字,从小到大顺序排列,并且通过前驱和后继两个指针,构成一个 <strong>双向链表</strong></p><p>由于是有序排列,所以 B+ 树也能够应对范围查询</p><p>对比 B 树,B+ 树的优点如下:</p><ol><li>由于数据按照双向链表有序组织,区间查询的性能比 B 树高</li><li>所有数据分布在叶子节点上,每次查询的次数相等,稳定性比 B 树高</li><li>遍历所有数据时,只需要遍历叶子节点下面的双向链表即可,不用扫描整棵树,而 B 树需要扫描整棵树</li></ol><h4 id="B-树-2"><a href="#B-树-2" class="headerlink" title="B* 树"></a>B* 树</h4><p>B* 树是在 B+ 树的基础上,更进一步</p><p>B+ 树在插入和删除节点时,分裂与合并节点带来性能开销,为了减少节点的操作次数,B* 树在每个非叶子节点上保存了相邻兄弟节点的指针</p><p>同时在初始化节点中关键字数量上,由 B+ 树的 <code>ceil(m/2)</code> 改为 <code>ciel(2m/3)</code></p><p>当某个节点的关键字个数达到 <code>2m/3</code> 时,会查询相邻兄弟节点之间是否还有空余,如有的话则插入关键字向兄弟节点转移,减少了节点的分裂次数</p><h3 id="聚簇索引和非聚簇索引"><a href="#聚簇索引和非聚簇索引" class="headerlink" title="聚簇索引和非聚簇索引"></a>聚簇索引和非聚簇索引</h3><p>假设当前表里存在一个主键列 id,和一个字段列 k,同时对于字段列 k 建立索引</p><p>此时表的索引结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjjearwj30k708hdie.jpg" alt="img.png"></p><p>可以看到,对于主键列的索引,叶子节点保存的内容为 <code>id - 数据</code> ,而对于非主键索引 k 来说,里面记录的内容为 <code>k - id</code></p><p>根据索引的叶子节点保存的东西不同,可以把索引分为两大类</p><ol><li>聚簇索引: 保存数据的索引</li><li>非聚簇索引: 保存主键的索引</li></ol><p>对于 <strong>聚簇索引和非聚簇索引,其检索有何区别</strong></p><p>简单来说,在聚簇索引上的查询,只需要通过查找主键 id 就可以得到具体的数据,一次索引树的访问即可</p><p>而非聚簇索引上的查询,则必须要先通过字段列查找到主键 id,然后再通过主键 id 去查找对应的数据,需要 2 次索引树的访问</p><p>对于非聚簇索引上的第二次查找主键 id 的过程,称为 <strong>回表</strong></p><p>由于回表多了一次索引树的查找,所以尽可能使用聚簇索引来完成数据检索</p><h3 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h3><p>假设存在如下 sql 语句,会执行多少次查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><ol><li>从非聚簇索引 k 里面查找到 k&#x3D;3 的记录,得到主键 id&#x3D;300</li><li>从聚簇索引里面查找到主键 id&#x3D;300 的记录,得到数据 R3 返回</li><li>继续遍历 k&#x3D;3 的下一个数据,k&#x3D;5,得到主键 id&#x3D;500</li><li>从聚簇索引里面查找到主键 id&#x3D;500 的记录,得到数据 R4 返回</li><li>继续遍历 k&#x3D;5 的下一个数据,k&#x3D;6,不在查询范围内,结束</li></ol><p>由上一节可知,通过非聚簇索引查询聚簇索引的现象称为 <strong>回表</strong></p><p>上面 5 个查询过程当中,2,4 发生 <strong>回表</strong> 查询,1,3,5 在索引列 k 上发生普通查询</p><p>由于索引列 k 里面的数据只记录了主键 id,并不包含 <code>select</code> 语句后面 <code>*</code> 里面的所有数据</p><p>所以不得不通过 <strong>回表</strong> 查询主键索引得到完整的数据</p><p>假如我们的 sql 发生一点小小的改动</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> k <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>此时 <code>select</code> 语句后面只需要查询 <code>k</code> 字段列即可,通过在 k 上面的普通索引,已经包含查询的所有信息了,此时无需再回表查询其他数据</p><p>这种 <strong>索引列 k 已经覆盖查询请求</strong> 的现象,称为 <strong>索引覆盖</strong></p><p><strong>索引覆盖能够有效的减少回表查询的次数,因此是一种提升性能的常用手段</strong></p><p><em>存储引擎和 Server 层的数据扫描统计</em></p><p>需要注意的是,在上面 <strong>索引覆盖</strong> 的查询过程当中</p><p>存储引擎实际扫描了 3 次,即 k&#x3D;3,&#x3D;5,&#x3D;6 然后返回数据 k&#x3D;3 和 k&#x3D;5</p><p>而对于 Serve 层来说,它只从存储引擎哪里拿到了 2 条记录,所以 Server 层认为实际扫描行数只有 2 条</p><h4 id="联合索引通过索引覆盖来提高查询效率"><a href="#联合索引通过索引覆盖来提高查询效率" class="headerlink" title="联合索引通过索引覆盖来提高查询效率"></a>联合索引通过索引覆盖来提高查询效率</h4><p>考虑如下场景,对于每个学生来说,都有 <code>学号</code>, <code>姓名</code>, <code>年龄</code>,</p><p>通常来说,通过 <code>学号</code> 已经能够唯一定位到一个学生,因此一般都选择在 <code>学号</code> 上建立主键索引</p><p>在 <code>姓名</code> 上,也创建普通索引</p><p>此时查询所有姓张的同学的 <code>姓名</code> 和 <code>年龄</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> name, age <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span><br></code></pre></td></tr></table></figure><p>此时是能通过 <code>姓名</code> 的索引找到所有姓张的主键 id,在通过主键 id 得到完整的数据行,最后取出 <code>姓名</code> 和 <code>年龄</code> 返回结果</p><p>若存在大量的这种查询,则 <strong>回表</strong> 会明显的拖慢查询的性能</p><p>若在 <code>姓名</code> 和 <code>年龄</code> 上建立联合索引 <code>name_age</code> 则查询就会变为在索引 <code>name_age</code> 里面查找姓张的同学和年龄,而索引 <code>name_age</code> 正好又包含了查询所需要的数据,此时就不用发生 <strong>回表</strong> 查询</p><p>这样的联合索引,通过 <strong>索引覆盖</strong> 实现了性能的优化和提升</p><h4 id="联合索引的-“最左匹配原则”-和-“最左前缀原则”"><a href="#联合索引的-“最左匹配原则”-和-“最左前缀原则”" class="headerlink" title="联合索引的 “最左匹配原则” 和 “最左前缀原则”"></a>联合索引的 “最左匹配原则” 和 “最左前缀原则”</h4><p><strong>定义:在联合索引列上,从左左侧的字段开始一直向右匹配索引,直到遇到范围查询(&gt;,&lt;,between,like),此时停止对后面的索引列的匹配</strong></p><p><strong>定义:最左匹配原则同样也满足最左前缀原则</strong></p><p>即对于索引 <code>name, age</code> 来说, 查询 <code>name like (&#39;张%)</code> 也能够用上索引</p><p>但是对于如下查询 <code>name like (%三)</code> 此时联合索引左侧的索引列 <code>name</code> 的查询条件前缀是不确定的 <code>%</code> 通配符,此时会导致 <strong>最左前缀原则</strong> 失效,从而导致 <strong>索引失效</strong></p><p>假如有联合索引 <code>(a,b,c,d)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">&gt;</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">5</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;h%&#x27;</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;123&#x27;</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;456&#x27;</span><br></code></pre></td></tr></table></figure><p>这里联合索引的顺序为 a&gt;b&gt;c&gt;d,所以 <code>where</code> 语句从 <code>a</code> 开始从左往右查找是否有索引列匹配</p><p><code>a &gt; 3</code> 和 <code>a like &#39;h%&#39;</code> 都是范围查询,所以根据定义可知,后面的索引列就不再匹配</p><p>所以以上 2 条 sql 只有 <code>a</code> 用上了索引, <code>b</code> 和 <code>c</code> 都没有用上索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br></code></pre></td></tr></table></figure><p>特殊情况</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br></code></pre></td></tr></table></figure><p>上面 2 条 sql 语句,mysql 的优化器会自动调整字段的位置,从而使用上联合索引加快查询速度</p><p><strong>总结</strong></p><p>根据 <strong>空间</strong> 来决定是否需要在联合索引上,为那些不满足 <strong>最左匹配原则</strong> 的字段列再次单独建立联合索引或者单独的索引</p><p>即是否又需要建立 <code>(b,d)</code> 或者 <code>(c)</code> 这样的联合索引或者单独索引,这取决于查询的频率以及是否满足 <strong>索引覆盖</strong> 来优化查询</p><h3 id="索引下沉-也称为索引下推"><a href="#索引下沉-也称为索引下推" class="headerlink" title="索引下沉(也称为索引下推)"></a>索引下沉(也称为索引下推)</h3><p>对于那些不满足 <strong>最左匹配原则</strong> 的查询,用不上索引的字段列究竟如何完成检索</p><p>考虑如下 sql ,同时有联合索引 <code>(name, age)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span> <span class="hljs-keyword">and</span> age <span class="hljs-operator">=</span> <span class="hljs-number">15</span><br></code></pre></td></tr></table></figure><p>根据 <strong>最左匹配原则</strong> 可以用到 <code>name</code> 这个索引,因为 <code>name</code> 后面有 <code>like</code> 语句,表明这是一个范围查询,所以后面的索引列停止匹配</p><p>此时假设存在以下数据:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjt909lj30lj07v41k.jpg" alt="img_1.png"></p><ul><li>在 mysql 5.6 版本以前,这样的查询只能通过在联合索引 <code>(name, age)</code> 上,通过 <code>name</code> 检索到第一个姓张的同学,得到对应的主键 id,然后回表查询对应的数据行,最后取出 <code>age</code> 字段返回结果集; 接着就是从 <code>name</code> 索引上依次遍历符合条件的主键 id,然后依次回表查询得到最终的完整数据</li></ul><p>可以看到的就是,每次查询都存在一个与之对应的回表操作,这无疑降低了查询的性能</p><ul><li>在 mysql 5.6 及以后的版本中,添加了一个新特性 <strong>索引下沉</strong></li></ul><p><strong>定义:将本来应该在 Server 层进行的过滤操作,下沉到存储引擎层完成; 在遍历索引的过程当中,预先过滤掉不满足索引条件的记录行,减少回表的次数</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7sck49cfpj30lp07zn0d.jpg" alt="img_2.png"></p><p>如果不使用索引下沉优化,则存储引擎只会根据索引 <code>name</code> 查找到所有姓张的同学,并依次回表查询到完整数据行返回给 Server 层</p><p>然后在 Server 层对结果集做 <code>age = 15</code> 的判断,筛选出满足查询条件的结果集</p><p>而对于使用索引下沉的优化来说,在检索联合索引 <code>(name,age)</code> 的时候,存储引擎就预先将 <code>age</code> 不满足条件的记录过滤掉; 将本来在 Server 层做的操作下沉到存储引擎层</p><p>这样最终需要回表的操作就只有 2 次了,减少了回表的次数,提高查询的性能</p><p><strong>索引下沉的条件,索引列中包含有待查询的字段,这样可以提前放到存储引擎来判断索引条件是否满足查询条件</strong></p><p>如果查询的是 <code>name</code> 和 <code>gender</code> ,由于索引列里面不包含 <code>gender</code> 即使将 <code>gender = 1</code>下沉到存储引擎,也无法通过索引覆盖得到 <code>gender</code> 值,还是需要依次回表查询才行</p><p>此时就失去了索引下沉的优化</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(二)mysql 事务隔离原理</title>
    <link href="/2022/11/03/mysql/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/"/>
    <url>/2022/11/03/mysql/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="数据库事务的四大特性"><a href="#数据库事务的四大特性" class="headerlink" title="数据库事务的四大特性"></a>数据库事务的四大特性</h2><ol><li>原子性:事务里一组操作要么全部成功,要么全部失败,不会出现一半成功一般失败的情况</li><li>持久性:事务一旦提交后,其变更就会永久保存下来,即使发生宕机也不会出现数据丢失的情况</li><li>隔离性:不同的事务在并发提交时,其表现的结果看起来是串行化操作的结果</li><li>一致性:数据保证数据从一个正确的状态转移到另一个正确的状态</li></ol><p>一致性难以理解:它为数据库提供了一种 <strong>约束</strong> ,就是说每时每刻数据库都按照正确的方式运行</p><p>比如说我们约定某个字段不能等于 0,那么当我们执行插入 0 值,或者更新为 0 值时,数据库就不允许这种操作发生,因为违反了一致性</p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><ol><li>读未提交:最低的安全级别,事务当中还没有提交的改动能够被其他事务观察到</li><li>读已提交:一个事务的操作只有提交之后才能被其他事务观察到</li><li>可重复度:一个事务在执行过程中看到的数据,总是跟这个事务启动前的结果保持一致</li><li>串行化:所有的事务通过 <strong>加锁</strong> 完成同步操作,出现竞争时必须等待其他事务释放锁资源</li></ol><p>假设数据库只存在一条记录,事务启动前值为 1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofspyx5j309205ugm5.jpg" alt="img_3.png"></p><ol><li><p>读未提交时: 事务 A 的 v1 值已经可以查询得到 2,因为这个级别下可以观察到其他未提交事务发生的改动,所以 v1 &#x3D; v2 &#x3D; v3 &#x3D; 2</p></li><li><p>读已提交级别时: 事务 A 的 v1 值仍然是 1,因为这个级别下只能观察到其他已经提交事务的改动,而 v1 时事务 B 还没有提交,所以事务 B 的改动事务 A 并不能观察到</p></li></ol><p>当事务 B 提交后, v2 &#x3D; v3 &#x3D; 2</p><ol start="3"><li>可重复度:先说结论,v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 2</li></ol><p>可重复度保证了事务在执行过程中观察到的数据和其执行前保持一致,对于事务 A 来说,启动事务前观察到值为 1,那么在执行事务过程当中,再去观察仍然还是得到 1</p><p>只有当事务 A 提交后,再去查询才能得到 v3 &#x3D; 2</p><ol start="4"><li>串行化,由于事务 A 先查询值,所以当事务 B 更新值的时候,必须等待事务 A 执行完成之后才能继续操作</li></ol><p>所以 v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 1</p><h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>在实际数据库查询时,会创建一个 <strong>视图</strong> ,其作用可以理解为启动前所有数据的一个 <strong>快照</strong> ,并且这个 <strong>快照</strong> 在整个事务的执行过程中,不会被其他事务影响到</p><ol><li>读未提交:没有快照,直接读取数据的上一个最新状态</li><li>读已提交:每次执行 sql 前,创建快照</li><li>可重复度:每次事务启动前,创建快照</li><li>串行化:没有快照,通过加锁保证穿行操作</li></ol><h3 id="mysql-具体的隔离级别是如何实现的-以-可重复读-为例"><a href="#mysql-具体的隔离级别是如何实现的-以-可重复读-为例" class="headerlink" title="mysql 具体的隔离级别是如何实现的 以 可重复读 为例"></a>mysql 具体的隔离级别是如何实现的 以 <strong>可重复读</strong> 为例</h3><p>mysql 在每条记录发生操作之前,都会提前记录一个 <strong>回滚段</strong> 的日志 也被称为 <code>undo log</code> ,充分体现了 mysql 写前日志的特性,任何数据发生改变前,都要先记录日志</p><p>这个 undo log 类似于一条链表,记录了数据每个发生变更时的上一个状态</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofzj9dkj30h4078abq.jpg" alt="img_4.png"></p><p>通过回滚操作,当前值 4 的状态可以回滚到之前记录过的任何一个状态</p><p>对于这条记录,处于不同时刻创建的事务,事故观察到的记录的状态均不一样</p><p>对于事务 A,B,C 来说,他们在启动时观察到的记录的值分别为 1,2,4, 这个特性就是 mysql 的 <strong>MVCC(多版本并发控制)</strong></p><p>同时根据视图快照的特性,对于视图 B 来说,如果有其他事务正在操作记录变更为 5,事务 B 也观察不到视图外面的改动</p><p><strong>注意,为什么说尽可能避免长事务,就是因为有 undo log 的存在,可能导致回滚链路非常长,造成磁盘空间的浪费</strong></p><p>详细说明一下这个 undo log 的组成</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rog6bdhhj30tw02ngmn.jpg" alt="img_5.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogb06x9j30fq02vt8z.jpg" alt="img_6.png"></p><p>第一部分主要是 undo log 记录的数据变更的具体信息等,用于回滚时反向操作数据用</p><p>第二部分则是构成回滚链的关键点,包含两个值</p><ol><li>trx_id: myslq 会为每一个事务分配一个 long 类型的唯一 id,这个 id 是递增的</li><li>roll_point: 这是一个只想 undo log 类型的指针,指向上一个旧数据版本的 undo log</li></ol><p>对于一个事务(trx_id &#x3D; 10)来说,在某一时刻操作数据,就会产生一条 trx_id &#x3D; 10,且 roll_point 指向上一个数据的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogfsah8j30ie05wgmn.jpg" alt="img_7.png"></p><p>若紧跟后面的事务(trx_id &#x3D; 18)也访问这条数据,那么就会产生一条 roll_point 指向 trx_id &#x3D; 10 的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogkelk4j30ia07640c.jpg" alt="img_8.png"></p><p>对于事务 A 来说,他是观察不到事务 B 的任何操作的</p><h3 id="视图-快照"><a href="#视图-快照" class="headerlink" title="视图(快照)"></a>视图(快照)</h3><p>再有了 <code>undo log</code> 日志链之后,myslq 基于 <code>undo log</code> 实现了另一种数据结构 <strong>视图</strong> 也可称为 <strong>快照</strong></p><p>视图主要包含以下几个变量:</p><ol><li>创建视图时,当前正处于活跃状态的事务(即还没有提交的事务) ids 集合</li><li>活跃事务 ids 集合里面最小的事务 id, <code>min_id</code></li><li>活跃事务 ids 集合里面 <strong>下一个要生成的事务</strong> id,即当前 ids 里面最大的事务 id + 1, <code>max_id</code>, 这样下一个事务 id 一定比当前所有活跃事务的 id 都要大</li><li>创建当前视图的事务 id, <code>created_trx_id</code></li></ol><p>其中 <code>min_id</code> 也称为 <code>低水位</code>, 同理 <code>max_id</code> 称为 <code>高水位</code></p><p>现在使用两个事务 A,B 来模拟可重复读场景下, 视图是如何工作的; 假设事务 A 在提交之前反复读取数据; 事务 B 在提交之前修改数据</p><h4 id="快照读"><a href="#快照读" class="headerlink" title="快照读"></a>快照读</h4><p>此时事务 A 创建时,有两个事务正处于活跃状态,id&#x3D;10 和 id&#x3D;18</p><p>自然事务 A 此时创建的视图数据:ids&#x3D;[10,18], min&#x3D;10, max&#x3D;18+1&#x3D;19, created_trx_id&#x3D;10</p><p>还记得之前说过的吗,每条记录被写之前,都会产生一条 <code>undo log</code>,用于记录数据的旧值</p><p>此时事务 A 访问记录,将事务 A 指向最新的 <code>undo log</code>,里面保存了最后一个访问记录的状态,假设最后一个访问记录的事务 id &#x3D; 8,此时的 undo log 如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogpfk8aj30iz04emyi.jpg" alt="img_9.png"></p><p>事务 A 的 <code>undo log</code> 保存的最后一个访问记录的事务 id &#x3D; 8,意味着什么</p><p>之前也说过,myslq 会为每个创建出来的事务分配一个 long 类型的事务 id 即 trx_id ,这个 id 随着时间先后顺序依次递增</p><p>当前事务 A 的 trx_id &#x3D; 10,而 <code>undo log</code> 里面记录的最后一个事务的 trx_id &#x3D; 8</p><p>这说明这条记录是在事务 A 创建之前就已经提交过的了,自然 事务 A 是能够访问到这条记录的值 X</p><p>此时,事务 B 启动,并且去更新记录的值为 B,这个时候由于写操作产生,会提前记录一条 <code>undo log</code></p><p>其内容很好分析,创建 <code>undo log</code> 的 trx_id 等于操作的事务 trx_id 即 18,且 <code>undo log</code> 的回滚指针 <code>roll_point</code> 指向上一个旧数据,也就是值 X 时的记录</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogum90bj30if07zmyz.jpg" alt="img_10.png"></p><p>此时,在事务 B 更新了数据之后,事务 A 再次去查询记录,发现 <code>undo log</code> 链路上有最新的节点,即 trx_id &#x3D; 18 的记录</p><p>但是事务 A 并不能立马认为记录就被更新为 B 了,因为它还需要根据快照里面保存的内容去判断这条更新操作究竟能不能够被它访问到,过程如下</p><ol><li>事务 A 发现最新记录 <code>undo log</code> 里面更新的事务 trx_id &#x3D; 18</li><li>事务 A 查询自己的视图里面的活跃事务 ids 集合,发现有 trx_id &#x3D; 18 的记录存在</li><li>这说明事务 A 创建视图的时候,trx_id &#x3D; 18 的事务跟自己一样处于活跃状态,也就是 <strong>未提交</strong> 状态</li><li>这个时候的记录 B 是由未提交的其他事务产生的,在当前视图下是不可观察到的</li><li>所以事务 A 根据 <code>undo log</code> 的 <code>roll_point</code> 查看上一个旧的记录,发现 trx_id &#x3D; 8,小于自己的低水位</li><li>说明 trx_id &#x3D; 8 的记录是由已经提交的事务产生,在当前视图下是可以观察到的</li><li>最终事务 A 第二次查询记录得到的值仍然是 X</li></ol><p>简单总结如下:</p><ul><li>如果 trx_id 小于低水位,表示这个版本在事务启动前已经提交,可见</li><li>如果 trx_id 大于高水为,表示这个版本在事务启动后生成,不可见</li><li>如果 trx_id 大于低水位,小于高水位,分为两种情况:</li></ul><ol><li>若 trx_id 在数组中,表示这个版本在事务启动时还未提交,不可见</li><li>若 trx_id 不在数组中,表示这个版本在事务启动时已经提交,可见</li></ol><p>这就通过视图实现了可重复读的效果</p><h4 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h4><p>来看另一种情况,在可重复读级别下会发生什么</p><p>假设有 A,B,C 三个事务按照下图所示的方式操作数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogzt3naj30fa0afwf7.jpg" alt="img_11.png"></p><p>假设此时 A,B,C 三个事务创建时,活跃的事务只有 trx_id &#x3D; 99,那么此时的快照分别如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7roh4s1lyj30et06ogo5.jpg" alt="img_12.png"></p><p>首先分析 A:</p><ol><li>get K 时,发现 k 的 undo log 指向数据为 (1,3) 的版本,且 trx_id &#x3D; 101</li><li>trx_id &#x3D; 101 大于事务 A 的高水位 100,说明这个版本不可见,往上查找 undo log</li><li>trx_id &#x3D; 102 大于事务 A 的高水位 100,同样不可见,继续网上查找 undo log</li><li>trx_id &#x3D; 90 小于事务 A 的低水位,可见,此时事务 A get k 的结果为 (1,1)</li></ol><p>接着分析 B:</p><ol><li>set K 时,创建新的 <code>undo log</code>,其 trx_id &#x3D; 当前更新数据的事务 id 101</li></ol><p>当按照一致性读的时候,写入 k 之前肯定要得到 k 的值,这里问题来了</p><p>事务 B 的高水位为 101,写入 k 之前的 <code>undo log</code> 版本为 102,此时是高于 B 的高水位的</p><p>也就是说如果按照一致性读来解释的话,B 应该只能拿到 90 版本的值 (1,1) ,从而在写之后更新版本 101 的值为 (1,2)</p><p>思考一个问题: C 在 B 之前已经更新了 k 值为 (1,2) 如果此时 B 按照一致性读取更新 K 值为 (1,2) 会导致 C 的更新丢失了</p><p>为了解决这个问题,mysql 引入了一个新的概念: <strong>当前读</strong></p><p>其含义就是: 所有的更新操作都是 <strong>先读后写</strong> ,而这个 <strong>读</strong> 必须是读取 <strong>当前最新的值</strong> ,不然以前的修改就会丢失</p><p>所以根据 <strong>当前读</strong> ,B 在更新 k 的时候,是已经能够拿到 C 的操作,所以 B 写入数据版本 101 的值为 (1,3)</p><p>随后 B 执行 get K 操作,一看当前最新的 <code>undo log</code> 的 trx_id &#x3D; 101 是自己,那当然可以读取到了</p><p>即,一个事务里面,之前发生过的更新操作,之后的查询操作一定能够观察到(自己写的数据自己认)</p><h4 id="两阶段锁协议"><a href="#两阶段锁协议" class="headerlink" title="两阶段锁协议"></a>两阶段锁协议</h4><p>考虑事务 C 修改为如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rohbk3gnj30fc09gdgm.jpg" alt="img_13.png"></p><p>虽然事务 C 在事务 B 之前发起了更新操作,但是并没有立即提交,而是在事务 B 的更新操作之后才提交的</p><p>此时事务 B 会如何处理呢</p><p>由于事务 C 的 <code>update</code> 操作会为当前数据加上写锁,而事务 B 根据当前读原则,要求其更新数据时必须是当前的最新数据</p><p>但是当前数据上的写锁仍然被其他事务持有,所以事务 B 不得不等待事务 C 释放写锁后才能读取到事务 C 的最新改动,从而更新值</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>总结来说</p><p>可重复读的本质就是通过 <strong>视图</strong> 达到 <strong>一致性读</strong></p><p>但是在遇到更新操作是,就必须通过 <strong>当前读</strong> 来保证之前的更新不会丢失</p><p>如果更新的记录被其他事务持有写锁,根据 <strong>当前读</strong> 原则,必须等待其他事务释放写锁后,才允许继续更新记录</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(一)mysql 日志系统</title>
    <link href="/2022/11/02/mysql/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    <url>/2022/11/02/mysql/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="日志模块-redo-log-和-binlog"><a href="#日志模块-redo-log-和-binlog" class="headerlink" title="日志模块 redo log 和 binlog"></a>日志模块 redo log 和 binlog</h2><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>首先明确一点: mysql 是 <strong>先写日志,再写磁盘</strong>  这个和 redis 的 <strong>先写磁盘,再写日志</strong> 正好相反</p><p>mysql 写 <strong>前日志</strong> ,redis 写 <strong>后日志</strong></p><p>在存储引擎内,任何更新操作都会先记录 <code>redo log</code> 后,并更新内存数据,然后再适当的时候将 <code>redo log</code> 的数据回写到磁盘里</p><p>由此可知 <code>redo log</code> 是存储引擎持有的</p><h3 id="redo-log-组成"><a href="#redo-log-组成" class="headerlink" title="redo log 组成"></a>redo log 组成</h3><p>实际上 <code>redo log</code> 也是由两个部分组成</p><ol><li>redo log buffer</li><li>redo log file</li></ol><p>这也是为了解决内存和磁盘读写速率不一致的问题</p><p>所以 mysql 也需要提供一定的机制,保证将 <code>redo log buffer</code> 缓冲里面的数据,刷新到 <code>redo log file</code> 磁盘里持久化</p><p>mysql 运行在用户态,要想真正写入磁盘,必须通过 <code>os</code> 提供的 <code>os buffer</code> 进入内核态调用 <code>fsync()</code> 才能写入磁盘</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5h2r8mj30ca0a4tau.jpg" alt="img.png"></p><p>mysql 提供 3 种写入 redo log 的配置</p><ol><li>延时写:不会在事务提交时写入 <code>redo log</code>,而是每秒写入 <code>os buffer</code> 后在调用 <code>fsync()</code> 刷盘,发生宕机时会丢失大概 1s 的数据</li><li>实时写,实时刷:事务提交后,写入 <code>os buffer</code> 立即刷新到磁盘,性能低,但是数据可靠性最高,即使宕机也不会丢数据</li><li>实时写,延时刷:事务提交后,写入 <code>os buffer</code> 每隔 1s 中左右刷新磁盘,发生宕机会丢失大概 1s 的数据</li></ol><p>整个 <code>redo log</code> 的数据结构类似以个环形数组,通过两个指针 <code>write_pos</code> 和 <code>check_point</code> 来记录读写进度</p><p><code>write_pos</code> 记录当前已经写入的位置,随着新数据到来, <code>write_pos</code> 指针会不停地往后移动</p><p><code>check_point</code> 记录当前正要落盘的位置,每次将数据落盘之后,<code>check_point</code> 也会往后移动</p><p>如果新数据的写入速度,超过了落盘的速度,导致 <code>write_pos</code> 和 <code>check_point</code> 相遇了</p><p>此时就需要暂停新数据的写入,先将一部分数据落盘后,空出来的 <code>redo log</code> 空间才允许新数据写入</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp577ek3j30ll0cx764.jpg" alt="img_1.png"></p><p>这样,当事务提交后,由于 mysql 写前日志的特性,即使还没来得及完成刷盘操作,也能通过 <code>redo log</code> 的 <code>check_point</code> 之后保存记录来恢复事务</p><h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>在存储引擎有 <code>redo log</code> 的存在,在 Server 层自然也有对应的 <code>binlog</code> 来记录日志</p><p>对比下 <code>redo log</code> 和 <code>binlog</code> 的不同点</p><ol><li><code>redo log</code> 写物理日志, <code>binlog</code> 写逻辑日志<br>物理日志就是记录磁盘页的操作:在第 <code>x</code> 页磁盘,偏移量为 <code>y</code> 的位置,写入 <code>z</code> 个字节</li></ol><p><code>binlog</code> 写逻辑日志,也就是说 <code>binlog</code> 记录的是每一条实际操作的 sql 语句<br>由于 <code>redo log</code> 写的是物理日志,其记录了磁盘操作的本质,在数据恢复上就比逻辑日志的 <code>binlog</code> 快很多</p><ol start="2"><li><code>redo log</code> 是类似环形数组的循环写入,有固定的大小</li></ol><p>而 <code>binlog</code> 则是顺序追加写入文件,这样记录了所有操作过的 sql 语句</p><p><code>redo log</code> 的大小固定,不可能无限制地写入日志,所以 <code>check_point</code> 保证了在其之前的数据都是已经刷入磁盘的</p><p>不会保存历史记录,相对于 <code>binlog</code> 而言,节省了很多空间</p><p>同时由于 <code>binlog</code> 一直追加写,并没有什么标志位能够得知哪条记录之前的 sql 是已经刷入磁盘的,在做数据恢复的时候,难以定位哪些还未刷盘的日志</p><p>而 <code>redo log</code> 通过 <code>check point</code> 可以很方便的找到未刷盘的日志位置,从而进行数据恢复</p><ol start="3"><li><code>redo log</code> 是存储引擎 innoDB 独有的,<code>binlog</code> 是 mysql Server 层持有的,跟存储引擎无关</li></ol><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>以 <code>slq = 为 id = 2 的记录 c 值加 1</code> 为例,看看 mysql 具体的执行过程</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5x282nj30cs0hkdik.jpg" alt="img_2.png"></p><ol><li><p>经过链接器,抛开查询缓存不谈,完成语法分析和分析,经过优化器来到执行器后</p></li><li><p>首先执行器调用存储引擎的接口检索 <code>id=2</code> 的记录,检查记录是否存在于 <code>buffer pool</code> 当中,若命中则直接执行器,否则将会从磁盘里面读出数据所在的 <strong>页</strong> 放入内存当中</p></li><li><p>执行器拿到 <code>id=2</code> 的记录后,对其 <code>c</code> 值完成加 1 操作后,在调用存储引擎的接口将其写入内存</p></li><li><p>存储引擎将更新后的数据写入内存后,立即写入 <code>redo log buffer</code> 当中,此时 <code>redo log</code> 处于 <code>prepare</code> 状态,然后返回到执行器</p></li><li><p>执行器接收到存储引擎完成数据写入后的响应,则记录当前 sql 到 <code>binlog</code> 里面,然后再调用存储引擎提交事务</p></li><li><p>存储引擎接收到执行器提交事务后的请求后,将刚刚 <code>redo log</code> 当中的 <code>prepare</code> 状态更新为 <code>commit</code></p></li></ol><p>可以看到整个过程当中,<code>redo log</code> 分别在不同的时期处于两种不同的状态,这个特性被称作 mysql 的 <code>两阶段提交</code></p><p>为何一个事务在写 <code>redo log</code> 的时候有两次操作,这个需要结合 <code>binlog</code> 解释下当事务提交时发生宕机后,如果通过 <code>binlog</code> 和 <code>redo log</code> 完成数据恢复</p><h4 id="mysql-数据恢复时的规则"><a href="#mysql-数据恢复时的规则" class="headerlink" title="mysql 数据恢复时的规则"></a>mysql 数据恢复时的规则</h4><ol><li>若 <code>redo log</code> 里面有 <code>commit</code> 记录,则直接提交当前事务</li><li>若 <code>redo log</code> 有 <code>prepare</code> 记录,则检查 <code>binlog</code> 是否有事务 <code>commit</code> 记录. 若 <code>binlog</code> 也有,则提交当前事务;若 <code>binlog</code> 没有,则回滚当前事务</li></ol><h4 id="如果先写-redo-log-再写-binlog"><a href="#如果先写-redo-log-再写-binlog" class="headerlink" title="如果先写 redo log 再写 binlog"></a>如果先写 redo log 再写 binlog</h4><p>若数据更新后,<code>redo log</code> 已经完成写入,此时再写入 <code>binlog</code> 发生宕机</p><p>在恢复数据的时候,检查到 <code>redo log</code> 里面已经有事务的 <code>commit</code> 记录,此时应该提交当前事务到数据库</p><p>此时主库完成事务提交, <code>c</code> 值已经被更新为 2</p><p>但是由于 <code>binlog</code> 没有记录,导致通过 <code>binlog</code> 同步到从库时,从库缺少了当前事务,从而导致主备的数据不一致</p><h4 id="如果先写-binlog-再写-redo-log"><a href="#如果先写-binlog-再写-redo-log" class="headerlink" title="如果先写 binlog 再写 redo log"></a>如果先写 binlog 再写 redo log</h4><p>若数据更新后先写入 <code>binlog</code>, 此时再写入 <code>redo log</code> 时发生宕机</p><p>在数据恢复的时候,检查 <code>redo log</code> 没有事务的 <code>commit</code> 的记录,从而主库缺少了当前事务的记录</p><p>而从库因为从 <code>binlog</code> 当中同步到了更新的事务,这也导致了主备的数据不一致</p><h4 id="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"><a href="#两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题" class="headerlink" title="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"></a>两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题</h4><ol><li><code>redo log prepare</code> 之后,写 <code>binlog</code> 之前宕机</li></ol><p>恢复数据时,检查到 <code>redo log</code> 有 <code>prepare</code> 的事务,再去检查 <code>binlong</code> 的情况,发现 <code>binlog</code> 里面没有记录事务</p><p>此时需要回滚 <code>redo log</code> 里面的事务,即主库回滚未提交的事务</p><p>这样主备之间通过 <code>binlog</code> 同步时,都没有宕机前未提交的事务,保证主备之间的数据一致性</p><ol start="2"><li><code>binlog</code> 完成,写 <code>redo log commit</code> 时宕机</li></ol><p>数据恢复时,检查到 <code>redo log</code> 有 <code>prepare</code> 记录,再去检查 <code>binlog</code> 的情况,发现 <code>binlog</code> 里面也有事务的记录</p><p>此时需要将 <code>redo log prepare</code> 修改为 <code>commit</code>,将 <code>binlog</code> 里面记录的事务提交到主库</p><p>这样从库因为已经从主库同步了 <code>binlog</code> 执行了最新的事务,但是主库由于宕机导致事务没有提交,所以这时候检查后需要将 <code>binlog</code> 里面的时候重新在主库提交一遍,这样保证主备之间的数据一致性</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 的二次开发</title>
    <link href="/2022/10/31/gin/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/"/>
    <url>/2022/10/31/gin/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h3 id="结合业务对-gin-做二次开发"><a href="#结合业务对-gin-做二次开发" class="headerlink" title="结合业务对 gin 做二次开发"></a>结合业务对 gin 做二次开发</h3><p>考虑下 gin 或者 go 原生的 http 包究竟为我们提供了哪些扩展点 <strong>根据开闭原则,对修改关闭,对扩展开放</strong></p><ol><li><p>go http Server</p></li><li><p>go http 包为我们提供了 Handler 接口</p></li></ol><p>其实 go 的 http 处理最终也是交给 <code>Handler</code> 去处理,这里可以通过实现这个接口来扩展自定义 http 框架(因为 go 也是这么做的)</p><ol start="3"><li>gin 的 <code>HandlerFunc</code> 中间函数,这个地方可以扩展的东西太多了,我们可以把各种和业务挂钩的 hook 函数全部添加到 <code>handlerChain</code> 里</li></ol><p>有点 <code>AOP</code> 的感觉嗷</p><h3 id="结合-fx-框架实现自定义启动和结束行为"><a href="#结合-fx-框架实现自定义启动和结束行为" class="headerlink" title="结合 fx 框架实现自定义启动和结束行为"></a>结合 fx 框架实现自定义启动和结束行为</h3><p><code>fx</code> 是 uber 开源的一款依赖注入框架,可以通过 <code>fx</code> 启动一个 <code>app</code> 服务,利用 <code>fx</code> 的 <code>hook</code> 函数,可以轻松地实现类似 <code>Spring</code> 的 <code>AOP</code> 能力</p><p>为 <code>fx</code> 容器注册启动和停止时的 <code>hook</code> 函数</p><p>首先根据前面总结的内容,启动 gin 服务,无非就是创建了一个 <code>http.Server</code> 容器而已</p><p>只不过 gin 通过实现 <code>Handler</code> 接口,实际上启动的是 gin 自定义的 <code>Engine</code> 对象而已</p><p>所以为了对 gin 做满足业务的二次开发,我们也通过同样的接口,定义我们自己的 <code>Server</code> 对象,并且让它配合 <code>fx</code> 框架完成启动和停止的自定义操作</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-comment">// 首先定义我们的自定义 `Server` 对象</span><br><span class="hljs-keyword">type</span> GinxServer <span class="hljs-keyword">struct</span> &#123;<br>server *http.Server<br>proxy  *ProxyGinEngine<br>&#125;<br><br><span class="hljs-keyword">type</span> ProxyGinEngine <span class="hljs-keyword">struct</span> &#123;<br>engine *gin.Engine<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStart() &#123;<br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server starting....&quot;</span>)<br>        <span class="hljs-comment">// 这里才是启动 gin 容器的关键代码</span><br>err := s.server.ListenAndServe()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;ginx listen and serve error: %s&quot;</span>, err.Error())<br>&#125;<br>&#125;()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStop() &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server stoping....&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 使用我们自定义的 Server</span><br>s := &amp;GinxServer&#123;<br>server: &amp;http.Server&#123;<br>Addr: addr,<br>&#125;,<br><span class="hljs-comment">// 底层仍然是 gin 的引擎,不过对它做了一些扩展</span><br>proxy: &amp;ProxyGinEngine&#123;engine: gin.New()&#125;,<br>&#125;<br><br>    <span class="hljs-comment">// 注册我们的路由函数</span><br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/ping&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>,<br>&#125;)<br>&#125;)<br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/hello&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;hello world&quot;</span>,<br>&#125;)<br>&#125;)<br><span class="hljs-keyword">return</span> s<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ctx := context.Background()<br>app := fx.New(<br>fx.Provide(ginx.NewServer),<br>fx.Invoke(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(lc fx.Lifecycle, server *ginx.GinxServer)</span></span> &#123;<br>lc.Append(fx.Hook&#123;<br>OnStart: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStart()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>OnStop: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStop()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;)<br>&#125;),<br>)<br>    <span class="hljs-comment">// 注意通过 ide 启动 main 函数后,再通过 ide 结束是无法出发 OnStop 事件的</span><br>    <span class="hljs-comment">// 因为 ide 的结束是直接杀死进程,而不是通过信号量的方式结束进程</span><br>    <span class="hljs-comment">// 调用 fx.Stop() 时,会发送信号量来结束进程,这样 OnStop() 函数才能触发</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>time.Sleep(<span class="hljs-number">2</span> * time.Second)<br>app.Stop(ctx)<br>&#125;()<br>app.Run()<br>&#125;<br></code></pre></td></tr></table></figure><p>注意这里有个大坑,在 <code>OnStart()</code> 里一定要用协程去启动这个 gin 的监听函数</p><p>对于 fx 框架来说,所有 <code>hook</code> 函数都必须正常启动,fx 应用才算最终启动</p><p>如果这里没有用协程启动,那么 <code>OnStart()</code> 函数将会一直阻塞下去(因为 <code>ListenAndServe()</code> 阻塞),相当于这个 <code>OnStart()</code> 函数就一直没有返回</p><p>而 fx 框架在执行 hook 函数时,发现某个 hook 超时没有正确返回,就会认为启动 fx.App 失败,从而发出停止的信号量</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nn3ybz8gj30t803rjvk.jpg" alt="img.png"></p><h3 id="添加自定义-HandlerFunc-函数"><a href="#添加自定义-HandlerFunc-函数" class="headerlink" title="添加自定义 HandlerFunc() 函数"></a>添加自定义 HandlerFunc() 函数</h3><p>假如我们要对每个 http 请求统计其请求耗时,以及添加相关的埋点信息,应当如何扩展 gin 的 <code>HandlerFunc</code> 函数</p><p>首先可以知道的是,在 <code>ServeHTTP()</code> 最终会调用到 gin 重写的 <code>ServerHTTP()</code> 方法</p><p>里面 gin 通过遍历路由树,找到请求对应的路由节点,然后顺序执行节点的 <code>[]HanderFunc()</code> 函数列表</p><p>其中有个很关键的函数 <code>c.Next()</code> 就是用来遍历整个 <code>[]HandlerFunc()</code> 中间件函数的</p><p>所以我们的两个目标: 1. 新增请求埋点 2. 统计接口耗时  就需要在这个 <code>c.Next()</code> 函数上动文章</p><p>简单回顾下这个 <code>c.Next()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br>c.index++<br><span class="hljs-keyword">for</span> c.index &lt; <span class="hljs-type">int8</span>(<span class="hljs-built_in">len</span>(c.handlers)) &#123;<br>c.handlers[c.index](c)<br>c.index++<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到,在 gin 的自定义上下文 <code>Context</code> 通过 <code>index</code> 字段记录了当前执行的中间件函数的位置,一旦所有函数执行完成之后,就会返回</p><p>首先记录请求埋点肯定是先于业务函数的,所以在初始化 gin 容器的时候,在其他业务 <code>api</code> 注册之前,就应该先行注册埋点函数</p><p>改造 <code>NewServer()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> ginx<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 省略前面的初始化</span><br><br>    <span class="hljs-comment">// 首先添加埋点函数的注册</span><br>    <span class="hljs-comment">// 这样每次遍历 []HandlerFunc 的时候第一个都是 这个埋点函数</span><br>    s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>        <span class="hljs-comment">// req := c.Request</span><br><span class="hljs-comment">// header := c.Request.Header</span><br><span class="hljs-comment">// body := c.Request.Body</span><br><span class="hljs-comment">// do something with req or header or body</span><br>fmt.Printf(<span class="hljs-string">&quot;do something with request&quot;</span>)<br>    &#125;)<br><br>    <span class="hljs-comment">// 接着注册我们的统计耗时的函数</span><br>s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>start := time.Now() <span class="hljs-comment">// 计算当前时间</span><br><span class="hljs-comment">// 注意这里调用 c.Next() 很关键</span><br>c.Next()<br>cost := time.Since(start) <span class="hljs-comment">// 计算耗时</span><br>fmt.Printf(<span class="hljs-string">&quot;cost time is %s&quot;</span>, cost.String())<br>&#125;)<br><br>    <span class="hljs-comment">// 省略业务路由的注册</span><br><span class="hljs-keyword">return</span> s<br>&#125;<br></code></pre></td></tr></table></figure><p>这里着重关注统计耗时的函数,在其内部再次调用了 <code>c.Next()</code> 函数</p><p>来看看调用链 :</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nmkujkcsj31240kegus.jpg" alt="1.png"></p><p>看看最终效果</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nqwvrx9zj30te0cowl4.jpg" alt="2.png"></p><p>可以看到埋点函数和统计耗时函数都能正常工作</p><p><strong>发现个很奇怪的地方,没来得及分析</strong></p><p>就是每次 gin 服务启动之后,第一次请求耗费的时间远长于后面的请求</p><p>有些情况下甚至第一次请求耗时是后面的几十倍</p><p>这个还没找到原因,如果有谁知道,可以通过博客的 <strong>About</strong> 页面取得联系方式告知我一下</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (三)</title>
    <link href="/2022/10/30/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/"/>
    <url>/2022/10/30/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/</url>
    
    <content type="html"><![CDATA[<h2 id="http-连接的建立和监听"><a href="#http-连接的建立和监听" class="headerlink" title="http 连接的建立和监听"></a>http 连接的建立和监听</h2><p>前面用了介绍了 <code>engine</code> 容器的初始化, 处理 <code>http</code> 请求的流程, <code>Router</code> 路由树的生成和注册</p><p>接下来将了解下,一个 http 连接究竟是如何建立的,以及如何将流程扭转到 gin 去实际处理一个请求</p><h3 id="http-ListenAndServe-函数"><a href="#http-ListenAndServe-函数" class="headerlink" title="http.ListenAndServe() 函数"></a>http.ListenAndServe() 函数</h3><p>回到 <code>gin.Run()</code> 函数实现,里面有个 <code>http.ListenAndServe(address, engine)</code> 函数</p><p>通过入参和签名,很明显的告诉我们这个函数将监听在 <code>address</code> 的连接, 第二个参数 <code>engine</code> 猜测最终会把请求交给 <code>engine</code> 容器去处理</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfglt6d4j30is06yado.jpg" alt="img.png"></p><p>首先创建一个 <code>Server</code> 对象,将需要监听的地址,和处理器 (和 gin 的中间函数 <code>HandlerFunc</code> 区分下)</p><p>其实这里的处理器,就是我们之前初始化的 <code>engine</code> 容器,不过 <code>engine</code> 实现了 <code>Handler</code> 接口而已</p><p>这里可以充分体现出 gin 在设计上遵循 <strong>依赖接口而不是依赖实现</strong> 的原则</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgu7g3rj30i1088q68.jpg" alt="img_1.png"></p><p>这里的 <code>Serve</code> 对象感觉和 java 的 <code>Socket</code> 套接字很类似,监听并 <strong>阻塞</strong> 等待</p><p>既然是类似套接字,那么自然就能关闭,所以检查当前的套接字是否关闭,已经关闭了就不能再监听地址接受请求了</p><p>后面就是创建 <code>tcp</code> 链接,以及处理事件</p><h4 id="Listen-函数"><a href="#Listen-函数" class="headerlink" title="Listen() 函数"></a>Listen() 函数</h4><p>跟进 <code>net.Listen()</code> 函数和 <code>lc.Listen()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>DefaultResolver.resolveAddrList(ctx, <span class="hljs-string">&quot;listen&quot;</span>, network, address, <span class="hljs-literal">nil</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>resolveAddrList()</code> 函数负责解析 <code>address</code> 的监听类型, 通过后面的逻辑可知,大致能够分为两类</p><ol><li>TCP 类型(通过 ip 地址加 port 端口,UDP 也类似)</li><li>UNIX 套接字类型???</li></ol><p>里面都是 go 原生的网络库实现,大致逻辑如下:</p><ol><li>解析 <code>ip</code> 地址,解析是 <code>ipv4</code> 还是 <code>ipv6</code> 的类型</li><li>尝试解析 <code>ip</code> 类型,如果不是一个合法的 <code>ip</code> 地址,就试着当做 <code>DNS</code> 地址解析</li></ol><p>接下来是为解析后的 <code>addr</code> 地址创建对应的的监听者对象 <code>sysListener</code> 这没什么好说的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl := &amp;sysListener&#123;<br>ListenConfig: *lc,<br>network:      network,<br>address:      address,<br>&#125;<br></code></pre></td></tr></table></figure><p>通过这个 <code>sysListener</code> 对象来完成实际的监听行为</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl.listenTCP(ctx, la)<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgz7a1zj30ff04rgo3.jpg" alt="img_2.png"></p><p>这里面都涉及到 <code>unix</code> 底层的套接字编程,得到网络文件描述符 <code>fd</code> 完成后续操作,哎我也看不懂了</p><p>有空还要去拜读下 <code>unix</code> 的 <code>socket</code> 套接字编程,再回头看看这里应该会清晰很多</p><p>最后把创建的套接字对象 <code>fd</code> 注入到 <code>sysListener</code> 里,这样这个监听者就相当于已经就绪了,可以进行监听操作</p><p>返回到 <code>http.ListenerAndServe(ln)</code> 将 <code>listen()</code> 函数创建得到的监听者 <code>ln</code> 当做参数传入</p><h4 id="Serve-函数"><a href="#Serve-函数" class="headerlink" title="Serve() 函数"></a>Serve() 函数</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>origListener := l<br>l = &amp;onceCloseListener&#123;Listener: l&#125;<br><span class="hljs-keyword">defer</span> l.Close()<br>&#125;<br></code></pre></td></tr></table></figure><p>通过 <code>OnceCloseListener</code> 对象包裹原始的 <code>Listener</code> 对象</p><p>从字面意思上来说,就是只允许调用一次 <code>Close()</code> 避免重复关闭一个已经关闭了的 <code>Listener</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">if</span> !srv.trackListener(&amp;l, <span class="hljs-literal">true</span>) &#123;<br><span class="hljs-keyword">return</span> ErrServerClosed<br>&#125;<br><span class="hljs-keyword">defer</span> srv.trackListener(&amp;l, <span class="hljs-literal">false</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>将传入的监听者 <code>ln</code> 注入到 <code>Serve</code> 对象里, defer 保证了回收 <code>Serve</code> 的时候会把 <code>ln</code> 移除掉</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>baseCtx := context.Background()<br><span class="hljs-comment">// ...</span><br>ctx := context.WithValue(baseCtx, ServerContextKey, srv)<br>&#125;<br></code></pre></td></tr></table></figure><p>创建一个空的 <code>Context</code> 对象,将 <code>Serve</code> 对象注入到上下文里</p><h4 id="阻塞监听"><a href="#阻塞监听" class="headerlink" title="阻塞监听"></a>阻塞监听</h4><p><strong>以上完成了所有准备,接下来开启一个死循环阻塞监听请求</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 调用监听者的 Accept() 函数,这是个同步阻塞函数</span><br><span class="hljs-comment">// 2022-10-30 本人无能,套接字编程,网络文件描述符相关的操作,实在是看不懂啊</span><br>rw, err := l.Accept()<br><br><span class="hljs-comment">// 当 l 监听到时间产生后, Accept() 函数返回,开始后面处理请求</span><br><span class="hljs-comment">// 可以通过启动 gin 的时候注册一个简单的 /ping 心跳路由</span><br><span class="hljs-comment">// curl 请求一下这个 /ping 路由即可</span><br><br><span class="hljs-comment">// 跳过监听得到的异常处理</span><br><br><span class="hljs-comment">// 这个 ConnContext 成员变量可以在初始化 Serve 对象的时候注入进去</span><br><span class="hljs-comment">// 本质是一个 func(ctx context.Context, c net.Conn) context.Context 函数变量</span><br><span class="hljs-comment">// 起作用是在得到一个新的 c 连接的时候,返回一个继承自 ctx 的新的上下文对象</span><br><span class="hljs-comment">// 具体怎么继承,以及要对这个新的上下文对象做什么处理,则有函数自行决定</span><br><br><span class="hljs-comment">// 这里要么使用原始的父 ctx 对象,要么通过 cc 函数得到个继承自 ctx 的新上下文对象</span><br>connCtx := ctx<br><span class="hljs-keyword">if</span> cc := srv.ConnContext; cc != <span class="hljs-literal">nil</span> &#123;<br>connCtx = cc(connCtx, rw)<br><span class="hljs-keyword">if</span> connCtx == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;ConnContext returned nil&quot;</span>)<br>&#125;<br>&#125;<br>tempDelay = <span class="hljs-number">0</span><br><span class="hljs-comment">// 将 http 裸的连接包成 conn 对象</span><br>c := srv.newConn(rw)<br>c.setState(c.rwc, StateNew, runHooks) <span class="hljs-comment">// before Serve can return</span><br><br><span class="hljs-comment">// 启动一个协程去处理接收到的连接 conn</span><br><span class="hljs-keyword">go</span> c.serve(connCtx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Unix</code> 网络套接字编程是很复杂的,这里因为之前没有充分准备,导致很多 <code>Socket</code> 底层通过 <code>Unix</code> 提供的文件描述符进行网络操作的代码看不懂</p><p>后面补充了 <code>Socket</code> 相关知识后,一定要回来再看看这里</p><p>整个流程总结如下:</p><ol><li>Accept() 函数阻塞监听,直到请求过来返回 net.conn 裸的 http 连接</li><li>如果 Accept() 返回有异常,则处理异常</li><li>如果 Serve 初始化了 ConnContext 函数成员变量,这个函数会继承全局的 ctx 上下文得到一个新的上下文对象</li><li>将裸的 http.conn 包装为 serve 包下面的 conn 结构,新建一个协程,使用第 3 步得到上下文去处理请求</li><li>主协程通过死循环仍然继续阻塞监听 Accept() 函数,直到下一个请求进来 go to 1</li></ol><h4 id="实际的-serve-connCtx-函数"><a href="#实际的-serve-connCtx-函数" class="headerlink" title="实际的 serve(connCtx) 函数"></a>实际的 serve(connCtx) 函数</h4><p>接下来进一步解析这个 <code>serve()</code> 函数如何处理请求的</p><p><code>serve()</code> 函数很长,挑重点解析</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> serve(ctx context.Context) &#123;<br><span class="hljs-comment">// 上下文的设置</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// defer 定义了发生异常后的处理流程</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 检查和处理 tls 协议的链接,即 https 请求</span><br><span class="hljs-comment">// ..</span><br><br><span class="hljs-comment">// 非 tls 协议, http 请求的处理</span><br><span class="hljs-comment">// 创建一个带有</span><br>ctx, cancelCtx := context.WithCancel(ctx)<br>c.cancelCtx = cancelCtx<br><span class="hljs-keyword">defer</span> cancelCtx()<br><br><span class="hljs-comment">// 初始化 buffer reader 和 buffer writer</span><br><span class="hljs-comment">// 为读取连接和向连接发送内容做好准备</span><br>c.r = &amp;connReader&#123;conn: c&#125;<br>c.bufr = newBufioReader(c.r)<br>c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, <span class="hljs-number">4</span>&lt;&lt;<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 解析请求</span><br>w, err := c.readRequest(ctx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>c.readRequest()</code> 函数将会实际处理 <code>conn</code> 对象的请求</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> readRequest(ctx context.Context) (w *response, err <span class="hljs-type">error</span>) &#123;<br><span class="hljs-comment">// 设置超时时间,最长读取时间,缓冲最大读取长度,等等参数</span><br><span class="hljs-comment">// 兼容一些老的客户端在发送 post 请求会后多带上了 /r/n 等换行符,从缓冲区读取的时候去掉这些字节</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 从缓冲区里读取请求内容</span><br>req, err := readRequest(c.bufr)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>readRequest(c.bufr)</code> 函数就是按照 <code>http 1.0</code> 规范解析请求报文</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfh60d1sj30ne03pwi9.jpg" alt="img_3.png"></p><p>首先解析报文行,得到请求方法,请求的协议和版本</p><p>紧跟着解析报文头,得到 <code>Header</code> 里面的值,处理 <code>Header</code> 里面约束的各种参数</p><p>校验一些协议和版本是否兼容,校验 <code>Header</code> 参数是否合法</p><p>最后通过传入的 <code>reader</code> 构造一个 <code>bufferWriter</code> 当做 <code>response</code> 的操作对象</p><h4 id="通过-ServeHTTP-函数扭转处理流程"><a href="#通过-ServeHTTP-函数扭转处理流程" class="headerlink" title="通过 ServeHTTP 函数扭转处理流程"></a>通过 ServeHTTP 函数扭转处理流程</h4><p>在前面通过 <code>readRequest()</code> 解析请求后,创建对应的 <code>http.response</code></p><p><strong>注意:重点来了,这个时候 go 原生的 net 网络包已经帮忙把一个 http 请求全部解析好; 这个时候就需要通过对外暴露的 ServeHTTP 接口把控制流程交给其实现类去处理; 否则请求将会由 go net 库自行处理掉</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfhd792kj30iy0b1dld.jpg" alt="img_4.png"></p><p>跟进这个 <code>ServeHTTP()</code> 方法,在这里面实际上调用的是 <code>server.Handerl.ServeHTTP()</code> 方法</p><p>此时,终于把控制流程交给了 gin 去处理</p><p>回到 gin 框架里面,如果对 gin 的流程有些忘记了的话,可以看看第一张里面关于 <code>gin 如何通过 Handler 接口实现接收和响应请求</code><br>的部分</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img_5.png"></p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (二)</title>
    <link href="/2022/10/29/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/"/>
    <url>/2022/10/29/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/</url>
    
    <content type="html"><![CDATA[<p>简单回顾: gin 从 <code>Run()</code> 函数启动容器之后</p><p>注册路由,添加路由中间函数的调用链</p><p>到使用 go 底层的 <code>net</code> 库绑定地址和端口,阻塞监听端口上的请求</p><p>到最后通过中间函数的调用链完成请求的处理</p><p>这里来看看 gin 容器是如何初始化的,都分别作了什么</p><h3 id="gin-容器的初始化"><a href="#gin-容器的初始化" class="headerlink" title="gin 容器的初始化"></a>gin 容器的初始化</h3><p>gin 提供了两个最常用的初始化方法</p><ol><li>gin.New()</li><li>gin.Default()</li></ol><p>其中 <code>Default()</code> 就是在 <code>New()</code> 的层面上,多添加了两个中间函数而已</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m78mblrej30ct049dhi.jpg" alt="img.png"></p><p>对于 <code>New()</code> 函数来说,在这里面初始化设置了 <code>engine</code> 对象的各种属性配置</p><p>比较关键的几个列出来单独说明下:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">()</span></span> *Engine &#123;<br>engine := &amp;Engine&#123;<br>RouteGroup: RouteGroup&#123; <span class="hljs-comment">// 初始化路由组对象</span><br>Handlers: <span class="hljs-literal">nil</span>,<br>basePath: <span class="hljs-string">&quot;/&quot;</span>,<br>root:     <span class="hljs-literal">true</span>, <span class="hljs-comment">// 设置为根节点</span><br>&#125;,<br><span class="hljs-comment">// &#123;省略&#125; </span><br>trees: <span class="hljs-built_in">make</span>(methodTrees, <span class="hljs-number">0</span>, <span class="hljs-number">9</span>) <span class="hljs-comment">// 为 9 种 http 方法初始化路由树</span><br>&#125;<br><span class="hljs-comment">// 初始化 Context 池,减少上下文的频繁创建,提高内存复用率</span><br>engine.RouterGroup.engine = engine<br>engine.pool.New = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-keyword">interface</span>&#123;&#125; &#123;<br><span class="hljs-keyword">return</span> engine.allocateContext()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="路由组的初始化"><a href="#路由组的初始化" class="headerlink" title="路由组的初始化"></a>路由组的初始化</h3><p>在有了 gin 容器之后,接下来需要做的就是为我们的 api 分类并设置路由组</p><p>就是把具有类似路由 path,隶属于同一个领域的 api 聚合到一个路由组里面,方便快速的查找路由</p><p>使用函数 <code>engine.Group()</code> 可以快速的聚合一组 api 路由</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m794m97bj30o305dn26.jpg" alt="img_1.png"></p><p>继续跟进 <code>engine.combineHandlers()</code> 函数一探究竟</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m799u5raj30mw06eaf6.jpg" alt="img_2.png"></p><p>之前接收到请求后,有个很关键的 <code>Next()</code> 函数,其遍历的所有 <code>handler</code>,都来自于路由组绑定的 <code>handlers</code></p><p>至于计算绝对路径的函数很简单,就是把上一个绝对路径和当前路由的 path 拼接到一块</p><h3 id="具体某个路由如何注册"><a href="#具体某个路由如何注册" class="headerlink" title="具体某个路由如何注册"></a>具体某个路由如何注册</h3><p>以 <code>engine.GET()</code> 函数为例,说一下一个具体的路由是如何注册到对应方法的路由组里去的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79eu2cwj30kt02z76o.jpg" alt="img_3.png"></p><p>调用 <code>engine.handler()</code> 函数完成实际的注册</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79jhejxj30od047q6k.jpg" alt="img_4.png"></p><p>其中 <code>calculateAbsolutePath()</code> 和 <code>combineHandlers()</code> 不在赘述</p><p>着重关注 <code>addRoute()</code> 是如何在路由树上添加路由</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> addRoute(method, path <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-comment">// 省略前置校验</span><br><br><span class="hljs-comment">// 检查当前 method 路由树的 root 节点是否存在,没有的话就创建为 root 节点</span><br>root := engine.trees.get(method)<br><span class="hljs-keyword">if</span> root == <span class="hljs-literal">nil</span> &#123;<br>root = <span class="hljs-built_in">new</span>(node)<br>root.fullPath = <span class="hljs-string">&quot;/&quot;</span><br>engine.trees = <span class="hljs-built_in">append</span>(engine.trees, methodTree&#123;method: method, root: root&#125;)<br>&#125;<br><span class="hljs-comment">// 重中之重,对路由树(前缀树)的处理</span><br>root.addRoute(path, handlers)<br><br><span class="hljs-comment">// 省略不重要的</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="addRoute-函数前缀树应用一探究竟"><a href="#addRoute-函数前缀树应用一探究竟" class="headerlink" title="addRoute() 函数前缀树应用一探究竟"></a>addRoute() 函数前缀树应用一探究竟</h3><p>有两个关键分支:</p><ol><li>root 为空创建前缀树根节点</li><li>root 非空,在前缀树上插入节点</li></ol><h4 id="root-为空创建空节点"><a href="#root-为空创建空节点" class="headerlink" title="root 为空创建空节点"></a>root 为空创建空节点</h4><p>以这组 RESTful api 为例说明:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/:id/children&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/play&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/dog&quot;</span>)<br></code></pre></td></tr></table></figure><p>第一次添加 <code>method</code> 的路由前缀树时,创建了空的 root 节点,在判断当前节点 <code>path</code> 长度为 0,并且没有 <code>children</code> 子节点时,就需要初始化 root 节点</p><p>直接调用 <code>insertChild()</code> 函数将当前路由插入到 root 节点当中</p><p>首先判断当前 path 是否包含通配符,例如 <code>/cat/:id</code></p><p>首次创建 root 前缀树时,不应该直接使用 <code>/cat/:id</code> 作为 <code>full path</code> 而是需要把通配符 <code>:id</code> 单独切割出来,正确的 <code>full path</code> 应该是 <code>/cat/</code></p><p>函数 <code>findWildcard()</code> 返回通配符 <code>:</code> 或者 <code>*</code> ,以及通配符规则是否符合 <code>valid</code> 和通配符所处的下标</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span></span> insertChild(path <span class="hljs-type">string</span>, fullPath <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 找到通配符的位置</span><br>wildcard, i, valid := findWildcard(path)<br><span class="hljs-comment">// 省略校验逻辑</span><br><span class="hljs-keyword">if</span> wildcard[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;:&#x27;</span> &#123; <span class="hljs-comment">// param</span><br><span class="hljs-comment">// 如果有通配符,则把通配符前面的 path 当做 root 节点的 path,而不是带有通配符的 path</span><br><span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// Insert prefix before the current wildcard</span><br>n.path = path[:i]<br>path = path[i:]<br>&#125;<br><span class="hljs-comment">// 为当前 root 节点创建带有通配符的子节点</span><br>child := &amp;node&#123;<br><span class="hljs-comment">// 通配符节点类型为 param,表示在路由树上有个通过参数来区分的路由节点</span><br>nType:    param,<br>path:     wildcard,<br>fullPath: fullPath,<br>&#125;<br><span class="hljs-comment">// 将通配符路由当做子路由添加到当前路由节点 &#x27;/cat/&#x27; 上</span><br>n.addChild(child)<br><span class="hljs-comment">// 设置当前路由节点 &#x27;/cat/&#x27; 带有通配符节点</span><br>n.wildChild = <span class="hljs-literal">true</span><br><span class="hljs-comment">// 更新路由树的指针,继续对通配符节点查找后续的路由树,例如 &#x27;/cat/:id/children`</span><br><span class="hljs-comment">// 表示列出 :id 的 cat 的所有小猫咪 :)</span><br><span class="hljs-comment">// 所以这里需要更新指针指向子节点,继续递归解析</span><br>n = child<br><span class="hljs-comment">// 注意:这里设置的是子节点的 priority 优先级属性</span><br><span class="hljs-comment">// 可以看到在对 root 节点每添加一个子路由,都会让全链路的节点 priority 值 +1</span><br><span class="hljs-comment">// 越靠近根节点的 prioriy 值越大</span><br>n.priority++<br><br><span class="hljs-comment">// 如果当前路径不是以通配符结尾, 例如 `/cat/:id/children` </span><br><span class="hljs-comment">// 那么会继续解析后续的 `/children` 为更深层次的路由子节点</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(wildcard) &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[<span class="hljs-built_in">len</span>(wildcard):]<br><span class="hljs-comment">// 新添加的节点,其 prioriy 值从 1 开始计算,每过一个父节点都比下面的孩子节点大 1</span><br>child := &amp;node&#123;<br>priority: <span class="hljs-number">1</span>,<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n = child<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-comment">// 添加中间函数</span><br>n.handlers = handlers<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// 省略</span><br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>对于第一个带有通配符的路由 <code>/cat/:id</code></p><p>在切割 <code>:id</code> 之后,得到路由为 <code>:id</code> 的通配符子节点</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79o3oj4j30bp050gnm.jpg" alt="img_5.png"></p><h4 id="root-节点非空-往路由前缀树继续添加子路由"><a href="#root-节点非空-往路由前缀树继续添加子路由" class="headerlink" title="root 节点非空,往路由前缀树继续添加子路由"></a>root 节点非空,往路由前缀树继续添加子路由</h4><p>回到 <code>addRoute()</code> 函数,继续看 root 非空的情况是如何处理的</p><p>首先一上来就是一个 100 行的无限循环,代码有点长,仔细解读</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">addRoute</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 从 root(n) 节点开始查找最长前缀的位置索引 i</span><br><span class="hljs-comment">// 这个函数很简单,双指针遍历比较找到第一个不相等的位置</span><br>i := longestCommonPrefix(path, n.path)<br><br><span class="hljs-comment">// 前面说过 gin 使用的紧凑型的前缀树,而非标准的字典前缀树,节省节点内存分配</span><br><span class="hljs-comment">// 如果当前节点是插入节点的子节点,则需要调整父子节点关系</span><br><span class="hljs-comment">// 例如已经插入 即 n = /cat/play/ball</span><br><span class="hljs-comment">// 现在插入 /cat/play</span><br><span class="hljs-comment">// 最后 n 变成 /cat/play, n.children = /ball</span><br><span class="hljs-comment">// 同理,如果继续添加路由 /cat</span><br><span class="hljs-comment">// n = /cat, n.c = /cat/play, n.c.c = /cat/play/ball</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(n.path) &#123;<br>child := node&#123;<br>path:      n.path[i:],<br>wildChild: n.wildChild,<br>indices:   n.indices,<br>children:  n.children,<br>handlers:  n.handlers,<br>priority:  n.priority - <span class="hljs-number">1</span>,<br>fullPath:  n.fullPath,<br>&#125;<br><br>n.children = []*node&#123;&amp;child&#125;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices = bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;n.path[i]&#125;)<br>n.path = path[:i]<br>n.handlers = <span class="hljs-literal">nil</span><br>n.wildChild = <span class="hljs-literal">false</span><br>n.fullPath = fullPath[:parentFullPathIndex+i]<br>&#125;<br><span class="hljs-comment">// 如果在先后顺序上符合父子关系,可以直接在节点 n 上创建对应的子节点</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[i:]<br>c := path[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">// 处理参数节点后带有 &#x27;/&#x27; 的情况</span><br><span class="hljs-keyword">if</span> n.nType == param &amp;&amp; c == <span class="hljs-string">&#x27;/&#x27;</span> &amp;&amp; <span class="hljs-built_in">len</span>(n.children) == <span class="hljs-number">1</span> &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>n = n.children[<span class="hljs-number">0</span>]<br>n.priority++<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// 处理带有公共前缀的节点</span><br><span class="hljs-comment">// 解释一下 indices 的作用,这个字符串保存当前节点下所有孩子节点最长公共前缀之后出现的第一个字符</span><br><span class="hljs-comment">// 例如 /cat/run</span><br><span class="hljs-comment">// 添加 /cat/run_with_me</span><br><span class="hljs-comment">// run 和 run_with_me 有着公共前缀 run</span><br><span class="hljs-comment">// 这样 /cat/run_with_me 就会被继续拆分为子节点 _with_me</span><br><span class="hljs-comment">// 父节点为 /cat/run =&gt; _with_me</span><br><br><span class="hljs-comment">// 在举例,若有 /person/eat 和 /person/laugh</span><br><span class="hljs-comment">// 此时 /person 节点有 indince = le</span><br><span class="hljs-comment">// 添加新路由 /person/lying,此时发现 lying 和 l 有公共前缀 l</span><br><span class="hljs-comment">// 就会将 /laugh 节点拆分为 /l 作为父节点,包含两个子节点 augh 和 ying</span><br><span class="hljs-comment">// 最终 /person/ =&gt; eat 和 l</span><br><span class="hljs-comment">// /l =&gt; augh 和 ying ,且 a 的 indince = ay,eat 没有孩子,所以没有 indinces</span><br><span class="hljs-keyword">for</span> i, max := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(n.indices); i &lt; max; i++ &#123;<br><span class="hljs-keyword">if</span> c == n.indices[i] &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>i = n.incrementChildPrio(i)<br>n = n.children[i]<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 如果插入节点和当前节点不在同一个父节点上,则直接插入到前缀树里</span><br><span class="hljs-keyword">if</span> c != <span class="hljs-string">&#x27;:&#x27;</span> &amp;&amp; c != <span class="hljs-string">&#x27;*&#x27;</span> &amp;&amp; n.nType != catchAll &#123;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices += bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;c&#125;)<br>child := &amp;node&#123;<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n.incrementChildPrio(<span class="hljs-built_in">len</span>(n.indices) - <span class="hljs-number">1</span>)<br>n = child<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> n.wildChild &#123;<br><span class="hljs-comment">// 如果当前节点是参数节点,往参数节点后面添加子节点</span><br>n = n.children[<span class="hljs-built_in">len</span>(n.children)<span class="hljs-number">-1</span>]<br>n.priority++<br><br><span class="hljs-comment">// Check if the wildcard matches</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(path) &gt;= <span class="hljs-built_in">len</span>(n.path) &amp;&amp; n.path == path[:<span class="hljs-built_in">len</span>(n.path)] &amp;&amp;<br><span class="hljs-comment">// Adding a child to a catchAll is not possible</span><br>n.nType != catchAll &amp;&amp;<br><span class="hljs-comment">// Check for longer wildcard, e.g. :name and :names</span><br>(<span class="hljs-built_in">len</span>(n.path) &gt;= <span class="hljs-built_in">len</span>(path) || path[<span class="hljs-built_in">len</span>(n.path)] == <span class="hljs-string">&#x27;/&#x27;</span>) &#123;<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// Wildcard conflict</span><br>pathSeg := path<br><span class="hljs-keyword">if</span> n.nType != catchAll &#123;<br>pathSeg = strings.SplitN(pathSeg, <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-number">2</span>)[<span class="hljs-number">0</span>]<br>&#125;<br>prefix := fullPath[:strings.Index(fullPath, pathSeg)] + n.path<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;&#x27;&quot;</span> + pathSeg +<br><span class="hljs-string">&quot;&#x27; in new path &#x27;&quot;</span> + fullPath +<br><span class="hljs-string">&quot;&#x27; conflicts with existing wildcard &#x27;&quot;</span> + n.path +<br><span class="hljs-string">&quot;&#x27; in existing prefix &#x27;&quot;</span> + prefix +<br><span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br><br>n.insertChild(path, fullPath, handlers)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// Otherwise add handle to current node</span><br><span class="hljs-keyword">if</span> n.handlers != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;handlers are already registered for path &#x27;&quot;</span> + fullPath + <span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br>n.handlers = handlers<br>n.fullPath = fullPath<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果后插入的节点在 <strong>关系上</strong> 是先插入节点的父节点,则需要调整父子节点的关系</p><p>原先的父节点 <code>/cat/play/ball</code> ,后插入的节点 <code>/cat/play</code></p><p>从关系上来说,后者应该是前者的前驱 <code>/cat/play</code> ; 前者截断后变为子节点 <code>/ball</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79vblj0j30a4055jsx.jpg" alt="img_6.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m7aa05qlj30bb0a8q6w.jpg" alt="img_7.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>gin 使用紧凑前缀树实现路由树,减少树节点的个数,提高查找效率</li><li>gin 对通配符 :xxx 和 *xxx 两种类型的参数有些特殊限制,尤其小心在 *xxx&#x2F;other 这种路由,会导致 &#x2F;other 节点失效,具体原因是因为 *xxx 节点被设置为 cathAll 类型,<br>其后面的路由不再匹配,全部由 *xxx 提供服务</li><li>其中 priority 字段的设计,是为了让出现次数更多的路由前缀尽可能早的匹配到请求上,提升前缀树检索的性能</li><li>其中 indinces 的设计,是为了将路由子节点尽可能多的拆分出公共前缀,这样做的目的也是为了减少路由树中路由节点的个数,提升检索性能</li></ol><p>总之,还是有很多细节没有列举完成,包括对通配符节点的特殊处理和判断,都没有一一解释代码了</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (一)</title>
    <link href="/2022/10/28/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/"/>
    <url>/2022/10/28/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h2 id="走进-Gin-的大门"><a href="#走进-Gin-的大门" class="headerlink" title="走进 Gin 的大门"></a>走进 Gin 的大门</h2><h3 id="启动-gin-服务"><a href="#启动-gin-服务" class="headerlink" title="启动 gin 服务"></a>启动 gin 服务</h3><p>启动 gin 服务很简单,代码里面只需要两行</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/gin-gonic/gin&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>r := gin.Default()<br>r.Run() <span class="hljs-comment">// listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)</span><br>&#125;<br></code></pre></td></tr></table></figure><p>跟进 <code>r.Run()</code> 方法一探究竟</p><h3 id="Run-方法"><a href="#Run-方法" class="headerlink" title="Run() 方法"></a>Run() 方法</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvpgnuj30m709ljx3.jpg" alt="img01.png"></p><p>可以看到 <code>Run()</code> 方法大概做了 3 件事</p><ol><li>解析配置的受信任 CIDRs 地址</li><li>如果有在启动时指定监听的地址,就解析对应 <code>addr</code> 地址</li><li>传入解析后的 <code>addr</code> 地址,并监听这个地址上的 http 事件</li></ol><p>通过上面的注释可知,其本质是 <code>http.ListenAndServe(addr, router)</code> 的一个实现</p><p>且 <code>Run()</code> 方法是一个阻塞方法,将会阻塞调用协程,除非异常发生</p><p>了解过 <code>Socket</code> 编程的应该都知道, <code>socket.Accept()</code> 就是一个阻塞方法,它会一直阻塞监听套接字绑定的 ip 和端口,直到收到请求数据才返回</p><p>可见 <code>http.ListenAndServe()</code> 也是一直阻塞并监听端口事件发生的</p><h3 id="http-ListenAndServe"><a href="#http-ListenAndServe" class="headerlink" title="http.ListenAndServe"></a>http.ListenAndServe</h3><p>这是 gin 的核心函数,其依赖于 go 语言内置的 <code>net</code> 库实现</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvnvo2j30ir06ladw.jpg" alt="img02.png"></p><p>注意,外面传入的是 <code>gin.engine</code> 到这里变成了 go 语言 <code>net</code> 库的 <code>Handler</code> 接口对象</p><p>可以看到的是 <code>gin.engine</code> 是实现了 <code>Hanler</code> 接口的</p><p>并且后续所有的 <code>request</code> 请求和 <code>response</code> 响应也都是通过这个 <code>Handler</code> 接口实现的</p><h3 id="gin-如何通过-Handler-接口实现接收和响应请求的"><a href="#gin-如何通过-Handler-接口实现接收和响应请求的" class="headerlink" title="gin 如何通过 Handler 接口实现接收和响应请求的"></a>gin 如何通过 Handler 接口实现接收和响应请求的</h3><p>跟进 <code>Handler</code> 接口,找到对应的 gin 实现 engine 对象</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img03.png"></p><p><code>engin.pool.Get()</code> 获取一个 gin 自己封装的 <code>Context</code> 对象,注意这里不是 go 原生的 <code>Context</code> 对象</p><p>可以看到 gin 使用了池化技术,做到内存复用,避免频繁的创建上下文</p><p>初始化 <code>Context</code> 对象时,把接收到的请求 <code>req</code> 也放到上下文里</p><p>进一步跟进 <code>handleHTTPRequest()</code> 函数看看 gin 究竟是如何处理请求的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> handleHTTPRequest(c *Context) &#123;<br>httpMethod := c.Request.Method <span class="hljs-comment">// 解析 method</span><br>rPath := c.Request.URL.Path    <span class="hljs-comment">// 解析 url path</span><br>unescape := <span class="hljs-literal">false</span><br><span class="hljs-comment">// &#123;一些对 url path 的额外处理&#125;</span><br><br><span class="hljs-comment">// gin 维护了所有 method 的路由树集合</span><br>t := engine.trees<br><span class="hljs-keyword">for</span> i, tl := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(t); i &lt; tl; i++ &#123;<br><span class="hljs-comment">// 遍历路由树集合找到当前 method 对应的的路由树</span><br><span class="hljs-keyword">if</span> t[i].method != httpMethod &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>root := t[i].root<br><span class="hljs-comment">// 从 root 节点开始查找路由树,直到查找到 path 对应的路由</span><br>value := root.getValue(rPath, c.params, unescape)<br><span class="hljs-keyword">if</span> value.params != <span class="hljs-literal">nil</span> &#123;<br>c.Params = *value.params<br>&#125;<br><span class="hljs-comment">// 如果路由有配置 handler 函数</span><br><span class="hljs-keyword">if</span> value.handlers != <span class="hljs-literal">nil</span> &#123;<br>c.handlers = value.handlers<br>c.fullPath = value.fullPath<br><span class="hljs-comment">// Next() 函数会依次执行路由配置的所有 handler 函数</span><br>c.Next()<br>c.writermem.WriteHeaderNow()<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里有两个关键点 <code>engine.trees</code> 路由树 和 <code>Next()</code> 函数</p><h3 id="先来看-Next-函数"><a href="#先来看-Next-函数" class="headerlink" title="先来看 Next() 函数"></a>先来看 Next() 函数</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvsw2xj30io05y0vq.jpg" alt="img04.png"></p><p>还记得之前的 <code>gin.engine</code> 对象吗? <code>engine</code> 实现了 <code>ServeHTTP</code> 接口,在里面封装了 gin 关于 http 请求的处理</p><p>其中 <code>c.reset()</code> 初始化 <code>Context</code> 上下文对象的时候,有设置 index 的值为 -1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmytfj309203fgm8.jpg" alt="img05.png"></p><p>这说明还没有 <code>handler</code> 函数处理的时候,<code>Context</code> 上下文里面保存的处理索引是从 <code>-1</code> 开始计算</p><p><code>Next()</code> 函数里,一来就让 index 自增 <code>c.index++</code> 后 index &#x3D; 0,说明从第 0 个 <code>handler</code> 函数开始依次执行</p><p>而 <code>handleHTTPRequest()</code> 函数在从路由树当中找到请求对应的路由节点后,如果发现这个路由有配置过 <code>handler</code> 函数,则会把路由配置的 <code>handler</code> 函数全部赋值给 <code>Context</code> 上下文 <code>c</code> 里</p><p>这样就相当于通过上下文 <code>c</code> 依次执行路由配置的 <code>handler</code> 函数处理请求,而每次执行 <code>handler</code> 之后,都会使 <code>index</code> 自增</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br><span class="hljs-comment">// 关注核心代码</span><br>c.handlers[c.index](c)<br><span class="hljs-comment">// c.index 表示当前待执行的索引</span><br><span class="hljs-comment">// c.handlers[] 数组</span><br><span class="hljs-comment">// c.handlers[c.index] 相当于取出处于 index 的 handler 函数</span><br><span class="hljs-comment">// 而 handler 函数的签名是 func (c *Context)</span><br><span class="hljs-comment">// 可以理解为 c.handlers[c.index] = func (c *Context)</span><br><span class="hljs-comment">// 所以 c.handlers[c.index](c) 相当于把 c 又当做参数传给了 handler 函数</span><br>&#125;<br></code></pre></td></tr></table></figure><p>除非设置了 <code>AbortIndex</code> 的值终止 <code>handlers</code> 的遍历,否则会执行完所有配置的 <code>handlers</code> 函数才会结束请求的处理</p><h3 id="engine-trees-路由树"><a href="#engine-trees-路由树" class="headerlink" title="engine.trees 路由树"></a>engine.trees 路由树</h3><p>接下来在看看路由树的是怎么实现的</p><p>一路跟进去看源码</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmodrj308903yq3f.jpg" alt="img06.png"></p><p>可以看到 gin 维护了一个 <code>[]methodTree</code> 数组,数组里面每个元素都是一个路由树节点对象,分别保存了当前路由的方法 <code>method</code> 和当前路由的根节点 <code>root</code></p><p>继续跟进树节点 <code>node</code> 看看怎么实现的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvxqjkj30m5062q5u.jpg" alt="img07.png"></p><p>其实路由树就是一棵 <strong>紧凑前缀树</strong></p><p>前缀树利用字符串的公共前缀来减少查询时间,而路由则天生符合前缀的特性</p><p>例如有以下几个路由:</p><ol><li>&#x2F;</li><li>&#x2F;order</li><li>&#x2F;order&#x2F;:name</li><li>&#x2F;order&#x2F;:id</li></ol><p>可以看到这些路由都有根节点 <code>/</code> ,同时下面三个路由都有重复节点 <code>/order</code></p><p>普通的前缀树保存每个字符,而 gin 使用 <strong>紧凑前缀树</strong> 保存每个路由节点,减少了内存的使用,提高查询效率</p><p>此时生成的路由前缀树如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvvkzyj307007z74p.jpg" alt="img08.png"></p><p>通过路由树可以快速的检索到对应的的路由节点,至于路由如何注册在这里暂且不表</p><h3 id="回到-handleHTTPRequest-方法"><a href="#回到-handleHTTPRequest-方法" class="headerlink" title="回到 handleHTTPRequest() 方法"></a>回到 handleHTTPRequest() 方法</h3><p>在经历了路由检索, <code>handler</code> 函数的处理,此时一笔请求就已经全部执行完毕了</p><p>通过 <code>c.WriteHeaderNow</code> 将 http 状态写回 header 后,当前请求的处理协程结束</p><p>主协程仍然阻塞在 <code>accept()</code> 监听方法上,通过 channel 来启动协程继续处理后续的请求</p><p>至此,一笔请求就被完整的处理完并返回给调用方</p><p>剩余的细节:</p><ol><li>go 内置的 net 网络通信库,如何建立连接,监听请求,前置处理</li><li>gin 注册路由如何生成路由树</li></ol><p>后面再说吧</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/10/27/hello-world/"/>
    <url>/2022/10/27/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
