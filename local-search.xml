<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>(十)mysql 索引失效的场景</title>
    <link href="/2022/11/05/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/"/>
    <url>/2022/11/05/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-当中索引失效的场景"><a href="#mysql-当中索引失效的场景" class="headerlink" title="mysql 当中索引失效的场景"></a>mysql 当中索引失效的场景</h2><h3 id="索引字段使用函数"><a href="#索引字段使用函数" class="headerlink" title="索引字段使用函数"></a>索引字段使用函数</h3><p>思考下 mysql 为何能够通过索引快速定位数据,是因为 <code>B+</code> 同层节点的有序性</p><p>如果说某些操作打破了这种有序性,那么就无法利用索引树来检索数据了,只能走全表扫描</p><p>例如 <code>select a from t where sum(a) &gt; 5</code> 这种对索引列做函数操作的,很有可能破坏索引的有序性</p><p>其实并不是说 mysql 对于这种函数操作完全放弃了索引,即使走全表扫描,仍然可以优化具体使用什么索引树来做全盘扫描</p><p>如果字段 <code>a</code> 上建立了索引,那么扫描索引 <code>a</code> 显然比扫描主键索引更快,这是因为 <code>索引覆盖</code> 带来的优化,不用取出整行数据,索引 <code>a</code> 已经包含了列 <code>a</code> 所需要的所有数据</p><p>同样的,还有更加隐蔽的操作也会导致索引失效</p><p>例如 <code>select * from t where id + 1 = 10000</code> 这里 <code>+1</code> 不会破坏有效性,但是仍然无法通过 id 定位到 <code>9999</code> 这一行 因为 mysql 无法计算 <code>多少 id +1 才能等于 10000</code><br>,还是需要全表扫描</p><p>如果改为 <code>where id = 10000 -1</code> 那么即可快速通过索引定位到 <code>9999</code> 行</p><h3 id="隐式类型转换会导致索引失效"><a href="#隐式类型转换会导致索引失效" class="headerlink" title="隐式类型转换会导致索引失效"></a>隐式类型转换会导致索引失效</h3><p>假如存在一个 <code>varchar()</code> 类型的列 <code>order_id</code> 上建有索引, 以下 sql 会让索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> order_id <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>注意到 <code>order_id</code> 本身是 <code>varchar()</code> 类型,但是 sql 语句里面却是用 <code>int</code> 整型变量在做比较,这会导致发生 <strong>隐形类型转换</strong> 从而导致索引失效</p><p><strong>mysql 将数字和字符串作为比较的话,会把字符串转换为数字</strong></p><p>为何隐式类型转换会导致索引失效</p><p>在了解到字符串如果和数字作对比,会把字符串转换为数字之后,上面 sql 的本质就发生了改变</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> <span class="hljs-built_in">CAST</span>(order_id <span class="hljs-keyword">AS</span> <span class="hljs-type">int</span>) <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>可以看到这里的隐式类型转换实际上是对字符串调用了 <code>CAST()</code> 函数,而之前说过,如果在索引列上有函数操作的话,可能会破坏索引树的有序性,从而 mysql 不使用索引改用全表扫描</p><p>同样的,如果在做关联查询的时候,两个连接的字段的字符编码不相同,也会触发隐式类型转换,从而导致索引失效</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>如果存在联合索引,则查询列里面的索引必须从最左侧开始且不允许跳过中间的索引列</p><p>例如存在联合索引 <code>a,b,c</code> ,如下 sql 语句属于 <strong>全值匹配</strong> 可以命中索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>这里跟查询列的顺序无关,只要在逻辑上满足索引列从左到右的匹配顺序即可,myslq 优化器会在内部自动调整索引的顺序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>非全值匹配</strong> 只要满足从左到右的前缀即可</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>但是不能出现缺少或者跳过,这样会导致最左前缀原则失效,从而导致索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 从左往右缺少 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <br><span class="hljs-comment">-- 跳过 b</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>同样对于模糊查找也必须满足最左前缀原则</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 模糊检索最左前缀 a 是确定的,后面 % 才是通配符,符合最左前缀原则,可以命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;a%&#x27;</span><br><br><span class="hljs-comment">-- 最左前缀 % 是通配符,属于不确定的,破坏了最左前缀原则,不能命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;%a&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="使用-OR-关键字"><a href="#使用-OR-关键字" class="headerlink" title="使用 OR 关键字"></a>使用 OR 关键字</h3><p>例如只有列 <code>a</code> 有索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>此时会导致索引失效,假设只有 <code>where b = 2</code> 此时肯定是全表扫描,已经得到 <code>a,b</code> 的值,就不用再遍历 <code>a</code> 的索引了; 否则使用 <code>a</code> 的索引后还需要一次全表扫描才能判断 <code>b</code> 的条件</p><p>使用 <code>or</code> 关键字的时候,必须保证两边都有索引才可以</p><h3 id="负向查询"><a href="#负向查询" class="headerlink" title="负向查询"></a>负向查询</h3><p>常见的负向查询有 <code>NOT, IS NOT NULL, !=, NOT IN, NOT LIKE</code> 等</p><p>这些查询不一定会导致索引失效,mysql 在实际执行的过程当中,根据优化器的判断决定是否选择索引,亦或者是全表扫描</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(九)mysql order by 原理细节</title>
    <link href="/2022/11/05/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/"/>
    <url>/2022/11/05/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<h2 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h2><p>假设有一张城市表,记录了城市里面每个人的名字,你年龄的信息</p><p>现在需要对城市是 <code>杭州</code> 的所有人,按照年龄排序后返回前 1000 人</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> city,name,age <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> city<span class="hljs-operator">=</span><span class="hljs-string">&#x27;杭州&#x27;</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> name limit <span class="hljs-number">999</span>;<br></code></pre></td></tr></table></figure><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>为了避免扫描全表,很自然的在 <code>where</code> 语句查询的字段 <code>city</code> 上加上索引</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsbrl2wj30th0fbjuw.jpg" alt="img.png"></p><p>使用 <code>explain</code> 指令查看执行情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsiczttj31bh041jxx.jpg" alt="img_1.png"></p><p>在 <code>extra</code> 一列里面可以看到 <code>using filesort</code> 表示进行了排序,实际 mysql 会为每个需要排序的线程分配一块内存区域专门用来加速排序,称为 <code>sort_buffer</code></p><p>一个完整的查询流程如下:</p><ol><li>初始化 <code>sort_buffer</code> ,里面有 3 个字段分别是 <code>city,name,age</code> </li><li>从 <code>city</code> 索引开始查找,找到第一个满足条件的主键 id ,即 <code>id_x</code></li><li>回表得到 <code>id_x</code> 对应的完整数据,取出 <code>name,age</code> 和 <code>city</code> 一起放入 <code>sort_buffer</code></li><li>从 <code>city</code> 索引继续取出下一个满足条件的主键 id,重复 34 过程,直到 <code>city</code> 不再满足条件</li><li>对 <code>sort_buffer</code> 里面的所有数据做快速排序</li><li>将排序结果前 1000 条返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsnhzo9j30m60gbtd4.jpg" alt="img_2.png"></p><p>需要注意的是,由于每次分配的 <code>sourt_buffer</code> 大小是固定的,其不一定能够完全放下所有需要排序的记录; 所以 mysql 会根据实际情况,在内存中完成排序,或者在磁盘上完成排序; 如果在磁盘上进行排序,就不得不依赖磁盘创建临时文件辅助排序</p><p>打开 msyql 的 <code>optimizer_trace</code> 查看优化器的输出</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt1fzvoj30mt05twgy.jpg" alt="img_3.png"></p><p>可以看到在磁盘排序时,使用了 12 个临时文件,这是因为在磁盘上排序一般使用 <strong>归并排序</strong> ,将整个数据集分为若干个子文件,对子文件进行排序后再合并为一个有序的大文件</p><h3 id="rowid-排序"><a href="#rowid-排序" class="headerlink" title="rowid 排序"></a>rowid 排序</h3><p>上面的全字段排序会将所有需要排序的字段取出放到 <code>sort_buffer</code> 里面,如果字段多,数据行多的话,就会导致 <code>sort_buffer</code> 里面要保存的数据太多,由于内存是有限制的,所以很快 <code>sort_buffer</code> 就会被占满,这样就需要把数据分散到多个临时文件里面做归并排序,其性能会差很多</p><p>可以通过修改 mysql 控制排序数据行长度的参数,让 myslq 选择另一种排序方式 <code>rowid</code> 排序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> max_length_for_sort_date<span class="hljs-operator">=</span><span class="hljs-number">16</span><br></code></pre></td></tr></table></figure><p>如果单行总长度超过这个值,就该用 <code>rowid</code> 排序</p><p><code>rowid</code> 排序不把单行所有字段放入 <code>sort_buffer</code> 里面,仅仅把主键 id 和需要排序的列放入 <code>sort_buffer</code>, 由于 <code>sort_buffer</code> 里面缺少了单行的所有信息,所以不能够在完成排序后直接返回,需要多添加一步回表查询的过程</p><p>当 <code>sort_buffer</code> 完成排序后,遍历前 1000 条记录,通过主键 id 再次回表查询得到所有的数据行返回</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugst18g8j30n10hhtf6.jpg" alt="img_4.png"></p><h3 id="全字段排序和-rowid-排序"><a href="#全字段排序和-rowid-排序" class="headerlink" title="全字段排序和 rowid 排序"></a>全字段排序和 rowid 排序</h3><p>如果 mysql 检测到内存足够,就会使用全字段排序,因为这样能够节省一次回表的查询开销</p><p>如果内存不足,则会改用 <code>rowid</code> 排序,这样可以提高一次性排序的行数,但是对应的代价就是多了一次回表查询</p><p>总的来说,mysql 体现了一个原则就是: 内存够用就要尽可能利用内存,减少磁盘的访问</p><h3 id="使用索引覆盖来加速排序过程"><a href="#使用索引覆盖来加速排序过程" class="headerlink" title="使用索引覆盖来加速排序过程"></a>使用索引覆盖来加速排序过程</h3><p>如果查询的列天然有序,则可以进一步提高 <code>order by</code> 语句的效率</p><p>对于仍然是查询 <code>city</code>, <code>name</code>, <code>age</code> 的 sql,如果在 <code>city</code> 和 <code>name</code> 上建立联合索引</p><p>这样 <code>where</code> 语句使用 <code>city</code> 索引检索的时候, <code>name</code> 也是自然有序的,这样可以节省排序的步骤,只需要一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt8teb7j30lq08xacf.jpg" alt="img_5.png"></p><p>如果在 <code>city</code>, <code>name</code>, <code>age</code> 三个字段上建立联合索引,这样检索的时候,索引树里面就已经全部包含了所有需要查询的数据,而且自然有序,这样的索引覆盖还能再减少一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugtf3quvj30he09cmyt.jpg" alt="img_6.png"></p><h3 id="随机排序"><a href="#随机排序" class="headerlink" title="随机排序"></a>随机排序</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand()<br></code></pre></td></tr></table></figure><p>当添加上 <code>rand()</code> 随机函数之后,如果再使用 <code>explain</code> 查看执行过程的话,会发现 <code>extra</code> 列上多了个 <code>using temporary</code> 表示当前查询会使用 <strong>临时表</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsdqh5nj307w01yq3k.jpg" alt="img_7.png"></p><p>对于带有临时内存表的排序,mysql 应当选择何种排序算法:</p><ol><li>如果是 <code>InnoDB</code> 为了减少磁盘访问,优先选择全字段排序</li><li>如果是带有临时内存表的排序,回表相当于访问内存,其性能几乎不会受到影响,此时会选择 <code>rowid</code> 排序</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> word <span class="hljs-keyword">from</span> t <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand() limit3<br></code></pre></td></tr></table></figure><p>其排序的查询过程如下:</p><ol><li>创建一张临时内存表,表里面保存两个字段 浮点数 <code>R</code> 和 字符串 <code>W</code></li><li>从主表中按照主键顺序取出 <code>word</code>,并且调用 <code>rand()</code> 函数生成一个随机浮点数,将这个随机浮点数和 <code>word</code> 放入内存表的 <code>R</code> 和 <code>W</code> 字段</li><li>在内存表上排序,初始化 <code>sort_buffer</code>, 其包含两个字段 浮点数和字符串</li><li>从内存表中一行一行地取出 <code>R</code> 和 <code>位置信息</code> 将其放入 <code>sort_buffer</code>,然后在 <code>sort_buffer</code> 里面完成排序</li><li>排序完成后,取前 3 个数据返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhskxbg6j30o30hrjvf.jpg" alt="img_8.png"></p><p>其中内存表的 <code>内存信息</code> 就是 mysql 为我们隐式生成的 <code>rowid</code>, 其实如果一张表没有显式指出主键的话,mysql 就会隐式的创建 <code>rowid</code> 当做主键 id 使用</p><p>如果单行数据超过了 mysql 配置的最大单行数据长度,则全字段排序会被转换为 <code>rowid</code> 排序,会导致在磁盘上通过临时文件进行归并排序</p><p>对于 <strong>随机排序</strong> 且还带有 <code>limit</code> 关键字的情况,归并排序完成后所有的数据都是有序的,此时只用取前 <code>limit</code> 个,但是实际上除了前 <code>limit</code> 个以外的数据,并不关系其是否有序,所以 mysql 在 5.6 版本引入了 <code>堆排序</code> </p><p>构造最大堆或者最小堆,初始化容量为 <code>limit</code> 个元素,将后续的元素依次添加到堆里,完成遍历后,堆里就保留了 <strong>最大</strong> 或者 <strong>最小</strong> 的前 <code>limit</code> 个元素,而后面的则无需关心是否有序</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsquhy8j30o00dqagy.jpg" alt="img_9.png"></p><p>无论如何,使用 <code>order by rand()</code> 都会导致复杂的排序计算</p><p>优雅的随机排序应当使用如下操作</p><ol><li>统计表的总行数 <code>C</code></li><li>计算随机数 <code>R = floor(C*rand())</code> 其中 <code>floor()</code> 函数负责向下取整</li><li><code>select xxxx limit Y,1</code> 表示从 <code>Y</code> 开始取出 <code>offer = </code> 即 <code>Y+1</code> 行</li></ol><p>若要得到 <code>X</code> 个随机记录,则将上述操作重复 <code>X</code> 次,这样可以避免主键空洞导致的伪随机</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(八)mysql count 函数机制</title>
    <link href="/2022/11/05/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="count-的实现原理"><a href="#count-的实现原理" class="headerlink" title="count(*) 的实现原理"></a>count(*) 的实现原理</h3><ol><li>在 <code>Myisam</code> 上,每个表的总行数保存在了磁盘上,因此 <code>count(*)</code> 可以在 O(1) 的时间复杂度之内得到,效率非常高</li><li>在 <code>InnoDB</code> 上,不会单独保存表的总行数,因此只能通过遍历所有数据,完成统计得到</li></ol><p>为什么 <code>InnoDB</code> 不保存总记录数,因为 <code>MVCC</code> 多版本并发控制导致,即使每次执行 <code>count(*)</code> 语句时,快照读返回的行数都不一定是准确的</p><p>例如事务 A 快照读的时候得到行数 10000,在这个过程中事务 B 插入了 1 行,因为快照读的原因事务 A 并不能观察到这 1 行,所以返回的行数并不准确</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubro5pldj30ne08yjuu.jpg" alt="img.png"></p><p>具体 mysql 是怎么实现 <code>count(*)</code> 的计算过程呢</p><p>由于只能一行一行地遍历所有数据,那么就需要从索引树的叶子节点的链表开始遍历; 前面说过,聚簇索引的叶子节点保存的是 <code>主键 id 和完整数据行</code>; 而非聚簇索引的叶子节点保存的是 <code>索引列和主键 id</code>; 这样对于相同大小的页,后者能够放下更多的节点</p><p>因此 myslq 实际上在做 <code>count(*)</code> 的时候,会选择最小的索引树进行遍历,加快遍历的速度</p><h3 id="使用缓存系统保存总数"><a href="#使用缓存系统保存总数" class="headerlink" title="使用缓存系统保存总数"></a>使用缓存系统保存总数</h3><p>如果有个业务需要频繁的访问表的总记录数,而数据又非常多,那么 <code>count(*)</code> 势必导致性能问题</p><p>考虑设计一个缓存系统来保存总数,每次增删记录的时候,同时更新缓存里面的总数</p><p>实际上并不能通过 redis 来完成这个缓存系统,因为总是存在数据不一致,有点类似幻读的感觉,例如下面两个例子</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubru7q69j30nc08yaay.jpg" alt="img_1.png"></p><p>实际上会话 B 在查询最近 100 条记录的时候,会把会话 A 插入的新数据查询出来,但是会话 B 访问 redis 的时候总计数却不包含这一条,因为此时会话 A 还没来得及更新 redis</p><p>如果反过来</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubrzdpldj30n809pt9j.jpg" alt="img_2.png"></p><p>会导致会话 B 从 redis 里面已经得到的总数已经新增了一条,但是最近 100 条记录里面却不包含这新增的一条,再次发生数据不一致的问题</p><p>这些都是因为缓存系统无法完全保证数据实时一致性,考虑使用数据库当做缓存系统使用</p><p>将对 redis 的操作更换为数据库操作,同时为其加上事务</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubs4hin0j30n50ci0ts.jpg" alt="img_3.png"></p><p>根据 <code>MVCC</code> 会话 B 读到的总数并不包含会话 A 新增的总数,而且前 100 条记录也不包含回话 A 新增的数据; 这是由 <code>MVCC</code> 的快照读保证的一致性</p><h3 id="不同的-count-函数使用方式"><a href="#不同的-count-函数使用方式" class="headerlink" title="不同的 count 函数使用方式"></a>不同的 count 函数使用方式</h3><p>不仅仅有 <code>count(*)</code> 能够统计行数,还有 <code>count(1)</code>, <code>count(主键)</code>, <code>count(字段)</code> 等等</p><p>其原理都差不多,<code>count()</code> 本身是一个聚合函数,起作用就是对于返回的结果集进行遍历,如果参数不是 <code>NULL</code> 就将结果值+1,所以上面那么多不同的 <code>count()</code> 操作,其本质就是在计算返回的结果集对应的参数不是 <code>NULL</code> 的总数</p><p>记住以下原则 <code>Server</code> 层要什么,存储引擎就给什么</p><ul><li><code>count(主键)</code> 存储引擎遍历整张表,把每一行的主键 <code>id</code> 取出来返回给 <code>Server</code> 层将,然后 <code>Server</code> 判断是否为 <code>NULL</code> 并计数</li><li><code>count(1)</code> 存储引擎遍历整张表,但是不取具体值,而是对每一行返回一个 1,由 <code>Server</code> 层判断是否为 <code>NULL</code> 并计数</li><li><code>count(字段)</code> 如果这个字段定义为 <code>NOT NULL</code> 非空的话,原理同 <code>count(主键)</code>; 如果定义允许 <code>NULL</code>,则需要对每一行判断是否为 <code>NULL</code> 后计数</li><li><code>count(*)</code> 优化器做了专门的优化,不会取所有值</li></ul><p>从性能层面来说 : <code>count(*) ≈ count(1) &gt; count(主键) &gt; count(字段)</code></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(七)mysql 表空间回收</title>
    <link href="/2022/11/05/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/"/>
    <url>/2022/11/05/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="表空间的存储设置"><a href="#表空间的存储设置" class="headerlink" title="表空间的存储设置"></a>表空间的存储设置</h3><p>首先有个设置 <code>innodb_file_per_table</code> 表示是否把表数据存储为单个文件,否则的话就放在共享表空间里</p><p>明确一点,单独存放为一个文件更好,因为这样更便于管理; 而且 <code>drop</code> 命令执行时会删除对应的表文件,如果放在共享空间里, <code>drop</code> 命令不会回收表空间</p><h3 id="delete-语句为何不会回收表空间"><a href="#delete-语句为何不会回收表空间" class="headerlink" title="delete 语句为何不会回收表空间"></a>delete 语句为何不会回收表空间</h3><p><strong>可以结合前面讲的索引复习</strong>, 都知道 mysql 的索引是用 <code>B+</code> 树实现的,由于 <code>B+</code> 树也是一种自平衡的树,所以在对某些索引进行删除或者插入的时候,由于单个节点存储的索引有限,势必会导致单个节点的分裂或者多个节点的重组</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatmc03pj30ex0bjjt2.jpg" alt="img.png"></p><p>假设需要删除 <code>R4</code> 这条记录,此时并不会实际操作磁盘,而是把页里面的 <code>R4</code> 标记为删除,这是一种 <strong>软删除</strong> 或者叫做 <strong>逻辑删除</strong></p><p>后面如果插入 <code>300</code> 到 <code>600</code> 的记录,是完全可以继续复用这个位置的</p><p>同理当插入一条记录的时候,如果此时页里面已经放满了数据,就会导致当前节点分裂为多个节点,将原先的页按照一定规则重新放到多个节点上</p><p>这里需要注意一点:</p><p>记录的删除仅仅是在页里面将当前数据的位置标记为可复用,而页的删除则是将里面所有的数据标记为可复用</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uattc0hej30oc0fjdk8.jpg" alt="img_1.png"></p><p>例如插入 <code>550</code> 的记录,此时由于页里面已经放满了索引此时需要把原来的页 A 一部分索引数据拆分到一个新的页 B 里面去;这里的拆分和重组由 <code>B+</code> 树的插入和删除性质计算的到</p><p>此时会导致原来完整的 A 出现了 <strong>数据空洞</strong>, 同时新页 B 也产生了 <strong>数据空洞</strong> ; 当一张表经过大量的增删改操作之后,很有可能存在不少的 <strong>数据空洞</strong> </p><p>总结来说,<code>delete</code> 语句仅仅是将页里面的记录位置标记为可以复用,而不是真正的删除页释放空间; 所以执行 <code>delete</code> 语句是无法回收表空间的</p><h3 id="重建表解决表空间空洞的问题"><a href="#重建表解决表空间空洞的问题" class="headerlink" title="重建表解决表空间空洞的问题"></a>重建表解决表空间空洞的问题</h3><p>利用 AB 表的思想,创建一张结构与 A 表相同的 B 表,依次扫描 A 表并顺序插入在 B 表当中, 这样处理过后 B 表的主键就是紧凑没有数据空洞的,数据页的利用率也更高; 操作完成后把流量切到 B 表,然后再删除 A 表即可</p><p>或者直接用 myslq 提供的指令 <code>alter table A engin = InnoDB</code> 进行表的重建</p><p>重建过程当中,如果有新数据写入旧表的话,是不会同步到新表的,此时会导致数据丢失,更新也一样; 所以整个重建过程,必须保证旧表处于只读状态</p><p>如果说保持表 A 的只读状态,那么此时的 <code>DDL</code> 操作就不是 <code>Online</code> 的</p><p>在 mysql 5.6 开始引入 <code>Online DDL</code> ,即重建过程当中,也支持对表 A 的写操作</p><p>基本原理如下:</p><ol><li>扫描表 A 的所有数据页,重新生成对应的 B+ 树,存储到临时文件当中</li><li>生成临时文件的过程中,如果有对表 A 的写操作,则记录在 <code>row log</code> 的日志文件当中</li><li>临时文件生成后,与 <code>row log</code> 的记录进行 <code>merge</code> 操作,得到最终的临时文件</li><li>将最终的临时文件应用到表 A 上</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatzz998j30o70ehdmc.jpg" alt="img_2.png"></p><p>前面说过表级锁有表锁和 <code>MDL</code> 锁,其中 <code>MDL</code> 写锁就是为了防止在查询过程当中表结构发生变化</p><p>而此时的 <code>DDL</code> 重建表操作就会申请到 <code>MDL</code> 写锁,按照其定义,后续对表 A 的读写请求应该都被阻塞了才对</p><p>其实实际重建表的过程当中,这里的 <code>MDL</code> 写锁在 <code>alter</code> 语句开始执行后,真正拷贝数据之前就已经退化成 <code>MDL</code> 读锁了,这样做重建的时候不会阻塞其他的增删改查操作</p><p>此时也不能直接释放 <code>MDL</code> 锁,这样是为了保护不受其他后面的 <code>DDL</code> 影响</p><p>在整个重建过程中,最耗时的是数据拷贝到临时表的过程,这里退化成读锁也不会阻塞其他正常请求,而到了真正需要拷贝数据的时候,相对于整个过程, <code>MDL</code> 写锁的持有过程相对来说并不长,可以近似认为是 <code>Online</code> 的</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(六)mysql 刷盘机制</title>
    <link href="/2022/11/05/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="mysql-的抖动"><a href="#mysql-的抖动" class="headerlink" title="mysql 的抖动"></a>mysql 的抖动</h3><p>在日常工作当中,监控 mysql 的 cpu 状况一般可以发现几个特征</p><ol><li>随着流量高峰导致的使用率上升,这种随着业务的频繁访问而上升,随着业务冷却的下降,属于正常波动</li><li>在平滑的曲线当中,经常会出现 <code>突刺</code> 般的抖动</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37pk9brj30me05s3yx.jpg" alt="img.png"></p><p>这种短暂的 <code>突刺</code> 抖动,一般情况都是因为 mysql 在做 <strong>刷盘</strong> 操作引起的</p><h3 id="结合日志系统理解刷盘"><a href="#结合日志系统理解刷盘" class="headerlink" title="结合日志系统理解刷盘"></a>结合日志系统理解刷盘</h3><p>对于前面提到的 mysql 的日志系统,以 <code>redo log</code> 为例,前面介绍过分为两个部分 <code>redo log buffer</code> 和 <code>redo log file</code></p><p><code>buffer</code> 保存在内存里, <code>file</code> 保存在磁盘上,这也是为了平衡内存和磁盘访问速率不统一的问题</p><p>但是保存在内存里的数据终究是不可靠的,会随着断电而丢失,所以必须在适当的时机将内存里的数据写入磁盘完成持久化操作,保证数据的安全</p><h4 id="脏页和干净页"><a href="#脏页和干净页" class="headerlink" title="脏页和干净页"></a>脏页和干净页</h4><p>当内存里面的数据页和磁盘里面的对应数据页内容不一致的时候,这个内存页就被称为 <code>脏页</code></p><p>反之若保持一致,则称内存页为 <code>干净页</code></p><p>回顾一下之前的数据写入过程,首先记录 <code>redo log</code> 这是由 mysql 写前日志的特性保证,然后将改动在 <code>buffer pool</code> 里面写入,这里可以结合缓存相关的东西一起复习,最后 mysql<br>找一个合适的时机,将 <code>redo log</code> 里面记录的操作写入磁盘完成持久化</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37w4jo6j30mt0d976q.jpg" alt="img_1.png"></p><h3 id="什么时候触发刷盘操作"><a href="#什么时候触发刷盘操作" class="headerlink" title="什么时候触发刷盘操作"></a>什么时候触发刷盘操作</h3><ol><li>当 <code>redo log</code> 的 <code>write_pos</code> 已经追上 <code>check_point</code> 的时候,表明 <code>redo log</code> 已经写满了无法再继续写入新数据,此时整个数据库的写操作都将被阻塞,必须要将 <code>check_point</code> 后面的数据刷入磁盘,以腾出空间让 <code>redo log</code> 恢复继续写入</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u38318laj30gb0fkace.jpg" alt="img_2.png"></p><p>当 <code>check_point</code> 的位置从 <code>cp</code> 推进到 <code>cp&#39;</code> 的时候,就必须把这个区间内的所有的日志(浅绿色部分)都刷入磁盘,当完成刷盘操作后,<code>check_point</code>的位置推进到 <code>cp&#39;</code> 这样就空出来新的位置给 <code>write_pos</code> 继续推进</p><ol start="2"><li>当缓冲池内存不足的时候,此时就必须要淘汰掉里面的部分数据页(对应可以结合 mysql 的缓存机制复习),如果从 <code>LRU</code> 里面淘汰的是干净页那还好说,直接移出 <code>LRU</code> 即可; 如果淘汰的是脏页,就必须要刷盘</li></ol><p>为何不考虑直接丢弃脏页,下次从磁盘读取旧的内存页,然后和 <code>redo log</code> 里面的操作结合返回呢</p><p>从性能角度上来说, 这里的 <code>merge</code> 操作对于读取页来说相对复杂了</p><p>而且刷盘能够保证一致性:</p><ul><li>若内存页里有数据,无论是脏页还是干净页,一定是最新的正确数据,命中缓存后直接返回</li><li>若内存页里没有数据,那么磁盘里面的一定是正确数据,从磁盘读入内存后直接返回即可,也不需要额外的 <code>merge</code> 操作</li></ul><ol start="3"><li><p>当 mysql 检测到系统负载不高的时候,也会进行刷盘操作; 即使系统的负载很高,也要见缝插针的刷脏页,避免造成内存不够或者 <code>redo log</code> 写满的情况发生(这个频率是每秒 1 次)</p></li><li><p>最后,当 mysql 需要停机的时候,关闭 mysql 进程之前,会将内存里面的所有脏页一次性全部刷入磁盘,避免内存里面的数据丢失</p></li></ol><h3 id="着重考虑下第-2-点的刷盘情况"><a href="#着重考虑下第-2-点的刷盘情况" class="headerlink" title="着重考虑下第 2 点的刷盘情况"></a>着重考虑下第 2 点的刷盘情况</h3><p>结合之前的缓存技术一起复习,当需要访问数据的时候,先检查缓存池里是否已有对应的页,若命中缓存则快速返回; 否则从磁盘里面读取对应的内存页</p><p>如果此时缓存池还没有写满,那么直接放入 <code>LRU</code> 即可</p><p>如果缓存池已经写满,就需要根据 <code>LRU</code> 淘汰页; 淘汰的是脏页,必须刷盘; 淘汰的是干净页,无需刷盘</p><p>mysql 通过两个参数来控制刷脏页的速率</p><ol><li>当前 <code>buffer pool</code> 里面的脏页比例 M</li><li>当前 <code>redo log</code> 的写盘速度 N</li></ol><p>简单来说就是取 <code>R = max(M, N)</code>,然后 mysql 就以 <code>R% * 磁盘写入能力</code> 的速率刷新脏页</p><h3 id="连坐刷新"><a href="#连坐刷新" class="headerlink" title="连坐刷新"></a>连坐刷新</h3><p>若一次请求需要刷新一个脏页,根据局部性原理,mysql 会判断当前页旁边的数据页是否也是脏页,如果也是脏页,就一起刷新掉; 而且这个判断机制会蔓延下去,也就是说如果邻居是脏页,还要继续判断邻居的邻居</p><p>这样最终可能导致一次简单的请求,原本刷新一个脏页就可完成,最后刷新的大批量的脏页,反而拖慢了整体查询的性能</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(五)mysql 锁</title>
    <link href="/2022/11/04/(%E4%BA%94)mysql%20%E9%94%81/"/>
    <url>/2022/11/04/(%E4%BA%94)mysql%20%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>锁是用来保证事务并发,数据安全的一种手段</p><p>mysql 有三种类型(注意:是 <strong>三种类型</strong> 而非 <strong>三种</strong>):</p><ol><li>全局锁</li><li>表级锁</li><li>行级锁</li></ol><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>全局锁就是对 <strong>整个数据库实例</strong> 加锁,在此期间,整个数据库处于 <strong>只读</strong> 状态,除了读其他所有操作都会被拒绝</p><p>全局锁的作用几乎都是用来做 <strong>整库备份</strong>, 如果在做整库备份的时候,没有加上全局锁,这个时候表仍然可以写,就会出现备份前后数据不一致的情况</p><p>在事务里面,mysql 通过 <code>MVCC</code> 多版本并发控制来保证事务的隔离性,用到的数据结构是 <code>视图</code>,这个视图保证了在启动事务的时候,是处于一个 <strong>静止状态的逻辑时间点</strong></p><p>参考事务,在做全局备份的时候,也生成一张视图,这样后续的读写请求都不会因为全局锁而阻塞; 既然有视图的存在,为何备份的时候还需要全局锁呢</p><p>考虑到有些存储引擎, 例如 <code>Myisam</code>, 它不支持事务; 这样在备份的时候仍然能取到最新的数据,破坏了数据的一致性</p><p>还有一种方式也能够实现类似于 <strong>全局锁</strong> 的能力,那就是 <strong>将数据库设置为只读状态</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span> readonly <span class="hljs-operator">=</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>但是仍然不建议使用将数据库设置为只读状态来进行整库备份</p><ol><li>客户端连接数据库实例后,加上全局锁进行备份,如果中间发生异常导致客户端断开连接,这个时候数据库也能将全局锁自动恢复,以保证数据库实例能够继续对外提供服务</li><li>如果是通过设置只读的状态,如果连接在中途断开后,数据库是不会从只读状态中恢复的,此时会导致整个数据库对外停止服务</li><li>有些数据库框架可能会用 <code>readonly</code> 字段做业务逻辑,例如判断是否是主库,是否是从库; 改变这个值可能会引起主从判断的逻辑</li></ol><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>表级锁有两种:</p><ol><li>表锁</li><li>元数据锁</li></ol><h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>表锁的使用限制非常严格,例如</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">lock tables t1 read, t2 write<br></code></pre></td></tr></table></figure><p>如果线程 A 在某个时刻执行上述语句后, 其他线程写 t1 ,读写 t2 的请求都会被阻塞,这个很好理解</p><p>但是对于线程 A 来说,就更加严格,它只能够读取 t1,连写 t1 都不行; 对于 t2 来说,线程 A 能够读写; 而且线程 A 也不能访问其他表</p><h4 id="MDL-元数据锁"><a href="#MDL-元数据锁" class="headerlink" title="MDL 元数据锁"></a>MDL 元数据锁</h4><p><code>MDL</code> 锁是不需要显式声明的,在访问一张表的时候,数据库会自动为这张表加上 <code>MDL</code> 锁</p><p>简单来说, <code>MDL</code> 锁是为了保障表结构的完整性不受到影响</p><p>例如当一个线程正在查询表 A 里面的 c1,c2,c3 三列数据列,此时另外一个线程却对表 A 执行了一条 <code>alter</code> 语句,结果是删掉了 c3 列</p><p>这就导致原来的线程在获取道德数据跟原来的表结构不一致了</p><p>mysql 引入了 <code>MDL</code> 锁,分为 <code>MDL</code>读和写两种子类型:</p><ul><li>读锁之间互不影响,也就是说对于同一张表, 每个线程都可以持有对应的 <code>MDL</code> 读锁,所以每个线程之间的读请求互不受到影响</li><li>写锁之间和读写锁之间互斥, 一旦有一个线程正在修改表结构,此时其他所有的读请求和写请求都会被阻塞掉,只有等待写锁释放后,才能进行后面的操作</li></ul><p>介绍一个由 <code>MDL</code> 锁导致的故障问题,假设有如下 4 个会话执行顺序如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgl1480lj30j30bvdih.jpg" alt="img.png"></p><p>会话 A,B 分别执行查询语句,申请 <code>MDL</code> 读锁,这没问题; 会话 C 执行 <code>alert</code> 语句申请 <code>MDL</code> 写锁,此时阻塞</p><p>问题来了,如果仅仅是会话 C 阻塞还好,可如果后面还有其他请求进来访问表,都会被会话 C 阻塞掉</p><p>为什么说会话 C 申请写锁被阻塞之后,还会继续阻塞其他读写锁的申请呢</p><p>mysql 在内部使用 <strong>优先队列</strong> 来维护所有的 <code>MDL</code> 锁申请,而且,而且 <strong>写锁的申请优先级高于读锁</strong></p><p>这就解释了为什么会话 C 的写锁申请阻塞,会导致后续的读写锁申请都被阻塞: <strong>因为有一个高优先级的申请在前面,所以队列后面的请求只能一直等待即使有相同的优先级</strong></p><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><p><code>MDL</code> 锁是有 <code>Server</code> 层提供的能力,而行级锁是由存储引擎提供的能力,有些例如 <code>Myisa</code> 就不支持行级锁</p><h4 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h4><p><strong>先说结论: 在 InnoDB 事务当中,行锁是在需要的时候才加上,而要等到事务提交后才释放锁, 这个叫做两阶段锁协议</strong></p><p>起作用就是,当事务需要持有多把锁时,要尽可能把最可能影响并发度的锁放到后面</p><p>举个简单的例子:</p><ol><li>客户使用账户 A 购买商家的东西,要在账户 A 上扣款</li><li>商家使用账户 B 进行收款</li><li>商家记录一笔交易记录</li></ol><p>可以看到上面的三步操作肯定是在一个事务里面执行,其中 1,2 分别是 <code>update</code> 操作,3 是 <code>insert</code> 操作,且 3 和 1,2 之前没有先后依赖关系</p><p>如果这个时候有另外一个客户也在商家这里购买东西,那么这也是 <code>update</code> 操作,且和前面的 1,2 步骤 <code>update</code> 的是同一个账户</p><p>为了使都操作账户 B 带来的并发等待最小,第一个客户应当对步骤进行重新排序,例如 3,1,2 这样把存在锁竞争的步骤 2 放到了最后面,这样第一个客户持有账户 B 的锁时间被降低到了最短,尽可能地降低锁导致的并发问题的影响</p><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>什么是死锁: 当并发系统中几个线程出现 <strong>循环等待</strong> 资源,涉及到的线程都在等待别人释放自己需要的资源,且 <strong>一直等待</strong> 下去的现象,称为死锁</p><p>死锁发生的 3 个必要条件:</p><ol><li>互斥条件:一个资源只能被一个线程使用,其他线程只能等待释放</li><li>请求和保持:一个线程请求其他互斥资源时,不会释放自己手里的资源</li><li>不可抢占:线程不能强行从其他线程那里获取自己需要的资源,只能等待其释放</li><li>循环等待:存在循环链,使得每个线程都在等待别人释放自己需要的资源</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgkpg18ij30jh0c6juh.jpg" alt="img_1.png"></p><p>可以看到事务 A 启动后申请对 id&#x3D;1 的资源的锁,事务 B 启动后申请对 id&#x3D;2 的资源的锁</p><p>然后事务 A 申请 id&#x3D;2 的锁,发现被事务 B 持有,此时事务 A 阻塞等待事务 B 释放 id&#x3D;2 的锁</p><p>接着事务 B 申请 id&#x3D;1 的锁,发现被事务 A 持有,此时事务 B 阻塞等待事务 A 释放 id&#x3D;1 的锁</p><p>这样两个事务都在等待对方释放自己的资源,进入死锁状态</p><h4 id="mysql-如何解决死锁"><a href="#mysql-如何解决死锁" class="headerlink" title="mysql 如何解决死锁"></a>mysql 如何解决死锁</h4><ol><li>超时等待</li></ol><p>mysql 有个超时等待时间,默认值为 50s,意味着一个线程进入等待后 50s 没有拿到资源,就放弃等待</p><p>50s 的等待时长一般难以接受,太小的话容易误伤正常的锁等待,所以这个策略很少使用</p><ol start="2"><li>主动死锁检测</li></ol><p>当一个事务发生等待时,会主动检测事务所依赖的所有线程是否有被其他线程锁住,以此循环下去最后判断是否出现了死锁</p><p>主动死锁检测虽然可以发现死锁,但是也存在性能问题</p><p>假如有 100 个线程同时更新 1 个资源,第一个拿到锁的线程开始处理,后面每个进来的新线程都要等待第一个线程释放锁,每个线程都要做一次死锁检测,而每次都会循环检查其他的线程,相当于最后产生了 10000 次死锁检查</p><p>最终的检测结果是没有发生死锁,但是这个过程却是相当耗费 cpu 资源的</p><h4 id="如何减少主动死锁检测带来的-cpu-性能消耗问题"><a href="#如何减少主动死锁检测带来的-cpu-性能消耗问题" class="headerlink" title="如何减少主动死锁检测带来的 cpu 性能消耗问题"></a>如何减少主动死锁检测带来的 cpu 性能消耗问题</h4><p>对于这种 <strong>热点数据</strong> 的并发更新,死锁检测往往会占用大量的 cpu 资源</p><ol><li>从源头上控制,假如能够限制客户端的并发,例如一个客户端发起 5 个链接,那么死锁检测的成本就很低能够接受</li></ol><p>但是难以避免出现大量客户端发起连接更新热点数据,即使单个客户端的并发数很小,但是客户端数量过多仍然会导致死锁检测耗费大量 cpu 资源</p><ol start="2"><li>在业务上做出拆分,将原来一整块的并发资源,拆分为多个子集</li></ol><p>例如原来的一个账户,拆分为 100 个账户的总和,每次更新总账户的时候,实际上是随机更新一个子账户</p><p>这样可以将一个资源面临的大量访问均分到多个资源上,减少单个资源的并发度,降低死锁检测的 cpu 消耗</p><p>但是这样要考虑如何汇总零散的资源,以及单个资源的上出现的特殊情况,这样的做法会导致业务的复杂程度变高</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(四)mysql 的各种缓存技术</title>
    <link href="/2022/11/03/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/"/>
    <url>/2022/11/03/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="预读-局部性原理"><a href="#预读-局部性原理" class="headerlink" title="预读 局部性原理"></a>预读 局部性原理</h3><p>操作系统有个很经典的理论,叫做 <strong>局部性原理</strong> ,意思就是说如果使用了一些数据,那么大概率接下来还会使用这些数据附近的其他数据</p><p>同时,磁盘的读写并不是按需读取,也就是说并不是需要什么数据就读取什么数据; 而是按照一定大小的页,一次性读取到内存当中,通常这个页的大小默认为 <code>4K</code></p><p>因为根据局部性原理,访问了数据 x 之后,大概率还会访问 x 附近的其他数据; 而如果是按需读取的话,在访问 x 之后,继续访问 y 和 z 又要进行磁盘操作,这无疑增大了 io 的消耗</p><p>对于按页读取 ,可以一次性将 x 所在的那一页都放到内存里,这样以后再访问 y 或者 z,就可以直接从内存里读取,无需磁盘操作</p><p>可能有疑问就是,如果 x 正好在当前页的最后一条记录,那么访问 y 或者 z 必然要再读取下一页; 实际上这种情况发生的概率非常小,即使如此,再读取下一页也比每次都访问磁盘的效率高得多,是值得接受的必要 io 消耗</p><p>mysql 为了利用磁盘按页读取的能力,在其内存缓存池里面,也是按照页为单位来加载磁盘上的数据</p><h3 id="mysql-如何管理缓存-读缓存-buffer-pool"><a href="#mysql-如何管理缓存-读缓存-buffer-pool" class="headerlink" title="mysql 如何管理缓存 读缓存(buffer pool)"></a>mysql 如何管理缓存 读缓存(buffer pool)</h3><p>管理缓存有个非常经典的算法, <code>LRU</code> 最近最少使用算法</p><p>最常见的实现就是通过一个固定大小的双向链表,将最近一次访问的页放到链表头,这样链尾上的最长时间没有使用的页就会被淘汰置换出链表</p><p><code>LRU</code> 在更新内存页的时候,又分为两种情况</p><ul><li>当前命中的页已经在缓存里面了,这时只需要把命中页置换到头部即可</li><li>当前命中的页还不在缓存里面,这时需要通过一次磁盘 io 把磁盘页读取出来放到缓存头部</li></ul><p>对于一个已经装满的缓存,第一种情况只会发生置换页的操作,不会有页被淘汰;第二种情况则是会淘汰尾部的最后一页</p><p>朴素 <code>LRU</code> 在很多内存缓存里面,例如 <code>MemoryCache</code> 运用的很多,但是 mysql 并没有选择朴素 <code>LRU</code> 算法,这是因为有以下两个问题</p><ol><li>预读失效</li><li>缓存污染</li></ol><h4 id="预读失效"><a href="#预读失效" class="headerlink" title="预读失效"></a>预读失效</h4><p>由于 mysql 预读将部分磁盘页放到缓存里面,但是因为某些原因,这些预读出来的页并没有实际访问到,导致预读失效</p><p>假设缓存大小等于 <code>10 ,且磁盘页 </code>50&#96; 被预读放入缓存,考虑如下情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6j8tn3ij30an02maa7.jpg" alt="img.png"></p><p>此时预读出来的页 <code>50</code> 被放到缓存头部,但是后续再也没有发生过对 <code>50</code> 的访问,这导致预读出来的数据 <code>50</code> 需要被置换 10 次后才能够被淘汰掉</p><p>这使得这些未命中的预读页,在缓存里面的停留时间过长</p><p>mysql 采用 <strong>改良的 LRU 算法</strong> ,将普通缓存改为 <strong>分代</strong> 设计,分为 <strong>新生代</strong> 和 <strong>老年代</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6jirxpjj30b504lmxj.jpg" alt="img_1.png"></p><ul><li>缓存被分为两个部分 <strong>新生代</strong> 和 <strong>老年代</strong></li><li>实际上是通过 4 个指针,分别维护新生代头尾和老年代头尾</li><li>新页在放入缓存的时候,首先放入 <strong>老年代</strong></li><li>如果 <strong>老年代</strong> 里面的页发生了命中,才会加入 <strong>新生代</strong></li><li>如果 <strong>老年代</strong> 里面的页没有发生命中,那么在 <strong>更短的时间内</strong> 它将被移除缓存</li></ul><p>这样使得那些被预读放入缓存,但是又长时间没被使用过的页,能够尽快的从老年代里面淘汰出去</p><h4 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h4><p>什么是缓存污染: <strong>当 mysql 发生大面积扫描数据行的时候,会将大量数据页放入缓存后,立马又再次换入新的数据页; 导致每页只在缓存里面停留非常短的时间就被置换出去</strong></p><p>缓存污染将会显著导致 mysql 的性能下降</p><p>例如一次全表扫描时:</p><ol><li>将预读页放入老年代</li><li>从老年代里面访问页加入新生代</li><li>下一次预读又会将全新的页刷入老年代</li><li>重复 123 步骤,直到完成全表扫描</li></ol><p>可以看到在这样的场景下,所有的页都被放入缓存 1 次后,立马又被新的页置换掉; 从而导致原本缓存里面真正的 <strong>热数据</strong> 被大量新页挤出缓存,从而导致 mysql 的性能下降</p><p>mysql 为了解决缓存污染问题,引入了 <strong>老年代停留窗口</strong> 的概念</p><p>放入老年代后,如果再次命中,并不会立即放入新生代,而是要求在老年代待满多少时间后才允许进入新生代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6joyl78j30ci082js4.jpg" alt="img_2.png"></p><p>假设有大量需要扫描的页需要进入缓存,此时首先进入的是老年代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6k1gfkzj30hw05fq47.jpg" alt="img_3.png"></p><p>如果老年代里面装不下,即使页被访问了,也会被缓存淘汰掉</p><p>这个时候缓存头部的那些高频命中的新生代热点数据,不会立马被这种大批量扫描的页给置换出去</p><p>对于能够命中新生代的查询来说,此时缓存依然能够提供服务,并且性能依旧高效</p><p>而对于老年代里面的页,命中后需要判断是否满足 <strong>老年代停留窗口</strong> 的时长 <code>T</code></p><ul><li>如果 <code>停留时长 &gt;= T</code>,则将其置换到新生代的头部,此时新生代的尾部页面会进入老年代作为的老年代的头部</li><li>如果 <code>停留时长 &lt; T</code>,则只会将其置换到老年代的头部,不会进入新生代</li></ul><h3 id="mysql-如何管理写缓存-change-buffer"><a href="#mysql-如何管理写缓存-change-buffer" class="headerlink" title="mysql 如何管理写缓存 (change buffer)"></a>mysql 如何管理写缓存 (change buffer)</h3><p>简单回顾下读缓存在 mysql 保存了什么内容</p><ol><li>索引页</li><li>索引页对应的数据页</li></ol><p>对于读请求,<code>buffer pool</code> 通过改进后的 <code>LRU</code> 算法实现缓存管理,解决 <code>预读失效</code> 和 <code>缓存污染</code> 的问题</p><p>对于写请求,究竟该如何管理缓存呢,以几个例子分别分析下</p><h4 id="写的页正好在-buffer-pool-里"><a href="#写的页正好在-buffer-pool-里" class="headerlink" title="写的页正好在 buffer pool 里"></a>写的页正好在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6ju3go6j308p072gmf.jpg" alt="img_4.png"></p><ol><li>直接在页上写入数据</li><li>然后写入 <code>redo log</code></li></ol><p>是否会出现一致性问题呢: <strong>不会</strong></p><ol><li>读取,会命中缓存池的页</li><li>缓存池 <code>LRU</code> 数据淘汰,会将 <code>脏页</code> 刷回磁盘</li><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li></ol><h4 id="写的页不在-buffer-pool-里"><a href="#写的页不在-buffer-pool-里" class="headerlink" title="写的页不在 buffer pool 里"></a>写的页不在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kjgoolj308j06vaaw.jpg" alt="img_5.png"></p><ol><li>一次随机磁盘访问,将需要写入的页加载到缓存池里</li><li>在缓存池里写入数据</li><li>写入 <code>redo log</code></li></ol><p>由于写入页不在缓存池里,多了一次从磁盘读取对应页的操作,mysql 为了减少这一次磁盘操作,引入了写缓存 <code>change buffer</code> 的概念</p><p><strong>定义:当对一张不在缓存池里且 <code>非唯一索引</code> 的页进行写入操作是时,并不会立即从磁盘里加载对应的页,而是通过在写缓存 <code>change buffer</code> 里 <code>记录</code> 当前操作,直到后面需要访问这张页的时候,在进行合并 <code>merge</code> 操作</strong></p><p>这样对流程上来说带来的改变如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kq2mdfj30bf06xmya.jpg" alt="img_6.png"></p><ol><li>没有立即从磁盘里面加载对应的数据页,而是在 <code>change buffer</code> 里面记录了一次操作</li><li>写入 <code>redo log</code></li></ol><p>可以看到因为有写缓存的存在,其性能与读请求几乎一致</p><p>同样可以分析下是否会产生一致性问题: <strong>同样也不会</strong></p><ol><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li><li>读取刚刚写入的数据,会有其他机制保证从磁盘里面取出旧的数据页,并和 <code>change buffer</code> 里面的记录完成合并</li><li>会有机制保证 <code>change buffer</code> 里面的改动在适当的实际刷入磁盘</li></ol><p>如果此时发生读取操作,会发生什么呢</p><ol><li>发现缓存里没有对应的页,从磁盘里面随机读取一次拿到对应的页放入缓存</li><li>将磁盘里面读出来的页和写缓存 <code>change buffer</code> 里面的操作进行合并 <code>merge</code> </li><li>将 <code>merge</code> 后的页根据 <code>LRU</code> 算法放入缓存池的对应位置 (老年代)</li></ol><p>可以看到: 再写操作发生时,并不会从磁盘里面加载页到缓存里面; 实际上是在读操作到来时,才会从磁盘里面真正加载到缓存里面然后进行 <code>merge</code> 操作</p><h4 id="为什么说写缓存只能用于-“非唯一索引”"><a href="#为什么说写缓存只能用于-“非唯一索引”" class="headerlink" title="为什么说写缓存只能用于 “非唯一索引”"></a>为什么说写缓存只能用于 “非唯一索引”</h4><p>这是由 <strong>一致性</strong> 决定</p><p>什么是一致性? 简单回顾下: 数据库保证数据能够从一个正确的状态转换为另一个正确的状态</p><p>为什么说 <code>change buffer</code> 写缓存在对于 <strong>唯一索引</strong> 的写操作时,没法保证一致性</p><p>由于 <strong>唯一索引</strong> 在写入数据时,需要保证数据的 <strong>唯一性</strong>, 而 <code>change buffer</code> 在记录写入操作时,并没有去校验这条记录 <strong>是否已经存在</strong></p><p>要校验数据的唯一性,必须要从磁盘里面读取出对应的索引页,以检查数据是否存在</p><p>既然这次磁盘操作必不可免,那为什么不直接从磁盘里面读出放到 <code>buffer pool</code> 里,然后直接对页进行修改</p><p>这样看来在中间添加一个 <code>change buffer</code> 写缓存,对于校验索引的唯一性来说,就显得毫无作用了</p><h3 id="什么场景适合开启写缓存"><a href="#什么场景适合开启写缓存" class="headerlink" title="什么场景适合开启写缓存"></a>什么场景适合开启写缓存</h3><p>根据上面的分析,有以下场景适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>非唯一索引</strong></li><li>写多读少</li></ol><p>什么时候不适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>唯一索引</strong></li><li>读多写少 或者说 写入一个数据后,立马读它(因为写缓存没有实际写页,缓存池里面也没有页,只能从磁盘里面加载,这就导致写缓存失效)</li></ol>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(三)mysql 索引深入浅出</title>
    <link href="/2022/11/03/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/"/>
    <url>/2022/11/03/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-的索引"><a href="#mysql-的索引" class="headerlink" title="mysql 的索引"></a>mysql 的索引</h2><h3 id="索引数据结构的发展"><a href="#索引数据结构的发展" class="headerlink" title="索引数据结构的发展"></a>索引数据结构的发展</h3><p>索引是一种数据结构,用来提高查询效率,常见的用于提高查询效率的数据结构大致可分为以下三种</p><ol><li>hash</li><li>有序数组</li><li>搜索树</li></ol><h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><p>hash 表提供一种 <code>k-v</code> 的关系,当输入 <code>key</code> 值,可以在 <code>O(1)</code> 的时间复杂度内返回对应的 <code>value</code> 值</p><p>但是 hash 表本身是无序的,也就是说对于确定的 <strong>等值</strong> 查询,即检索在不在,有没有这种情况来说,hash 表能够胜任</p><p>但是对于范围查询,hash 表的性能表现就会非常差,因为 hash 表无法确定数据的范围,所以在对范围查询时,需要遍历整个 hash 表</p><h4 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h4><p>有序数组的结构本身也很简单,他对范围查询提供很好的性能表现,对于等值查询,则可以借助有序的特点,使用 <code>二分查找</code> 提高查找效率</p><p>但是数组的问题就在于对于元素的删除和增加操作非常麻烦,通常需要大批量连续移动若干个节点,才能保证数组的数据结构不被破坏</p><p>如果采用有序链表,虽然能够提高插入和删除操作,但代价就是失去了随机访问的能力,对于 <strong>等值查询</strong> 链表则需要遍历所有节点</p><h4 id="搜索树"><a href="#搜索树" class="headerlink" title="搜索树"></a>搜索树</h4><p>对于二叉搜索树来说,每个左孩子都小于父节点,每个右孩子都大于父节点,可以看做是二分查找的运用,其搜索一个节点是否存在的时间复杂度是 <code>O(logn)</code></p><p>考虑最极端的情况,如果所有节点都只有左孩子,那么整棵树将退化成一条链表,此时时间复杂度退化为 <code>O(n)</code></p><p>所以为了平衡这些极端情况,维持 <code>O(logn)</code> 的时间复杂度,需要树能够做出自平衡,所谓平衡就是说树中每个节点的左子树和右子树的深度之差不超过 1</p><p>这种具有自平衡的二叉搜索树叫做 <code>AVL</code> 树</p><p>但是数据库也放弃使用 <code>AVL</code> 树当做索引,原因如下:</p><p><code>AVL</code> 树是一棵 <strong>二叉树</strong> ,每个节点只能保存两个孩子节点,如果说数据量过大,那么二叉树的深度将会变得非常深</p><p>索引数据并非只存在于内存里,还需要保存到磁盘上;每个节点在磁盘上的位置并不是连续的,如果对于非常靠近叶子节点的位置,其搜索次数能够轻松达到几十上百次</p><p>这样就会导致几十上百次磁盘的访问,整体的检索性能会严重被树深影响</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B 树"></a>B 树</h4><p>为了解决 <code>AVL</code> 树二叉导致磁盘访问频繁的问题,引入 <strong>N 叉树</strong> 的概念</p><p>根据经验, innoDB 里面的 <code>N</code> 大概在 1200 左右,对于一棵树深高度为 3 的 N 叉树,其能够保存接近 17 亿的数据</p><p>这样查询一个节点,其最多也就访问 3 次磁盘而已,极大地减少了对磁盘的访问</p><p>B 树在普通 N 叉树的基础上,会在节点里面同时保存数据,也就是说一个 B 树的节点不仅仅会保存索引值,还会保存对应的数据</p><p>这就导致了空间的浪费,也会拖慢检索速度,举个简单的例子说明,假说一个节点值保存 8k 的内容</p><p>如果节点里面的数据占用了 3k,那么剩下的索引值就只有 5k,如果本可以通过一次查询得到的索引值,由于节点上保存了数据,导致需要多次查询才能得到对应的索引值</p><p>至此 mysql 索引的终极解决方案 B+ 树横空出世</p><h4 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B+ 树"></a>B+ 树</h4><p>B+ 树在 B 树的基础上,将中间节点保存的数据全部移除,这样中间节点就只负责保存索引值</p><p>所有的数据都落到叶子节点上,这样每次查询的次数都是相同的,提高了查询的稳定性</p><p>对于 B 树来说,有些数据可能在根节点,有些数据可能在叶子节点,不同的查询可能根据位置不同有较大的差异</p><p>B+ 树的叶子节点按照关键字,从小到大顺序排列,并且通过前驱和后继两个指针,构成一个 <strong>双向链表</strong></p><p>由于是有序排列,所以 B+ 树也能够应对范围查询</p><p>对比 B 树,B+ 树的优点如下:</p><ol><li>由于数据按照双向链表有序组织,区间查询的性能比 B 树高</li><li>所有数据分布在叶子节点上,每次查询的次数相等,稳定性比 B 树高</li><li>遍历所有数据时,只需要遍历叶子节点下面的双向链表即可,不用扫描整棵树,而 B 树需要扫描整棵树</li></ol><h4 id="B-树-2"><a href="#B-树-2" class="headerlink" title="B* 树"></a>B* 树</h4><p>B* 树是在 B+ 树的基础上,更进一步</p><p>B+ 树在插入和删除节点时,分裂与合并节点带来性能开销,为了减少节点的操作次数,B* 树在每个非叶子节点上保存了相邻兄弟节点的指针</p><p>同时在初始化节点中关键字数量上,由 B+ 树的 <code>ceil(m/2)</code> 改为 <code>ciel(2m/3)</code></p><p>当某个节点的关键字个数达到 <code>2m/3</code> 时,会查询相邻兄弟节点之间是否还有空余,如有的话则插入关键字向兄弟节点转移,减少了节点的分裂次数</p><h3 id="聚簇索引和非聚簇索引"><a href="#聚簇索引和非聚簇索引" class="headerlink" title="聚簇索引和非聚簇索引"></a>聚簇索引和非聚簇索引</h3><p>假设当前表里存在一个主键列 id,和一个字段列 k,同时对于字段列 k 建立索引</p><p>此时表的索引结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjjearwj30k708hdie.jpg" alt="img.png"></p><p>可以看到,对于主键列的索引,叶子节点保存的内容为 <code>id - 数据</code> ,而对于非主键索引 k 来说,里面记录的内容为 <code>k - id</code></p><p>根据索引的叶子节点保存的东西不同,可以把索引分为两大类</p><ol><li>聚簇索引: 保存数据的索引</li><li>非聚簇索引: 保存主键的索引</li></ol><p>对于 <strong>聚簇索引和非聚簇索引,其检索有何区别</strong></p><p>简单来说,在聚簇索引上的查询,只需要通过查找主键 id 就可以得到具体的数据,一次索引树的访问即可</p><p>而非聚簇索引上的查询,则必须要先通过字段列查找到主键 id,然后再通过主键 id 去查找对应的数据,需要 2 次索引树的访问</p><p>对于非聚簇索引上的第二次查找主键 id 的过程,称为 <strong>回表</strong></p><p>由于回表多了一次索引树的查找,所以尽可能使用聚簇索引来完成数据检索</p><h3 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h3><p>假设存在如下 sql 语句,会执行多少次查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><ol><li>从非聚簇索引 k 里面查找到 k&#x3D;3 的记录,得到主键 id&#x3D;300</li><li>从聚簇索引里面查找到主键 id&#x3D;300 的记录,得到数据 R3 返回</li><li>继续遍历 k&#x3D;3 的下一个数据,k&#x3D;5,得到主键 id&#x3D;500</li><li>从聚簇索引里面查找到主键 id&#x3D;500 的记录,得到数据 R4 返回</li><li>继续遍历 k&#x3D;5 的下一个数据,k&#x3D;6,不在查询范围内,结束</li></ol><p>由上一节可知,通过非聚簇索引查询聚簇索引的现象称为 <strong>回表</strong></p><p>上面 5 个查询过程当中,2,4 发生 <strong>回表</strong> 查询,1,3,5 在索引列 k 上发生普通查询</p><p>由于索引列 k 里面的数据只记录了主键 id,并不包含 <code>select</code> 语句后面 <code>*</code> 里面的所有数据</p><p>所以不得不通过 <strong>回表</strong> 查询主键索引得到完整的数据</p><p>假如我们的 sql 发生一点小小的改动</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> k <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>此时 <code>select</code> 语句后面只需要查询 <code>k</code> 字段列即可,通过在 k 上面的普通索引,已经包含查询的所有信息了,此时无需再回表查询其他数据</p><p>这种 <strong>索引列 k 已经覆盖查询请求</strong> 的现象,称为 <strong>索引覆盖</strong></p><p><strong>索引覆盖能够有效的减少回表查询的次数,因此是一种提升性能的常用手段</strong></p><p><em>存储引擎和 Server 层的数据扫描统计</em></p><p>需要注意的是,在上面 <strong>索引覆盖</strong> 的查询过程当中</p><p>存储引擎实际扫描了 3 次,即 k&#x3D;3,&#x3D;5,&#x3D;6 然后返回数据 k&#x3D;3 和 k&#x3D;5</p><p>而对于 Serve 层来说,它只从存储引擎哪里拿到了 2 条记录,所以 Server 层认为实际扫描行数只有 2 条</p><h4 id="联合索引通过索引覆盖来提高查询效率"><a href="#联合索引通过索引覆盖来提高查询效率" class="headerlink" title="联合索引通过索引覆盖来提高查询效率"></a>联合索引通过索引覆盖来提高查询效率</h4><p>考虑如下场景,对于每个学生来说,都有 <code>学号</code>, <code>姓名</code>, <code>年龄</code>,</p><p>通常来说,通过 <code>学号</code> 已经能够唯一定位到一个学生,因此一般都选择在 <code>学号</code> 上建立主键索引</p><p>在 <code>姓名</code> 上,也创建普通索引</p><p>此时查询所有姓张的同学的 <code>姓名</code> 和 <code>年龄</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> name, age <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span><br></code></pre></td></tr></table></figure><p>此时是能通过 <code>姓名</code> 的索引找到所有姓张的主键 id,在通过主键 id 得到完整的数据行,最后取出 <code>姓名</code> 和 <code>年龄</code> 返回结果</p><p>若存在大量的这种查询,则 <strong>回表</strong> 会明显的拖慢查询的性能</p><p>若在 <code>姓名</code> 和 <code>年龄</code> 上建立联合索引 <code>name_age</code> 则查询就会变为在索引 <code>name_age</code> 里面查找姓张的同学和年龄,而索引 <code>name_age</code> 正好又包含了查询所需要的数据,此时就不用发生 <strong>回表</strong> 查询</p><p>这样的联合索引,通过 <strong>索引覆盖</strong> 实现了性能的优化和提升</p><h4 id="联合索引的-“最左匹配原则”-和-“最左前缀原则”"><a href="#联合索引的-“最左匹配原则”-和-“最左前缀原则”" class="headerlink" title="联合索引的 “最左匹配原则” 和 “最左前缀原则”"></a>联合索引的 “最左匹配原则” 和 “最左前缀原则”</h4><p><strong>定义:在联合索引列上,从左左侧的字段开始一直向右匹配索引,直到遇到范围查询(&gt;,&lt;,between,like),此时停止对后面的索引列的匹配</strong></p><p><strong>定义:最左匹配原则同样也满足最左前缀原则</strong></p><p>即对于索引 <code>name, age</code> 来说, 查询 <code>name like (&#39;张%)</code> 也能够用上索引</p><p>但是对于如下查询 <code>name like (%三)</code> 此时联合索引左侧的索引列 <code>name</code> 的查询条件前缀是不确定的 <code>%</code> 通配符,此时会导致 <strong>最左前缀原则</strong> 失效,从而导致 <strong>索引失效</strong></p><p>假如有联合索引 <code>(a,b,c,d)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">&gt;</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">5</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;h%&#x27;</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;123&#x27;</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;456&#x27;</span><br></code></pre></td></tr></table></figure><p>这里联合索引的顺序为 a&gt;b&gt;c&gt;d,所以 <code>where</code> 语句从 <code>a</code> 开始从左往右查找是否有索引列匹配</p><p><code>a &gt; 3</code> 和 <code>a like &#39;h%&#39;</code> 都是范围查询,所以根据定义可知,后面的索引列就不再匹配</p><p>所以以上 2 条 sql 只有 <code>a</code> 用上了索引, <code>b</code> 和 <code>c</code> 都没有用上索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br></code></pre></td></tr></table></figure><p>特殊情况</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br></code></pre></td></tr></table></figure><p>上面 2 条 sql 语句,mysql 的优化器会自动调整字段的位置,从而使用上联合索引加快查询速度</p><p><strong>总结</strong></p><p>根据 <strong>空间</strong> 来决定是否需要在联合索引上,为那些不满足 <strong>最左匹配原则</strong> 的字段列再次单独建立联合索引或者单独的索引</p><p>即是否又需要建立 <code>(b,d)</code> 或者 <code>(c)</code> 这样的联合索引或者单独索引,这取决于查询的频率以及是否满足 <strong>索引覆盖</strong> 来优化查询</p><h3 id="索引下沉-也称为索引下推"><a href="#索引下沉-也称为索引下推" class="headerlink" title="索引下沉(也称为索引下推)"></a>索引下沉(也称为索引下推)</h3><p>对于那些不满足 <strong>最左匹配原则</strong> 的查询,用不上索引的字段列究竟如何完成检索</p><p>考虑如下 sql ,同时有联合索引 <code>(name, age)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span> <span class="hljs-keyword">and</span> age <span class="hljs-operator">=</span> <span class="hljs-number">15</span><br></code></pre></td></tr></table></figure><p>根据 <strong>最左匹配原则</strong> 可以用到 <code>name</code> 这个索引,因为 <code>name</code> 后面有 <code>like</code> 语句,表明这是一个范围查询,所以后面的索引列停止匹配</p><p>此时假设存在以下数据:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjt909lj30lj07v41k.jpg" alt="img_1.png"></p><ul><li>在 mysql 5.6 版本以前,这样的查询只能通过在联合索引 <code>(name, age)</code> 上,通过 <code>name</code> 检索到第一个姓张的同学,得到对应的主键 id,然后回表查询对应的数据行,最后取出 <code>age</code> 字段返回结果集; 接着就是从 <code>name</code> 索引上依次遍历符合条件的主键 id,然后依次回表查询得到最终的完整数据</li></ul><p>可以看到的就是,每次查询都存在一个与之对应的回表操作,这无疑降低了查询的性能</p><ul><li>在 mysql 5.6 及以后的版本中,添加了一个新特性 <strong>索引下沉</strong></li></ul><p><strong>定义:将本来应该在 Server 层进行的过滤操作,下沉到存储引擎层完成; 在遍历索引的过程当中,预先过滤掉不满足索引条件的记录行,减少回表的次数</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7sck49cfpj30lp07zn0d.jpg" alt="img_2.png"></p><p>如果不使用索引下沉优化,则存储引擎只会根据索引 <code>name</code> 查找到所有姓张的同学,并依次回表查询到完整数据行返回给 Server 层</p><p>然后在 Server 层对结果集做 <code>age = 15</code> 的判断,筛选出满足查询条件的结果集</p><p>而对于使用索引下沉的优化来说,在检索联合索引 <code>(name,age)</code> 的时候,存储引擎就预先将 <code>age</code> 不满足条件的记录过滤掉; 将本来在 Server 层做的操作下沉到存储引擎层</p><p>这样最终需要回表的操作就只有 2 次了,减少了回表的次数,提高查询的性能</p><p><strong>索引下沉的条件,索引列中包含有待查询的字段,这样可以提前放到存储引擎来判断索引条件是否满足查询条件</strong></p><p>如果查询的是 <code>name</code> 和 <code>gender</code> ,由于索引列里面不包含 <code>gender</code> 即使将 <code>gender = 1</code>下沉到存储引擎,也无法通过索引覆盖得到 <code>gender</code> 值,还是需要依次回表查询才行</p><p>此时就失去了索引下沉的优化</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(二)mysql 事务隔离原理</title>
    <link href="/2022/11/03/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/"/>
    <url>/2022/11/03/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="数据库事务的四大特性"><a href="#数据库事务的四大特性" class="headerlink" title="数据库事务的四大特性"></a>数据库事务的四大特性</h2><ol><li>原子性:事务里一组操作要么全部成功,要么全部失败,不会出现一半成功一般失败的情况</li><li>持久性:事务一旦提交后,其变更就会永久保存下来,即使发生宕机也不会出现数据丢失的情况</li><li>隔离性:不同的事务在并发提交时,其表现的结果看起来是串行化操作的结果</li><li>一致性:数据保证数据从一个正确的状态转移到另一个正确的状态</li></ol><p>一致性难以理解:它为数据库提供了一种 <strong>约束</strong> ,就是说每时每刻数据库都按照正确的方式运行</p><p>比如说我们约定某个字段不能等于 0,那么当我们执行插入 0 值,或者更新为 0 值时,数据库就不允许这种操作发生,因为违反了一致性</p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><ol><li>读未提交:最低的安全级别,事务当中还没有提交的改动能够被其他事务观察到</li><li>读已提交:一个事务的操作只有提交之后才能被其他事务观察到</li><li>可重复度:一个事务在执行过程中看到的数据,总是跟这个事务启动前的结果保持一致</li><li>串行化:所有的事务通过 <strong>加锁</strong> 完成同步操作,出现竞争时必须等待其他事务释放锁资源</li></ol><p>假设数据库只存在一条记录,事务启动前值为 1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofspyx5j309205ugm5.jpg" alt="img_3.png"></p><ol><li><p>读未提交时: 事务 A 的 v1 值已经可以查询得到 2,因为这个级别下可以观察到其他未提交事务发生的改动,所以 v1 &#x3D; v2 &#x3D; v3 &#x3D; 2</p></li><li><p>读已提交级别时: 事务 A 的 v1 值仍然是 1,因为这个级别下只能观察到其他已经提交事务的改动,而 v1 时事务 B 还没有提交,所以事务 B 的改动事务 A 并不能观察到</p></li></ol><p>当事务 B 提交后, v2 &#x3D; v3 &#x3D; 2</p><ol start="3"><li>可重复度:先说结论,v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 2</li></ol><p>可重复度保证了事务在执行过程中观察到的数据和其执行前保持一致,对于事务 A 来说,启动事务前观察到值为 1,那么在执行事务过程当中,再去观察仍然还是得到 1</p><p>只有当事务 A 提交后,再去查询才能得到 v3 &#x3D; 2</p><ol start="4"><li>串行化,由于事务 A 先查询值,所以当事务 B 更新值的时候,必须等待事务 A 执行完成之后才能继续操作</li></ol><p>所以 v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 1</p><h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>在实际数据库查询时,会创建一个 <strong>视图</strong> ,其作用可以理解为启动前所有数据的一个 <strong>快照</strong> ,并且这个 <strong>快照</strong> 在整个事务的执行过程中,不会被其他事务影响到</p><ol><li>读未提交:没有快照,直接读取数据的上一个最新状态</li><li>读已提交:每次执行 sql 前,创建快照</li><li>可重复度:每次事务启动前,创建快照</li><li>串行化:没有快照,通过加锁保证穿行操作</li></ol><h3 id="mysql-具体的隔离级别是如何实现的-以-可重复读-为例"><a href="#mysql-具体的隔离级别是如何实现的-以-可重复读-为例" class="headerlink" title="mysql 具体的隔离级别是如何实现的 以 可重复读 为例"></a>mysql 具体的隔离级别是如何实现的 以 <strong>可重复读</strong> 为例</h3><p>mysql 在每条记录发生操作之前,都会提前记录一个 <strong>回滚段</strong> 的日志 也被称为 <code>undo log</code> ,充分体现了 mysql 写前日志的特性,任何数据发生改变前,都要先记录日志</p><p>这个 undo log 类似于一条链表,记录了数据每个发生变更时的上一个状态</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofzj9dkj30h4078abq.jpg" alt="img_4.png"></p><p>通过回滚操作,当前值 4 的状态可以回滚到之前记录过的任何一个状态</p><p>对于这条记录,处于不同时刻创建的事务,事故观察到的记录的状态均不一样</p><p>对于事务 A,B,C 来说,他们在启动时观察到的记录的值分别为 1,2,4, 这个特性就是 mysql 的 <strong>MVCC(多版本并发控制)</strong></p><p>同时根据视图快照的特性,对于视图 B 来说,如果有其他事务正在操作记录变更为 5,事务 B 也观察不到视图外面的改动</p><p><strong>注意,为什么说尽可能避免长事务,就是因为有 undo log 的存在,可能导致回滚链路非常长,造成磁盘空间的浪费</strong></p><p>详细说明一下这个 undo log 的组成</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rog6bdhhj30tw02ngmn.jpg" alt="img_5.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogb06x9j30fq02vt8z.jpg" alt="img_6.png"></p><p>第一部分主要是 undo log 记录的数据变更的具体信息等,用于回滚时反向操作数据用</p><p>第二部分则是构成回滚链的关键点,包含两个值</p><ol><li>trx_id: myslq 会为每一个事务分配一个 long 类型的唯一 id,这个 id 是递增的</li><li>roll_point: 这是一个只想 undo log 类型的指针,指向上一个旧数据版本的 undo log</li></ol><p>对于一个事务(trx_id &#x3D; 10)来说,在某一时刻操作数据,就会产生一条 trx_id &#x3D; 10,且 roll_point 指向上一个数据的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogfsah8j30ie05wgmn.jpg" alt="img_7.png"></p><p>若紧跟后面的事务(trx_id &#x3D; 18)也访问这条数据,那么就会产生一条 roll_point 指向 trx_id &#x3D; 10 的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogkelk4j30ia07640c.jpg" alt="img_8.png"></p><p>对于事务 A 来说,他是观察不到事务 B 的任何操作的</p><h3 id="视图-快照"><a href="#视图-快照" class="headerlink" title="视图(快照)"></a>视图(快照)</h3><p>再有了 <code>undo log</code> 日志链之后,myslq 基于 <code>undo log</code> 实现了另一种数据结构 <strong>视图</strong> 也可称为 <strong>快照</strong></p><p>视图主要包含以下几个变量:</p><ol><li>创建视图时,当前正处于活跃状态的事务(即还没有提交的事务) ids 集合</li><li>活跃事务 ids 集合里面最小的事务 id, <code>min_id</code></li><li>活跃事务 ids 集合里面 <strong>下一个要生成的事务</strong> id,即当前 ids 里面最大的事务 id + 1, <code>max_id</code>, 这样下一个事务 id 一定比当前所有活跃事务的 id 都要大</li><li>创建当前视图的事务 id, <code>created_trx_id</code></li></ol><p>其中 <code>min_id</code> 也称为 <code>低水位</code>, 同理 <code>max_id</code> 称为 <code>高水位</code></p><p>现在使用两个事务 A,B 来模拟可重复读场景下, 视图是如何工作的; 假设事务 A 在提交之前反复读取数据; 事务 B 在提交之前修改数据</p><h4 id="快照读"><a href="#快照读" class="headerlink" title="快照读"></a>快照读</h4><p>此时事务 A 创建时,有两个事务正处于活跃状态,id&#x3D;10 和 id&#x3D;18</p><p>自然事务 A 此时创建的视图数据:ids&#x3D;[10,18], min&#x3D;10, max&#x3D;18+1&#x3D;19, created_trx_id&#x3D;10</p><p>还记得之前说过的吗,每条记录被写之前,都会产生一条 <code>undo log</code>,用于记录数据的旧值</p><p>此时事务 A 访问记录,将事务 A 指向最新的 <code>undo log</code>,里面保存了最后一个访问记录的状态,假设最后一个访问记录的事务 id &#x3D; 8,此时的 undo log 如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogpfk8aj30iz04emyi.jpg" alt="img_9.png"></p><p>事务 A 的 <code>undo log</code> 保存的最后一个访问记录的事务 id &#x3D; 8,意味着什么</p><p>之前也说过,myslq 会为每个创建出来的事务分配一个 long 类型的事务 id 即 trx_id ,这个 id 随着时间先后顺序依次递增</p><p>当前事务 A 的 trx_id &#x3D; 10,而 <code>undo log</code> 里面记录的最后一个事务的 trx_id &#x3D; 8</p><p>这说明这条记录是在事务 A 创建之前就已经提交过的了,自然 事务 A 是能够访问到这条记录的值 X</p><p>此时,事务 B 启动,并且去更新记录的值为 B,这个时候由于写操作产生,会提前记录一条 <code>undo log</code></p><p>其内容很好分析,创建 <code>undo log</code> 的 trx_id 等于操作的事务 trx_id 即 18,且 <code>undo log</code> 的回滚指针 <code>roll_point</code> 指向上一个旧数据,也就是值 X 时的记录</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogum90bj30if07zmyz.jpg" alt="img_10.png"></p><p>此时,在事务 B 更新了数据之后,事务 A 再次去查询记录,发现 <code>undo log</code> 链路上有最新的节点,即 trx_id &#x3D; 18 的记录</p><p>但是事务 A 并不能立马认为记录就被更新为 B 了,因为它还需要根据快照里面保存的内容去判断这条更新操作究竟能不能够被它访问到,过程如下</p><ol><li>事务 A 发现最新记录 <code>undo log</code> 里面更新的事务 trx_id &#x3D; 18</li><li>事务 A 查询自己的视图里面的活跃事务 ids 集合,发现有 trx_id &#x3D; 18 的记录存在</li><li>这说明事务 A 创建视图的时候,trx_id &#x3D; 18 的事务跟自己一样处于活跃状态,也就是 <strong>未提交</strong> 状态</li><li>这个时候的记录 B 是由未提交的其他事务产生的,在当前视图下是不可观察到的</li><li>所以事务 A 根据 <code>undo log</code> 的 <code>roll_point</code> 查看上一个旧的记录,发现 trx_id &#x3D; 8,小于自己的低水位</li><li>说明 trx_id &#x3D; 8 的记录是由已经提交的事务产生,在当前视图下是可以观察到的</li><li>最终事务 A 第二次查询记录得到的值仍然是 X</li></ol><p>简单总结如下:</p><ul><li>如果 trx_id 小于低水位,表示这个版本在事务启动前已经提交,可见</li><li>如果 trx_id 大于高水为,表示这个版本在事务启动后生成,不可见</li><li>如果 trx_id 大于低水位,小于高水位,分为两种情况:</li></ul><ol><li>若 trx_id 在数组中,表示这个版本在事务启动时还未提交,不可见</li><li>若 trx_id 不在数组中,表示这个版本在事务启动时已经提交,可见</li></ol><p>这就通过视图实现了可重复读的效果</p><h4 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h4><p>来看另一种情况,在可重复读级别下会发生什么</p><p>假设有 A,B,C 三个事务按照下图所示的方式操作数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogzt3naj30fa0afwf7.jpg" alt="img_11.png"></p><p>假设此时 A,B,C 三个事务创建时,活跃的事务只有 trx_id &#x3D; 99,那么此时的快照分别如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7roh4s1lyj30et06ogo5.jpg" alt="img_12.png"></p><p>首先分析 A:</p><ol><li>get K 时,发现 k 的 undo log 指向数据为 (1,3) 的版本,且 trx_id &#x3D; 101</li><li>trx_id &#x3D; 101 大于事务 A 的高水位 100,说明这个版本不可见,往上查找 undo log</li><li>trx_id &#x3D; 102 大于事务 A 的高水位 100,同样不可见,继续网上查找 undo log</li><li>trx_id &#x3D; 90 小于事务 A 的低水位,可见,此时事务 A get k 的结果为 (1,1)</li></ol><p>接着分析 B:</p><ol><li>set K 时,创建新的 <code>undo log</code>,其 trx_id &#x3D; 当前更新数据的事务 id 101</li></ol><p>当按照一致性读的时候,写入 k 之前肯定要得到 k 的值,这里问题来了</p><p>事务 B 的高水位为 101,写入 k 之前的 <code>undo log</code> 版本为 102,此时是高于 B 的高水位的</p><p>也就是说如果按照一致性读来解释的话,B 应该只能拿到 90 版本的值 (1,1) ,从而在写之后更新版本 101 的值为 (1,2)</p><p>思考一个问题: C 在 B 之前已经更新了 k 值为 (1,2) 如果此时 B 按照一致性读取更新 K 值为 (1,2) 会导致 C 的更新丢失了</p><p>为了解决这个问题,mysql 引入了一个新的概念: <strong>当前读</strong></p><p>其含义就是: 所有的更新操作都是 <strong>先读后写</strong> ,而这个 <strong>读</strong> 必须是读取 <strong>当前最新的值</strong> ,不然以前的修改就会丢失</p><p>所以根据 <strong>当前读</strong> ,B 在更新 k 的时候,是已经能够拿到 C 的操作,所以 B 写入数据版本 101 的值为 (1,3)</p><p>随后 B 执行 get K 操作,一看当前最新的 <code>undo log</code> 的 trx_id &#x3D; 101 是自己,那当然可以读取到了</p><p>即,一个事务里面,之前发生过的更新操作,之后的查询操作一定能够观察到(自己写的数据自己认)</p><h4 id="两阶段锁协议"><a href="#两阶段锁协议" class="headerlink" title="两阶段锁协议"></a>两阶段锁协议</h4><p>考虑事务 C 修改为如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rohbk3gnj30fc09gdgm.jpg" alt="img_13.png"></p><p>虽然事务 C 在事务 B 之前发起了更新操作,但是并没有立即提交,而是在事务 B 的更新操作之后才提交的</p><p>此时事务 B 会如何处理呢</p><p>由于事务 C 的 <code>update</code> 操作会为当前数据加上写锁,而事务 B 根据当前读原则,要求其更新数据时必须是当前的最新数据</p><p>但是当前数据上的写锁仍然被其他事务持有,所以事务 B 不得不等待事务 C 释放写锁后才能读取到事务 C 的最新改动,从而更新值</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>总结来说</p><p>可重复读的本质就是通过 <strong>视图</strong> 达到 <strong>一致性读</strong></p><p>但是在遇到更新操作是,就必须通过 <strong>当前读</strong> 来保证之前的更新不会丢失</p><p>如果更新的记录被其他事务持有写锁,根据 <strong>当前读</strong> 原则,必须等待其他事务释放写锁后,才允许继续更新记录</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(一)mysql 日志系统</title>
    <link href="/2022/11/02/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    <url>/2022/11/02/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="日志模块-redo-log-和-binlog"><a href="#日志模块-redo-log-和-binlog" class="headerlink" title="日志模块 redo log 和 binlog"></a>日志模块 redo log 和 binlog</h2><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>首先明确一点: mysql 是 <strong>先写日志,再写磁盘</strong>  这个和 redis 的 <strong>先写磁盘,再写日志</strong> 正好相反</p><p>mysql 写 <strong>前日志</strong> ,redis 写 <strong>后日志</strong></p><p>在存储引擎内,任何更新操作都会先记录 <code>redo log</code> 后,并更新内存数据,然后再适当的时候将 <code>redo log</code> 的数据回写到磁盘里</p><p>由此可知 <code>redo log</code> 是存储引擎持有的</p><h3 id="redo-log-组成"><a href="#redo-log-组成" class="headerlink" title="redo log 组成"></a>redo log 组成</h3><p>实际上 <code>redo log</code> 也是由两个部分组成</p><ol><li>redo log buffer</li><li>redo log file</li></ol><p>这也是为了解决内存和磁盘读写速率不一致的问题</p><p>所以 mysql 也需要提供一定的机制,保证将 <code>redo log buffer</code> 缓冲里面的数据,刷新到 <code>redo log file</code> 磁盘里持久化</p><p>mysql 运行在用户态,要想真正写入磁盘,必须通过 <code>os</code> 提供的 <code>os buffer</code> 进入内核态调用 <code>fsync()</code> 才能写入磁盘</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5h2r8mj30ca0a4tau.jpg" alt="img.png"></p><p>mysql 提供 3 种写入 redo log 的配置</p><ol><li>延时写:不会在事务提交时写入 <code>redo log</code>,而是每秒写入 <code>os buffer</code> 后在调用 <code>fsync()</code> 刷盘,发生宕机时会丢失大概 1s 的数据</li><li>实时写,实时刷:事务提交后,写入 <code>os buffer</code> 立即刷新到磁盘,性能低,但是数据可靠性最高,即使宕机也不会丢数据</li><li>实时写,延时刷:事务提交后,写入 <code>os buffer</code> 每隔 1s 中左右刷新磁盘,发生宕机会丢失大概 1s 的数据</li></ol><p>整个 <code>redo log</code> 的数据结构类似以个环形数组,通过两个指针 <code>write_pos</code> 和 <code>check_point</code> 来记录读写进度</p><p><code>write_pos</code> 记录当前已经写入的位置,随着新数据到来, <code>write_pos</code> 指针会不停地往后移动</p><p><code>check_point</code> 记录当前正要落盘的位置,每次将数据落盘之后,<code>check_point</code> 也会往后移动</p><p>如果新数据的写入速度,超过了落盘的速度,导致 <code>write_pos</code> 和 <code>check_point</code> 相遇了</p><p>此时就需要暂停新数据的写入,先将一部分数据落盘后,空出来的 <code>redo log</code> 空间才允许新数据写入</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp577ek3j30ll0cx764.jpg" alt="img_1.png"></p><p>这样,当事务提交后,由于 mysql 写前日志的特性,即使还没来得及完成刷盘操作,也能通过 <code>redo log</code> 的 <code>check_point</code> 之后保存记录来恢复事务</p><h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>在存储引擎有 <code>redo log</code> 的存在,在 Server 层自然也有对应的 <code>binlog</code> 来记录日志</p><p>对比下 <code>redo log</code> 和 <code>binlog</code> 的不同点</p><ol><li><code>redo log</code> 写物理日志, <code>binlog</code> 写逻辑日志<br>物理日志就是记录磁盘页的操作:在第 <code>x</code> 页磁盘,偏移量为 <code>y</code> 的位置,写入 <code>z</code> 个字节</li></ol><p><code>binlog</code> 写逻辑日志,也就是说 <code>binlog</code> 记录的是每一条实际操作的 sql 语句<br>由于 <code>redo log</code> 写的是物理日志,其记录了磁盘操作的本质,在数据恢复上就比逻辑日志的 <code>binlog</code> 快很多</p><ol start="2"><li><code>redo log</code> 是类似环形数组的循环写入,有固定的大小</li></ol><p>而 <code>binlog</code> 则是顺序追加写入文件,这样记录了所有操作过的 sql 语句</p><p><code>redo log</code> 的大小固定,不可能无限制地写入日志,所以 <code>check_point</code> 保证了在其之前的数据都是已经刷入磁盘的</p><p>不会保存历史记录,相对于 <code>binlog</code> 而言,节省了很多空间</p><p>同时由于 <code>binlog</code> 一直追加写,并没有什么标志位能够得知哪条记录之前的 sql 是已经刷入磁盘的,在做数据恢复的时候,难以定位哪些还未刷盘的日志</p><p>而 <code>redo log</code> 通过 <code>check point</code> 可以很方便的找到未刷盘的日志位置,从而进行数据恢复</p><ol start="3"><li><code>redo log</code> 是存储引擎 innoDB 独有的,<code>binlog</code> 是 mysql Server 层持有的,跟存储引擎无关</li></ol><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>以 <code>slq = 为 id = 2 的记录 c 值加 1</code> 为例,看看 mysql 具体的执行过程</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5x282nj30cs0hkdik.jpg" alt="img_2.png"></p><ol><li><p>经过链接器,抛开查询缓存不谈,完成语法分析和分析,经过优化器来到执行器后</p></li><li><p>首先执行器调用存储引擎的接口检索 <code>id=2</code> 的记录,检查记录是否存在于 <code>buffer pool</code> 当中,若命中则直接执行器,否则将会从磁盘里面读出数据所在的 <strong>页</strong> 放入内存当中</p></li><li><p>执行器拿到 <code>id=2</code> 的记录后,对其 <code>c</code> 值完成加 1 操作后,在调用存储引擎的接口将其写入内存</p></li><li><p>存储引擎将更新后的数据写入内存后,立即写入 <code>redo log buffer</code> 当中,此时 <code>redo log</code> 处于 <code>prepare</code> 状态,然后返回到执行器</p></li><li><p>执行器接收到存储引擎完成数据写入后的响应,则记录当前 sql 到 <code>binlog</code> 里面,然后再调用存储引擎提交事务</p></li><li><p>存储引擎接收到执行器提交事务后的请求后,将刚刚 <code>redo log</code> 当中的 <code>prepare</code> 状态更新为 <code>commit</code></p></li></ol><p>可以看到整个过程当中,<code>redo log</code> 分别在不同的时期处于两种不同的状态,这个特性被称作 mysql 的 <code>两阶段提交</code></p><p>为何一个事务在写 <code>redo log</code> 的时候有两次操作,这个需要结合 <code>binlog</code> 解释下当事务提交时发生宕机后,如果通过 <code>binlog</code> 和 <code>redo log</code> 完成数据恢复</p><h4 id="mysql-数据恢复时的规则"><a href="#mysql-数据恢复时的规则" class="headerlink" title="mysql 数据恢复时的规则"></a>mysql 数据恢复时的规则</h4><ol><li>若 <code>redo log</code> 里面有 <code>commit</code> 记录,则直接提交当前事务</li><li>若 <code>redo log</code> 有 <code>prepare</code> 记录,则检查 <code>binlog</code> 是否有事务 <code>commit</code> 记录. 若 <code>binlog</code> 也有,则提交当前事务;若 <code>binlog</code> 没有,则回滚当前事务</li></ol><h4 id="如果先写-redo-log-再写-binlog"><a href="#如果先写-redo-log-再写-binlog" class="headerlink" title="如果先写 redo log 再写 binlog"></a>如果先写 redo log 再写 binlog</h4><p>若数据更新后,<code>redo log</code> 已经完成写入,此时再写入 <code>binlog</code> 发生宕机</p><p>在恢复数据的时候,检查到 <code>redo log</code> 里面已经有事务的 <code>commit</code> 记录,此时应该提交当前事务到数据库</p><p>此时主库完成事务提交, <code>c</code> 值已经被更新为 2</p><p>但是由于 <code>binlog</code> 没有记录,导致通过 <code>binlog</code> 同步到从库时,从库缺少了当前事务,从而导致主备的数据不一致</p><h4 id="如果先写-binlog-再写-redo-log"><a href="#如果先写-binlog-再写-redo-log" class="headerlink" title="如果先写 binlog 再写 redo log"></a>如果先写 binlog 再写 redo log</h4><p>若数据更新后先写入 <code>binlog</code>, 此时再写入 <code>redo log</code> 时发生宕机</p><p>在数据恢复的时候,检查 <code>redo log</code> 没有事务的 <code>commit</code> 的记录,从而主库缺少了当前事务的记录</p><p>而从库因为从 <code>binlog</code> 当中同步到了更新的事务,这也导致了主备的数据不一致</p><h4 id="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"><a href="#两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题" class="headerlink" title="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"></a>两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题</h4><ol><li><code>redo log prepare</code> 之后,写 <code>binlog</code> 之前宕机</li></ol><p>恢复数据时,检查到 <code>redo log</code> 有 <code>prepare</code> 的事务,再去检查 <code>binlong</code> 的情况,发现 <code>binlog</code> 里面没有记录事务</p><p>此时需要回滚 <code>redo log</code> 里面的事务,即主库回滚未提交的事务</p><p>这样主备之间通过 <code>binlog</code> 同步时,都没有宕机前未提交的事务,保证主备之间的数据一致性</p><ol start="2"><li><code>binlog</code> 完成,写 <code>redo log commit</code> 时宕机</li></ol><p>数据恢复时,检查到 <code>redo log</code> 有 <code>prepare</code> 记录,再去检查 <code>binlog</code> 的情况,发现 <code>binlog</code> 里面也有事务的记录</p><p>此时需要将 <code>redo log prepare</code> 修改为 <code>commit</code>,将 <code>binlog</code> 里面记录的事务提交到主库</p><p>这样从库因为已经从主库同步了 <code>binlog</code> 执行了最新的事务,但是主库由于宕机导致事务没有提交,所以这时候检查后需要将 <code>binlog</code> 里面的时候重新在主库提交一遍,这样保证主备之间的数据一致性</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 的二次开发</title>
    <link href="/2022/10/31/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/"/>
    <url>/2022/10/31/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h3 id="结合业务对-gin-做二次开发"><a href="#结合业务对-gin-做二次开发" class="headerlink" title="结合业务对 gin 做二次开发"></a>结合业务对 gin 做二次开发</h3><p>考虑下 gin 或者 go 原生的 http 包究竟为我们提供了哪些扩展点 <strong>根据开闭原则,对修改关闭,对扩展开放</strong></p><ol><li><p>go http Server</p></li><li><p>go http 包为我们提供了 Handler 接口</p></li></ol><p>其实 go 的 http 处理最终也是交给 <code>Handler</code> 去处理,这里可以通过实现这个接口来扩展自定义 http 框架(因为 go 也是这么做的)</p><ol start="3"><li>gin 的 <code>HandlerFunc</code> 中间函数,这个地方可以扩展的东西太多了,我们可以把各种和业务挂钩的 hook 函数全部添加到 <code>handlerChain</code> 里</li></ol><p>有点 <code>AOP</code> 的感觉嗷</p><h3 id="结合-fx-框架实现自定义启动和结束行为"><a href="#结合-fx-框架实现自定义启动和结束行为" class="headerlink" title="结合 fx 框架实现自定义启动和结束行为"></a>结合 fx 框架实现自定义启动和结束行为</h3><p><code>fx</code> 是 uber 开源的一款依赖注入框架,可以通过 <code>fx</code> 启动一个 <code>app</code> 服务,利用 <code>fx</code> 的 <code>hook</code> 函数,可以轻松地实现类似 <code>Spring</code> 的 <code>AOP</code> 能力</p><p>为 <code>fx</code> 容器注册启动和停止时的 <code>hook</code> 函数</p><p>首先根据前面总结的内容,启动 gin 服务,无非就是创建了一个 <code>http.Server</code> 容器而已</p><p>只不过 gin 通过实现 <code>Handler</code> 接口,实际上启动的是 gin 自定义的 <code>Engine</code> 对象而已</p><p>所以为了对 gin 做满足业务的二次开发,我们也通过同样的接口,定义我们自己的 <code>Server</code> 对象,并且让它配合 <code>fx</code> 框架完成启动和停止的自定义操作</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-comment">// 首先定义我们的自定义 `Server` 对象</span><br><span class="hljs-keyword">type</span> GinxServer <span class="hljs-keyword">struct</span> &#123;<br>server *http.Server<br>proxy  *ProxyGinEngine<br>&#125;<br><br><span class="hljs-keyword">type</span> ProxyGinEngine <span class="hljs-keyword">struct</span> &#123;<br>engine *gin.Engine<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStart() &#123;<br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server starting....&quot;</span>)<br>        <span class="hljs-comment">// 这里才是启动 gin 容器的关键代码</span><br>err := s.server.ListenAndServe()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;ginx listen and serve error: %s&quot;</span>, err.Error())<br>&#125;<br>&#125;()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStop() &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server stoping....&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 使用我们自定义的 Server</span><br>s := &amp;GinxServer&#123;<br>server: &amp;http.Server&#123;<br>Addr: addr,<br>&#125;,<br><span class="hljs-comment">// 底层仍然是 gin 的引擎,不过对它做了一些扩展</span><br>proxy: &amp;ProxyGinEngine&#123;engine: gin.New()&#125;,<br>&#125;<br><br>    <span class="hljs-comment">// 注册我们的路由函数</span><br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/ping&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>,<br>&#125;)<br>&#125;)<br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/hello&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;hello world&quot;</span>,<br>&#125;)<br>&#125;)<br><span class="hljs-keyword">return</span> s<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ctx := context.Background()<br>app := fx.New(<br>fx.Provide(ginx.NewServer),<br>fx.Invoke(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(lc fx.Lifecycle, server *ginx.GinxServer)</span></span> &#123;<br>lc.Append(fx.Hook&#123;<br>OnStart: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStart()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>OnStop: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStop()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;)<br>&#125;),<br>)<br>    <span class="hljs-comment">// 注意通过 ide 启动 main 函数后,再通过 ide 结束是无法出发 OnStop 事件的</span><br>    <span class="hljs-comment">// 因为 ide 的结束是直接杀死进程,而不是通过信号量的方式结束进程</span><br>    <span class="hljs-comment">// 调用 fx.Stop() 时,会发送信号量来结束进程,这样 OnStop() 函数才能触发</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>time.Sleep(<span class="hljs-number">2</span> * time.Second)<br>app.Stop(ctx)<br>&#125;()<br>app.Run()<br>&#125;<br></code></pre></td></tr></table></figure><p>注意这里有个大坑,在 <code>OnStart()</code> 里一定要用协程去启动这个 gin 的监听函数</p><p>对于 fx 框架来说,所有 <code>hook</code> 函数都必须正常启动,fx 应用才算最终启动</p><p>如果这里没有用协程启动,那么 <code>OnStart()</code> 函数将会一直阻塞下去(因为 <code>ListenAndServe()</code> 阻塞),相当于这个 <code>OnStart()</code> 函数就一直没有返回</p><p>而 fx 框架在执行 hook 函数时,发现某个 hook 超时没有正确返回,就会认为启动 fx.App 失败,从而发出停止的信号量</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nn3ybz8gj30t803rjvk.jpg" alt="img.png"></p><h3 id="添加自定义-HandlerFunc-函数"><a href="#添加自定义-HandlerFunc-函数" class="headerlink" title="添加自定义 HandlerFunc() 函数"></a>添加自定义 HandlerFunc() 函数</h3><p>假如我们要对每个 http 请求统计其请求耗时,以及添加相关的埋点信息,应当如何扩展 gin 的 <code>HandlerFunc</code> 函数</p><p>首先可以知道的是,在 <code>ServeHTTP()</code> 最终会调用到 gin 重写的 <code>ServerHTTP()</code> 方法</p><p>里面 gin 通过遍历路由树,找到请求对应的路由节点,然后顺序执行节点的 <code>[]HanderFunc()</code> 函数列表</p><p>其中有个很关键的函数 <code>c.Next()</code> 就是用来遍历整个 <code>[]HandlerFunc()</code> 中间件函数的</p><p>所以我们的两个目标: 1. 新增请求埋点 2. 统计接口耗时  就需要在这个 <code>c.Next()</code> 函数上动文章</p><p>简单回顾下这个 <code>c.Next()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br>c.index++<br><span class="hljs-keyword">for</span> c.index &lt; <span class="hljs-type">int8</span>(<span class="hljs-built_in">len</span>(c.handlers)) &#123;<br>c.handlers[c.index](c)<br>c.index++<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到,在 gin 的自定义上下文 <code>Context</code> 通过 <code>index</code> 字段记录了当前执行的中间件函数的位置,一旦所有函数执行完成之后,就会返回</p><p>首先记录请求埋点肯定是先于业务函数的,所以在初始化 gin 容器的时候,在其他业务 <code>api</code> 注册之前,就应该先行注册埋点函数</p><p>改造 <code>NewServer()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> ginx<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 省略前面的初始化</span><br><br>    <span class="hljs-comment">// 首先添加埋点函数的注册</span><br>    <span class="hljs-comment">// 这样每次遍历 []HandlerFunc 的时候第一个都是 这个埋点函数</span><br>    s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>        <span class="hljs-comment">// req := c.Request</span><br><span class="hljs-comment">// header := c.Request.Header</span><br><span class="hljs-comment">// body := c.Request.Body</span><br><span class="hljs-comment">// do something with req or header or body</span><br>fmt.Printf(<span class="hljs-string">&quot;do something with request&quot;</span>)<br>    &#125;)<br><br>    <span class="hljs-comment">// 接着注册我们的统计耗时的函数</span><br>s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>start := time.Now() <span class="hljs-comment">// 计算当前时间</span><br><span class="hljs-comment">// 注意这里调用 c.Next() 很关键</span><br>c.Next()<br>cost := time.Since(start) <span class="hljs-comment">// 计算耗时</span><br>fmt.Printf(<span class="hljs-string">&quot;cost time is %s&quot;</span>, cost.String())<br>&#125;)<br><br>    <span class="hljs-comment">// 省略业务路由的注册</span><br><span class="hljs-keyword">return</span> s<br>&#125;<br></code></pre></td></tr></table></figure><p>这里着重关注统计耗时的函数,在其内部再次调用了 <code>c.Next()</code> 函数</p><p>来看看调用链 :</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nmkujkcsj31240kegus.jpg" alt="1.png"></p><p>看看最终效果</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nqwvrx9zj30te0cowl4.jpg" alt="2.png"></p><p>可以看到埋点函数和统计耗时函数都能正常工作</p><p><strong>发现个很奇怪的地方,没来得及分析</strong></p><p>就是每次 gin 服务启动之后,第一次请求耗费的时间远长于后面的请求</p><p>有些情况下甚至第一次请求耗时是后面的几十倍</p><p>这个还没找到原因,如果有谁知道,可以通过博客的 <strong>About</strong> 页面取得联系方式告知我一下</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (三)</title>
    <link href="/2022/10/30/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/"/>
    <url>/2022/10/30/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/</url>
    
    <content type="html"><![CDATA[<h2 id="http-连接的建立和监听"><a href="#http-连接的建立和监听" class="headerlink" title="http 连接的建立和监听"></a>http 连接的建立和监听</h2><p>前面用了介绍了 <code>engine</code> 容器的初始化, 处理 <code>http</code> 请求的流程, <code>Router</code> 路由树的生成和注册</p><p>接下来将了解下,一个 http 连接究竟是如何建立的,以及如何将流程扭转到 gin 去实际处理一个请求</p><h3 id="http-ListenAndServe-函数"><a href="#http-ListenAndServe-函数" class="headerlink" title="http.ListenAndServe() 函数"></a>http.ListenAndServe() 函数</h3><p>回到 <code>gin.Run()</code> 函数实现,里面有个 <code>http.ListenAndServe(address, engine)</code> 函数</p><p>通过入参和签名,很明显的告诉我们这个函数将监听在 <code>address</code> 的连接, 第二个参数 <code>engine</code> 猜测最终会把请求交给 <code>engine</code> 容器去处理</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfglt6d4j30is06yado.jpg" alt="img.png"></p><p>首先创建一个 <code>Server</code> 对象,将需要监听的地址,和处理器 (和 gin 的中间函数 <code>HandlerFunc</code> 区分下)</p><p>其实这里的处理器,就是我们之前初始化的 <code>engine</code> 容器,不过 <code>engine</code> 实现了 <code>Handler</code> 接口而已</p><p>这里可以充分体现出 gin 在设计上遵循 <strong>依赖接口而不是依赖实现</strong> 的原则</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgu7g3rj30i1088q68.jpg" alt="img_1.png"></p><p>这里的 <code>Serve</code> 对象感觉和 java 的 <code>Socket</code> 套接字很类似,监听并 <strong>阻塞</strong> 等待</p><p>既然是类似套接字,那么自然就能关闭,所以检查当前的套接字是否关闭,已经关闭了就不能再监听地址接受请求了</p><p>后面就是创建 <code>tcp</code> 链接,以及处理事件</p><h4 id="Listen-函数"><a href="#Listen-函数" class="headerlink" title="Listen() 函数"></a>Listen() 函数</h4><p>跟进 <code>net.Listen()</code> 函数和 <code>lc.Listen()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>DefaultResolver.resolveAddrList(ctx, <span class="hljs-string">&quot;listen&quot;</span>, network, address, <span class="hljs-literal">nil</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>resolveAddrList()</code> 函数负责解析 <code>address</code> 的监听类型, 通过后面的逻辑可知,大致能够分为两类</p><ol><li>TCP 类型(通过 ip 地址加 port 端口,UDP 也类似)</li><li>UNIX 套接字类型???</li></ol><p>里面都是 go 原生的网络库实现,大致逻辑如下:</p><ol><li>解析 <code>ip</code> 地址,解析是 <code>ipv4</code> 还是 <code>ipv6</code> 的类型</li><li>尝试解析 <code>ip</code> 类型,如果不是一个合法的 <code>ip</code> 地址,就试着当做 <code>DNS</code> 地址解析</li></ol><p>接下来是为解析后的 <code>addr</code> 地址创建对应的的监听者对象 <code>sysListener</code> 这没什么好说的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl := &amp;sysListener&#123;<br>ListenConfig: *lc,<br>network:      network,<br>address:      address,<br>&#125;<br></code></pre></td></tr></table></figure><p>通过这个 <code>sysListener</code> 对象来完成实际的监听行为</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl.listenTCP(ctx, la)<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgz7a1zj30ff04rgo3.jpg" alt="img_2.png"></p><p>这里面都涉及到 <code>unix</code> 底层的套接字编程,得到网络文件描述符 <code>fd</code> 完成后续操作,哎我也看不懂了</p><p>有空还要去拜读下 <code>unix</code> 的 <code>socket</code> 套接字编程,再回头看看这里应该会清晰很多</p><p>最后把创建的套接字对象 <code>fd</code> 注入到 <code>sysListener</code> 里,这样这个监听者就相当于已经就绪了,可以进行监听操作</p><p>返回到 <code>http.ListenerAndServe(ln)</code> 将 <code>listen()</code> 函数创建得到的监听者 <code>ln</code> 当做参数传入</p><h4 id="Serve-函数"><a href="#Serve-函数" class="headerlink" title="Serve() 函数"></a>Serve() 函数</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>origListener := l<br>l = &amp;onceCloseListener&#123;Listener: l&#125;<br><span class="hljs-keyword">defer</span> l.Close()<br>&#125;<br></code></pre></td></tr></table></figure><p>通过 <code>OnceCloseListener</code> 对象包裹原始的 <code>Listener</code> 对象</p><p>从字面意思上来说,就是只允许调用一次 <code>Close()</code> 避免重复关闭一个已经关闭了的 <code>Listener</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">if</span> !srv.trackListener(&amp;l, <span class="hljs-literal">true</span>) &#123;<br><span class="hljs-keyword">return</span> ErrServerClosed<br>&#125;<br><span class="hljs-keyword">defer</span> srv.trackListener(&amp;l, <span class="hljs-literal">false</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>将传入的监听者 <code>ln</code> 注入到 <code>Serve</code> 对象里, defer 保证了回收 <code>Serve</code> 的时候会把 <code>ln</code> 移除掉</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>baseCtx := context.Background()<br><span class="hljs-comment">// ...</span><br>ctx := context.WithValue(baseCtx, ServerContextKey, srv)<br>&#125;<br></code></pre></td></tr></table></figure><p>创建一个空的 <code>Context</code> 对象,将 <code>Serve</code> 对象注入到上下文里</p><h4 id="阻塞监听"><a href="#阻塞监听" class="headerlink" title="阻塞监听"></a>阻塞监听</h4><p><strong>以上完成了所有准备,接下来开启一个死循环阻塞监听请求</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 调用监听者的 Accept() 函数,这是个同步阻塞函数</span><br><span class="hljs-comment">// 2022-10-30 本人无能,套接字编程,网络文件描述符相关的操作,实在是看不懂啊</span><br>rw, err := l.Accept()<br><br><span class="hljs-comment">// 当 l 监听到时间产生后, Accept() 函数返回,开始后面处理请求</span><br><span class="hljs-comment">// 可以通过启动 gin 的时候注册一个简单的 /ping 心跳路由</span><br><span class="hljs-comment">// curl 请求一下这个 /ping 路由即可</span><br><br><span class="hljs-comment">// 跳过监听得到的异常处理</span><br><br><span class="hljs-comment">// 这个 ConnContext 成员变量可以在初始化 Serve 对象的时候注入进去</span><br><span class="hljs-comment">// 本质是一个 func(ctx context.Context, c net.Conn) context.Context 函数变量</span><br><span class="hljs-comment">// 起作用是在得到一个新的 c 连接的时候,返回一个继承自 ctx 的新的上下文对象</span><br><span class="hljs-comment">// 具体怎么继承,以及要对这个新的上下文对象做什么处理,则有函数自行决定</span><br><br><span class="hljs-comment">// 这里要么使用原始的父 ctx 对象,要么通过 cc 函数得到个继承自 ctx 的新上下文对象</span><br>connCtx := ctx<br><span class="hljs-keyword">if</span> cc := srv.ConnContext; cc != <span class="hljs-literal">nil</span> &#123;<br>connCtx = cc(connCtx, rw)<br><span class="hljs-keyword">if</span> connCtx == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;ConnContext returned nil&quot;</span>)<br>&#125;<br>&#125;<br>tempDelay = <span class="hljs-number">0</span><br><span class="hljs-comment">// 将 http 裸的连接包成 conn 对象</span><br>c := srv.newConn(rw)<br>c.setState(c.rwc, StateNew, runHooks) <span class="hljs-comment">// before Serve can return</span><br><br><span class="hljs-comment">// 启动一个协程去处理接收到的连接 conn</span><br><span class="hljs-keyword">go</span> c.serve(connCtx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Unix</code> 网络套接字编程是很复杂的,这里因为之前没有充分准备,导致很多 <code>Socket</code> 底层通过 <code>Unix</code> 提供的文件描述符进行网络操作的代码看不懂</p><p>后面补充了 <code>Socket</code> 相关知识后,一定要回来再看看这里</p><p>整个流程总结如下:</p><ol><li>Accept() 函数阻塞监听,直到请求过来返回 net.conn 裸的 http 连接</li><li>如果 Accept() 返回有异常,则处理异常</li><li>如果 Serve 初始化了 ConnContext 函数成员变量,这个函数会继承全局的 ctx 上下文得到一个新的上下文对象</li><li>将裸的 http.conn 包装为 serve 包下面的 conn 结构,新建一个协程,使用第 3 步得到上下文去处理请求</li><li>主协程通过死循环仍然继续阻塞监听 Accept() 函数,直到下一个请求进来 go to 1</li></ol><h4 id="实际的-serve-connCtx-函数"><a href="#实际的-serve-connCtx-函数" class="headerlink" title="实际的 serve(connCtx) 函数"></a>实际的 serve(connCtx) 函数</h4><p>接下来进一步解析这个 <code>serve()</code> 函数如何处理请求的</p><p><code>serve()</code> 函数很长,挑重点解析</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> serve(ctx context.Context) &#123;<br><span class="hljs-comment">// 上下文的设置</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// defer 定义了发生异常后的处理流程</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 检查和处理 tls 协议的链接,即 https 请求</span><br><span class="hljs-comment">// ..</span><br><br><span class="hljs-comment">// 非 tls 协议, http 请求的处理</span><br><span class="hljs-comment">// 创建一个带有</span><br>ctx, cancelCtx := context.WithCancel(ctx)<br>c.cancelCtx = cancelCtx<br><span class="hljs-keyword">defer</span> cancelCtx()<br><br><span class="hljs-comment">// 初始化 buffer reader 和 buffer writer</span><br><span class="hljs-comment">// 为读取连接和向连接发送内容做好准备</span><br>c.r = &amp;connReader&#123;conn: c&#125;<br>c.bufr = newBufioReader(c.r)<br>c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, <span class="hljs-number">4</span>&lt;&lt;<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 解析请求</span><br>w, err := c.readRequest(ctx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>c.readRequest()</code> 函数将会实际处理 <code>conn</code> 对象的请求</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> readRequest(ctx context.Context) (w *response, err <span class="hljs-type">error</span>) &#123;<br><span class="hljs-comment">// 设置超时时间,最长读取时间,缓冲最大读取长度,等等参数</span><br><span class="hljs-comment">// 兼容一些老的客户端在发送 post 请求会后多带上了 /r/n 等换行符,从缓冲区读取的时候去掉这些字节</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 从缓冲区里读取请求内容</span><br>req, err := readRequest(c.bufr)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>readRequest(c.bufr)</code> 函数就是按照 <code>http 1.0</code> 规范解析请求报文</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfh60d1sj30ne03pwi9.jpg" alt="img_3.png"></p><p>首先解析报文行,得到请求方法,请求的协议和版本</p><p>紧跟着解析报文头,得到 <code>Header</code> 里面的值,处理 <code>Header</code> 里面约束的各种参数</p><p>校验一些协议和版本是否兼容,校验 <code>Header</code> 参数是否合法</p><p>最后通过传入的 <code>reader</code> 构造一个 <code>bufferWriter</code> 当做 <code>response</code> 的操作对象</p><h4 id="通过-ServeHTTP-函数扭转处理流程"><a href="#通过-ServeHTTP-函数扭转处理流程" class="headerlink" title="通过 ServeHTTP 函数扭转处理流程"></a>通过 ServeHTTP 函数扭转处理流程</h4><p>在前面通过 <code>readRequest()</code> 解析请求后,创建对应的 <code>http.response</code></p><p><strong>注意:重点来了,这个时候 go 原生的 net 网络包已经帮忙把一个 http 请求全部解析好; 这个时候就需要通过对外暴露的 ServeHTTP 接口把控制流程交给其实现类去处理; 否则请求将会由 go net 库自行处理掉</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfhd792kj30iy0b1dld.jpg" alt="img_4.png"></p><p>跟进这个 <code>ServeHTTP()</code> 方法,在这里面实际上调用的是 <code>server.Handerl.ServeHTTP()</code> 方法</p><p>此时,终于把控制流程交给了 gin 去处理</p><p>回到 gin 框架里面,如果对 gin 的流程有些忘记了的话,可以看看第一张里面关于 <code>gin 如何通过 Handler 接口实现接收和响应请求</code><br>的部分</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img_5.png"></p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (二)</title>
    <link href="/2022/10/29/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/"/>
    <url>/2022/10/29/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/</url>
    
    <content type="html"><![CDATA[<p>简单回顾: gin 从 <code>Run()</code> 函数启动容器之后</p><p>注册路由,添加路由中间函数的调用链</p><p>到使用 go 底层的 <code>net</code> 库绑定地址和端口,阻塞监听端口上的请求</p><p>到最后通过中间函数的调用链完成请求的处理</p><p>这里来看看 gin 容器是如何初始化的,都分别作了什么</p><h3 id="gin-容器的初始化"><a href="#gin-容器的初始化" class="headerlink" title="gin 容器的初始化"></a>gin 容器的初始化</h3><p>gin 提供了两个最常用的初始化方法</p><ol><li>gin.New()</li><li>gin.Default()</li></ol><p>其中 <code>Default()</code> 就是在 <code>New()</code> 的层面上,多添加了两个中间函数而已</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m78mblrej30ct049dhi.jpg" alt="img.png"></p><p>对于 <code>New()</code> 函数来说,在这里面初始化设置了 <code>engine</code> 对象的各种属性配置</p><p>比较关键的几个列出来单独说明下:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">()</span></span> *Engine &#123;<br>engine := &amp;Engine&#123;<br>RouteGroup: RouteGroup&#123; <span class="hljs-comment">// 初始化路由组对象</span><br>Handlers: <span class="hljs-literal">nil</span>,<br>basePath: <span class="hljs-string">&quot;/&quot;</span>,<br>root:     <span class="hljs-literal">true</span>, <span class="hljs-comment">// 设置为根节点</span><br>&#125;,<br><span class="hljs-comment">// &#123;省略&#125; </span><br>trees: <span class="hljs-built_in">make</span>(methodTrees, <span class="hljs-number">0</span>, <span class="hljs-number">9</span>) <span class="hljs-comment">// 为 9 种 http 方法初始化路由树</span><br>&#125;<br><span class="hljs-comment">// 初始化 Context 池,减少上下文的频繁创建,提高内存复用率</span><br>engine.RouterGroup.engine = engine<br>engine.pool.New = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-keyword">interface</span>&#123;&#125; &#123;<br><span class="hljs-keyword">return</span> engine.allocateContext()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="路由组的初始化"><a href="#路由组的初始化" class="headerlink" title="路由组的初始化"></a>路由组的初始化</h3><p>在有了 gin 容器之后,接下来需要做的就是为我们的 api 分类并设置路由组</p><p>就是把具有类似路由 path,隶属于同一个领域的 api 聚合到一个路由组里面,方便快速的查找路由</p><p>使用函数 <code>engine.Group()</code> 可以快速的聚合一组 api 路由</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m794m97bj30o305dn26.jpg" alt="img_1.png"></p><p>继续跟进 <code>engine.combineHandlers()</code> 函数一探究竟</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m799u5raj30mw06eaf6.jpg" alt="img_2.png"></p><p>之前接收到请求后,有个很关键的 <code>Next()</code> 函数,其遍历的所有 <code>handler</code>,都来自于路由组绑定的 <code>handlers</code></p><p>至于计算绝对路径的函数很简单,就是把上一个绝对路径和当前路由的 path 拼接到一块</p><h3 id="具体某个路由如何注册"><a href="#具体某个路由如何注册" class="headerlink" title="具体某个路由如何注册"></a>具体某个路由如何注册</h3><p>以 <code>engine.GET()</code> 函数为例,说一下一个具体的路由是如何注册到对应方法的路由组里去的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79eu2cwj30kt02z76o.jpg" alt="img_3.png"></p><p>调用 <code>engine.handler()</code> 函数完成实际的注册</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79jhejxj30od047q6k.jpg" alt="img_4.png"></p><p>其中 <code>calculateAbsolutePath()</code> 和 <code>combineHandlers()</code> 不在赘述</p><p>着重关注 <code>addRoute()</code> 是如何在路由树上添加路由</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> addRoute(method, path <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-comment">// 省略前置校验</span><br><br><span class="hljs-comment">// 检查当前 method 路由树的 root 节点是否存在,没有的话就创建为 root 节点</span><br>root := engine.trees.get(method)<br><span class="hljs-keyword">if</span> root == <span class="hljs-literal">nil</span> &#123;<br>root = <span class="hljs-built_in">new</span>(node)<br>root.fullPath = <span class="hljs-string">&quot;/&quot;</span><br>engine.trees = <span class="hljs-built_in">append</span>(engine.trees, methodTree&#123;method: method, root: root&#125;)<br>&#125;<br><span class="hljs-comment">// 重中之重,对路由树(前缀树)的处理</span><br>root.addRoute(path, handlers)<br><br><span class="hljs-comment">// 省略不重要的</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="addRoute-函数前缀树应用一探究竟"><a href="#addRoute-函数前缀树应用一探究竟" class="headerlink" title="addRoute() 函数前缀树应用一探究竟"></a>addRoute() 函数前缀树应用一探究竟</h3><p>有两个关键分支:</p><ol><li>root 为空创建前缀树根节点</li><li>root 非空,在前缀树上插入节点</li></ol><h4 id="root-为空创建空节点"><a href="#root-为空创建空节点" class="headerlink" title="root 为空创建空节点"></a>root 为空创建空节点</h4><p>以这组 RESTful api 为例说明:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/:id/children&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/play&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/dog&quot;</span>)<br></code></pre></td></tr></table></figure><p>第一次添加 <code>method</code> 的路由前缀树时,创建了空的 root 节点,在判断当前节点 <code>path</code> 长度为 0,并且没有 <code>children</code> 子节点时,就需要初始化 root 节点</p><p>直接调用 <code>insertChild()</code> 函数将当前路由插入到 root 节点当中</p><p>首先判断当前 path 是否包含通配符,例如 <code>/cat/:id</code></p><p>首次创建 root 前缀树时,不应该直接使用 <code>/cat/:id</code> 作为 <code>full path</code> 而是需要把通配符 <code>:id</code> 单独切割出来,正确的 <code>full path</code> 应该是 <code>/cat/</code></p><p>函数 <code>findWildcard()</code> 返回通配符 <code>:</code> 或者 <code>*</code> ,以及通配符规则是否符合 <code>valid</code> 和通配符所处的下标</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span></span> insertChild(path <span class="hljs-type">string</span>, fullPath <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 找到通配符的位置</span><br>wildcard, i, valid := findWildcard(path)<br><span class="hljs-comment">// 省略校验逻辑</span><br><span class="hljs-keyword">if</span> wildcard[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;:&#x27;</span> &#123; <span class="hljs-comment">// param</span><br><span class="hljs-comment">// 如果有通配符,则把通配符前面的 path 当做 root 节点的 path,而不是带有通配符的 path</span><br><span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// Insert prefix before the current wildcard</span><br>n.path = path[:i]<br>path = path[i:]<br>&#125;<br><span class="hljs-comment">// 为当前 root 节点创建带有通配符的子节点</span><br>child := &amp;node&#123;<br><span class="hljs-comment">// 通配符节点类型为 param,表示在路由树上有个通过参数来区分的路由节点</span><br>nType:    param,<br>path:     wildcard,<br>fullPath: fullPath,<br>&#125;<br><span class="hljs-comment">// 将通配符路由当做子路由添加到当前路由节点 &#x27;/cat/&#x27; 上</span><br>n.addChild(child)<br><span class="hljs-comment">// 设置当前路由节点 &#x27;/cat/&#x27; 带有通配符节点</span><br>n.wildChild = <span class="hljs-literal">true</span><br><span class="hljs-comment">// 更新路由树的指针,继续对通配符节点查找后续的路由树,例如 &#x27;/cat/:id/children`</span><br><span class="hljs-comment">// 表示列出 :id 的 cat 的所有小猫咪 :)</span><br><span class="hljs-comment">// 所以这里需要更新指针指向子节点,继续递归解析</span><br>n = child<br><span class="hljs-comment">// 注意:这里设置的是子节点的 priority 优先级属性</span><br><span class="hljs-comment">// 可以看到在对 root 节点每添加一个子路由,都会让全链路的节点 priority 值 +1</span><br><span class="hljs-comment">// 越靠近根节点的 prioriy 值越大</span><br>n.priority++<br><br><span class="hljs-comment">// 如果当前路径不是以通配符结尾, 例如 `/cat/:id/children` </span><br><span class="hljs-comment">// 那么会继续解析后续的 `/children` 为更深层次的路由子节点</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(wildcard) &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[<span class="hljs-built_in">len</span>(wildcard):]<br><span class="hljs-comment">// 新添加的节点,其 prioriy 值从 1 开始计算,每过一个父节点都比下面的孩子节点大 1</span><br>child := &amp;node&#123;<br>priority: <span class="hljs-number">1</span>,<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n = child<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-comment">// 添加中间函数</span><br>n.handlers = handlers<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// 省略</span><br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>对于第一个带有通配符的路由 <code>/cat/:id</code></p><p>在切割 <code>:id</code> 之后,得到路由为 <code>:id</code> 的通配符子节点</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79o3oj4j30bp050gnm.jpg" alt="img_5.png"></p><h4 id="root-节点非空-往路由前缀树继续添加子路由"><a href="#root-节点非空-往路由前缀树继续添加子路由" class="headerlink" title="root 节点非空,往路由前缀树继续添加子路由"></a>root 节点非空,往路由前缀树继续添加子路由</h4><p>回到 <code>addRoute()</code> 函数,继续看 root 非空的情况是如何处理的</p><p>首先一上来就是一个 100 行的无限循环,代码有点长,仔细解读</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">addRoute</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 从 root(n) 节点开始查找最长前缀的位置索引 i</span><br><span class="hljs-comment">// 这个函数很简单,双指针遍历比较找到第一个不相等的位置</span><br>i := longestCommonPrefix(path, n.path)<br><br><span class="hljs-comment">// 前面说过 gin 使用的紧凑型的前缀树,而非标准的字典前缀树,节省节点内存分配</span><br><span class="hljs-comment">// 如果当前节点是插入节点的子节点,则需要调整父子节点关系</span><br><span class="hljs-comment">// 例如已经插入 即 n = /cat/play/ball</span><br><span class="hljs-comment">// 现在插入 /cat/play</span><br><span class="hljs-comment">// 最后 n 变成 /cat/play, n.children = /ball</span><br><span class="hljs-comment">// 同理,如果继续添加路由 /cat</span><br><span class="hljs-comment">// n = /cat, n.c = /cat/play, n.c.c = /cat/play/ball</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(n.path) &#123;<br>child := node&#123;<br>path:      n.path[i:],<br>wildChild: n.wildChild,<br>indices:   n.indices,<br>children:  n.children,<br>handlers:  n.handlers,<br>priority:  n.priority - <span class="hljs-number">1</span>,<br>fullPath:  n.fullPath,<br>&#125;<br><br>n.children = []*node&#123;&amp;child&#125;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices = bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;n.path[i]&#125;)<br>n.path = path[:i]<br>n.handlers = <span class="hljs-literal">nil</span><br>n.wildChild = <span class="hljs-literal">false</span><br>n.fullPath = fullPath[:parentFullPathIndex+i]<br>&#125;<br><span class="hljs-comment">// 如果在先后顺序上符合父子关系,可以直接在节点 n 上创建对应的子节点</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[i:]<br>c := path[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">// 处理参数节点后带有 &#x27;/&#x27; 的情况</span><br><span class="hljs-keyword">if</span> n.nType == param &amp;&amp; c == <span class="hljs-string">&#x27;/&#x27;</span> &amp;&amp; <span class="hljs-built_in">len</span>(n.children) == <span class="hljs-number">1</span> &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>n = n.children[<span class="hljs-number">0</span>]<br>n.priority++<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// 处理带有公共前缀的节点</span><br><span class="hljs-comment">// 解释一下 indices 的作用,这个字符串保存当前节点下所有孩子节点最长公共前缀之后出现的第一个字符</span><br><span class="hljs-comment">// 例如 /cat/run</span><br><span class="hljs-comment">// 添加 /cat/run_with_me</span><br><span class="hljs-comment">// run 和 run_with_me 有着公共前缀 run</span><br><span class="hljs-comment">// 这样 /cat/run_with_me 就会被继续拆分为子节点 _with_me</span><br><span class="hljs-comment">// 父节点为 /cat/run =&gt; _with_me</span><br><br><span class="hljs-comment">// 在举例,若有 /person/eat 和 /person/laugh</span><br><span class="hljs-comment">// 此时 /person 节点有 indince = le</span><br><span class="hljs-comment">// 添加新路由 /person/lying,此时发现 lying 和 l 有公共前缀 l</span><br><span class="hljs-comment">// 就会将 /laugh 节点拆分为 /l 作为父节点,包含两个子节点 augh 和 ying</span><br><span class="hljs-comment">// 最终 /person/ =&gt; eat 和 l</span><br><span class="hljs-comment">// /l =&gt; augh 和 ying ,且 a 的 indince = ay,eat 没有孩子,所以没有 indinces</span><br><span class="hljs-keyword">for</span> i, max := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(n.indices); i &lt; max; i++ &#123;<br><span class="hljs-keyword">if</span> c == n.indices[i] &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>i = n.incrementChildPrio(i)<br>n = n.children[i]<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 如果插入节点和当前节点不在同一个父节点上,则直接插入到前缀树里</span><br><span class="hljs-keyword">if</span> c != <span class="hljs-string">&#x27;:&#x27;</span> &amp;&amp; c != <span class="hljs-string">&#x27;*&#x27;</span> &amp;&amp; n.nType != catchAll &#123;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices += bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;c&#125;)<br>child := &amp;node&#123;<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n.incrementChildPrio(<span class="hljs-built_in">len</span>(n.indices) - <span class="hljs-number">1</span>)<br>n = child<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> n.wildChild &#123;<br><span class="hljs-comment">// 如果当前节点是参数节点,往参数节点后面添加子节点</span><br>n = n.children[<span class="hljs-built_in">len</span>(n.children)<span class="hljs-number">-1</span>]<br>n.priority++<br><br><span class="hljs-comment">// Check if the wildcard matches</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(path) &gt;= <span class="hljs-built_in">len</span>(n.path) &amp;&amp; n.path == path[:<span class="hljs-built_in">len</span>(n.path)] &amp;&amp;<br><span class="hljs-comment">// Adding a child to a catchAll is not possible</span><br>n.nType != catchAll &amp;&amp;<br><span class="hljs-comment">// Check for longer wildcard, e.g. :name and :names</span><br>(<span class="hljs-built_in">len</span>(n.path) &gt;= <span class="hljs-built_in">len</span>(path) || path[<span class="hljs-built_in">len</span>(n.path)] == <span class="hljs-string">&#x27;/&#x27;</span>) &#123;<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// Wildcard conflict</span><br>pathSeg := path<br><span class="hljs-keyword">if</span> n.nType != catchAll &#123;<br>pathSeg = strings.SplitN(pathSeg, <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-number">2</span>)[<span class="hljs-number">0</span>]<br>&#125;<br>prefix := fullPath[:strings.Index(fullPath, pathSeg)] + n.path<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;&#x27;&quot;</span> + pathSeg +<br><span class="hljs-string">&quot;&#x27; in new path &#x27;&quot;</span> + fullPath +<br><span class="hljs-string">&quot;&#x27; conflicts with existing wildcard &#x27;&quot;</span> + n.path +<br><span class="hljs-string">&quot;&#x27; in existing prefix &#x27;&quot;</span> + prefix +<br><span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br><br>n.insertChild(path, fullPath, handlers)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// Otherwise add handle to current node</span><br><span class="hljs-keyword">if</span> n.handlers != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;handlers are already registered for path &#x27;&quot;</span> + fullPath + <span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br>n.handlers = handlers<br>n.fullPath = fullPath<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果后插入的节点在 <strong>关系上</strong> 是先插入节点的父节点,则需要调整父子节点的关系</p><p>原先的父节点 <code>/cat/play/ball</code> ,后插入的节点 <code>/cat/play</code></p><p>从关系上来说,后者应该是前者的前驱 <code>/cat/play</code> ; 前者截断后变为子节点 <code>/ball</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79vblj0j30a4055jsx.jpg" alt="img_6.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m7aa05qlj30bb0a8q6w.jpg" alt="img_7.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>gin 使用紧凑前缀树实现路由树,减少树节点的个数,提高查找效率</li><li>gin 对通配符 :xxx 和 *xxx 两种类型的参数有些特殊限制,尤其小心在 *xxx&#x2F;other 这种路由,会导致 &#x2F;other 节点失效,具体原因是因为 *xxx 节点被设置为 cathAll 类型,<br>其后面的路由不再匹配,全部由 *xxx 提供服务</li><li>其中 priority 字段的设计,是为了让出现次数更多的路由前缀尽可能早的匹配到请求上,提升前缀树检索的性能</li><li>其中 indinces 的设计,是为了将路由子节点尽可能多的拆分出公共前缀,这样做的目的也是为了减少路由树中路由节点的个数,提升检索性能</li></ol><p>总之,还是有很多细节没有列举完成,包括对通配符节点的特殊处理和判断,都没有一一解释代码了</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (一)</title>
    <link href="/2022/10/28/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/"/>
    <url>/2022/10/28/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h2 id="走进-Gin-的大门"><a href="#走进-Gin-的大门" class="headerlink" title="走进 Gin 的大门"></a>走进 Gin 的大门</h2><h3 id="启动-gin-服务"><a href="#启动-gin-服务" class="headerlink" title="启动 gin 服务"></a>启动 gin 服务</h3><p>启动 gin 服务很简单,代码里面只需要两行</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/gin-gonic/gin&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>r := gin.Default()<br>r.Run() <span class="hljs-comment">// listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)</span><br>&#125;<br></code></pre></td></tr></table></figure><p>跟进 <code>r.Run()</code> 方法一探究竟</p><h3 id="Run-方法"><a href="#Run-方法" class="headerlink" title="Run() 方法"></a>Run() 方法</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvpgnuj30m709ljx3.jpg" alt="img01.png"></p><p>可以看到 <code>Run()</code> 方法大概做了 3 件事</p><ol><li>解析配置的受信任 CIDRs 地址</li><li>如果有在启动时指定监听的地址,就解析对应 <code>addr</code> 地址</li><li>传入解析后的 <code>addr</code> 地址,并监听这个地址上的 http 事件</li></ol><p>通过上面的注释可知,其本质是 <code>http.ListenAndServe(addr, router)</code> 的一个实现</p><p>且 <code>Run()</code> 方法是一个阻塞方法,将会阻塞调用协程,除非异常发生</p><p>了解过 <code>Socket</code> 编程的应该都知道, <code>socket.Accept()</code> 就是一个阻塞方法,它会一直阻塞监听套接字绑定的 ip 和端口,直到收到请求数据才返回</p><p>可见 <code>http.ListenAndServe()</code> 也是一直阻塞并监听端口事件发生的</p><h3 id="http-ListenAndServe"><a href="#http-ListenAndServe" class="headerlink" title="http.ListenAndServe"></a>http.ListenAndServe</h3><p>这是 gin 的核心函数,其依赖于 go 语言内置的 <code>net</code> 库实现</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvnvo2j30ir06ladw.jpg" alt="img02.png"></p><p>注意,外面传入的是 <code>gin.engine</code> 到这里变成了 go 语言 <code>net</code> 库的 <code>Handler</code> 接口对象</p><p>可以看到的是 <code>gin.engine</code> 是实现了 <code>Hanler</code> 接口的</p><p>并且后续所有的 <code>request</code> 请求和 <code>response</code> 响应也都是通过这个 <code>Handler</code> 接口实现的</p><h3 id="gin-如何通过-Handler-接口实现接收和响应请求的"><a href="#gin-如何通过-Handler-接口实现接收和响应请求的" class="headerlink" title="gin 如何通过 Handler 接口实现接收和响应请求的"></a>gin 如何通过 Handler 接口实现接收和响应请求的</h3><p>跟进 <code>Handler</code> 接口,找到对应的 gin 实现 engine 对象</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img03.png"></p><p><code>engin.pool.Get()</code> 获取一个 gin 自己封装的 <code>Context</code> 对象,注意这里不是 go 原生的 <code>Context</code> 对象</p><p>可以看到 gin 使用了池化技术,做到内存复用,避免频繁的创建上下文</p><p>初始化 <code>Context</code> 对象时,把接收到的请求 <code>req</code> 也放到上下文里</p><p>进一步跟进 <code>handleHTTPRequest()</code> 函数看看 gin 究竟是如何处理请求的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> handleHTTPRequest(c *Context) &#123;<br>httpMethod := c.Request.Method <span class="hljs-comment">// 解析 method</span><br>rPath := c.Request.URL.Path    <span class="hljs-comment">// 解析 url path</span><br>unescape := <span class="hljs-literal">false</span><br><span class="hljs-comment">// &#123;一些对 url path 的额外处理&#125;</span><br><br><span class="hljs-comment">// gin 维护了所有 method 的路由树集合</span><br>t := engine.trees<br><span class="hljs-keyword">for</span> i, tl := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(t); i &lt; tl; i++ &#123;<br><span class="hljs-comment">// 遍历路由树集合找到当前 method 对应的的路由树</span><br><span class="hljs-keyword">if</span> t[i].method != httpMethod &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>root := t[i].root<br><span class="hljs-comment">// 从 root 节点开始查找路由树,直到查找到 path 对应的路由</span><br>value := root.getValue(rPath, c.params, unescape)<br><span class="hljs-keyword">if</span> value.params != <span class="hljs-literal">nil</span> &#123;<br>c.Params = *value.params<br>&#125;<br><span class="hljs-comment">// 如果路由有配置 handler 函数</span><br><span class="hljs-keyword">if</span> value.handlers != <span class="hljs-literal">nil</span> &#123;<br>c.handlers = value.handlers<br>c.fullPath = value.fullPath<br><span class="hljs-comment">// Next() 函数会依次执行路由配置的所有 handler 函数</span><br>c.Next()<br>c.writermem.WriteHeaderNow()<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里有两个关键点 <code>engine.trees</code> 路由树 和 <code>Next()</code> 函数</p><h3 id="先来看-Next-函数"><a href="#先来看-Next-函数" class="headerlink" title="先来看 Next() 函数"></a>先来看 Next() 函数</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvsw2xj30io05y0vq.jpg" alt="img04.png"></p><p>还记得之前的 <code>gin.engine</code> 对象吗? <code>engine</code> 实现了 <code>ServeHTTP</code> 接口,在里面封装了 gin 关于 http 请求的处理</p><p>其中 <code>c.reset()</code> 初始化 <code>Context</code> 上下文对象的时候,有设置 index 的值为 -1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmytfj309203fgm8.jpg" alt="img05.png"></p><p>这说明还没有 <code>handler</code> 函数处理的时候,<code>Context</code> 上下文里面保存的处理索引是从 <code>-1</code> 开始计算</p><p><code>Next()</code> 函数里,一来就让 index 自增 <code>c.index++</code> 后 index &#x3D; 0,说明从第 0 个 <code>handler</code> 函数开始依次执行</p><p>而 <code>handleHTTPRequest()</code> 函数在从路由树当中找到请求对应的路由节点后,如果发现这个路由有配置过 <code>handler</code> 函数,则会把路由配置的 <code>handler</code> 函数全部赋值给 <code>Context</code> 上下文 <code>c</code> 里</p><p>这样就相当于通过上下文 <code>c</code> 依次执行路由配置的 <code>handler</code> 函数处理请求,而每次执行 <code>handler</code> 之后,都会使 <code>index</code> 自增</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br><span class="hljs-comment">// 关注核心代码</span><br>c.handlers[c.index](c)<br><span class="hljs-comment">// c.index 表示当前待执行的索引</span><br><span class="hljs-comment">// c.handlers[] 数组</span><br><span class="hljs-comment">// c.handlers[c.index] 相当于取出处于 index 的 handler 函数</span><br><span class="hljs-comment">// 而 handler 函数的签名是 func (c *Context)</span><br><span class="hljs-comment">// 可以理解为 c.handlers[c.index] = func (c *Context)</span><br><span class="hljs-comment">// 所以 c.handlers[c.index](c) 相当于把 c 又当做参数传给了 handler 函数</span><br>&#125;<br></code></pre></td></tr></table></figure><p>除非设置了 <code>AbortIndex</code> 的值终止 <code>handlers</code> 的遍历,否则会执行完所有配置的 <code>handlers</code> 函数才会结束请求的处理</p><h3 id="engine-trees-路由树"><a href="#engine-trees-路由树" class="headerlink" title="engine.trees 路由树"></a>engine.trees 路由树</h3><p>接下来在看看路由树的是怎么实现的</p><p>一路跟进去看源码</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmodrj308903yq3f.jpg" alt="img06.png"></p><p>可以看到 gin 维护了一个 <code>[]methodTree</code> 数组,数组里面每个元素都是一个路由树节点对象,分别保存了当前路由的方法 <code>method</code> 和当前路由的根节点 <code>root</code></p><p>继续跟进树节点 <code>node</code> 看看怎么实现的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvxqjkj30m5062q5u.jpg" alt="img07.png"></p><p>其实路由树就是一棵 <strong>紧凑前缀树</strong></p><p>前缀树利用字符串的公共前缀来减少查询时间,而路由则天生符合前缀的特性</p><p>例如有以下几个路由:</p><ol><li>&#x2F;</li><li>&#x2F;order</li><li>&#x2F;order&#x2F;:name</li><li>&#x2F;order&#x2F;:id</li></ol><p>可以看到这些路由都有根节点 <code>/</code> ,同时下面三个路由都有重复节点 <code>/order</code></p><p>普通的前缀树保存每个字符,而 gin 使用 <strong>紧凑前缀树</strong> 保存每个路由节点,减少了内存的使用,提高查询效率</p><p>此时生成的路由前缀树如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvvkzyj307007z74p.jpg" alt="img08.png"></p><p>通过路由树可以快速的检索到对应的的路由节点,至于路由如何注册在这里暂且不表</p><h3 id="回到-handleHTTPRequest-方法"><a href="#回到-handleHTTPRequest-方法" class="headerlink" title="回到 handleHTTPRequest() 方法"></a>回到 handleHTTPRequest() 方法</h3><p>在经历了路由检索, <code>handler</code> 函数的处理,此时一笔请求就已经全部执行完毕了</p><p>通过 <code>c.WriteHeaderNow</code> 将 http 状态写回 header 后,当前请求的处理协程结束</p><p>主协程仍然阻塞在 <code>accept()</code> 监听方法上,通过 channel 来启动协程继续处理后续的请求</p><p>至此,一笔请求就被完整的处理完并返回给调用方</p><p>剩余的细节:</p><ol><li>go 内置的 net 网络通信库,如何建立连接,监听请求,前置处理</li><li>gin 注册路由如何生成路由树</li></ol><p>后面再说吧</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>源码</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/10/27/hello-world/"/>
    <url>/2022/10/27/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
