<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>(一)jvm 内存模型</title>
    <link href="/2022/11/15/(%E4%B8%80)jvm%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/11/15/(%E4%B8%80)jvm%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h3 id="jvm-的内存模型"><a href="#jvm-的内存模型" class="headerlink" title="jvm 的内存模型"></a>jvm 的内存模型</h3><p>jvm 内存模型由以下几个部分组成</p><ul><li>方法区 method</li><li>堆 heap</li><li>虚拟机栈 vm stack</li><li>本地方法栈 native method stack</li><li>程序计数器 program counter (pc)</li></ul><p>其中方法区和堆是所有线程共享的,而虚拟机栈,本地方法栈和程序计数器则是每个线程独有的</p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器的作用就是标记当前线程执行到的字节码行号; 当时间片轮转导致线程上下文切换或者进入循环分支等流程,都需要通过程序计数器来控制</p><h4 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h4><p>虚拟机栈用于保存,每个方法在运行时 jvm 创建的 <code>栈帧</code> ,而 <code>栈帧</code> 则是用于保存方法需要的本地变量等信息; 一个方法的执行和返回,就对应了线程里面虚拟机栈 <code>栈帧</code> 的入栈和出栈</p><p>当虚拟机栈超过一定深度之后,就会引发 <code>StackOverflow</code> 异常; 或者申请分配 <code>栈帧</code> 时所需要的内存不够,就会引发 <code>OutOfMemory</code> 异常</p><h4 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h4><p>区域别类里面的方法,本地方法栈保存的是 jvm 需要使用的 <code>native</code> 方法</p><h4 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h4><p>虚拟机里面所有对象的创建都是在堆空间上直接分配的; 包括后面的垃圾回收过程也几乎都是运行在堆空间上</p><p>当对空间不足以分配实例的所需的内存是,会引发 <code>OOM</code> 异常</p><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><p>方法区也是所有线程共享的一块区域,里面保存了 jvm 启动时加载的各种静态变量,静态方法,静态实例等; 还有各种常量,类加载信息都会保存在方法区内</p><p>与堆进行区分,也称作 <code>非堆区</code> 或者叫做 <code>永久代</code> ,在后面的 jdk 发展过程当中 <code>永久代</code> 慢慢被废弃,直到 <code>本地内存</code>  <code>元空间</code> 将其完全替代</p>]]></content>
    
    
    <categories>
      
      <category>jvm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jvm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十六)redis 数据倾斜和访问倾斜</title>
    <link href="/2022/11/14/redis/(%E5%8D%81%E5%85%AD)redis%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%92%8C%E8%AE%BF%E9%97%AE%E5%80%BE%E6%96%9C/"/>
    <url>/2022/11/14/redis/(%E5%8D%81%E5%85%AD)redis%20%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%92%8C%E8%AE%BF%E9%97%AE%E5%80%BE%E6%96%9C/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是数据倾斜"><a href="#什么是数据倾斜" class="headerlink" title="什么是数据倾斜"></a>什么是数据倾斜</h3><p>当 redis 以集群部署时,如果大量数据都被分配到同一个或者集中在少数几个哈希槽里面,就称此时发生了 <code>数据倾斜</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85333yalij30f50ce40c.jpg" alt="img.png"></p><h3 id="什么原因会导致数据倾斜发生"><a href="#什么原因会导致数据倾斜发生" class="headerlink" title="什么原因会导致数据倾斜发生"></a>什么原因会导致数据倾斜发生</h3><ol><li><code>bigkey</code>: 如果某个哈希槽里面有个绝大无比的 <code>bigkey</code> ,此时从外部看起来就是这个哈希槽里面的数据量远超过其他哈希槽</li></ol><p>而之前说过,访问或者操作一个 <code>bigkey</code> 是一件很消耗性能的事,很可能导致 redis 的主线程阻塞在处理 <code>bigkey</code> 上,导致 redis 服务不可用</p><p>解决方案: </p><p>将 <code>bigkey</code> 进行拆分,拆成若干个更小的 <code>key</code> 再存放于不同的哈希槽,使数据均匀分布在不同的哈希槽里; 同时业务层在写入一个 <code>key</code> 时就要尽量避免将大量数据写入同一个 <code>key</code> 当中</p><ol start="2"><li><code>Slot</code> 分配不均匀</li></ol><p>在部署 redis 进群时,采用手动指定分配哈希槽的方式; 如果某些个配置较高的节点希望充当主节点使用,此时就可能会给这些节点多分配几个哈希槽</p><p>然而实际上的数据和哈希槽的映射关系并不能提前知道; 如果恰好大量数据全部集中在这几个哈希槽里,就会导致数据倾斜</p><p>解决方案:</p><p>保持部署的节点配置一致,同时使用 redis 默认的均匀分布策略; 或者发生数据倾斜事,手动迁移其中若干个哈希槽到其他节点上</p><ol start="3"><li><code>Hash tag</code> 导致</li></ol><p>如果在设置一个哈希 <code>key</code> 时,指定了 <code>Hash tag</code>,可能导致大量 <code>key</code> 有着相同的 <code>Hash tag</code> 从而被分配到几个集中的哈希槽上,出现数据倾斜</p><p><code>Hash tag</code> 本身的目的是为了解决 redis 集群不支持 <code>夸实例</code> 的事务操作或者范围检索的问题</p><p>使用 <code>Hash tag</code> 能够把不同的 <code>key</code> 指定映射到同一个实例上,这样就可以对单个节点进行事务操作或者范围检索</p><h3 id="什么是访问倾斜"><a href="#什么是访问倾斜" class="headerlink" title="什么是访问倾斜"></a>什么是访问倾斜</h3><p>当大量请求集中访问若干热点 <code>key</code> 时,这时候这些热点 <code>key</code> 所处的哈希槽对应的实例就会有大量请求进入,而其他实例的请求寥寥无几; 这种现象就称为 <code>访问倾斜</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h8533ai6vjj30gf0clac3.jpg" alt="img_1.png"></p><p>此时并不是说哈希槽内的 <code>key</code> 分配不均匀,而是说热点 <code>key</code> 会被大量访问,无论将这些 <code>key</code> 迁移到哪个哈希槽,都会导致对应哈希槽的实例面临大量请求</p><p>对于只读 <code>key</code> 来说,可以将 <code>value</code> 复制若干份,并且把备份的 <code>key</code> 添加一些随机数,这样通过多个 <code>key</code> 保存了同一份 <code>value</code> 值</p><p>再把这些备份 <code>key</code> 都均匀分布到哈希槽里,再把这些哈希槽都均匀分布到实例节点上; 当客户端请求热点 <code>key</code> 时,以同样的算法添加随机数,这样就相当于把原来的热点 <code>key</code> 均匀分布到若干实例上,避免了单个实例接受大量请求的问题</p><p>但是需要注意的是 <code>热点数据拷贝</code> 只能解决 <code>只读</code> 数据的访问倾斜问题</p><p>对于 <code>读写</code> 数据,其拷贝会导致严重的数据不一致问题; 此时唯一的办法就是 <code>增加节点配置</code></p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十五)redis 脑裂</title>
    <link href="/2022/11/14/redis/(%E5%8D%81%E4%BA%94)redis%20%E8%84%91%E8%A3%82/"/>
    <url>/2022/11/14/redis/(%E5%8D%81%E4%BA%94)redis%20%E8%84%91%E8%A3%82/</url>
    
    <content type="html"><![CDATA[<h3 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h3><p>当一个集群内部同时存在两个或者两个以上的主节点,这两个节点都能进行请求的读写,这种现象称为 <code>脑裂</code> 它看起来就是一个人拥有了两个大脑</p><h3 id="最可能导致脑裂的原因"><a href="#最可能导致脑裂的原因" class="headerlink" title="最可能导致脑裂的原因"></a>最可能导致脑裂的原因</h3><p>在哨兵模式下,如果主节点在一段时间内无法响应哨兵的心跳包,此时哨兵判定主节点 <code>客观下线</code> 后随机启动主从切换过程</p><p>如果在这个过程当中原来的主节点恢复正常,此时由于主从切换还未完成,仍然有新的请求进入原来的主节点处理</p><p>此时的集群看起来就有两个主节点</p><h3 id="数据丢失后如何判断是不是因为脑裂引起"><a href="#数据丢失后如何判断是不是因为脑裂引起" class="headerlink" title="数据丢失后如何判断是不是因为脑裂引起"></a>数据丢失后如何判断是不是因为脑裂引起</h3><ol><li>判断主从同步的延迟</li></ol><p><code>replication backlog</code> 里面获取主库的 <code>master_repl_offer</code> 和从库的 <code>slave_repl_offset</code> 检查这两个值是否相等; 如果说主从同步之间存在一定的延迟,则数据丢失可能是主从同步时,异常宕机引起的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h851p3udiyj30hd0e075l.jpg" alt="img.png"></p><p>如果说主从同步的进度是相等的,则数据丢失可能是由于脑裂导致,过程如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h851p8ekgvj30hj0d10uw.jpg" alt="img_1.png"></p><p>更严重的是当主从切换完成后,哨兵会对之前的老主节点发出 <code>slaveof</code> 指令,令其变为从节点与新的主节点进行同步</p><p>在主从切换后进行首次全量同步,会清空从节点本地数据库的所有数据,相当于老的主节点在 <code>脑裂</code> 期间所接受的写请求数据将会全丢失; 最终导致严重的数据丢失问题</p><h3 id="如何避免脑裂问题"><a href="#如何避免脑裂问题" class="headerlink" title="如何避免脑裂问题"></a>如何避免脑裂问题</h3><p>redis 提供了两个关键参数,控制一个主节点能否继续接受新的请求</p><ol><li><code>min-slaves-to-write</code>: 一个主节点至少要有 <code>N</code> 个从节点与之进行通行时,主节点才能接受客户端的读写请求</li><li><code>min-slaves-max-log</code>: 主从节点同步时,最长不得超过 <code>N</code> 秒的延迟</li></ol><p>一旦一个主节点不满足上述的任何一点,此时 redis 就拒绝主节点接受客户端的请求</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十四)redis 事务</title>
    <link href="/2022/11/13/redis/(%E5%8D%81%E5%9B%9B)redis%20%E4%BA%8B%E5%8A%A1/"/>
    <url>/2022/11/13/redis/(%E5%8D%81%E5%9B%9B)redis%20%E4%BA%8B%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h2 id="redis-如何保证事务的四大特性"><a href="#redis-如何保证事务的四大特性" class="headerlink" title="redis 如何保证事务的四大特性"></a>redis 如何保证事务的四大特性</h2><h3 id="redis-的事务实现"><a href="#redis-的事务实现" class="headerlink" title="redis 的事务实现"></a>redis 的事务实现</h3><p>redis 本身提供了较为简单的事务支持,主要涉及到 2 个指令,完成 3 个步骤</p><ol><li>客户端发送 <code>MULTI</code> 指令显示声明开启一个事务</li><li>客户端随后将事务的指令发送给 redis,redis 在收到这些指令后不会立即执行,而是放入一个暂存队列里面等待最后一个事务提交的指令</li><li>客户端发送 <code>EXEC</code> 指令声明提交当前事务,redis 在收到 <code>EXEC</code> 之后会依次从暂存队列里面取出中间收到的指令并执行</li></ol><p>由于 redis 对事物的支持比较简单,主要关注下对于事务的四大特征 <code>ACID</code> redis 与 msyql 都有哪些不同</p><h4 id="A-原子性"><a href="#A-原子性" class="headerlink" title="A 原子性"></a>A 原子性</h4><p>分三种情况分析 redis 对原子性的支持</p><ol><li>在事务真正只执行前报错</li></ol><p>在客户端发送 <code>EXEC</code> 之前,如果客户端发送了 redis 不支持的指令,此时 redis 会报错并且记录下这个错误,此时事务里面的其他所有的指令都不会被执行,原子性得到保证</p><ol start="2"><li>在事务执行过程中报错</li></ol><p>有些指令能通过 redis 的语法检查,但是在运行时才会具体报错</p><p>例如对一个 <code>string</code> 字符串类型的 <code>key</code> 做 <code>LPOP</code> 操作,在没有真正执行命令之前,redis 是不知道 <code>LPOP</code> 指令后面操作的 <code>key</code> 的具体类型</p><p>所以这个错误只有在运行时才会发生,此时 redis 会继续执行剩下的语句</p><p>对于 mysql 来说,如果事务过程又发生错误,此时所有的已经执行的语句都会发生回滚,而 redis 是 <code>没有回滚</code> 的会继续把剩下的正确语句执行完成</p><p>在这种情况下,redis 无法保证事务的原子性</p><ol start="3"><li>在执行时发生宕机</li></ol><p>如果 redis 有打开 <code>AOF</code> 日志进行持久化,在宕机后数据恢复时,可以通过工具检测 <code>AOF</code> 日志里面记录的事务是否完整</p><p>因为 <code>AOF</code> 日志是每执行一条指令后写入(写后日志),如果 <code>AOF</code> 日志记录有 <code>MULT</code> 开启事务,但是并没有 <code>EXEC</code> 提交事务,此时恢复工具会清理 <code>AOF</code> 里面这些不完整的事务记录</p><p>这样在使用 <code>AOF</code> 日志做数据恢复时,就不会执行这些未提交的事务指令了,此时事务的原子性能够得到保证</p><p>总结如下:</p><ol><li>命令入队时,语法检查报错,整个事务不会执行,事务的原子性能够得到保证</li><li>提交事务后,执行事务语句时报错,跳过报错的语句,继续执行剩下正确的语句,事务的原子性无法得到保证</li><li>执行事务时,发生宕机,如果有开启 <code>AOF</code> 日志,则能够保证事务的原子性; 如果没有开启 <code>AOF</code> ,则无法保证事务的原子性</li></ol><h4 id="C-一致性"><a href="#C-一致性" class="headerlink" title="C 一致性"></a>C 一致性</h4><p>对于上述三种情况,依旧可以分析一致性问题</p><ol><li>命令入队时报错,此时没有任何语句被执行,能够保证数据库的一致性</li><li>提交事务后,错误的命令不会执行,正确的命令可以执行,此时数据库的一致性没有被破坏</li></ol><p>需要注意的,这里的一致性,宏观层面上说的是,数据库能够从一个正确的状态转移到另一个正确的状态,这叫做数据库的一致性</p><p>对于这种情况,错误的状态并没有发生,而正确的指令也能够得到执行,对于数据库来说,能够得到正确的结果 <code>(即使在业务看来是错误的结果,但 redis 数据执行并没有报错)</code> ,所以对于 redis 数据库来说,一致性是没有受到破坏的</p><ol start="3"><li>执行事务时发生宕机<ul><li>如果没有开启 <code>AOF</code> 或者 <code>RDB</code> 则执行一半的事务在宕机后就全部丢失了,重启恢复数据时自然也没有,数据库的一致性没有受到破坏</li><li>如果开启了 <code>RDB</code> 快照,但是 <code>RDB</code> 快照在事务执行时不会记录,所以使用 <code>RDB</code> 快照做数据恢复时,也没有事务的记录,数据库的一致性没有受到破坏</li><li>如果开启了 <code>AOF</code> 日志,在做数据恢复时,恢复工具能够检测 <code>AOF</code> 日志当中未执行完的事务语句并且清除掉,数据库的一致性也没有受到破坏</li></ul></li></ol><h4 id="I-隔离性"><a href="#I-隔离性" class="headerlink" title="I 隔离性"></a>I 隔离性</h4><ol><li>在事务之前使用 <code>watch</code> 机制保证事务的隔离性</li></ol><p>如果一个事务还没有提交 <code>EXEC</code> 语句,此时并没有得到真正的执行,而是所有指令都处于就绪队列里面; 如果此时还存在其他并发操作,就需要依赖 <code>watch</code> 机制保证事务的隔离性不被破坏</p><p><code>watch</code> 机制的作用是在事务执行前,监控一个或者多个变量是否发生改变; 当真正提交 <code>EXEC</code> 指令时, <code>watch</code> 机制会检查事务修改的变量是否和事务提交前发生了变化</p><p>如果被其他事务修改了,那么就放弃当前事务的执行,避免事务的隔离性发生破坏 <code>(没有类似于 mysql 的快照读)</code>; 如果没有发生改变,则可以继续执行事务</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h84curi2fsj30i30bgq5y.jpg" alt="img.png"></p><p>如果事务没有使用 <code>watch</code> 机制,那么事务的隔离性可能受到破坏</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h84cuy1i6wj30ht09nacd.jpg" alt="img_1.png"></p><ol start="2"><li>在事务提交后,因为 redis 是单主线程,隔离性能够得到保证</li></ol><p>这个很简单了,因为 redis 单主线程的缘故,一旦事务开始执行后,其他指令只得乖乖等待主线程完成事务之后才能处理; 所以事务的隔离性在这种情况下不会被破坏</p><h4 id="D-持久性"><a href="#D-持久性" class="headerlink" title="D 持久性"></a>D 持久性</h4><ol><li>即使开启了 <code>AOF</code> 日志或者 <code>RDB</code> 快照,由于刷盘机制的问题,都存在宕机后部分数据丢失的情况</li><li>如果没有开启持久化操作</li></ol><p>无论采用什么持久化方式,这两种情况数据库的持久性都没有得到保证</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十三)redis 原子性问题</title>
    <link href="/2022/11/13/redis/(%E5%8D%81%E4%B8%89)redis%20%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98/"/>
    <url>/2022/11/13/redis/(%E5%8D%81%E4%B8%89)redis%20%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="并发场景下如何保证正确性"><a href="#并发场景下如何保证正确性" class="headerlink" title="并发场景下如何保证正确性"></a>并发场景下如何保证正确性</h3><p>并发读取一个数据不需要额外考虑,因为本身读操作之间是共享的</p><p>并发写一个数据则需要考虑互斥问题,同一时间对于同一个数据来说只能有一个线程进行写操作,其他线程都必须等待; 不然就会导致严重的并发问题</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83sa17v4wj30iu0bo400.jpg" alt="img.png"></p><p>例如这个例子,线程 A 和线程 B 同时更新一个库存值,由于并没有任何额外的并发控制,导致最终的数据表现和预期不一致</p><p>这是由于线程对库存的可以拆分为 3 个子步骤:</p><ol><li>获取当前的库存值</li><li>当前库存值-1</li><li>将最新的库存值写入缓存</li></ol><p>而这 3 个子步骤之间并没有通过任何方式进行并发控制,导致多个线程同时操作,最后出现数据不一致的问题</p><p>最简单的解决并发安全问题的手段有两个</p><ol><li>加锁使之串行化</li><li>使用原子操作</li></ol><h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><p>加锁是解决并发问题的最简单最直接的方式,但是加锁和释放锁会明显的导致系统并发性下降,同时这两个过程也会增大请求的响应耗时</p><p>如果是分布式服务,还必须引入分布式锁,这也会加大系统的复杂程度</p><h3 id="redis-提供的原子操作"><a href="#redis-提供的原子操作" class="headerlink" title="redis 提供的原子操作"></a>redis 提供的原子操作</h3><p>为了实现并发操作临界区资源,redis 提供了两种方式保证指令的原子性</p><ol><li>将多条指令通过一个 <code>Lua</code> 脚本的方式提交给 redis 执行</li><li>将多条指令合并为 1 条指令执行</li></ol><h4 id="redis-的单指令操作"><a href="#redis-的单指令操作" class="headerlink" title="redis 的单指令操作"></a>redis 的单指令操作</h4><p>因为 redis 的核心线程只有一个,所以当主线程执行一条指令的时候,就无法执行其他指令; 有这个特性就能够保证 redis 在执行单指令的时候一定是一个原子操作</p><p>对于数据的加减,有原子增和原子减,即 <code>INCR/DECR</code> ,多个线程并发执行原子增&#x2F;减指令,其最终效果与串行化执行表现一致</p><p>还例如使用 redis 作为分布式锁时,通常需要在加锁前先判断锁是否可获取</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">get</span> <span class="hljs-keyword">lock</span><br><span class="hljs-keyword">if</span> (got) &#123;<br>    <span class="hljs-keyword">set</span> <span class="hljs-keyword">lock</span><br>&#125;<br>// <span class="hljs-keyword">do</span> something <span class="hljs-keyword">with</span> <span class="hljs-keyword">lock</span><br>del <span class="hljs-keyword">lock</span><br></code></pre></td></tr></table></figure><p>可以看在一次分布式锁的获取过程当中,先判断,在加锁是两个步骤,如果直接提交的话是无法保证原子性的</p><p>redis 提供了 <code>set if not exist</code> 类似的单指令操作,用于实现最简单的分布式锁</p><h4 id="redis-Lua-脚本"><a href="#redis-Lua-脚本" class="headerlink" title="redis Lua 脚本"></a>redis Lua 脚本</h4><p>如果一个业务无法使用 redis 提供的单指令完成,又要保证其原子性,就必须使用 <code>Lua</code> 脚本</p><p>将多条指令放入一个 <code>Lua</code> 脚本里面提交给 redis 执行,redis 会把 <code>Lua</code> 脚本当做一个整体去执行,在这个执行过程当中不会被其他指令打断,从而保证了 <code>Lua</code> 脚本的原子性</p><h3 id="redis-如何实现分布式锁"><a href="#redis-如何实现分布式锁" class="headerlink" title="redis 如何实现分布式锁"></a>redis 如何实现分布式锁</h3><p>前面说到,想要保证并发安全问题,除了原子操作以外,还有个最简单解决并发问题的方案,那就是加锁使命令串行化</p><p>对于一个分布式系统来说,锁都必须要求是所有其他系统都能访问到的,而不是只属于某个服务的 <strong>本地锁</strong>; 这要求锁必须保存到一个能够被多个客户端共享访问的系统上,redis 正好就是一个共享存储的系统,所以可以使用 redis 来实现分布式锁</p><h4 id="单节点-redis-实现分布式锁"><a href="#单节点-redis-实现分布式锁" class="headerlink" title="单节点 redis 实现分布式锁"></a>单节点 redis 实现分布式锁</h4><p>最简单的 redis 锁实现就是通过一个变量,来判断这个变量值来决定是上锁还是没有上锁; 例如约定 <code>锁变量 == 1</code> 表示已上锁,而 <code>锁变量 == 0</code> 表示没有上锁</p><p>由于是单节点 redis,而且 redis 的核心线程也只有 1 个,即使线程 A 和 C 同时发出加锁请求,redis 也只能串行化处理; 所以同一时间内最多只能有 1 个线程能够持有锁</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83sa6z51vj30hx0e0q5i.jpg" alt="img_1.png"></p><p>释放锁的过程也很简单,就是把对应锁变量的值修改为 <code>0</code>, 这样其他线程就能继续持有和释放这同一把锁</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83sacwjkyj30gt0d6jt1.jpg" alt="img_2.png"></p><p>简单分析可以发现,上锁的过程包含好几个步骤:</p><ol><li>获取锁变量的值</li><li>判断锁变量值是否等于 <code>0</code></li><li>如果等于 <code>0</code> 则设置锁变量的值为 <code>1</code> 表示当前线程已经持有这把锁</li><li>如果等于 <code>1</code> 则上锁失败,继续等待下一次请求上锁</li></ol><p>而这些步骤再实际执行时,因为可能存在并发安全的问题,所以必须保证原子性</p><p>redis 对于分布式锁的实现,提供了一条单指令 <code>SETNX</code> 其效果等于 <code>SET key value IF NOT EXIST</code>: 如果 <code>key</code> 不存在的话就设置对应的键值对数据; 如果 <code>key</code> 已经存在,则不做任何操作</p><p>这里的锁变量不再是某个变量值是否为 <code>0</code> 或者 <code>1</code> ,而是直接判断某个变量存在与否; 当不再需要锁是,直接 <code>DEL key</code> 删掉变量即可</p><h4 id="SETNX-指令实现的分布式锁的潜在风险"><a href="#SETNX-指令实现的分布式锁的潜在风险" class="headerlink" title="SETNX 指令实现的分布式锁的潜在风险"></a>SETNX 指令实现的分布式锁的潜在风险</h4><p>上述方案并不是完美的分布式锁实现, 单单只用一条 <code>SETNX</code> 指令还存在其他风险</p><ol><li>如果某个线程上锁成功,但是在释放锁之前异常挂掉了,此时这个变量值将会一直存在下去无法被释放; 这会导致其他线程再也无法获取到锁,从而阻塞整个服务的运行</li></ol><p>针对这个问题最简单的办法,就是 <code>给分布式锁添加上一个自动过期时间</code></p><p>这样一来,即使某个线程持有锁之后异常挂掉了,在经过一段时间后,锁也会自动释放; 不会完全阻塞其他线程</p><ol start="2"><li>如果某个线程上锁成功,但是其他线程执行了 <code>DEL key</code> 指令,这会导致线程的锁被其他线程误释放掉</li></ol><p>此时如果有其他线程申请到了锁,这样就会和第一个线程同时操作临界区资源,最后可能导致严重的数据不一致问题</p><p>针对锁被其他线程 <strong>误</strong> 释放的问题,可以在加锁的时候,带上一个唯一标识以区分不同的加锁请求</p><p>上述加锁方案仅仅通过 <code>0</code> 或者 <code>1</code>,或者单纯的判断变量是否存在, 这是无法区分出不同的加锁请求的; 这就要求在加锁的时候,在锁变量上带上自己的唯一标识</p><p>这个唯一标识的取值并不固定,线程 id,客户端 id 这种有唯一性约束的都可以</p><p>最后上锁指令变为 <code>SETNX key unique_id EX 10</code> 其中 <code>EX 或者 PX</code> 表示带上超时时间单位分别是 <code>秒</code> 或者 <code>毫秒</code></p><p>这样在释放锁的时候,就不再是简单的 <code>DEL key</code> 了,而是先获取锁变量的值,判断其 <code>value</code> 是否等于自己的唯一性标识,如果是才删除,否则说明是别人加的锁自己不能删除</p><p>这导致释放锁的操作变为多个步骤,还必须通过 <code>Lua</code> 脚本保证释放锁也是一个原子性操作</p><ol start="3"><li>锁过期问题</li></ol><p>在经历了上面两个优化之后,还存在另一个问题,那就是如果持有锁的线程在处理业务的时候耗时过长,超过了上锁时设置的自动过期时间; 这也会导致锁被提前释放,可能引起并发安全问题</p><p>这里 redis 原生没有提供对应的解决方案,需要通过其他额外的三方提供类似于 <code>自动续期</code> 的功能</p><ol start="4"><li>单机节点宕机</li></ol><p>由于 redis 是单节点部署,如果说 redis 发生了宕机,此时整个系统的锁就无法正常提供服务,整个业务相当于不可用</p><p>最终,还是需要依靠集群部署的 redis 提供分布式锁,才能有效解决上面提到的所有问题</p><h4 id="redis-分布式锁"><a href="#redis-分布式锁" class="headerlink" title="redis 分布式锁"></a>redis 分布式锁</h4><p>想要实现系统的高可用,单节点明显是不可能的; 一旦引入了分布式,整个系统的复杂度也就远比单机系统更为复杂; 在分布式锁的设计上,就需要按照一定的步骤和规范进行加解锁操作; 否则将会导致非预期的表现</p><p>redis 官方提供了基于集群部署下的分布式锁实现 <code>RedLock 红锁</code>; 简单来说,就是采用 <code>过半机制</code>,即加锁和释放锁的标志为 <code>在半数以上的节点上操作成功</code></p><p>这样分布式锁就保存在多个主节点上,即使有主节点发生宕机,其他主节点仍然能够维护这些分布式锁</p><p>红锁的主要实现过程如下,假设整个 redis 集群当中有 <code>N</code> 个节点:</p><ol><li>客户端获取当前时间 <code>now</code></li><li>客户端 <code>依次</code> 向 <code>N</code> 个节点发送加锁请求</li></ol><ul><li>加锁的过程与单节点几乎一致,即 <code>SETNX key unique_id EX expire</code></li><li>如果在对某个节点请求加锁的过程发生了超时,就继续向下一个节点发起加锁请求; 这里加锁时的超时时间远小于整个锁的超时时间,保证如果能拿到锁,也不至于立马就过期被释放掉</li></ul><ol start="3"><li>一旦客户端请求完 <code>N</code> 个节点后,就需要计算整个加锁过程的 <code>总耗时 cost</code></li></ol><p>只有在满足下面两个条件时,才认为最终加锁成功</p><ol><li>加锁成功的节点个数过半 <code>即 &gt;= N/2 + 1</code></li><li>总耗时小于锁的超时时间,即 <code>cost &lt; expire</code>,最终锁的有效时间为 <code>expire - cost</code></li></ol><p><strong>需要注意的是,如果一个客户端最终加锁失败,那么它必须立即向所有节点发送解锁请求</strong></p><p>使用了 <code>Redlock</code> 之后,只要保证集群当中有半数以上的实例正常工作,就能保证分布式锁的正常工作</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十二)redis 缓存问题</title>
    <link href="/2022/11/13/redis/(%E5%8D%81%E4%BA%8C)redis%20%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/"/>
    <url>/2022/11/13/redis/(%E5%8D%81%E4%BA%8C)redis%20%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-缓存所面临的问题"><a href="#redis-缓存所面临的问题" class="headerlink" title="redis 缓存所面临的问题"></a>redis 缓存所面临的问题</h3><p>在高并发业务下,数据库往往是性能最为薄弱的环节; 所以使用 redis 放在业务和数据库之间,作为旁路缓存起到一个缓冲的作用,避免所有请求全部打到数据库; 这样可以大大的缓解数据库的压力</p><p>当 redis 作为旁路缓存使用时,就不得不考虑以下几个问题</p><ol><li>缓存穿透</li><li>缓存击穿</li><li>缓存雪崩</li><li>缓存污染或者缓存写满(回顾下缓存的淘汰策略)</li><li>缓存和数据库的一致性问题</li></ol><h3 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h3><p>什么是 <code>缓存穿透</code>, 就是一个数据 <strong>即不存在于数据库,也不存在于缓存里</strong> ; 每次对这个数据的请求都不会命中缓存,而是直接发向数据库</p><p>由于数据库里面也没有,所以也不会回写到缓存里,导致缓存的存在失去了意义</p><p>在大量请求的场景下,如有有人恶意构造不存在的 <code>key</code> 从而发起攻击,很可能导致数据库压力过大</p><p>解决方案:</p><ol><li>业务层做校验,对于一些请求非法资源的,直接拦截掉; 例如 <code>id &lt; 0</code></li></ol><p>实际上业务层无法做到对所有非法请求的拦截,只能过滤掉一些常规的明显的非法参数</p><ol start="2"><li>如果在缓存和数据库里面都查询不到数据,业务层可以回写一个空数据,即 <code>key-null</code> 到缓存里面; 这样下次对于这个不存在的 <code>key</code> 的请求,就可以由缓存快速返回空值 <code>null</code></li></ol><p>如果有大量不存在的 <code>key</code> 请求都通过这种方式在缓存里面写入了空 <code>key-null</code>,就会造成缓存的内存空间被浪费; 可以对这些 <code>key-null</code> 设置一个较小的过期时间 <code>10s</code><br>之类的,避免缓存里面长时间被塞满空 <code>key-null</code> 键值对</p><ol start="3"><li>使用布隆过滤器</li></ol><h4 id="使用布隆过滤器来减少缓存穿透的问题"><a href="#使用布隆过滤器来减少缓存穿透的问题" class="headerlink" title="使用布隆过滤器来减少缓存穿透的问题"></a>使用布隆过滤器来减少缓存穿透的问题</h4><p>布隆过滤器是一种 <code>概率型数据结构</code> ,用于在有限的内存空间内,快速判断一个元素是否存在于集合当中</p><p>为什么说是 <code>概率型</code> 因为布隆过滤器是基于统计判断的; 如果布隆过滤器说元素存在于集合当中,此时元素 <strong>可能</strong> 不存在(统计发生了偏差错误); 如果布隆过滤器说元素不存在于集合当中,此时元素 <strong>一定</strong> 不存在</p><p>布隆过滤器的基本数据结构其实就是一个 <code>bit 数组</code>,首先分配一块内存空间作为 <code>bit 数组</code> ,数组的每个位都初始化为 <code>0</code></p><p>当有一个元素加入时,布隆过滤器使用 <code>K</code> 个互相独立的哈希函数计算得到 <code>K</code> 个不同的位置,然后把这 <code>K</code> 个不同的位置设置为 <code>1</code></p><p>当需要检测一个元素是否存在于集合当中时,则仍然使用这些哈希函数计算得到对应的位置,判断这些位置上是否全部是 <code>1</code>,如果全部是 <code>1</code> ,则元素 <code>可能</code> 存在于集合当中; 如果有 <code>0</code> 出现,则元素 <code>一定</code> 不存在集合当中</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83cyg2hrbj30lm0cl424.jpg" alt="img.png"></p><p>由于布隆过滤器使用哈希函数计算,不可避免会产生 <code>哈希碰撞</code></p><p>即不同的元素经过哈希函数计算后,得到了相同的哈希值; 导致集合只有其中一个元素时,也会判断另一个元素存在</p><p>而且布隆过滤器存在几个比较致命的问题:</p><ol><li>不允许对布隆过滤器中的元素做删除操作</li><li>当布隆过滤当中的元素增多时,其误判率会增大</li></ol><p>因为存在 <code>哈希碰撞</code> 的问题,导致一个元素被删除后,将 <code>bit 位</code> 置 <code>0</code> 的时候会影响其他元素的哈希值; 因此导致布隆过滤也认为其他被影响到的元素不存在于集合当中</p><h3 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h3><p>什么是 <code>缓存击穿</code>, 针对热点数据的访问非常频繁,而缓存里面没有这条数据,导致大量请求在短时间内全部打到了数据库,因为数据库压力激增</p><p>什么情况会导致缓存击穿: 当某个热点数据过期后,被 redis 淘汰掉,此时大量请求会穿过 redis 直接来到数据库</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83cymyd61j30ho09i75x.jpg" alt="img_1.png"></p><p>对于缓存击穿问题,解决办法也比较直接</p><ol><li>既然是由于热点数据过期导致未命中缓存,就直接把热点数据设置一个很长的过期时间直到大流量时间过去; 或者干脆设置热点数据永不过期</li><li>缓存击穿是因为短时间内高并发请求透过缓存直接打到数据库; 针对高并发场景下,一个最原始最直接的办法就是 <code>加锁互斥串行化</code></li></ol><p>针对加锁,主要实现如下:</p><ul><li>第一个拿到锁的线程查询数据库后,回写到缓存里</li><li>后面没拿到锁的线程全部排队等待锁</li><li>当第一个线程完成缓存回写之后,后续所有请求都会由缓存直接返回; 即使存在加锁和释放的过程也很短暂</li></ul><h3 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h3><p>什么是 <code>缓存雪崩</code>, 缓存击穿是一个 <code>key</code> 发生过期导致针对这个 <code>key</code> 的请求全部打到数据库; 而 <code>缓存雪崩</code> 就是短时间内, <code>大量</code> 的 <code>key</code> 发生过期,从而引发大量数据打入数据库,导致数据库压力激增</p><p><code>缓存雪崩</code> 和 <code>缓存击穿</code> 一个很明显的区别就是: 击穿是针对一个 <code>key</code> 过期的大量并发请求; 而雪崩是大量 <code>key</code> 过期时的大量并发请求; 后者对业务的影响更为严重</p><h4 id="缓存雪崩的原因之一-短时间内大量数据过期"><a href="#缓存雪崩的原因之一-短时间内大量数据过期" class="headerlink" title="缓存雪崩的原因之一: 短时间内大量数据过期"></a>缓存雪崩的原因之一: 短时间内大量数据过期</h4><p>很简单的一个场景,例如有一批热点短视频需要由运营发布上线,此时为了配合运营,开发人员使用批处理任务或者脚本将这批视频数据刷入缓存里面,由于是批处理任务所以这些视频数据被设置了相同的过期时间</p><p>当这个过期时间到达后,这批热点数据立马全部在缓存里面失效; 后续所有对这批数据的请求,将会全部直接打到数据库,引发缓存雪崩</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83cysg1ovj30hh09jwg9.jpg" alt="img_2.png"></p><p>解决的办法也很简单,针对批量设置热点数据过期的问题,可以引入一个随机数,每次对数据设置过期时间 <code>expire</code> 时,都为其加上一个随机数 <code>random</code> 这样可以有效的解决相同过期时间到达后,大量数据的过期</p><p>除了添加随机过期时间,还可以从业务层面直接降级熔断</p><ul><li>如果是非关键路径上的请求,则可以在业务层暂时快速失败,提前返回错误,控制或者预先准备好的预定义数据</li><li>如果是关键路径上的请求,则允许这部分请求先打到数据库; 这样可以减少直接进入数据的请求量; 当这些请求完成了缓存回写后,后续的请求依然可以通过缓存快速得到结果</li></ul><p>服务限流也是一种有效手段,例如业务的请求量是 <code>10000/s</code> ,而其中 <code>9000</code> 个可以在 redis 处理直接返回,剩下的 <code>1000</code> 个只能由数据库提供支持</p><p>在某一时刻 redis 宕机不可用,此时大量 <code>key</code> 全部失效,导致请求压力一下子来到了数据库,引起缓存雪崩</p><p>这个时候当业务端发现 redis 不可用,或者发现缓存雪崩(通常监控到数据库的请求量突增的情况)时,可以在业务层启动限流,让原来的 <code>10000/s</code> 请求量限制到 <code>1000/s</code><br>这样数据库的压力与原来保持一致,可以避免缓存雪崩时数据库的性能被严重影响</p><h3 id="缓存和数据库之间的数据一致性问题"><a href="#缓存和数据库之间的数据一致性问题" class="headerlink" title="缓存和数据库之间的数据一致性问题"></a>缓存和数据库之间的数据一致性问题</h3><p>将 redis 当做旁路缓存使用,只要涉及到数据的更新,就很容易出现缓存和数据库之间的一致性问题</p><p>旁路缓存的一致性保证了什么?</p><ol><li>如果缓存中有数据,则缓存中的数据必须和数据库里的数据保持一致</li><li>如果缓存里面没有数据,则数据库里的数据必须是最新值</li></ol><p>任何不满足上述两点的情况,都属于数据不一致的问题</p><h3 id="读写缓存的数据一致性问题"><a href="#读写缓存的数据一致性问题" class="headerlink" title="读写缓存的数据一致性问题"></a>读写缓存的数据一致性问题</h3><p>对于 <code>读写缓存</code> 来说,有两种写回数据库的策略</p><ol><li>同步直写:写缓存时,也同步写数据库,两个都写入成功后才返回成功,保证数据的强一致性</li><li>异步回写:写缓存成功后就返回操作成功,等缓存页被淘汰时,当做 <code>脏页</code> 刷入数据库</li></ol><p>对于有强一致性要求的场景,就只能采用同步直写策略; 且业务端需要把写缓存和写数据库放到同一个事务里面操作; 通过事务的原子性保证要么全部写成功,要么全部失败回滚</p><p>对于 <code>只读缓存</code> 来说</p><p>如果有新增数据,就直接写入数据库,这样未命中缓存的请求就可以通过数据库拿到最新数据,并且写回缓存</p><p>如果有更新数据,则分两种策略:</p><ol><li>先删除缓存的数据,再更新数据库</li><li>先更新数据库,然后再删除缓存的数据</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83hzqwf0hj30hg08a0tz.jpg" alt="img.png"></p><ol><li>新增数据时,符合旁路缓存的一致性要求,不会产生一致性问题</li><li>删改数据时,如果采用先删缓存,再删数据库</li></ol><p>如果缓存删除成功,但是数据库更新失败; 后续的请求在缓存未命中的情况下,就会从数据库里面取到旧值</p><p>或者说线程 A 准备更新记录,如果刚把缓存的数据删除; 此时线程 B 读取数据缓存缺失,就会从数据库里面取到还没来得及更新的旧值,导致数据不一致</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i0ab1nbj30j609iq4u.jpg" alt="img_1.png"></p><ol start="3"><li>删改数据时,如果采用先删数据库,再删缓存的策略</li></ol><p>如果数据库删除成功,缓存删除失败; 后续的请求直接命中缓存,取到旧数据</p><p>或者说线程 A 准备更新数据,刚刚把数据库里面的数据更新掉; 此时线程 B 读取数据命中缓存后直接返回,此时线程 B 读到的是线程 A 还没来得及更新的旧值,导致数据不一致问题再次发生</p><p>可以看到,在并发场景下,读写数据的数据一致性问题难以得到保障</p><h3 id="如何解决读写数据库的数据一致性问题"><a href="#如何解决读写数据库的数据一致性问题" class="headerlink" title="如何解决读写数据库的数据一致性问题"></a>如何解决读写数据库的数据一致性问题</h3><p>无论写请求时更新还是删除,在操作缓存的时候,都进行删除操作,即使是更新数据</p><p>考虑两个并发线程 A,B 同时更新一条数据</p><ol><li>A 先更新数据库,B 接着更新数据库,此时数据库里面记录的最新值是 B 的结果</li><li>当 B 更新完数据库后,更新缓存里面的旧值后返回,B 完成请求</li><li>此时 A 拿着自己从数据库里面刚更新的旧值,又把缓存里面 B 更新的新值给覆盖掉,此时产生了数据不一致问题</li></ol><p>如果上述两个线程在更新数据库之后,都采用删除缓存的操作,就不会有数据不一致的问题产生</p><h4 id="更新缓存-或者更新数据库失败的场景-可以采用消息队列进行重试"><a href="#更新缓存-或者更新数据库失败的场景-可以采用消息队列进行重试" class="headerlink" title="更新缓存,或者更新数据库失败的场景,可以采用消息队列进行重试"></a>更新缓存,或者更新数据库失败的场景,可以采用消息队列进行重试</h4><p>首先将需要更新或者删除的数据发到消息队列里,然后更新或删除数据库或者缓存里面的数据,如果这个步骤失败了则从消息队里面取出消息进行重试</p><p>直到数据库和缓存的数据都已经更新完成之后,把消息队列里面的消息移除,避免重复消费</p><p>如果重试次数达到阈值,则直接向业务端返回报错</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i027ep7j30j80b4ju1.jpg" alt="img_2.png"></p><p>这个过程当中,仍然存在数据不一致的问题,只不过重试机制保证的是数据的最终一致性,无法保证数据的强一致性</p><h4 id="先删除缓存-再更新数据库"><a href="#先删除缓存-再更新数据库" class="headerlink" title="先删除缓存,再更新数据库"></a>先删除缓存,再更新数据库</h4><p>线程 A 准备更新数据,刚刚把数据库里面的数据更新掉; 线程 B 读取数据命中缓存后直接返回,此时线程 B 读到的是线程 A 还没来得及更新的旧值</p><p>如果是删除而不是更新操作,上面的线程 B 可能会把数据库里面的旧值继续写回缓存; 这样在线程 A 对缓存的更新操作完成之前,后续的并发请求仍然会从缓存里面读取到旧值</p><h4 id="延时双删-策略"><a href="#延时双删-策略" class="headerlink" title="延时双删 策略"></a>延时双删 策略</h4><p>为了尽可能避免 <code>先删除缓存,再更新数据库</code> 策略下的数据不一致问题</p><p>简单来说,就是在写数据库的前后,都执行一次缓存的删除操作,伪代码如下</p><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs q">redis.<span class="hljs-keyword">delete</span>(<span class="hljs-built_in">key</span>)<br>mysql.<span class="hljs-keyword">update</span>(<span class="hljs-built_in">key</span>)<br>sleep(n)<br>redis.<span class="hljs-keyword">delete</span>(<span class="hljs-built_in">key</span>)<br></code></pre></td></tr></table></figure><p>其中有个关键点就是 <code>sleep(n)</code> ,这里的等待时间,是为了保证读请求结束后,写请求可以把读请求因为缓存缺失而写回缓存的脏数据给删除掉</p><p>问题是这个 <code>n</code> 值是一个很难确认的数值; 如果 <code>n</code> 值过大,则会导致后续的读请求可能继续读到脏数据; 如果 <code>n</code> 值过小,也可能导致发生脏读的请求还没写入缓存,此时写请求就结束了,接着发生脏读的请求又把脏数据写回缓存</p><p><strong>实际上延时双删是非常不靠谱的解决方案,因为这个 <code>sleep(n)</code> 的评估非常难,而且 <code>sleep(n)</code> 这一步本就不可避免的增大了链路的整体耗时</strong></p><p>如果非要采用 <code>先删除缓存,再更新数据库</code> 的策略,最好使用 <code>消息队列</code> 将第二次删除操作异步化</p><p>这样可以在不 <strong>太</strong> 影响链路整体耗时的情况下,借助 <code>消息队列</code> 的异步和重试机制,保证数据的最终一致性</p><h4 id="先更新数据库-再删除缓存"><a href="#先更新数据库-再删除缓存" class="headerlink" title="先更新数据库,再删除缓存"></a>先更新数据库,再删除缓存</h4><p>对于旁路缓存来说,采用的就是 <code>先更新数据库,再删除缓存</code> 的策略</p><p>但是不可避免也会存在数据不一致的问题</p><p>线程 A 更新数据库之后,还没来得及删除缓存时,线程 B 已经读取到缓存的旧值并返回</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i0lmu3hj30j508q0wf.jpg" alt="img_3.png"></p><h2 id="总结-无论是先删缓存还是先操作数据库-都存在数据不一致的问题"><a href="#总结-无论是先删缓存还是先操作数据库-都存在数据不一致的问题" class="headerlink" title="总结: 无论是先删缓存还是先操作数据库,都存在数据不一致的问题"></a>总结: 无论是先删缓存还是先操作数据库,都存在数据不一致的问题</h2><p>而先删缓存,在操作数据库,其最终结果可能连最终一致性都无法得到保障; 只能通过额外的步骤来保证数据的最终一致性,但是这样又引入了更高的系统复杂度</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i0qo8aoj30k408qq4y.jpg" alt="img_4.png"></p><p>可以看到,在线程 A 删除缓存之后, 线程 B 在 A 更新数据库之前已经读取到了旧值,并且还把旧值给写回缓存了; 这样后续的请求都只能读到缓存里面的脏数据; 数据的最终一致性没有得到保证</p><p>而先操作数据库,再删除缓存,能够保证数据的最终一致性</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i0va75rj30kp0ahjtw.jpg" alt="img_5.png"></p><p>可以看到当线程 A 更新数据库后,线程 B 从缓存里面读取到旧值返回,当线程 A 将缓存里面的旧值删掉后,下一个请求就会把数据库里面的最新值写回缓存; 就这样保证了数据的最终一致性</p><p>即使也有数据不一致的问题产生,但是先操作数据库,再删除缓存能够保证数据的最终一致性; 对于大部分能够不需要强一致性的业务来说,这就是最简单的解决方案</p><p>考虑一种特殊情况,如果某个数据刚好过期,或者缓存里面压根就没有</p><p>此时线程 B 先从数据库里面读到了旧值,接着线程 A 更新数据库然后删除缓存(即使没有也执行删除操作),最后线程 B 再把刚刚读到的旧值给写回缓存,这样后续所有请求都会读取到旧值,导致数据不一致问题产生</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83i0zoxtoj30l509ywgx.jpg" alt="img_6.png"></p><p>在实际情况下,这要求线程 B 从数据库里读出旧值到写回缓存的这段期间时间长于线程 A 更新数据库后再删除缓存</p><p>更新数据库的时间通常比查询数据库的时间更长,而线程 B 仅仅是查询数据库,却反而比线程 A 更新数据还要花更长的时间; 这种概率非常小</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十一)redis 缓存淘汰策略</title>
    <link href="/2022/11/12/redis/(%E5%8D%81%E4%B8%80)redis%20%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/"/>
    <url>/2022/11/12/redis/(%E5%8D%81%E4%B8%80)redis%20%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-的缓存淘汰机制"><a href="#redis-的缓存淘汰机制" class="headerlink" title="redis 的缓存淘汰机制"></a>redis 的缓存淘汰机制</h3><p>想要淘汰一个缓存,有两步关键的步骤</p><ol><li>通过一定的策略,选出 <strong>需要被淘汰</strong> 的缓存</li><li>在合适的时机,将这些缓存从内存里删除</li></ol><p>一旦 redis 实例配置好整体缓存的大小之后,除非是只读缓存否则总会发生缓存被写满的那一刻</p><p>而淘汰缓存就必须要解决上面两个问题:如何选?什么时候删?</p><h3 id="redis-缓存淘汰策略-解决如何选问题"><a href="#redis-缓存淘汰策略-解决如何选问题" class="headerlink" title="redis 缓存淘汰策略(解决如何选问题)"></a>redis 缓存淘汰策略(解决如何选问题)</h3><p>redis 在 4.0 以后提供了 8 种缓存淘汰策略</p><ol><li>不进行缓存淘汰,只有 <code>noeviction</code> 这一种 (通常也没有人会选择这种策略)</li><li>会进行缓存淘汰的其他 7 种策略还可以按照两类进行划分<ul><li>设置了过期时间的数据</li><li>所有范围内的数据</li></ul></li></ol><h4 id="设置了过期时间数据的淘汰策略"><a href="#设置了过期时间数据的淘汰策略" class="headerlink" title="设置了过期时间数据的淘汰策略"></a>设置了过期时间数据的淘汰策略</h4><ol><li>volatile-ttl: 在筛选时,针对设置了过期时间的键值对,根据过期时间的先后进行删除,越早过期的数据越早被删除</li><li>volatile-random: 在筛选时,针对设置了过期时间的键值对,随机选出若干数据进行删除</li><li>volatile-lru: 在筛选时,针对设置了过期时间的键值对,使用 <code>LRU</code> 算法选择需要淘汰的数据</li><li>volatile-lfu: 在筛选时,针对设置了过期时间的键值对,使用 <code>LFU</code> 算法选择需要淘汰的数据</li></ol><h4 id="所有数据的淘汰策略"><a href="#所有数据的淘汰策略" class="headerlink" title="所有数据的淘汰策略"></a>所有数据的淘汰策略</h4><ol><li>allkeys-random: 针对所有数据随机选择并删除</li><li>allkeys-lru: 针对所有数据,使用 <code>LRU</code> 算法选择需要淘汰的数据</li><li>allkeys-lfu: 针对所有数据,使用 <code>LFU</code> 算法选择需要淘汰的数据</li></ol><p>需要注意的是,如果 redis 配置的是针对所有数据的淘汰策略; 那么按照策略选出来的数据即使还没有到过期时间,也会被淘汰掉</p><h3 id="LRU-算法"><a href="#LRU-算法" class="headerlink" title="LRU 算法"></a>LRU 算法</h3><p><code>LRU</code> 算法即 <code>最近最少使用</code> , 可以把一段时间内最不常用的数据筛选出来,而那些频繁被访问的热数据则会继续留在缓存里面</p><p><code>LRU</code> 会把所有缓存页组织为一条链表,表头是 <code>MRU端</code> 表尾是 <code>LRU端</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83ayzqhv2j30ih0iijvw.jpg" alt="img.png"></p><p>当 <code>LRU</code> 缓存里面有数据被命中了,则会被放置到表头; 而那些迟迟没有命中的数据则会随着时间推移慢慢来到表尾</p><p>当 <code>LRU</code> 被放满,而新的请求数据不在 <code>LRU</code> 里面,此时 <code>LRU</code> 发生了缺页就会从磁盘里面加载最新的数据页放到表头; 这样处于表尾的冷数据就会被淘汰掉</p><p>朴素的 <code>LRU</code> 根据局部性原理,认为当前被访问的数据接下来还会访问的概率会很大,所以直接放到表头; 而 <code>LRU</code> 当有大量数据被访问时(类似 mysql 全表扫描导致 <code>buffer pool</code> 缓冲区污染的问题),会带来很多链表节点的移动操作,此时可能会导致 redis 性能下降</p><p>redis 在朴素 <code>LRU</code> 算法上进行了一些改良,并没有通过传统的链表组织数据</p><p>redis 会记录每个数据的最近一次访问时间戳(由 redis 的抽象数据结构 <code>redisObject</code> 记录),这个字段记为 <code>lru</code> 值</p><p>当 redis 需要淘汰数据时,首次会根据配置一次性选出 <code>N</code> 个数据放到一个集合里面; 接下来 redis 会比较这 <code>N</code> 个数据的 <code>lru</code> 值,把最小 <code>lru</code> 值的数据淘汰出去</p><p>后续再次需要进行数据淘汰的时候,redis 会把需要淘汰的数据加入到第一次淘汰时的集合里面去; 这里能够进入淘汰集合的要求是: <code>能进入淘汰集合的数据的 lru 字段必须必集合里面的最小 lru 值还要小</code></p><p>当淘汰集合放满之后,redis 就会把集合中 <code>lru</code> 最小的数据淘汰出去</p><p>这样 redis 就不用维护一个所有数据的链表,也不用每次移动链表节点,只需要比较 <code>redisObject</code> 的 <code>lru</code> 字段即可, 提升了缓存的性能</p><ul><li>如果系统有明显冷热数据的情况,优先选择 <code>allkeys-lru</code> 策略</li><li>如果系统没有明显的冷热数据区分,选择 <code>allkeys-random</code> 进行随机淘汰就可以</li><li>如果系统有 <strong>置顶</strong> 等要求,则选择 <code>volatile-lru</code> 策略,并且将这些置顶的数据设置为永不过期</li></ul><h3 id="如何删除被淘汰的数据"><a href="#如何删除被淘汰的数据" class="headerlink" title="如何删除被淘汰的数据"></a>如何删除被淘汰的数据</h3><p>与 mysql 的 <code>buffer pool</code> 淘汰缓存页类似,同样 redis 也将缓存页分为 <code>干净页</code> 和 <code>脏页</code> </p><ul><li><p>如果需要淘汰的是一张 <code>干净页</code> ,那么直接从内存里面出删除即可</p></li><li><p>如果淘汰的是一张 <code>脏页</code> ,那么从内存删除前还需要把脏页刷入数据库之后才能删除</p></li></ul><h3 id="缓存污染问题"><a href="#缓存污染问题" class="headerlink" title="缓存污染问题"></a>缓存污染问题</h3><p>什么是缓存污染,就是在某些场景之下,有些数据被访问的次数非常少,甚至只有一次,但是仍然停留在缓存里面,造成缓存空间的浪费</p><p>当缓存污染不严重时,新数据还能继续被加入缓存中使用; 当缓存污染占用了较大的空间后,缓存空间已经被用完之后,新数据页想要进入缓存就必须淘汰掉部分页,这就引入了额外的性能开销</p><h4 id="如何解决缓存污染"><a href="#如何解决缓存污染" class="headerlink" title="如何解决缓存污染"></a>如何解决缓存污染</h4><p>最直接的想法就是,把那些缓存命中率很低的数据筛选出来并淘汰掉</p><h4 id="redis-的-8-种缓存淘汰策略"><a href="#redis-的-8-种缓存淘汰策略" class="headerlink" title="redis 的 8 种缓存淘汰策略"></a>redis 的 8 种缓存淘汰策略</h4><ol><li>noeviction: 不淘汰缓存</li><li>针对设置了过期时间的数据:<ul><li>volatile-random: 随机从设置了过期时间的数据中选择部分进行淘汰</li><li>volatile-ttl: 从设置了过期时间的数据淘汰掉已过期的数据</li><li>volatile-lru: 使用 <code>LRU</code> 算法淘汰部分设置了过期时间的数据</li><li>volatile-lfu: 使用 <code>LFU</code> 算法淘汰部分设置了过期时间的数据</li></ul></li><li>针对所有数据:<ul><li>allkeys-random: 随机从所有数据中选择部分进行淘汰</li><li>allkeys-ttl: 从所有数据中淘汰掉已过期的数据</li><li>allkeys-lru: 使用 <code>LRU</code> 算法部分淘汰所有数据</li><li>allkeys-lfu: 使用 <code>LFU</code> 算法淘汰部分所有数据</li></ul></li></ol><p>对于两种随机淘汰策略,很难准确选出那些缓存利用率低的数据,所以在解决缓存污染上效果并不好</p><p>对于两种判断过期时间的策略,由于过期时间并不能反映出缓存的利用率,很可能存在过期时间很长但是几乎不被命中的数据,,所以在解决缓存污染上效果也不好</p><p>除非明确知道有些数据会在什么时候过期,这样当数据不可用之后,自然会被淘汰掉,避免一直留在缓存里面造成污染,但这些数据在真实的服务中,只是很少一部分,绝大多数的数据都无法准确得知其在什么时候应该失效</p><h4 id="LRU-如何避免缓存污染"><a href="#LRU-如何避免缓存污染" class="headerlink" title="LRU 如何避免缓存污染"></a>LRU 如何避免缓存污染</h4><p>简单回顾下 <code>LRU</code> 的过程:</p><ol><li>首次随机选择 <code>N</code> 个数据放入淘汰集合当中,根据 <code>redisObject</code> 的 <code>lru</code> 字段排序后,最小的将会被淘汰掉</li><li>后面每次需要淘汰数据时,都放入淘汰集合当中,然后淘汰掉 <code>lru</code> 字段最小的数据; 这里要能进入淘汰集合的要求是小于淘汰集合当中最小的 <code>lru</code> 值</li><li>重复步骤 2</li></ol><p>一般场景下,缓存命中率高的数据会在 <code>LRU</code> 里面停留较长的时间,那些命中率低的数据则会在适当的时机呗淘汰掉,对于减轻缓存污染的影响有一定作用</p><p>但是对于类似 mysql 的全表扫描场景这时候 <code>LRU</code> 的表现就很糟糕; 这种场景下,每个数据记录的 <code>lru</code> 值都很大,在进入缓存后很难被 <code>LRU</code> 算法淘汰掉,而且这些数据又占用了大量空间</p><p>当有新数据需要进入缓存时,因为缓存被大量数据污染,又会进行淘汰,还是会影响 redis 的性能</p><h4 id="LFU-如何避免单次扫描大量数据导致的缓存污染"><a href="#LFU-如何避免单次扫描大量数据导致的缓存污染" class="headerlink" title="LFU 如何避免单次扫描大量数据导致的缓存污染"></a>LFU 如何避免单次扫描大量数据导致的缓存污染</h4><p>在 redis 4.0 之后,引入了新的缓存淘汰算法 <code>LFU</code></p><p><code>LFU</code> 即最不经常使用: <code>LFU</code> 淘汰那些在一定时间范围内,使用次数最少的数据页<br><code>LRU</code> 是最近最少使用: <code>LRU</code> 淘汰那些最长时间没有被使用过的数据页</p><p>为了统计使用次数,<code>LFU</code> 在 <code>LRU</code> 的基础上将 <code>redisObject</code> 的 <code>lru</code> 字段稍加改善: <code>把原来的 24 位长度的字段拆分为前 16 位用于记录时间戳,后 8 位用于记录访问次数</code></p><p>当进行 <code>LFU</code> 淘汰时,会在淘汰集合里面选出访问次数最少的数据进行淘汰; 如果选出来的数据访问次数都相同,再根据 <code>lru</code> 值最小的数据进行淘汰</p><p>问题点 1: <code>8bit</code> 最多只能表示 256 次,但实际上一个数据被访问的次数很可能超过这个次数,这样 <code>LFU</code> 在次数到达 256 次之后,就不能新增计数,从而导致 <code>LFU</code> 统计不准</p><p>redis 为了避免 <code>8bti</code> 很快被使用完的问题,引入了对计数的优化,新增了一个计数因子 <code>lfu_log_factory</code> 字段,可以简单理解为这个计数因子导致最终的技术并不是 <code>线性增长</code> 的</p><p>官方给出了不同的计数因子下,达到 <code>255</code> 所需要的实际次数</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h83lg791zoj30j904pac9.jpg" alt="img.png"></p><p>问题点 2: 当有些数据在短时间内被大量访问过后,导致其引用计数很大,但是从此以后再也不会被访问了,此时的 <code>LFU</code> 该怎样筛选出这些造成污染的数据</p><p>为了解决这个问题,redis 还引入了 <code>lfu_decay_time</code> 计数衰减因子,简单来说就是数据的引用计数次数,会随着这个 <code>计数衰减因子</code> 而不断减少</p><p>所以那些短时间内被大量访问的数据,之后由于计数衰减因子的存在,其引用计数次数会不断地减少; 直到最后被 <code>LFU</code> 淘汰掉</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可以看到,在应对缓存污染这个问题上</p><ul><li>不淘汰缓存 noeviction</li><li>随机淘汰缓存 volatile-random 和 allkeys-random</li><li>按照过期时间淘汰缓存 volatile-ttl 和 allkeys-ttl</li></ul><p>这几种淘汰策略要么无法避免缓存污染,要么就是对降低缓存污染的效果很小</p><ul><li><code>LRU</code> 在一般场景下,可以很好的避免缓存污染,但是无法处理 <code>单次扫描式查询</code></li><li><code>LFU</code> 则可以很好的解决 <code>LRU</code> 无法处理的 <code>单次扫描式查询</code> 但是要求 redis 版本在 4.0 以上</li></ul><h3 id="redis-过期删除策略"><a href="#redis-过期删除策略" class="headerlink" title="redis 过期删除策略"></a>redis 过期删除策略</h3><p>上面说到的缓存淘汰策略略,都是在 redis 的运行内存已经超过了设置的最大内存后,触发的操作</p><p>如果还没有达到最大内存,此时对数据的请求则叫做过期删除操作</p><p>redis 提供了三种过期删除策略</p><ol><li>定时删除</li></ol><p>需要为每个 <code>key</code> 绑定一个计时器,当计时器结束之后,就触发删除行为</p><p>可以保证每个 <code>key</code> 都会被在过期后尽快删除; CPU 需要维护大量的计时器,资源开销大,得不偿失</p><ol start="2"><li>惰性删除</li></ol><p>当一个 <code>key</code> 过期后,并不立即从内存中删除掉,而是等到下一次查询到来时; 如果发现这个 <code>key</code> 已经过期,这时才删除掉并且向业务端返回 <code>key</code> 不存在的错误</p><p>好处是能够节省大量的内存释放操作,对 CPU 是最友好的; 缺点是如果过期的 <code>key</code> 再也不会被访问,就会导致大量的无效 <code>key</code> 滞留在 redis 当中,造成内存浪费</p><ol start="3"><li>定期删除</li></ol><p>每隔一段时间 <code>T</code> 就取出一定量的 <code>key</code> 检查并删除掉已经过期的 <code>key</code></p><p>好处是能够稳定的清理过期 <code>key</code>,也能通过限制频率保证对 CPU 的开销维持到一个比较低的范围</p><p>缺点是如果频率过低,就会导致频繁的内存释放操作,会给 CPU 带来压力,严重的时候退化为 <code>定时删除</code>; 如果频率过高,过期 <code>key</code> 就不会及时被删除,严重的时候退化为 <code>惰性删除</code></p><h3 id="主从同步下由于过期删除策略导致的脏读"><a href="#主从同步下由于过期删除策略导致的脏读" class="headerlink" title="主从同步下由于过期删除策略导致的脏读"></a>主从同步下由于过期删除策略导致的脏读</h3><p>假设一个 <code>key</code> 的过期时间设置为 <code>1min</code> ,从 <code>12:00</code> 主库接收到写入这条数据的指令并写入主库,此时 <code>key</code> 的过期时间为 <code>12:01</code></p><p>如果主从同步之间的延迟为 <code>2min</code> 即从库在 <code>12:02</code> 的时候才与主库完成全量同步,此时从库写入这条数据,那么 <code>key</code> 的过期时间为 <code>12:03</code></p><p>所以客户端在 <code>12:02 ~12:03</code> 这个时间范围内,仍然能够在从库里面读到已经过期的数据</p><p>在 redis 3.2 以前的版本,从库读到过期数据时不会判断过期时间,会直接返回已经过期的数据</p><p>在 redis 3.2 之后的版本,从库读到过期数据时会判断过期时间,如果在主库上已经过期了,则会返回一个空值回去</p><p>为了避免这种情况发生,最好的办法就是设置一个 <code>确切的过期时间点</code> ,例如 <code>SET key EXPIREAT xxx</code> 假如都把时间设置到 <code>2022-11-14 12:00:00</code> 过期</p><p>这样就不会存在因为主从延迟导致的过期时间被推后了而产生的脏读</p><p>如果要这么做的话,就必须保证主从库之间的时钟是同步的,只需要保证主从库从同一个 <code>NTP</code> 时间服务器上同步时间即可</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十)redis 旁路缓存</title>
    <link href="/2022/11/12/redis/(%E5%8D%81)redis%20%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98/"/>
    <url>/2022/11/12/redis/(%E5%8D%81)redis%20%E6%97%81%E8%B7%AF%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h3 id="将-redis-当做旁路缓存使用"><a href="#将-redis-当做旁路缓存使用" class="headerlink" title="将 redis 当做旁路缓存使用"></a>将 redis 当做旁路缓存使用</h3><p>在业务客户端和数据库持久层中间,加上 redis,此时 redis 就以旁路缓存的身份提供服务</p><p>作为缓存使用的redis 有两种方式</p><ol><li>只读缓存</li><li>读写缓存</li></ol><h4 id="只读缓存"><a href="#只读缓存" class="headerlink" title="只读缓存"></a>只读缓存</h4><p>redis 只提供读请求,所有的写请求都直接打到数据库</p><p>对于删除操作,当删除数据库的记录后,还需要删除 redis 里面保存的记录,以免下次又从缓存里面读到了</p><p>对于读请求,如果没有命中 redis 缓存,则会直接访问数据库,并且回写到 redis 里面,以便下次直接从 redis 里获取数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82lz1mtthj30j50acgnw.jpg" alt="img.png"></p><p>对于只读缓存来说,数据库能够提供数据的可靠性保证,不会有丢失数据的风险; 所以对于那些只读的数据例如图片,短视频等内容,可以考虑使用 redis 作为只读缓存</p><h4 id="读写缓存"><a href="#读写缓存" class="headerlink" title="读写缓存"></a>读写缓存</h4><p>对于读写缓存来说,redis 不仅仅要处理读请求,现在还负责处理写请求,这样最新的数据都只会在 redis 里面保存; 如果发生异常宕机的话,这些新数据就会因为没有持久化到数据库里导致数据丢失</p><p>对于读写缓存来说,有两种配置策略</p><ol><li>同步直写: 客户端将写请求发送给 redis 之后,也会发送给数据库进行处理; 等到缓存和数据库都返回处理成功后,才返回给业务端; 这样即使发生宕机,数据库里面也有最新的数据,提供了数据的可靠性保证</li></ol><p>同步直写的缺点就是: 由于 redis 和数据库处理数据的速度不同,很可能 redis 在短时间之内就返回了,而等待数据库处理完成后已经过去一段时间; 这无疑增大了请求的整体耗时</p><ol start="3"><li>异步回写: 客户端将所有写请求都放到缓存里面处理; 等到这些数据即将从缓存里面被淘汰时,redis 将这些最新的数据写回数据库; 这样所有的读写请求都在 redis 处理,客户端可以在很短的时间的回复业务方的请求; 只不过一旦发生异常宕机,那些还没来得及写回数据库的数据就会有丢失的风险了</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82lz7158pj30is0a1abo.jpg" alt="img_1.png"></p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(九)redis 性能分析</title>
    <link href="/2022/11/12/redis/(%E4%B9%9D)redis%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    <url>/2022/11/12/redis/(%E4%B9%9D)redis%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-可能存在的性能问题"><a href="#redis-可能存在的性能问题" class="headerlink" title="redis 可能存在的性能问题"></a>redis 可能存在的性能问题</h3><p>redis 在运行时,要和非常多的对象进行交互,有些交互在内存里面完成,非常快; 而有些交互则通过网络或者磁盘进行,相对较慢</p><ul><li>客户端: 通过网络交互,客户端发起增删改查请求,redis 处理这些请求</li><li>持久化: 通过磁盘交互,redis 有 <code>AOF</code> 日志和 <code>RDB</code> 快照两种方式进行持久化,都需要最终完成落盘操作</li><li>主从节点: 通过网络交互,包括哨兵连接,集群节点的 <code>gossip</code> 协议交互,主从同步,主从切换,哈希槽迁移</li></ul><h4 id="redis-和客户端的交互"><a href="#redis-和客户端的交互" class="headerlink" title="redis 和客户端的交互"></a>redis 和客户端的交互</h4><p>客户端和 redis 的连接使用了 IO 多路复用机制,令网络 IO 线程专门处理网络请求的建立和响应,而数据的处理则由主线程完成,使得网络 IO 不会阻塞主线程的计算</p><p>对于主线程的计算操作,与 mysql 类似,任何大数据操作,大事务等等都会导致实例的性能下降</p><p>同样的对于 redis 来说, <code>集合全量查询</code> 和 <code>集合大量数据的聚合操作</code> 都会显著影响 redis 性能</p><p><code>keys *</code> 查询所有 <code>key</code> 将会导致 redis 扫描整个数据库,非常影响性能</p><p>对数据的增删改,redis 不同的数据结构有些数据的增删很方便,有些数据查询很方便</p><p>试想一下,如果对一个大 <code>key</code> 进行删除操作,将会引起大量内存释放; 同时操作系统为了避免内存碎片的产生,在有内存释放的地方就会有内存的整理和管理; 这也将导致 redis 主线程的阻塞</p><p>同理,清空一个 redis 实例的数据库,也将导致全量数据的删除,也是性能的阻塞点之一</p><h4 id="redis-和磁盘的交互"><a href="#redis-和磁盘的交互" class="headerlink" title="redis 和磁盘的交互"></a>redis 和磁盘的交互</h4><p>在之前介绍持久化的时候已经说过,redis 为了避免写磁盘操作阻塞主线程,无论是在 <code>AOF</code> 还是 <code>RDB</code> 的过程当中,都是通过 <code>fork</code> 一个专门的后台子线程进行持久化操作,这样主线程可以继续处理外部的请求</p><p>然而在做 <code>AOF</code> 的时候,根据不同的配置决定了不同的刷盘时机,对于 <code>实时写盘</code> 的策略,redis 每次在写入 <code>AOF</code> 日之后,都将调用 <code>fsync()</code> 进行刷盘,这是的磁盘操作就会影响主线程的性能</p><h4 id="redis-主从节点之间的交互"><a href="#redis-主从节点之间的交互" class="headerlink" title="redis 主从节点之间的交互"></a>redis 主从节点之间的交互</h4><p>首次主从同步的时候,从节点会清空本地的所有数据,这就是第一点提到的 <strong>删除大批量数据</strong> 会阻塞整体实例的性能</p><p>而且当从节点接收到主节点的全量 <code>RDB</code> 数据之后,会把数据加载到自己的内存当中,如果 <code>RDB</code> 文件过大,加载的过程也就越慢</p><h4 id="redis-集群节点之间的交互"><a href="#redis-集群节点之间的交互" class="headerlink" title="redis 集群节点之间的交互"></a>redis 集群节点之间的交互</h4><p>当有集群节点因为负载均衡正在进行哈希槽迁移时,如果哈希槽里面有 <code>bigkey</code> 的存在,也将导致整个迁移过程变慢,影响到节点的性能</p><h3 id="异步执行减少阻塞导致的性能问题"><a href="#异步执行减少阻塞导致的性能问题" class="headerlink" title="异步执行减少阻塞导致的性能问题"></a>异步执行减少阻塞导致的性能问题</h3><ol><li>读写请求明显无法通过异步执行,读请求是 redis 的关键路径,只能同步进行; 所以对于集合的全量查询,或者聚合操作,都不可避免的会导致性能问题</li><li>删除请求,删除请求并不需要客户端同步等待删除结果,所以可以通过后台子线程处理删除操作; 所以对于 <code>bigkey</code> 的删除或者清空数据的操作也可以交给后台子线程处理</li><li>写 <code>AOF</code> 很明显是异步操作,不阻塞主线程</li><li>主从同步,从节点加载 <code>RDB</code> 快照文件,简单来说其实这里就是读数据,明显也是关键路径只能交给从节点的主线程处理</li></ol><h3 id="redis-的异步执行机制"><a href="#redis-的异步执行机制" class="headerlink" title="redis 的异步执行机制"></a>redis 的异步执行机制</h3><p>当一个 redis 实例启动后,主线程会首先创建出 3 个子线程,分别用于 <code>AOF</code> 或者 <code>RDB</code> 的持久化操作, 键值对的删除操作,以及文件关闭????</p><p>主线程通过维护一个任务链表与子线程进行交互,主线程将接收到的删除请求和清空数据等请求,封装为一个任务并放入队列然后返还给客户端表示完成</p><p>子线程再等到 CPU 资源分配后,就会从队列里面取出没有处理的任务,开始执行对应的操作</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82ervmomyj30j408stap.jpg" alt="img.png"></p><h3 id="CPU-的架构也会影响-redis-的性能"><a href="#CPU-的架构也会影响-redis-的性能" class="headerlink" title="CPU 的架构也会影响 redis 的性能"></a>CPU 的架构也会影响 redis 的性能</h3><p>明确一点, <strong>在多 CPU 架构上,应用程序可以运行在不同的处理器上</strong>, 也就是说 redis 可以先在物理核 1 上运行一段时间后,再被调度到物理核 2 上继续运行</p><p>由于每个物理核之间的 <code>私有缓存 L1 和 L3</code> 是不会共享给其他核心的,当 redis 被调度到另一个物理核运行时,在进行内存访问就需要通过总线访问之前的物理核; 这种跨核心访问内存的行为被称为 <code>远端访问</code> ,很明显 <code>远端访问</code> 会增加应用处理的延迟</p><p>redis 在执行的时候,会记录自身的 <code>运行时信息</code> ,还会把访问最为频繁的数据缓存到物理核心的 <code>L1 和 L2</code> 缓存上</p><p>当发生物理核心调度之后,redis 的 <code>运行时数据</code> 就需要重新加载到新的物理核心上,同时之前缓存在 <code>L1 和 L2</code> 上的数据也将失效,重新加载到新的物理核心缓存里也会导致应用的运行延迟增大</p><h3 id="CPU-的上下文切换"><a href="#CPU-的上下文切换" class="headerlink" title="CPU 的上下文切换"></a>CPU 的上下文切换</h3><p>多核 CPU 架构下, CPU 核心的调度被称为 <code>上下文切换</code> 这是引起 redis 性能问题的罪魁祸首</p><p>可以通过 <code>taskset</code> 指令,将 redis 实例和物理核心进行绑定,避免发生频繁的 <code>上下文切换</code></p><p>需要注意的是,并不是说随便将 redis 实例与一个物理核心进行绑定就好了</p><p>对于 redis 的网络交互,依赖于操作系统的网络中断程序,当有数据进入网卡硬件后,网络中断层序会把数据从网卡的缓冲区读出并写入内核的缓冲区,然后发出对应的事件</p><p>内核的 <code>epoll</code> 机制接收到事件后,便会通知 redis 的 IO 线程,这样 redis 的 IO 线程会从内核的缓冲区读出数据,并写入 redis 的用户态缓冲区</p><p>如果说网卡的网络中断程序和 redis 实例并不处于同一个物理核心; 此时 redis 从内核态缓冲区读出数据就属于 <code>远端访问</code> 这会耗费更多的时间</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82es23ug6j30j60bkdjl.jpg" alt="img_1.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82es78241j30iu07kq41.jpg" alt="img_2.png"></p><p>最好的办法就是把网络中断处理程序和 redis 的实例绑定到同一个物理核心上,避免 <code>远端访问</code> 引起的性能问题</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82esbqjdaj30j009ijt6.jpg" alt="img_3.png"></p><h3 id="绑定核心的风险"><a href="#绑定核心的风险" class="headerlink" title="绑定核心的风险"></a>绑定核心的风险</h3><p>需要注意的是, <code>物理核心</code> 里面还会有 <code>逻辑核心</code> ,如果把 redis 实例和 <code>逻辑核心</code> 进行了绑定; 这样 redis 在做持久化是 <code>fork</code> 的子线程很有可能会与主线程进行资源竞争</p><p>所以最好的办法就是把 redis 实例和 <code>物理核心</code> 进行绑定,这样可以共用 <code>物理核心</code> 下面的所有 <code>逻辑核心</code> ,让主线程和子线程分别使用不同的 <code>逻辑核心</code> 处理,减少对 CPU 资源的竞争</p><p>通过 <code>lscpu</code> 指令查看 cpu 核心情况,再通过 <code>taskset -c xxx,xxx,xxx ./redis-server</code> 将 redis 实例和某些逻辑核心进行绑定; 要求这些逻辑核心属于同一个物理核心</p><h3 id="redis-自身的问题导致性能下降"><a href="#redis-自身的问题导致性能下降" class="headerlink" title="redis 自身的问题导致性能下降"></a>redis 自身的问题导致性能下降</h3><ol><li>慢查询一般有两点解决办法</li></ol><ul><li>把有性能问题的查询语句使用其他高效的命令代替; </li><li>对于需要做聚合统计的请求,改为查询请求,在客户端本地进行聚合计算,避免拖慢 redis 的性能</li></ul><ol start="2"><li><code>key</code> 的过期清理</li></ol><p>redis 会定期清理一些过期的 <code>key</code> 避免内存被这些 <code>key</code> 浪费</p><p>一般情况是每 <code>100ms</code> 删除一些过期 <code>key</code> ,清理算法有如下两种</p><ul><li>采样 <code>active_expire_cycle_lookups_per_loop</code> 的个数,将其中过期的 <code>key</code> 删掉</li></ul><p>什么意思,如果这个配置项值为 <code>N</code>, 每次随机采样 <code>N</code> 个 <code>key</code> ,并将里面过期的 <code>key</code> 给删除掉; 这样每秒钟大概能删除 <code>10N</code> 个过期的 <code>key</code>, 这个默认值是 <code>20</code></p><ul><li>如果超过 <code>25%</code> 的 <code>key</code> 过期了,就会找出过期的 <code>key</code> 并执行删除操作,直到过期 <code>key</code> 的比例下降至 <code>25%</code> 一下</li></ul><p>对于这种清理算法,在 redis 4.0 以前是由主线程进行的,并且会一直执行删除操作直到满足比例,这个过程将会阻塞所有其他请求; 导致 redis 不可用</p><p>在 redis 4.0 以后引入异步子线程执行这个清理算法,避免对主线程的阻塞</p><p>对于第二点,最有可能引起的操作就是 <strong>使用带有相同参数的 expire 命令设置 key 的过期时间</strong>, 这会导致大量 <code>key</code> 具有相同的过期时间,从而导致这个过期比例突然超过 <code>25%</code> 引起删除操作</p><p>如果业务必不可免的需要给大量 <code>key</code> 设置过期时间,可以在每次的基数上,添加一个小小的随机值; 避免大量 <code>key</code> 在同一时间全部超时而出发清理操作,影响 redis 性能</p><h3 id="磁盘问题导致性能下降"><a href="#磁盘问题导致性能下降" class="headerlink" title="磁盘问题导致性能下降"></a>磁盘问题导致性能下降</h3><h4 id="AOF-日志持久化操作"><a href="#AOF-日志持久化操作" class="headerlink" title="AOF 日志持久化操作"></a>AOF 日志持久化操作</h4><p>当 redis 选用 <code>AOF</code> 日志作为持久化的手段时,有三种不同的刷盘配置</p><ol><li>实时写: 每次执行完写请求后,都将记录写入 <code>os buffer</code> ,并且同步调用 <code>fsync</code> 进行刷盘</li><li>实时写,延时刷: 每次执行完写请求后,都将记录写入 <code>os buffer</code>, 但是每隔 <code>1s</code> 调用一次 <code>fsync</code> 进行刷盘</li><li>延时写: 每次执行完写请求之后,都将记录写入 <code>os buffer</code>, 但是什么时候调用 <code>fsync</code> 由操作系统决定</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82g3hmanlj30j904376o.jpg" alt="img.png"></p><p>对于 <code>实时写</code> 方案,每次都是由主线程调用 <code>fsync</code> 必将阻塞主线程</p><p>对于 <code>实时写,延时刷</code> 方案,是由后台子线程调用 <code>fsync</code> ,不会阻塞主线程</p><p>当进行 <code>AOF</code> 记录的时候,为了减小 <code>AOF</code> 日志文件的大小, 必不可免会有 <code>AOF</code> 重写的操作; 而如果 <code>AOF</code> 日志已经很大了,此时的重写过程也需要很长的时间,当重写过程大量占用磁盘 IO 资源时,调用 <code>fsync</code> 的线程又将被阻塞</p><p>redis 主线程在写入 <code>os buffer</code> 之后,并不是完全不再考虑这个操作了,而是还会监控子线程调用 <code>fsync</code> 的进度</p><p>如果子线程的 <code>fsync</code> 频繁被阻塞,这也会引起主线程的阻塞</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82g3mlktvj30ja09q40l.jpg" alt="img_1.png"></p><h4 id="操作系统内存-swap"><a href="#操作系统内存-swap" class="headerlink" title="操作系统内存 swap"></a>操作系统内存 swap</h4><p><code>内存 swap</code> 操作是将内存页和磁盘页进行换入和换出的操作,这个过程涉及到磁盘的读写; 一旦触发 <code>内存 swap</code> 无论是换入还是换出的过程,其性能都将收到影响</p><p>而 redis 是内存数据库,一旦 redis 所需要访问的数据不在内存里,就必须从磁盘里面读取,这将增大 redis 的响应时间</p><p>解决办法只有两个: 提高 redis 实例的内存或者使用 redis 集群分摊单节点的内存压力</p><h4 id="内存大页问题"><a href="#内存大页问题" class="headerlink" title="内存大页问题"></a>内存大页问题</h4><p>较新版本的 <code>Linux</code> 内核支持内存大页,也就是支持一个 <code>2MB</code> 的内存页分配,常规的操作系统一个内存页一般只有 <code>8KB</code> 或者 <code>16KB</code></p><p>对于 redis 而言,如果需要访问的数据正好处于一张大页内存里,这还好不会影响性能</p><p>如果说需要访问的数据不在内存页上,就需要一次性从磁盘里面读出 <code>2MB</code> 的内存页,即使只读取或者修改其中几 kb 的数据</p><p>对于写 <code>AOF</code> 日志也是一样,原来一次刷盘只用刷入 <code>8KB</code> 或者 <code>16KB</code> 大小,而现在需要一次性刷入 <code>2MB</code> 的页,即使只写了一点点可能几 kb 的日志量,也需要 <code>2MB</code> 的磁盘资源</p><p>解决办法就是关闭内存大页机制</p><h4 id="内存碎片问题"><a href="#内存碎片问题" class="headerlink" title="内存碎片问题"></a>内存碎片问题</h4><p>redis 在申请内存的时候,有很多种内存分配方式可以选择,例如 <code>libc, jemalloc, tcmalloc</code> ,而 redis 默认使用的是 <code>jemalloc</code> </p><p><code>jemalloc</code> 的分配策略之一就是每次分配超过实际需要的最小 2 的幂次大小,即每次分配都是 <code>8B, 16B, 32B</code> 等等</p><p>redis 选用这样的内存分配方式,其目的就是为了减少内存的分配次数</p><p>例如 redis 申请 20 个字节的空间, <code>jemalloc</code> 就会为其分配 32 个字节的内存; 这样当 redis 如果对这个数据进行扩容时,如果 32 字节仍然可以满足长度的话,就不会触发新的内存分配了</p><p>造成内存碎片的原因</p><ol><li>内存分配器的策略问题: 可以看到对于 <code>jemalloc</code> 来说它本身的分配策略决定了在内存分配时必然会产生内存碎片,因为它只能按照 2 的幂次分配大小; 这会导致内存使用效率下降</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82gurgdrdj30i4085t9t.jpg" alt="img.png"></p><ol start="2"><li>键值对的删除和额修改会导致原有分配的空间被回收掉; 或者说键值对的扩展和缩小也会导致新的内存分配; 也会带来内存碎片问题</li></ol><p>redis 可以通过命令 <code>INFO memory</code> 检测当前运行时的内存状态; 对于内存碎片的比例一般在 <code>1 ~ 1.5</code> 比较合适,因为内存碎片问题是无法完全避免的,只能说尽量减少</p><h4 id="redis-如何清理内存碎片"><a href="#redis-如何清理内存碎片" class="headerlink" title="redis 如何清理内存碎片"></a>redis 如何清理内存碎片</h4><p>对于 redis 4.0 之前,有且只有一个办法,那就是重启 redis 实例这样 redis 就会重新分配整个数据的内存空间,此时的内存碎片率是最低的</p><p>但是重启带来的后果也很明显</p><ul><li>没有持久化的数据会永久丢失</li><li>进行持久化恢复的时候,如果 <code>AOF</code> 日志或者 <code>RDB</code> 文件过大,数据恢复的时间将会很长; 如果是单节点部署的话,此时重启实例将会导致 redis 完全不可用</li></ul><p>对于 redis 4.0 以后的版本,官方提供了自动整理内存碎片的能力; 简单来说就是 <code>移位合并</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82guyrx8uj30iv093jsx.jpg" alt="img_1.png"></p><p>redis 通过移动数据的位置,让他们尽可能的合并到一块连续内存上,减少内存碎片出现的概率</p><p>只不过, <strong>碎片整理是有代价的</strong> ,将数据从原来的位置拷贝到新的位置,这会带来时间开销; 而且碎片整理只能由主线程进行; 所以碎片整理会导致一定程度阻塞主线程,从而导致性能降低</p><p>如果启用了碎片整理功能,又想尽可能减少对主线程的阻塞; 就只能提高自动整理出发的碎片率阈值,以及调低最长碎片整理时间,以免长时间进行碎片整理完全阻塞主线程</p><p>相关参数如下:</p><ul><li>内存碎片字节数达到 <code>设定的 mb</code> 时,开始清理</li><li>内存碎片空间占用率达到 <code>设定的比例</code> 时,开始清理</li><li>CPU 进行碎片整理所占用的时间不得低于 <code>设定的比例</code>, 避免时间果断导致碎片整理的效果不好</li><li>CPU 进行碎片整理所占用的时间不得超过 <code>设定的比例</code>, 避免长时间进行碎片整理而阻塞主线程</li></ul>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(八)redis 统计 key</title>
    <link href="/2022/11/12/redis/(%E5%85%AB)redis%20%E7%BB%9F%E8%AE%A1%20key/"/>
    <url>/2022/11/12/redis/(%E5%85%AB)redis%20%E7%BB%9F%E8%AE%A1%20key/</url>
    
    <content type="html"><![CDATA[<h3 id="统计能力"><a href="#统计能力" class="headerlink" title="统计能力"></a>统计能力</h3><p>在实际业务场景当中,redis 出了当做缓存使用; 还经常做的事就是统计各种 <code>key</code> 相关的数据</p><p>例如:</p><ul><li>app 的登录用户</li><li>电商网站的评论,点赞,点踩等能力</li><li>app 的签到场景</li></ul><p>由于实际业务场景当中的请求量或者说用户规模都是巨大的,针对不同的场景选择合适的数据结构去保存这些行为数据是很值得优化的</p><h3 id="集合的常用统计模式"><a href="#集合的常用统计模式" class="headerlink" title="集合的常用统计模式"></a>集合的常用统计模式</h3><ol><li>聚合统计</li><li>排序统计</li><li>二值状态统计</li><li>基数统计</li></ol><p>将业务场景里面的统计需求,转化抽象为上述四种模式之一,在针对性的选择合适的 redis 数据结构,能够提高 redis 的统计性能,还能减少 redis 的内存开销</p><h4 id="聚合统计"><a href="#聚合统计" class="headerlink" title="聚合统计"></a>聚合统计</h4><p>这是最常见的统计模式,其定义是: <strong>统计多个集合元素的聚合结果</strong> ; 其表现行为通常以 <code>求并集</code>, <code>求交集</code>, <code>求差集</code> 等等形式体现</p><p>例如统计某一天内用户的新增数量 或者 遇上一天相比的用户留存数量 或者 某一时间段之内的所有用户数量</p><p>针对含有唯一性 id 的数据,使用 redis 的集合 <code>set</code> 是非常合适的数据结构</p><p>集合 1 保存所有使用过的用户</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h8288wgvu0j30ht0dfdhi.jpg" alt="img.png"></p><p>对于每一天,通过加上当天的日期,用于保存当天使用过的用户数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h82894mwmyj30hs0c70ul.jpg" alt="img_1.png"></p><p>对于 <code>20200803</code> 当天新增的用户,可以用 <code>user:id</code> - <code>user:id:20200803</code> 得到</p><p>如果需要统计二天的相比前一天的留存客户,则可以使用 <code>user:id:20200804</code> ∩ <code>user:id:20200803</code> 求两个集合的交集就是 <code>0803</code> 在 <code>0804</code> 留存的客户</p><p>需要注意的一点就是, <code>set</code> 的交并补计算复杂度比较高,在数据量较大的情况下,可能会导致主线程阻塞</p><p>为了避免集合运算阻塞主线程,最好的办法是 <strong>在集群中选择一个从库,专门执行聚合计算,或者直接把原始结果返回给调用方,让调用方在本地完成计算</strong> ,而不要阻塞 redis 的服务</p><h4 id="排序统计"><a href="#排序统计" class="headerlink" title="排序统计"></a>排序统计</h4><p>排序统计要求待统计的 <code>key</code> 按照某种规则进行排序,例如按照时间顺序的评论,或者按照点赞多少的热评,这些都属于排序统计模式</p><p>redis 支持排序的集合有两类, <code>List</code> 列表和 <code>Sorted Set</code>有序集合</p><p>对于 <code>List</code> 来说,其排序规则就是按照元素进入 <code>List</code> 的顺序决定的; 而对于 <code>Sorted Set</code> 其排序规则则是可以根据元素自定义权重值; 也就是说 <code>Sorted Set</code> 支持自定义排序</p><p>如果说需要排序统计的 <code>key</code> 本身符合一些自然的先后规律,例如时间顺序; 使用 <code>List</code> 就可以很好的支持这些元素的排序</p><p>按照时间先后顺序,每产生一条新的评论就通过 <code>LPUSH</code> 插入到 <code>List</code> 的头部,这样越远离头部的元素,就是时间越靠后的元素</p><p>但是考虑一个分页查询的场景,例如有 10 个元素,分别是 <code>[1,10]</code> 如果一页展示 3 个元素</p><p>那么第一页就是 <code>LRANGE comments 0 2</code> &#x3D; [1,3], 第二页就是 <code>LRANGE comments 3 5</code> [4,6]</p><p>ok,这看起来没什么问题,那如果说此时一条新的评论产生,这样原先的集合变为 [11,1] [1,10],再使用第二页的命令就会把之前第一页的评论 <code>3</code> 查询出来,相当于读取到了旧元素</p><p><code>Sorted Set</code> 排序集合可以实现自定义权重值排序,对于频繁地更新元素和增删元素,也能通过 <code>ZRANGEBYSCORE</code> 命令准确地获取排序后范围的元素</p><h4 id="二值状态统计"><a href="#二值状态统计" class="headerlink" title="二值状态统计"></a>二值状态统计</h4><p>什么叫 <code>二值状态统计</code>: 即统计元素只有 <code>0</code> 和 <code>1</code> 两种状态</p><p>常见的运用就是统计打卡签到场景</p><p>对于每天的打卡或者签到场景来说,一个月也才 30 天,一年也才 365 天,只需要使用一个 <code>bitmap</code> 位图的数据结构即可实现; redis 原生提供了扩展类型数据结构 <code>bitmap</code></p><p>把每天映射到 <code>bitmap</code> 的每一位上,如果当前位 &#x3D; 1,则表示当天有过打卡,否则表示当天没有打卡</p><p>而且使用命令 <code>BITCOUNT</code> 可以快速的统计当前 <code>bitmap</code> 里面 <code>1</code> 的个数(具体计算公式猜想为 <code>while(n&gt;0) k=n&amp;(n-1) </code>,其中 n 为位图最终表示的数据,k 为 1 的个数)</p><h4 id="基数统计"><a href="#基数统计" class="headerlink" title="基数统计"></a>基数统计</h4><p>基数统计就是用于统计那些集合内不重复的元素个数,看起来与聚合统计很相似; 很容易就能想到通过 <code>set</code> 或者 <code>hash</code> 来保存数据</p><p>但实际上当数据量非常巨大时,单个 <code>set</code> 或者 <code>hash</code> 结构将会消耗非常多的内存</p><p>redis 提供了一个专门用于基数统计的数据结构 <code>HyperLogLog</code>, 有着固定大小的内存消耗,大约在 <code>12KB</code> 左右,但是能够统计超过 <code>2^64</code> 个元素</p><p>虽然 <code>HyperLogLog</code> 有着很低的内存使用率,但是其实现原理是基于统计计算的,与实际值存在偏差</p><p>如果说统计结果需要准确的数据,就不得不使用 <code>set</code> 或者 <code>hash</code> 了</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(七)redis gossip 协议</title>
    <link href="/2022/11/11/redis/(%E4%B8%83)redis%20gossip%20%E5%8D%8F%E8%AE%AE/"/>
    <url>/2022/11/11/redis/(%E4%B8%83)redis%20gossip%20%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h3 id="gossip-协议"><a href="#gossip-协议" class="headerlink" title="gossip 协议"></a>gossip 协议</h3><p><code>Gossip</code> 协议保证了在一个连通的有界网络当中,每个节点都与其他节点随机通信,当过一段时间后,整个集群的所有节点状态变为一致性的</p><p>redis 使用 <code>Gossip</code> 协议主要包含以下几个命令:</p><ol><li>MEET: 已有集群的节点会向新添加的节点发出邀请,使之加入集群内部</li><li>PING: 每个节点每秒会随机向其他节点发送心跳包,包含当前节点的哈希槽,ip 地址,端口,当前状态以及最后一次通信的时间等信息</li></ol><p>毕竟是随机发送,考虑极端情况下,有些节点一直没有被随机选中,这就会导致这些节点一直没有被同步过状态</p><p>redis 使用一个配置项 <code>cluster-node-timeout</code> 限制最久没有回复 <code>PONG</code> 指令的节点,一旦发现自己的节点列表里面有超过 <code>cluster-node-timeout</code> 的节点,会立即给这个节点发送 <code>PING</code> 指令以同步集群状态</p><ol start="3"><li>PONG: 当节点收到来自其他节点的 <code>PING</code> 命令后,会向其回复 <code>PONG</code> 消息,消息内容同样包含 <code>PING</code> 消息的内容</li><li>FAIL: 当节点 A <code>PING</code> 不通节点 B 时,节点 A 会向集群内其他节点 <code>广播</code> 这条消息,其他节点在接收到后会将节点 B 标记为下线</li></ol><p>这样在通过一定时间之后,集群当中每个实例都能接收到其他所有实例维护的哈希槽信息,相当于每个实例都保存了其他所有实例的信息</p><h3 id="gossip-协议故障检测"><a href="#gossip-协议故障检测" class="headerlink" title="gossip 协议故障检测"></a>gossip 协议故障检测</h3><p>每个节点在发送 <code>PING</code> 消息里面都会带上当前节点的状态: <code>正常运行</code>, <code>疑似下线</code>, <code>已下线</code></p><ol><li>当节点 A 得到节点 B 的 <code>PING</code> 消息,里面告知节点 C 进入了 <code>疑似下线</code> 状态; 此时节点 A 会在自己维护的节点列表里面找到节点 C 的结构体,并将节点 B 的疑似下线消息保存到节点 C<br>结构体的 <code>fail_reports</code> 链表里</li><li>并且节点 A 也会想其它节点传播 <code>PING</code> 消息,里面报告了节点 C 进入了 <code>疑似下线</code> 状态</li><li>如果超过半数以上的节点都认为节点 C <code>疑似下线</code>,那么最先将节点 C 标记为 <code>疑似下线</code> 的节点 B 会向其他所有节点 <code>广播</code> <code>FAIL</code> 消息</li><li>收到 <code>FAIL</code> 消息的节点立即更新自己维护的其他节点状态,将节点 C 标记为 <code>已下线</code></li></ol><h4 id="gossip-和广播"><a href="#gossip-和广播" class="headerlink" title="gossip 和广播"></a>gossip 和广播</h4><p><code>gossip</code> 依靠的是节点之间的互相随机传播,当有非常紧急的消息需要发送时,就需要通过 <code>广播</code> 的形式通知其他 <code>所有</code> 节点</p><h3 id="集群节点如何通过-gossip-协议通信"><a href="#集群节点如何通过-gossip-协议通信" class="headerlink" title="集群节点如何通过 gossip 协议通信"></a>集群节点如何通过 gossip 协议通信</h3><h4 id="什么时候发送心跳包"><a href="#什么时候发送心跳包" class="headerlink" title="什么时候发送心跳包"></a>什么时候发送心跳包</h4><p>redis 节点会记录向 <strong>每一个</strong> 节点最后一次发送 <code>PING</code> 和收到 <code>PONG</code> 的时间; 然后在节点上有一个定时任务按照一定规则选出一些节点发送 <code>PING</code> 心跳包</p><ul><li>每次定时任务向所有其他未知节点(通常是新加入集群的节点,或者说下线后恢复上线的节点)发送 <code>MEET</code> 或者 <code>PING</code></li><li>每秒从所有已知节点当中选出若干个节点,向其中上一次发送 <code>PING</code> 最旧的节点发送 <code>PING</code></li><li>每次定时任务向收到 <code>PONG</code> 超过 <code>timeout/2</code> 的节点发送 <code>PING</code> 节点</li><li>每次收到 <code>MEET</code> 或者 <code>PING</code> 之后,立即回复 <code>PONG</code></li></ul><h4 id="发送的心跳包内容"><a href="#发送的心跳包内容" class="headerlink" title="发送的心跳包内容"></a>发送的心跳包内容</h4><ol><li>Header:<ul><li>当前节点维护的哈希槽信息</li><li>当前节点的运行状态(正常运行,疑似下线,已下线)</li><li>当前节点的主从状态</li><li>当前节点的 ip 和端口信息</li></ul></li><li>Body<ul><li>发送者已知节点的 <code>ping_sent</code> 和 <code>pong_received</code> 信息</li><li>发送者已知节点的 ip 和端口信息</li><li>发送者已知节点的状态信息(正常运行,疑似下线,已下线)</li></ul></li></ol><h4 id="如何处理心跳"><a href="#如何处理心跳" class="headerlink" title="如何处理心跳"></a>如何处理心跳</h4><ol><li>新节点加入时<ul><li>向起他任意一个节点发送 <code>MEET</code></li><li>从 <code>PONG</code> 里面得到对方节点已知的其他节点信息将这些节点加入自己的未知节点列表</li><li>循环上述步骤,直到所有节点都已经已知,完成新节点加入集群</li></ul></li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h8264vk2nij30h30ctmz2.jpg" alt="img.png"></p><ol start="2"><li><p><code>slot</code> 信息</p><ul><li>接收消息的节点判断发送消息节点所维护的 <code>slot</code> 信息与本地记录是否相同</li><li>如果相同,则不做任何处理</li><li>如果不相同,判断 <code>currentEpoch</code> 谁更大<ul><li>如果发送方 <code>currentEpoch</code> 更大,则将发送方的 <code>slot</code> 信息更新到本地</li><li>如果接收方 <code>currentEpoch</code> 更大,则发送 <code>UPDATE</code> 给发送方,让发送方更新 <code>slot</code> 新</li></ul></li></ul></li><li><p>主从信息</p><ul><li>当接收方发现发送方的主从关系发生变更时,更新本地的记录</li></ul></li><li><p>故障发现</p><ul><li>超过超时时间没有回复 <code>PONG</code> 的节点,会被发送 <code>PING</code> 的节点标记为 <code>疑似下线</code></li><li><code>疑似下线</code> 消息会随着 <code>gossip</code> 协议在集群中传播开来</li><li>每个节点收到 <code>PING</code> 之后,会检测里面对其他节点的状态信息,如果发现有 <code>疑似下线</code> 的节点,则在本地维护一个下线状态投票记录</li><li>当某个节点维护的下线状态投票记录里面,对一个 <code>疑似下线</code> 节点的标记达到大多数时,当前节点就会向集群传播 <code>FAIL</code> 消息</li><li>其他节点接收到 <code>FAIL</code> 消息后,立马把对应的 <code>疑似下线</code> 的节点标记为 <code>已下线</code></li></ul></li></ol><h3 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h3><p>当一个节点所属的 <code>master</code> 节点发生故障后,会尝试进行 <code>Fail-over 选主</code> ,由于挂掉的 <code>master</code> 可能有多个,所以需要使用类似于 <code>Raft</code> 的协议来保证最终一致性</p><h4 id="currentEpoch-epoch-纪元"><a href="#currentEpoch-epoch-纪元" class="headerlink" title="currentEpoch - epoch(纪元)"></a>currentEpoch - epoch(纪元)</h4><p><code>currentEpoch</code> 表明了集群中状态变更的迭代版本号,每个节点都会记录自己当前的版本号 </p><p>当集群节点创建时,无论是 <code>master</code> 还是 <code>slave</code> 都将自己的版本号 <code>currentEpoch</code> 设置为 0</p><p>当节点接收到 <code>PING</code> 时,会判断发送者的 <code>currentEpoch</code> 和当前自己的 <code>currentEpoch</code></p><ul><li>如果发送方的 <code>currentEpoch</code> 更大,则会将自己的版本号更新为发送方的版本号</li><li>如果自己的 <code>currentEpoch</code>, 则会向发送方回复 <code>UPDATE</code> 要求其更新 <code>currentEpoch</code> 为自己的 <code>currentEpoch</code></li></ul><p>经过 <code>gossip</code> 协议传播一段时间后,整个集群的 <code>currentEpoch</code> 最终将保持一致</p><p>当集群的状态发生改变,通常是发生主从切换即 <code>master</code> 节点的故障转移时</p><p><code>slave</code> 节点为了执行 <code>Fail-over 选主</code> 操作而征求其他节点的同意时,会将自己的 <code>currentEpoch + 1</code>,此时这个 <code>currentEpoch</code> 时整个集群当中最大的值</p><ul><li>发起 <code>Fail-over 选主</code> 的 <code>slave</code> 节点进行广播,这里的广播消息其他 <code>slave</code> 节点不会响应,只有其他 <code>master</code> 才会响应这条广播消息</li><li>对于一个 <code>master</code> 来说,可能在一个时间段内有多个 <code>slave</code> 尝试进行 <code>Fail-over 选主</code> 拉票,此时的 <code>master</code> 只会为第一个拉票请求头赞成票; 剩下的其他拉票请求都头反对票</li><li>当尝试 <code>Fail-over 选主</code> 的 <code>slave</code> 节点收集到所有 <code>master</code> 节点的投票信息后,判断有没有超过 <code>大多数</code></li><li>如果超过了大多数节点,则发送广播消息,告知其他节点自己成为了新的 <code>master</code> 节点</li><li>此时其他所有节点的 <code>currentEpoch</code> 值由于都小于新的 <code>master</code> 节点的 <code>currentEpoch</code> 值,都会在收到广播消息后,更新自己的 <code>currentEpoch</code> 为最新值; 在经过一段时间的 <code>gossip</code> 之后,整个集群的状态再次恢复一致</li></ul><h4 id="configEpoch-epoch-纪元"><a href="#configEpoch-epoch-纪元" class="headerlink" title="configEpoch - epoch(纪元)"></a>configEpoch - epoch(纪元)</h4><p>与 <code>currentEpoch</code> 类似,只不过 <code>configEpoch</code> 只在节点维护的哈希槽发生变化时才会改变</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(六)redis 切片集群</title>
    <link href="/2022/11/11/redis/(%E5%85%AD)redis%20%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4/"/>
    <url>/2022/11/11/redis/(%E5%85%AD)redis%20%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-的单机部署"><a href="#redis-的单机部署" class="headerlink" title="redis 的单机部署"></a>redis 的单机部署</h3><p>考虑如下情况,假如有一批数据预估在 <code>25G</code> 左右,此时应当选用什么样配置的 redis 来保存这批数据</p><p>通常情况下,redis 的机器内存要超过数据量才够,此时选用一台 <code>32G</code> 的服务器,还能有剩余 <code>7G</code> 来做 redis 持久化,持久化的方式选为 <code>RDB</code> 快照</p><p>可实际情况并不令人满意,在 redis 实例正常运行一段时间之后,开始变得缓慢起来,很容易想到是在做 <code>RDB</code> 快照的时候造成了性能问题</p><p>每当需要 <code>RDB</code> 快照的时候,主线程都会 <code>fork</code> 一个子线程去后台专门做快照,然而在 <code>fork</code> 的过程当中,需要复制主线程内的所有内存数据,足足有 <code>25G</code> 之大</p><p>显然此时的 <code>fork</code> 操作阻塞了主线程的正常运行,需要更换 redis 的部署方式</p><h3 id="redis-的切片集群"><a href="#redis-的切片集群" class="headerlink" title="redis 的切片集群"></a>redis 的切片集群</h3><p>相对于上面的单机部署来说,很容易想到集群化,将 <code>25G</code> 的数据平均分为 5 个 <code>5G</code> 大小的切片,将这个 5 个切片分别部署在 5 台 redis 实例上</p><p>这样每个 redis 实例所需要的服务器资源也变少了,而且 <code>RDB</code> 快照时需要复制的内存数据页变小了,<code>fork</code> 操作对主线程的影响几乎没有</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81m0nccsvj30j409x76v.jpg" alt="img.png"></p><h3 id="扩容方式"><a href="#扩容方式" class="headerlink" title="扩容方式"></a>扩容方式</h3><p>一般来说常见的扩容方式分为以下两种</p><ol><li>纵向扩展: 每次增加单机的配置; 例如单机 <code>10G</code> 增加到单机 <code>50G</code> ,或者增加单机内存,或者更换单机更好的 CPU,都属于纵向扩展</li><li>水平扩展: 每次增加一台与之前完全相同配置的 redis 实例来组成一个复杂的 redis 集群</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81m0s34nkj30iu09agnh.jpg" alt="img_1.png"></p><h4 id="纵向扩展"><a href="#纵向扩展" class="headerlink" title="纵向扩展"></a>纵向扩展</h4><p>优点</p><ol><li>扩展时比较方便,实施简单</li></ol><p>缺点:</p><ol><li>单机内存过大时,一次全量的 <code>RDB</code> 操作在 <code>fork</code> 时会阻塞主线程更长的时间</li><li>从 <code>16G</code> 扩为 <code>32G</code> 很便宜,但是从 <code>512G</code> 扩容到 <code>1T</code> 其成本将会非常高</li></ol><h4 id="横向扩展"><a href="#横向扩展" class="headerlink" title="横向扩展"></a>横向扩展</h4><p>为了避免纵向扩展的两个问题,又要保存更多的数据,只能通过增加 redis 实例的数量来实现</p><p>在面对千万级, 亿级数据的时候,集群化部署 redis 是非常合适的选择</p><p>缺点:</p><ol><li>数据切片之后,该如何分配到不同的 redis 实例上</li><li>客户端如何确认自己要查询或者更改的数据在哪个 redis 实例上</li></ol><h3 id="redis-cluster-技术"><a href="#redis-cluster-技术" class="headerlink" title="redis cluster 技术"></a>redis cluster 技术</h3><p>在 redis 3.0 之后,官方提供了 <code>redis cluster</code> 技术来实现切片集群</p><h4 id="redis-cluster-哈希槽分配"><a href="#redis-cluster-哈希槽分配" class="headerlink" title="redis cluster 哈希槽分配"></a>redis cluster 哈希槽分配</h4><p>具体来说,<code>redis cluster</code> 技术采用 <code>hash slot</code> 哈希槽来处理数据和实例之间的映射关系</p><p>在 <code>redis cluster</code> 方案当中,一共提供了 <code>16384</code> 个槽位用于存放数据; 每个保存在 redis 里面的键值对; 都会根据其 <code>key</code> 值被映射到一个唯一的哈希槽里面存放 <code>value</code>;<br>具体的哈希算法是将 <code>key</code> 通过 <code>CRC16</code> 校验后得到一个 <code>16bit</code> 的值,再把这个值和 <code>16384</code> 取模,最后得到的结果就是具体的哈希槽</p><p>在创建 redis 集群的时候,redis 会自动的把 <code>16384</code> 个哈希槽平均分配到每个实例里面; 若有 <code>N</code> 个实例,则每个实例存储的哈希槽个数为 <code>16384/N</code></p><p>当然也可以通过配置,手动决定哪些实例保存哪些哈希槽</p><p>通常来说如果 redis 集群每个实例的配置有所不同,如果 <code>key</code> 都是均匀访问,那么配置低的实例面临的压力会明显大于配置高的实例,此时就需要手动分配哈希槽; 如果每个实例的配置一样,那么 redis 自动分配就更加简单</p><p>需要注意的是: 如果手动分配哈希槽,则需要所有 <code>16384</code> 个槽位全部分配完,否则 <code>redis cluster</code> 无法正常工作</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81m0wakvmj30iz09lwh3.jpg" alt="img_2.png"></p><h4 id="客户端如何查询"><a href="#客户端如何查询" class="headerlink" title="客户端如何查询"></a>客户端如何查询</h4><p>当完成数据到哈希槽的分配,哈希槽到实例的分配之后,客户端如何得知自己需要访问的数据应该请求哪个具体的实例呢</p><p>首先数据到哈希槽的映射关系,可以通过 <code>CRC16(key) % 16384</code> 得到; 然而哈希槽到实例的映射关系则无法通过计算得到</p><p>但是实际客户端在访问 redis 集群的时候,只需要连接上任意一个实例,就可以访问整个集群当中其他实例上的数据,这是如何做到的 -&gt; redis 的 <code>Gossip</code> 协议</p><h4 id="客户端如何查询具体某个-key"><a href="#客户端如何查询具体某个-key" class="headerlink" title="客户端如何查询具体某个 key"></a>客户端如何查询具体某个 key</h4><p>集群稳定运行一段时间后,节点之间通过 <code>Gossip</code> 协议可以保证每个节点都有全量的哈希槽信息</p><p>这样客户端连接任意一个实例,都能够获得整个集群的哈希槽分配情况,并且把这个分配信息缓存到自己的本地</p><p>当客户端需要访问一条数据时,首先根据 <code>CRC16(key) % 16384</code> 得到当前 <code>key</code> 所属的哈希槽,再根据自己维护的实例和哈希槽的映射关系表来访问 <code>key</code> 所在的实例</p><p>实际上,哈希槽和实例的对应关系也并不是一成不变的; 对于业务压力大的时候,需要新增 redis 实例; 自然也会有减少 redis 实例的情况</p><p>redis 为了负载均衡,当实例个数发生变化的时候,会将哈希槽全部重新分配一次; 此时实例之间继续通过一定的通信方式将哈希槽的配置信息互相传递,然而客户端该怎么办呢</p><p>redis 提供了一种 <code>重定向机制</code>,就是当客户端通过本地缓存的旧哈希槽实例映射表访问具体某个 <code>key</code> 时,如果此时的实例上并没有这个 <code>key</code> 值,就会向客户端回复一个 <code>MOVED</code> 指令, <code>MOVED</code><br>指令里面就包含了 <code>key</code> 所在最新实例的 ip 地址和端口等信息</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">GET</span> testkey<br><span class="hljs-attribute">MOVED</span> <span class="hljs-number">7800</span> <span class="hljs-number">172.16.19.3:6379</span><br></code></pre></td></tr></table></figure><p>其中 <code>7800</code> 表示当前 <code>key</code> 所处第 <code>7800</code> 个哈希槽,而当前哈希槽归 <code>172.16.19.3:6379</code> 这个实例维护; 这样一来客户端就可以重新向新的实例发起请求了</p><p>同时客户端还会把最新的哈希槽实例映射关系更新到本地的缓存,以便下次可以直接访问而不再需要重定向 <code>MOVED</code> 了</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81m11azd2j30hy0f1dk7.jpg" alt="img_3.png"></p><h4 id="哈希槽迁移时查询数据"><a href="#哈希槽迁移时查询数据" class="headerlink" title="哈希槽迁移时查询数据"></a>哈希槽迁移时查询数据</h4><p>有一种场景,就是当实例数量发生变更,redis 在做哈希槽迁移时,此时客户端向一个正在发生哈希槽迁移的实例发起请求,此时客户端会受到一条回复</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">GET</span> testkey<br>(<span class="hljs-literal">error</span>) ASK <span class="hljs-number">7800</span> <span class="hljs-number">172.16.19.5:6379</span><br></code></pre></td></tr></table></figure><p>其中 <code>7800</code> 表示当前请求的 <code>key</code> 所处的哈希槽, 返回 <code>ASK</code> 命令表示当前哈希槽正处于迁移状态, <code>172.16.19.5:6379</code> 表示数据所处的最新实例地址</p><p>此时客户端需要再向实例发起 <code>ASKING</code> 命令,表示 <strong>允许</strong> 让实例返回当前请求的数据,接下来再发送 <code>GET</code> 命令得到具体的数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81m15sl7cj30j20ef42s.jpg" alt="img_4.png"></p><h4 id="MOVED-和-ASK"><a href="#MOVED-和-ASK" class="headerlink" title="MOVED 和 ASK"></a>MOVED 和 ASK</h4><p><code>MOVED</code> 重定向指令是在哈希槽已经完成了迁移后,请求到老实例时回复的指令,此时客户端会根据老实例回复的信息更新自己本地缓存的哈希槽实例映射表</p><p><code>ASK</code> 指令是在哈希槽正在迁移时,请求到老实例回复的指令; 此时客户端需要根据老实例回复的 <code>key</code> 所在的新实例发送 <code>ASKING</code> 指令表示允许从正在迁移哈希槽的实例中读取数据; 再发送 <code>GET</code> 指令真正读取数据;<br>此时客户端并不会更新自己本地缓存的哈希槽实例映射表</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(四)redis 哨兵模式</title>
    <link href="/2022/11/11/redis/(%E4%BA%94)redis%20%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
    <url>/2022/11/11/redis/(%E4%BA%94)redis%20%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h3 id="读写分离场景下主库宕机怎么办"><a href="#读写分离场景下主库宕机怎么办" class="headerlink" title="读写分离场景下主库宕机怎么办"></a>读写分离场景下主库宕机怎么办</h3><p>读写分离场景下,只有主库才能提供写服务; 如果主库发生故障宕机,此时所有的写请求将不可用,而且从库的主从同步也会断开导致读请求可能产生数据不一致问题</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2ajpchj30iz0cqjto.jpg" alt="img.png"></p><p>此时需要将一个从库提升为新的主库来提供写服务,其他从库继续从这个新的主库上进行主从同步; 这个过程涉及到 3 个问题</p><ol><li>主库是否真的挂了</li><li>选哪个从库作为主库</li><li>怎么把新主库的信息告知给其他从库和客户端</li></ol><p>redis 提供了 <code>哨兵</code> 机制实现主库的选举和自动切换以及故障转移</p><h4 id="哨兵的基本流程"><a href="#哨兵的基本流程" class="headerlink" title="哨兵的基本流程"></a>哨兵的基本流程</h4><p>哨兵的本质就是一个运行在特殊模式下的 redis 进程; 主从库 redis 实例运行的时候,哨兵进程也随之运行; 主要负责三个任务</p><ol><li>监控</li></ol><p>当哨兵和其他主从库正常运行时,哨兵需要周期性地给其他所有库发送心跳检测 <code>ping</code> 命令,用于检测对应 redis 实例是否在线运行</p><p>如果在规定时间内哨兵没有收到对应实例回应的 <code>pong</code> 命令,则哨兵此时会把这个实例标记为 <code>下线状态</code></p><p>同理,如果是主库在规定时间内没有回复 <code>pong</code> 命令,此时哨兵会认为主库下线,就会启动主从切换的流程</p><ol start="2"><li>选主</li></ol><p>当启动主从切换流程后,哨兵接下来的任务就是在众多的从库当中选择一个新的主库</p><ol start="3"><li>通知</li></ol><p>当新的主库产生后,哨兵需要把新的主库的实例信息发送给其他所有从库,让从库与新主库之间建立联系继续进行主从同步; 同时还要把新主库的信息和已经下线的老主库信息发送给客户端,让客户端的写请求进入新的主库</p><p>需要注意的是,在第一步监控过程当中,将一个 redis 实例标记为 <code>下线状态</code> 这里其实是有两种不同的状态,分为 <code>主观下线</code> 和 <code>客观下线</code></p><h4 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h4><p>哨兵在监控过程当中,向每个实例发送 <code>ping</code> 命令心跳包,用于检测实例是否处于正常在线状态; 如果一个实例长时间没有回复 <code>pong</code> 命令,或者因为网络延迟导致 <code>pong</code> 命令超时,此时哨兵会 <code>主观</code> 地认为这个实例不可用,从而将其标记为 <code>主观下线</code> 状态</p><ol><li>如果是一个从库被标记为 <code>主观下线</code> 此时影响还不算太大,因为其他主从库仍然能够提供服务,整个集群对外的服务不会中断</li><li>如果是一个主库被标记为 <code>主观下线</code> 这个时候问题就来了,因为主从切换是一个很复杂的过程,进行一次主从切换很可能导致服务发生中断; 这个时候能简单地认为主库真的挂掉了吗</li></ol><p>首先哨兵也可能存在误判,主库正常提供服务,如果是主库和哨兵之间的网络通信出现了一些波动,导致网络延迟哨兵没有收到主库的心跳包,这个时候哨兵就误以为主库故障了</p><p>亦或者说主库正在面临较大的压力,处理大量的请求导致回复一条 <code>pong</code> 命令来不及,这个时候也不能简单地认为主库故障了,很有可能是人家忙不过来而已</p><h4 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h4><p>为了避免单个哨兵节点将主库标记为 <code>主观下线</code> 从而导致频繁的主从切换,实际场景下的哨兵通常也是采用集群部署的方式</p><p>即多个哨兵节点构成一个哨兵集群,这个哨兵集群同时负责监控所有 redis 实例,以及共同决定选主和主从切换发生的时机,减少单机哨兵节点的误判</p><p>当哨兵集群内超过一定数量的哨兵都认为主库已经发生故障,这个时候的主库会被标记为 <code>客观下线</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2hbnmfj30j606z0uh.jpg" alt="img_1.png"></p><p>如上图所示,哨兵 2 认为主库挂掉了,但此时哨兵 1 和 3 都认为主库健康,少数服从多数原则此时主库最终被认定为健康状态</p><p>而当哨兵 1 和 2 都认为主库挂掉了,此时哨兵 3 认为主库健康,同样也是少数服从多数,此时主库被最终认定为 <code>客观下线</code></p><p>这个少数服从多数最简单的判断公式就是: 当有 N 个哨兵节点时,如果有 <code>N/2 + 1</code> 个哨兵节点同时认为主库 <code>主观下线</code> 此时就最终判定为主库 <code>客观下线</code> 从而进行新的选主和主从切换</p><h3 id="哨兵模式的选主过程"><a href="#哨兵模式的选主过程" class="headerlink" title="哨兵模式的选主过程"></a>哨兵模式的选主过程</h3><p>一旦主库被认定为 <code>客观下线</code> 接下来就要在众多的从库当中,选出一个 <code>最合适</code> 的新主库; 这个过程可以简化为 <code>筛选+打分</code></p><p>简单来说,先按照一定的条件,筛选出一批可能的从库; 然后按照一定规则对这些从库打分,最后得分最高的从库被选定为新的从库</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2m6wyjj30j1091wg5.jpg" alt="img_2.png"></p><h4 id="筛选条件"><a href="#筛选条件" class="headerlink" title="筛选条件"></a>筛选条件</h4><p>通常来说,主库需要面临更大的压力,如果一个从库本身的配置较低或者网络就不稳定,那么它也不具备成为新主库的条件; 已经下线的从库自然更没法参与选主过程</p><p>而且对于网络状态的判断,并不能简单的通过当前可用就认为这个从库的网络一直很好; 还需要判断之前的网络状态; 如果在这之前从库经常和主库发生断连,并且这个断连次数超过了一定配置;那么也认为这个从库的网络状态并不好</p><p>可以通过配置主从库之间的最大连接时间,以及最大断连次数来判断一个从库的综合网络状况</p><h4 id="从库打分"><a href="#从库打分" class="headerlink" title="从库打分"></a>从库打分</h4><p>在完成筛选过程后,就需要对通过的从库按照一定的规则进行打分,具体的打分规则如下:</p><ol><li><p>第一轮: 检查从库有没有配置过优先级,优先级更高的从库得分高; 优先级可以通过配置手动指定,通常把一些配置更好,网络质量更佳的从库配置更高的优先级; 这样当发生主从切换的时候,这些优质的从库更有可能成为新的主库</p></li><li><p>第二轮: 如果所有从库的优先级都一样; 哨兵就需要判断所有从库与旧主库的同步进度, 同步进度越近的从库得分越高</p></li></ol><p>对于第二轮打分,如何判断主从之间的同步进度:</p><p>之前有说过 redis 在做主从同步的时候,主库上维护了一个 <code>replicaiton buffer</code> 和 <code>replication backlog</code>, 其中 <code>backlog</code> 是一个环形数组,而且主库和从库分别在 <code>backlog</code> 上记录主库的最新写入位置和从库的最新读取位置; 这两个位置中间的差距就称为主从同步的偏移量 <code>offset</code></p><p>此时就通过这个 <code>offset</code> 的值,取出所有从库的 <code>offset</code> 判断哪个从库有最小的 <code>offset</code> 值,这样就可以认为这个从库之前与旧主库的同步进度更接近,如果把它选为新主库的话,数据不一致的可能性更低</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2qqt3gj30j405q759.jpg" alt="img_4.png"></p><p>可以看到此时的旧主库写入位置为 <code>1000</code></p><p>从库 1 的读入位置为 <code>950</code> 此时 <code>offset=50</code>; 从库 2 的读入位置为 <code>950</code> 此时 <code>offset=50</code>; 从库 3 的读入位置为 <code>900</code> 此时 <code>offset=100</code></p><p>这样从库 3 的同步进度明显落后于从库 1 和 2,在第二轮打分中,从库 3 被淘汰掉</p><ol start="3"><li>第三轮: 实例 id 号小的从库得分更高</li></ol><p>在经历了网络质量检查,主从同步进度检查两轮打分之后,如果还剩下多个从库,此时就选取里面实例 id 号最小的从库成为新的主库</p><p>至此,整个选主过程就完成,新的主库产生</p><h4 id="通知其他从库和客户端有新的主库产生"><a href="#通知其他从库和客户端有新的主库产生" class="headerlink" title="通知其他从库和客户端有新的主库产生"></a>通知其他从库和客户端有新的主库产生</h4><p>完成选主之后,的主从切换,称为 <code>故障转移</code></p><h3 id="pubsub-消息通知机制"><a href="#pubsub-消息通知机制" class="headerlink" title="pubsub 消息通知机制"></a>pubsub 消息通知机制</h3><p>多个哨兵之间如何完成互相发现,哨兵之间如何进行通信,这依赖于 redis 提供的 <code>pub/sub</code> 消息机制</p><p>所有哨兵都订阅主库上的同一个频道 <code>_sentinel__:hello</code> ,这样当有一个哨兵往这个频道里发送消息时,其他哨兵都能通过订阅这个频道接收到对应的消息</p><p>(感觉可以把这个频道理解为消息队列的 <code>topic</code> 主题)</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2v5vogj30j10a7wgc.jpg" alt="img_5.png"></p><p>哨兵 1 往频道里发送自己的 ip 地址和端口号,哨兵 2 和 3 接收到消息后就能与哨兵 1 建立连接,同理哨兵 2 和 3 之间也是通过这种方式建立连接</p><p>哨兵除了在互相之间建立连接,还需要和主库从库之间建立连接,这样才能监控主从库的运行状态</p><p>哨兵通过向主库发送 <code>info</code> 命令,查询主库上的从库列表信息,在得到所有所有从库列表信息之后就可以和从库之间建立连接了</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h2zduqxj30ff09yjt0.jpg" alt="img_6.png"></p><p>除了哨兵之间,哨兵和主从库之间建立连接,哨兵还需要和客户端之间建立连接,这样当发生主从切换后,哨兵才能将新主库的地址信息发送给客户端,不然客户端无法感知到主从切换和新主库的存在</p><p>对于哨兵来说,其本质就是一个特殊的 redis 实例,只不过哨兵并不对外提供查询和写入的服务而已,所以哨兵自己也可以有消息频道,这样客户端就能够通过订阅哨兵的不同消息频道,接收各种事件,处理对应的业务了</p><p>借助于 redis 提供的 <code>pubsub</code> 消息机制,主从切换当中最后一个步骤也完成了,此时客户端就能通过订阅的频道,接收到主从切换完成的消息,以及新主库的配置信息,从而跟新主库建立连接进行后续的业务处理</p><h3 id="主从切换由哪个哨兵发起"><a href="#主从切换由哪个哨兵发起" class="headerlink" title="主从切换由哪个哨兵发起"></a>主从切换由哪个哨兵发起</h3><p>对于哨兵集群来说,任何一个哨兵节点都可以发起主从切换,只要它获得了足够的资源</p><p>当一个哨兵认为主库 <code>主观下线</code> 时,他就会往其他所有哨兵发出一条 <code>is_master_down_by_addr</code> 的指令,其他哨兵在接收到这条指令后,就会检测主库之间的状态</p><p>如果有其他哨兵也认为主库已经 <code>主观下线</code> 则会给第一个认为 <code>主观下线</code> 的哨兵回复一条 <code>Y</code> 赞成票</p><p>如果其他哨兵并不认为主库已经 <code>主观下线</code> 则会给第一个认为 <code>主观下线</code> 的哨兵回复一条 <code>N</code> 反对票</p><p>这样,当第一个发起投票的哨兵在接收到其他所有哨兵的回复之后,统计所有的票数,满足两个条件就发起主从切换</p><ol><li>得到的赞成票必须超过哨兵节点个数的一半及以上, 也就是说 &#96;赞成票 &gt;&#x3D; N&#x2F;2 + 1</li><li>得到的赞成票必须超过一个配置的 <code>quorum</code> 值</li></ol><p>此时的哨兵就会把主库标记为 <code>客观下线</code> ,这样这次主从切换就由当前哨兵发起,此时当前哨兵称为 <code>leader</code></p><p>整个投票的过程,称为 <code>leader</code> 的选举</p><p>当一个哨兵开始发起选举投票后,如果还收到了其他哨兵选举投票的申请时,会直接回复 <code>N</code> 反对票; 而且对于同一个哨兵,他只能在第一次无条件投出赞成票,之后的所有其他选举请求,都只会投反对票</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h81h33laxxj30j70cyjuo.jpg" alt="img_7.png"></p><p>一个哨兵在发起选举之后,如果没有得到半数以上的赞成票,此时会等待一段时间后,重新发起选举</p><h3 id="概念阐述"><a href="#概念阐述" class="headerlink" title="概念阐述"></a>概念阐述</h3><ol><li>要判断一个主库是否 <code>客观下线</code> 必须要认为其 <code>主观下线</code> 的哨兵个数超过 <code>quorum</code> 值</li><li>要发起一次主从切换,必须要完成一次选主过程; 而哨兵要成为 <code>leader</code> 必须满足两个条件<ul><li>得到的赞成票超过哨兵总数的半数以上,即 <code>赞成票 &gt;= N/2 + </code></li><li>得到的赞成票大于等于 <code>quorum</code> 值</li></ul></li></ol><p>考虑如下场景: 有 5 个哨兵组成的哨兵集群,其中 3 个哨兵发生了故障,配置的 <code>quorum</code> 值为 2; 如果此时主库真的发生故障, 主库能否被标记为 <code>客观下线</code> ? 整个集群能否发生主从切换</p><ol><li>当一个哨兵发现主库 <code>主观下线</code> 后发起一次选举投票,首先给自己投一票,再将选举请求发送给其他哨兵</li><li>另一个哨兵如果先接收到投票请求,再发现主库故障; 此时会给另一个哨兵投赞成票; 接着发起一次选主投票,由于自己已经投过赞成票了,所以只能给自己投反对票<ul><li>如果另一个哨兵先发现主库故障,再收到投票请求; 此时会先发起选主投票并给自己投赞成票, 之后接收到另一个哨兵的选举请求时,由于已经给自己投了赞成票,所以只能给另一个哨兵回复反对票</li><li>此时两个哨兵都给自己投票,结果是都没能超过半数以上; 此时不会产生 <code>leader</code> 也不会发生主从切换</li><li>每个哨兵再发起选举后如果没能成为 <code>leader</code> 则会等待一段时间后再次发起选举投票</li></ul></li><li>对于 2.1 此时一个哨兵得到了 2 票赞成票大于等于 <code>quorum</code> 值了,但是由于一共有 5 个哨兵,没能超过哨兵的一半; 所以也无法成为 <code>leader</code><ul><li>对于 2.2 更不会有 <code>leader</code> 产生</li></ul></li></ol><p>所以对于这种情况: 主库能够被标记为 <code>客观下线</code>; 整个集群无法发生主从切换</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(四)redis 主从同步</title>
    <link href="/2022/11/11/redis/(%E5%9B%9B)redis%20%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/"/>
    <url>/2022/11/11/redis/(%E5%9B%9B)redis%20%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-如何保证高可用"><a href="#redis-如何保证高可用" class="headerlink" title="redis 如何保证高可用"></a>redis 如何保证高可用</h3><p>对于 redis 来说高可用有两层含义</p><ol><li>异常宕机时数据尽量不丢失</li><li>服务尽量少中断</li></ol><p>对于第 1 点来说,redis 通过 <code>AOF</code> 和 <code>RDB</code> 两种不同的持久化方式来保证数据尽量不丢失</p><p>对于第 2 点来说,如果一个节点挂掉了,想要中断服务的时间尽可能短,最简单的办法就是部署多台实例; 这样某个节点挂掉之后还能有其他节点继续对外提供服务</p><p>对于第 2 点,如何保证每个节点之间的数据一致性,又成了难题</p><h4 id="redis-的读写分离"><a href="#redis-的读写分离" class="headerlink" title="redis 的读写分离"></a>redis 的读写分离</h4><p>如果所有节点之间平行对外提供服务,即每个节点都能处理读和写请求; 对于读请求来说是幂等的,所有节点都可以提供读服务,这个不需要额外考虑</p><p>对于写请求来说,如果客户端 3 个写请求分别被发到了 3 个不同的节点上,对于客户端来说,后续的查询无论命中了哪个节点,都是脏数据</p><p>redis 采用读写分离避免上述情况发生: 读请求从库和主库都能处理响应; 写请求只有主库能够处理,在主库处理完成后同步给其他从库保证数据的 <strong>最终一致性</strong></p><p>可以看到,redis 的读写分离只能保证 <strong>最终一致性</strong>, 不是 <strong>强一致性</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80wk46gmkj30im067gmt.jpg" alt="img.png"></p><h3 id="redis-主从同步"><a href="#redis-主从同步" class="headerlink" title="redis 主从同步"></a>redis 主从同步</h3><p>启动 redis 实例时,可以通过 <code>replaceof</code> 或者 <code>slaveof 5.0 之前</code> 指令形成主从关系,之后会按照 3 个过程进行第一次主从同步</p><ol><li>主从之间建立连接,准备开始同步</li><li>主库将数据发送给从库</li><li>主库将第 2 步期间新进来的写请求发送个从库</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80wka46xej30j208fq59.jpg" alt="img_1.png"></p><h4 id="建立连接阶段"><a href="#建立连接阶段" class="headerlink" title="建立连接阶段"></a>建立连接阶段</h4><p>从库向主库发送指令 <code>psync</code> 表示即将进行主从同步,参数包含 <code>主库的实例 id</code> 和 <code>同步进度偏移量</code><br><code>?</code> 由于第一次进行主从同步,此时从库并不知道主库的实例 id; <code>-1</code> 表示第一次进行全量同步</p><p>当主库接收到从库的 <code>psync</code> 指令后,会通过 <code>fullsync</code> 指令响应给从库,并且在响应里面带上自己的 <code>主库实例 id</code> 和 <code>当前的复制进度</code></p><h4 id="全量同步阶段"><a href="#全量同步阶段" class="headerlink" title="全量同步阶段"></a>全量同步阶段</h4><p>在完成握手建立连接之后,主库会把当前的所有数据全部发送给从库; 从库接收到数据后在本地完成数据加载; 这个阶段使用 <code>RDB</code> 方式进行数据导入</p><ol><li>主库开始全量同步,执行 <code>bgsave</code> 命令 <code>fork</code> 一个子线程开始生成全量 <code>RDB</code> 文件</li><li>接着将这个全量 <code>RDB</code> 文件发送给从库</li><li>从库接收到主库的全量 <code>RDB</code> 文件之后,直接清空本地的数据; 使用主库的全量 <code>RDB</code> 文件导入到本地的数据库; 避免留下之前的脏数据</li></ol><p>根据 <code>RDB</code> 快照的生成过程,在主从同步时,主库的主线程仍然能够处理请求,自然也会接收到新的写请求</p><p>为了保证这些写请求在从库上不会丢失; 主库会把 <code>RDB</code> 期间的写请求全部写入 <code>RDB</code> 缓冲区,即 <code>replication buffer</code></p><p>当主库将全量 <code>RDB</code> 文件发送完成之后,再把这个增量 <code>RDB</code> 文件继续发送个从库; 从库将这两个 <code>RDB</code> 文件的数据应用到本地的数据库之后,就完成了一次全量同步</p><h4 id="级联部署"><a href="#级联部署" class="headerlink" title="级联部署"></a>级联部署</h4><p>可以看到在全量同步的过程当中,有两个明显的性能问题</p><ol><li>主库生成全量的 <code>RDB</code> 文件</li><li>主库将全量的 <code>RDB</code> 文件通过网络发送给从库</li></ol><p>根据之前说的,生成 <code>RDB</code> 快照时,即使是通过 <code>fork</code> 子线程的方式避免阻塞主线程; 但是如果全量数据过大的话,<code>fork</code> 操作本身也会阻塞主线程</p><p>而且发送过大的全量 <code>RDB</code> 文件,也会消耗大量的网络资源,导致正常的读写请求无法进入主库</p><p>为了解决全量同步过程当中主库压力过大的问题,redis 引入了 <code>级联部署</code> 的方式,即 <code>主-从-从</code> 模式</p><p>在之前的主从结构当中,所有的从库都是直接和主库相连,这样对于同一份 <code>RDB</code> 快照来说,就要发给所有的从节点</p><p>在级联部署当中,可以手动选择一个从库用于级联部分其他的从库,再让这个从库老大成为主库的从库</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80wkfiie9j30j809o766.jpg" alt="img_2.png"></p><p>这样,就将原来的 <code>1 主 4 从</code> 变成了 <code>1 主 2 从</code>; 主库在做全量同步的时候,只需要发送 2 份 <code>RDB</code> 快照文件即可,网络压力直接减少到原来的一半</p><h4 id="网络断连或者阻塞导致的主从同步失败"><a href="#网络断连或者阻塞导致的主从同步失败" class="headerlink" title="网络断连或者阻塞导致的主从同步失败"></a>网络断连或者阻塞导致的主从同步失败</h4><p>一旦主库和从库之间完成了首次全量同步,主库就会通过之前已经握手建立好的连接,持续地向从库发送新的写请求; 这个过程称为 <code>基于长连接的命令传播</code></p><p>但是考虑到如果网络在这个过程当中出现了问题,如断连或者网络带宽本身就阻塞了; 主从同步就无法继续通过长连接传播命令; 这样也无法保证整个集群的数据一致性了</p><ol><li>对于老版本的 redis (2.8 以前) 网络断连之后,下一次连接恢复时,会进行一次全量同步; 如果网络本身质量不好频繁断连,每次的全量同步会造成非常大的性能问题</li><li>redis 2.8 以后引入了 <code>增量同步</code> 技术; 即网络重连之后,不进行全量同步,而是会把主库在断连期间接收到写请求发送给从库</li></ol><p>增量同步技术实现的关键点,就是之前介绍的全量同步过程中的第三个阶段,有个 <code>replication backlog</code> 缓冲区</p><p>当全量同步在生成全量 <code>RDB</code> 和发送全量 <code>RDB</code> 的过程中,会把主库新接收到的写请求记录在这个 <code>replication buffer</code> 当中,当全量 <code>RDB</code> 文件发送完毕后,再把这些增量数据全部发送给从库</p><p>看一看这个 <code>replication backlog (复制积压缓冲区)</code> 的具体构成:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80wkksknij30j204zwgb.jpg" alt="img_3.png"></p><p>与 mysql 的 <code>redo log</code> 非常类似,<code>replication backlog</code> 也是一个环形缓冲区</p><p>有两个指针,记录主库写入的位置 <code>write_pos</code> 和从库读的位置 <code>read_pos</code>,这两个指针中间的差值就成为主从同步的偏移量 <code>offset</code> </p><p>需要区分下: <code>replication buffer</code> 和 <code>replication backlog</code></p><ol><li><code>buffer</code> 在每个从库上都有一份,用于接收增量同步进行时的数据</li><li><code>backlog</code> 只在主库上有一份记录,所有的从库共用这一份 <code>backlog</code> 缓冲</li></ol><p>回顾一下第一次全量同步的第 1 步,从库向主库发送 <code>psync ? -1</code> 指令,其中 <code>offset=-1</code> 表示进行一次全量同步</p><p>对于第一次全量同步,主库的写入点和从库的读取点是一致的,随着服务的持续运转,持续进行增量主从同步,主库的写入点和从库的读取点都会向后移动,正常来说,这两个指针的偏移量基本相等</p><p>如果在某个时刻网络发生了断连,导致主从同步中断,在网络恢复之后; 从库会向主库发送 <code>psync 主库id offset</code> 的指令,将自己的读取点告诉给主库</p><p>此时主库会判断当前从库的读取点和自己的写入点之间的差距,此时主库会把这中间差距的写入请求重新发送给从库; 由此继续进行增量的同步</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80wkp7ytwj30j709omz8.jpg" alt="img_4.png"></p><h4 id="replication-backlog-覆盖写的问题"><a href="#replication-backlog-覆盖写的问题" class="headerlink" title="replication backlog 覆盖写的问题"></a>replication backlog 覆盖写的问题</h4><p>由于 <code>replication backlog</code> 是一个环形的缓冲区,如果网络断连或者主从延迟时间过长,会导致主库的写入点位置超过了从库的读入点,覆盖了部分还没有同步到从库的数据; 导致数据的不一致问题</p><p>实际上在配置 <code>复制积压缓冲区</code> 的大小时,需要考虑到主库写入速度和网络传输速度; 而且为了应对一些突发状况,实际场景下还要把这个大小扩大一倍</p><p>例如当前主库每秒写入 <code>2000</code> 条记录,每条记录大小为 <code>2KB</code>, 网络每秒能够传输 <code>1000</code> 条记录</p><p>此时 <code>replication buffer</code> 缓冲需要保存 <code>1000</code> 条记录,大小至少需要 <code>2MB</code>,实际上 <code>replication backlog</code> 的大小就需要设置为 <code>buffer</code> 的两倍以上,避免覆盖写</p><p>但是如果主库压力特别快,写入速度远超于从库同步的进度,再大的 <code>backlog</code> 也都将被主库写满; 所以一味地增加 <code>backlog</code> 的大小,属于治标不治本的方案</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(三)redis 持久化机制</title>
    <link href="/2022/11/10/redis/(%E4%B8%89)redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/10/redis/(%E4%B8%89)redis%20%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-的持久化机制"><a href="#redis-的持久化机制" class="headerlink" title="redis 的持久化机制"></a>redis 的持久化机制</h3><p>由于 redis 是内存型数据库,当 redis 实例发生异常宕机时,其内存里面的数据将会全部丢失; 所以 redis 也需要通过持久化操作来避免异常宕机导致的数据丢失问题发生</p><p>redis 提供了 3 种持久化方式:</p><ol><li>AOF 日志</li><li>RDB 内存快照</li><li>MIX 两者的混合模式</li></ol><h3 id="AOF-日志"><a href="#AOF-日志" class="headerlink" title="AOF 日志"></a>AOF 日志</h3><p>mysql 也有写日志,而且 mysql 的特性是写 <code>前日志</code> 也就是说在实际的数据写入之前,先写日志</p><p>而 redis 则恰恰相反,redis 是写 <code>后日志</code> 也就是当数据写入内存之后,才会记录日志; 要弄清楚为什么 redis 写 <code>后日志</code> 需要先了解 <code>AOF</code> 日志究竟保存了什么内容</p><p>相比于 mysql 的 <code>redo log</code>,记录的是修改后的数据,也就是哪个库那张表那个数据行多少偏移量上修改了什么</p><p>而 redis 的 <code>AOF</code> 日志也是类似于 <code>redo log</code> 记录的是什么 <code>key</code> 发生了什么修改,其组成部分如下:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-number">*3</span><br><span class="hljs-variable">$3</span><br><span class="hljs-built_in">set</span><br><span class="hljs-variable">$7</span><br>testkey<br><span class="hljs-variable">$9</span><br>testvalue<br></code></pre></td></tr></table></figure><p><code>*3</code> 表示当前操作命令有 3 个部分组成,每个部分都是由 <code>$+数字</code> 开头,后面紧跟跟具体的命令或者操作数; <code>$</code> 后面的 <code>数字</code> 表示当前命令或者操作数占用的字节数</p><p><code>$3 set</code> 表示 <code>set</code> 指令占用了 3 个字节, <code>$7 testkey</code> 表示操作数 <code>testkey</code> 占用了 7 个字节</p><p>为什么 redis 采用写 <code>后日志</code> 的方式,说到底还是为了快,为了性能</p><p>如果 redis 已经将命令成功执行了,则表示命令本身的语法和操作并没有问题,无需进行额外的校验,可以直接写到日志里面</p><p>如果说是写 <code>前日志</code> 的话,还需要对命令进行语法检查,或者一致性检查; 例如 mysql 的唯一键冲突,或者记录不存在等等检查,可以节约系统资源</p><p>如果不进行前置检查,直接将命令写入日志的话,如果命令本身是错误的在使用日志做数据恢复的时候,就会发生报错</p><p><code>AOF</code> 日志的缺点</p><ol><li>如果写入内存后,还没来得及写入 <code>AOF</code> 日志,此时宕机会导致数据丢; 如果 redis 用于缓存,还能从数据库里面恢复数据; 如果 redis 用作数据库的话,丢失的数据将无法恢复</li><li><code>AOF</code> 写日志不阻塞当前命令执行,但是写 <code>AOF</code> 日志也是在主线程中执行的,如果写盘的 IO 压力过大,将会严重影响后续命令的执行</li></ol><h4 id="AOF-的回写策略"><a href="#AOF-的回写策略" class="headerlink" title="AOF 的回写策略"></a>AOF 的回写策略</h4><p>为了解决主线程写 <code>AOF</code> 日志导致的阻塞问题,redis 提供了 3 种写 <code>AOF</code> 日志的策略</p><ol><li>Always 实时写:类似于 mysql 的同步刷盘,每次命令执行后,都立即写入 <code>AOF</code> 日志; 这样做数据可靠性最强,但是性能较低</li><li>Everysec 每秒写回:类似于 mysql 的实时写延时刷,每次命令执行后,先写入 <code>AOF</code> 的内存缓冲区,依靠其他后台线程每 1s 将 <code>AOF</code> 内存缓冲区内的数据刷入磁盘</li><li>No 操作系统控制刷盘时机:类似于 mysql 的延时写,每次命令执行后,只写入 <code>AOF</code> 内存缓冲区; 至于什么时候刷盘,由操作系统决定; 性能最高但是数据可靠性最低</li></ol><p>对于第 2 点,如果发生异常宕机,仍然会丢失 1s 之前的数据</p><h4 id="AOF-重写机制"><a href="#AOF-重写机制" class="headerlink" title="AOF 重写机制"></a>AOF 重写机制</h4><p>由于 <code>AOF</code> 是以文件的形式记录所有接收到的 <strong>写请求</strong>, 必不可免会导致 <code>AOF</code> 日志文件过大的情况; 即使是顺序写,对于一个大文件来说起磁盘写入的性能仍然低下</p><p>而且如果要使用 <code>AOF</code> 日志来做数据恢复的话,一个巨大的 <code>AOF</code> 日志势必导致数据恢复的时间非常缓慢,也会影响到 redis 的正常使用</p><p>redis 为了避免 <code>AOF</code> 日志文件越写越大,引入了 <code>AOF</code> 重写机制,其具体过程如下: 进行 <code>AOF</code> 重写时,会基于当前 redis 数据库现状创建一个新的 <code>AOF</code> 日志文件,会遍历所有的键值对,使用 <code>一条</code> 命令来记录写入</p><p>为什么说重写的 <code>AOF</code> 日志可以减小日志文件的大小呢?</p><p>因为 <code>AOF</code> 日志是追加写入的方式,也就是说 redis 对于每一条写记录,都会记录对应的 <code>AOF</code> 日志,对于一个 <code>key</code> 的重复</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fmi1e2yj332a0u017w.jpg" alt="img.png"></p><p>对于写入一个 <code>list</code> 来说, <code>AOF</code> 日志会记录完整的所有写操作,而重写的 <code>AOF</code> 日志则是只会记录当前最新状态的记录</p><p>即无论对 <code>list</code> 有多少次操作,重写 <code>AOF</code> 时的状态只有确切的一条,就只用记录这一条日志就够了</p><p>为了避免重写 <code>AOF</code> 日志对主线程的阻塞,redis 实际上有专门的后台线程 <code>bgrewriteaof</code> 去处理重写 <code>AOF</code> 日志</p><p><strong>一处拷贝,两处日志</strong></p><ul><li>一处拷贝是指: 当需要进行 <code>AOF</code> 日志重写时,此时的主线程会 <code>fork</code> 一个子线程出来,<code>fork</code> 出来的子线程拥有与重写时主线程完全一致的内存数据; 这样子线程就可以在不阻塞主线程的情况下,在后台异步的重写 <code>AOF</code> 日志</li></ul><p>之前提到过,为了避免写 <code>AOF</code> 日志时写盘速率影响到主线程,此时主线程实际上写入的是 <code>AOF</code> 日志缓冲区,然后按照配置的刷盘策略去将日志缓冲区的记录刷到磁盘上的 <code>AOF</code> 文件里</p><p>由于重写 <code>AOF</code> 时是 <code>fork</code> 的子线程,而在 <code>fork</code> 之后还会有新的写请求进来,这样子线程的内存数据和主线程的内存数据就会产生不一致</p><ul><li>两处日志就是为了解决上述的不一致问题: 当主线程 <code>fork</code> 之后继续处理新的写请求时,此时不仅仅会将新的写请求写入 <code>AOF</code> 日志缓冲区,还会继续写入 <code>AOF</code> 重写日志缓冲区; 这样当子线程完成 <code>AOF</code> 重写之后,再把 <code>AOF</code> 重写缓冲区内的增量写请求继续重写后与当前结果合并,这样一个完整的 <code>AOF</code> 重写日志就完成了,而且 <code>fork</code> 之后的写请求也不会丢失</li></ul><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fn02t77j30j108xdib.jpg" alt="img_1.png"></p><h4 id="AOF-重写时的性能问题"><a href="#AOF-重写时的性能问题" class="headerlink" title="AOF 重写时的性能问题"></a>AOF 重写时的性能问题</h4><p>重写 <code>AOF</code> 日志时,虽然使用了子线程在后台操作,但是仍然有阻塞主线程的场景</p><ol><li>主线程 <code>fork</code> 子线程时,需要拷贝虚拟页表,可能会阻塞</li><li>当有 <code>bigkey</code> 写入时,根据写时复制优化,需要拷贝 <code>key</code> 的全量数据到新的内存页里面,可能会阻塞</li><li>当重写 <code>AOF</code> 日志完成后,应用重写 <code>AOF</code> 缓冲区时,可能会阻塞</li></ol><h4 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h4><p>什么是写时复制</p><p>如果 <code>fork</code> 子线程时全量拷贝主线程的内存数据,此时很有可能导致内存不够,为了避免全量拷贝主线程内存,操作系统在做 <code>fork</code> 时引入了写时复制的概念</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fn62qwej30hd0fhtar.jpg" alt="img_2.png"></p><p>当主线程需要写入数据的时候,如果此时数据页正好在内存当中,则会在内存上单独分配一块内存出来将原有的内存页复制到新页里面,主线程的数据全部写入新的数据页</p><p>这样原来 <code>fork</code> 的子线程仍然访问原来的老数据页,使得在做 <code>AOF</code> 重写时,主线程和子线程的读写互不影响</p><p>且写时复制对于 redis 这种读多写少的数据库,能够减少数据页的分配,提高内存的使用率,减少 <code>fork</code> 子线程的阻塞时间</p><h3 id="RDB-内存快照"><a href="#RDB-内存快照" class="headerlink" title="RDB 内存快照"></a>RDB 内存快照</h3><p>由于 <code>AOF</code> 日志记录的是每一条操作指令和操作数,并不是实际的数据; 所以在使用 <code>AOF</code> 日志进行数据恢复的时候,需要 redis 把这些指令和操作数全部拿出来重新执行一遍</p><p>且 <code>AOF</code> 日志记录所有写指令,如果日志文件过大,在做数据恢复的时候将严重影响 redis 性能</p><p>redis 的另一种持久化方式: <code>RDB</code> 内存快照</p><p><code>RDB</code> 就是在某一时刻,记录了 redis 瞬间的所有数据和状态,并且以文件的形式持久化到磁盘上</p><p>与 <code>AOF</code> 相比, <code>RDB</code> 记录的是某一时刻的全量数据,而 <code>AOF</code> 则是记录的数据的操作; 所以在做数据恢复的时候,可以很方便的把 <code>RDB</code> 文件直接导入到 redis 当中</p><h4 id="RDB-快照的范围"><a href="#RDB-快照的范围" class="headerlink" title="RDB 快照的范围"></a>RDB 快照的范围</h4><p>要明确一点 <code>RDB</code> 做的是 <code>全量</code> 数据快照; 如果 redis 里面的数据量非常多,那么 <code>全量</code> 快照很有可能阻塞主线程的工作; 类比于 <code>AOF</code> 日志, redis 也提供了后台线程执行快照</p><p><code>bgsave</code> 命令可以创建一条后台子线程专门处理当前时刻的 <code>RDB</code> 快照数据,避免阻塞主线程</p><h4 id="RDB-快照时-写请求如何处理"><a href="#RDB-快照时-写请求如何处理" class="headerlink" title="RDB 快照时,写请求如何处理"></a>RDB 快照时,写请求如何处理</h4><p>对于业务系统来说,如果为了处理一次 <code>RDB</code> 快照,而让整个 redis 进入只读状态,这是不允许接收的; 然而如果在做 <code>RDB</code> 快照时仍然有写请求进入,此时就可能导致 <code>RDB</code> 快照数据和 redis 本身保存的数据不一致问题</p><p>对于写请求, <code>RDB</code> 类似于 <code>AOF</code> 仍然采用 <code>写时复制</code> 技术,保证数据的一致性; 当主线程需要写入数据时,会将这份数据的内存页复制出一个新的内存页; 主线程的写入操作全部放到新的内存页上; 同时子线程的 <code>RDB</code> 快照也会读取新的内存页,保证数据的一致性不被破坏</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fnb7r21j30i709qtao.jpg" alt="img_3.png"></p><h4 id="RDB-快照的频率"><a href="#RDB-快照的频率" class="headerlink" title="RDB 快照的频率"></a>RDB 快照的频率</h4><p>为了保证数据尽可能的最新,<code>RDB</code> 快照的频率必然也要变得更加频繁; 这样可以减少两次快照之间异常宕机导致的改动丢失; 但是 <code>RDB</code> 快照的频率也不是越快越好</p><ol><li>虽然 <code>bgsave</code> 子线程做快照时不阻塞主线程,但是每次子线程都要从主线程 <code>fork</code> 出来,而 <code>fork</code> 操作会把主线程的虚拟内存映射表全部赋值给子线程; 如果 redis 里面的数据量非常大,这里的 <code>fork</code> 操作也会影响到主线程的处理</li><li>由于 <code>RDB</code> 快照每次都记录全量的数据,而频繁地将全量数据写入磁盘; 也会导致 redis 整体性能下降</li></ol><h4 id="增量-RDB"><a href="#增量-RDB" class="headerlink" title="增量 RDB"></a>增量 RDB</h4><p>由于每次全量 <code>RDB</code> 需要记录的数据太多了,而放慢 <code>RDB</code> 频率又会导致宕机时丢失更多的数据; redis 引入了增量 <code>RDB</code> 技术</p><p>即在一次全量 <code>RDB</code> 之后,后面仅仅记录发生改动的数据,即只做增量 <code>RDB</code> 操作</p><p>增量 <code>RDB</code> 看起来很美好,但实际上并不是如此,因为 redis 要为每条记录维护元数据,而这些元数据大小是固定的; 如果说大量很小的字段被增量写入 <code>RDB</code> 可能一条记录也就 2,3 个字节; 但是其元数据可能固定高达 8 个字节; 这样 redis 就不得不为这些小字段去维护大量的元数据; 浪费大量内存,显得有点得不偿失</p><h4 id="混合-AOF-和-RDB-持久化"><a href="#混合-AOF-和-RDB-持久化" class="headerlink" title="混合 AOF 和 RDB 持久化"></a>混合 AOF 和 RDB 持久化</h4><p>在 redis 4.0 以后引入了混合模式: 即以一定的间隔做全量 <code>RDB</code> 快照; 同时在快照期间通过记录 <code>AOF</code> 日志的形式保存增量数据</p><p>这样即保证了有 <code>RDB</code> 快照可以快速恢复到上一时刻,也保证了快照期间的写请求不会丢失,还保证了 <code>AOF</code> 日志文件不会变得过于庞大,因为它只记录每次快照期间的增量数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h80fngtx5rj30iu0blmzs.jpg" alt="img_4.png"></p><p>在下一次发生全量快照的时候,直接清空 <code>AOF</code> 日志即可,因为下一次全量快照已经包含了这部分 <code>AOF</code> 日志记录的数据,这样进一步减小了 <code>AOF</code> 日志文件的大小</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(二)redis 为什么快</title>
    <link href="/2022/11/10/redis/(%E4%BA%8C)redis%20%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB/"/>
    <url>/2022/11/10/redis/(%E4%BA%8C)redis%20%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-使用单线程"><a href="#redis-使用单线程" class="headerlink" title="redis 使用单线程"></a>redis 使用单线程</h3><ol><li>完全基于内存,绝大部分请求都是在内存中计算处理,少量需要持久化的操作才会涉及到写磁盘</li><li>数据结构是专门设计的,操作简单</li><li>单线程,省去了线程间的上下文切换和 CPU 消耗,不存在资源竞争,不涉及加锁和释放的操作</li></ol><p>这里的单线程指的是 <strong>处理网络 IO 请求和键值对读写(核心工作线程)</strong> 是单线程的,而对于那些需要持久化的操作,例如写日志,异步删除,集群间节点数据同步等是有额外线程执行的</p><h3 id="IO-多路复用"><a href="#IO-多路复用" class="headerlink" title="IO 多路复用"></a>IO 多路复用</h3><h4 id="select-模型"><a href="#select-模型" class="headerlink" title="select 模型"></a>select 模型</h4><p>将所有已连接的 <code>socket</code> 都放入一个 <strong>文件描述符集合</strong> 当中,调用 <code>select</code> 函数把这个集合拷贝给内核,让内核轮训集合检测是否有网络事件</p><p>而内核检测是否有网络事件产生的方式则是通过遍历每个文件描述符,如果有网络事件产生,则将此 <code>socket</code> 标记为可读或者可写,遍历完成后把这个集合再拷贝回用户态交给 <code>select</code> 函数处理</p><p>此时用户态还需要做 <strong>第二次</strong> 遍历,才能找到就绪的 <code>socket</code> 并且进行处理</p><p>可以看到 <code>select</code> 模型有如下特点:</p><ol><li>需要遍历 2 次文件描述符集合</li><li>发生 2 次用户态到内核态,内核态到用户态的拷贝</li></ol><p>而且操作系统在不修改配置的情况下,默认只允许一个进程最大操作 <code>1024</code> 个文件描述符</p><h4 id="poll-模型"><a href="#poll-模型" class="headerlink" title="poll 模型"></a>poll 模型</h4><p>几乎与 <code>select</code> 一样,仅仅是使用链表来组织 <strong>文件描述符集合</strong> ,突破了 <code>select</code> 最大监听数量而已</p><h4 id="epoll-模型"><a href="#epoll-模型" class="headerlink" title="epoll 模型"></a>epoll 模型</h4><ol><li>使用 <strong>红黑树</strong> 存储文件描述符集合</li><li>使用 <strong>就绪队列</strong> 存储就绪的文件描述符</li><li>每个文件描述符只需要在添加时传入一次,通过事件更改描述符状态</li></ol><p><code>select, poll</code> 都只有一个相关函数,而 <code>epoll</code> 有 3 个相关函数 </p><p><code>epoll_create()</code></p><p>创建一个 <code>epoll</code> 实例,其内部主要有两个结构:</p><ul><li>监听列表: 所有需要监听的文件描述符集合,使用 <strong>红黑树</strong> 存储</li><li>就绪列表: 监听列表里面已经就绪的文件描述符结合,使用 <strong>队列</strong> 存储</li></ul><p><code>epoll_ctl()</code> </p><p>监听文件描述符 <code>fd</code> 上发生的 <code>event</code> 事件</p><p>调用 <code>epoll_ctl()</code> 函数会将当前文件描述符 <code>fd</code> 添加到 <code>epoll</code> 实例的监听列表里面,同时为 <code>fd</code> 设置一个回调函数,并且监听指定的 <code>event</code> 事件; 当 <code>fd</code> 上发生指定事件 <code>event</code> 之后,就会调用回调函数将 <code>fd</code> 放入 <code>epoll</code> 实例的就绪列表里面</p><p><code>epoll_wati()</code></p><p><code>epoll</code> 模型的主要处理函数,起作用相当于 <code>select</code>,当调用 <code>epoll_wait()</code> 时,会返回 <code>epoll</code> 实例的就绪列表里面的描述符个数,避免 <code>select, poll</code> 每次遍历所有集合元素</p><h4 id="水平触发"><a href="#水平触发" class="headerlink" title="水平触发"></a>水平触发</h4><p>当监听到文件描述符就绪后,就会触发通知,如果当前文件描述符缓冲区内的数据没有处理完,下次遍历到的时候还会继续发出通知</p><h4 id="边缘触发"><a href="#边缘触发" class="headerlink" title="边缘触发"></a>边缘触发</h4><p>仅当文件描述符从未就绪变更为就绪时,触发一次通知,且之后不会再次通知; 这要求处理函数必须在通知到来时,将缓冲区内的数据通过循环全部处理完成</p><p>边缘触发可以减少 <code>select</code> 的调用次数,只不过在一次调用当中需要反复调用多次 <code>read</code> </p><p><code>epoll</code> 采用边缘触发的方式,保证每次调用 <code>epoll_wait()</code> 都是有效的,因为一次调用必须把缓冲区内的所有数据全部处理完才能返回,否则内核会认为就绪的文件描述符的状态没有发生改变(还有数据没处理完,仍然是就绪状态),从而不再发出后续的通知导致内容丢失</p><h4 id="redis-的-IO-多路复用"><a href="#redis-的-IO-多路复用" class="headerlink" title="redis 的 IO 多路复用"></a>redis 的 IO 多路复用</h4><p>redis 将监听套接字的工作交给内核完成,而内核采用 <code>epoll</code> 的机制同事监听多个套接字和管理已就绪的套接字; 一旦有请求到来,通过就绪队列可以快速的找到文件描述符,交给 redis 的 IO 进程处理</p><p>这样 redis 就实现了一个 IO 进程复用,处理多个网络请求的效果</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zrs431btj30io0chq61.jpg" alt="img.png"></p><p>可以看到,redis 的 IO 进程其实就是在不断的处理 <code>epoll_create</code> 创建的 <code>epoll</code> 实例的就绪队列,每个就绪的文件描述符因为有 <code>epoll_wati</code> 的调用,都记录了监听的事件和对应的回调函数</p><p>当 redis 的 IO 进程拿到就绪的文件描述符之后,可以直接调用对应的回调函数进行请求的处理; 并且不会阻塞在某一个请求上,而是可以继续处理队列里下一个就绪的请求</p><h3 id="Linux-零拷贝技术"><a href="#Linux-零拷贝技术" class="headerlink" title="Linux 零拷贝技术"></a>Linux 零拷贝技术</h3><p>一次常规的读取数据后写盘操作,其流程如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85k2i93wyj30g808h404.jpg" alt="img.png"></p><ol><li>用户态发起 <code>read()</code> 陷入内核态,内核态发起 IO 请求,读取磁盘中的数据  <code>(第一次上下文切换)</code></li><li>CPU 将磁盘当中的数据复制到内核缓冲区  <code>(第一次数据拷贝)</code></li><li>CPU 将内核缓冲区当中的数据复制到用户缓冲区,从内核态切换到用户态  <code>(第二次上下文切换,第二次数据拷贝)</code></li><li>进程处理用户缓冲区内的数据</li><li>用户态发起 <code>write()</code> 陷入内核态,内核态将用户缓冲区的的数据拷贝到内核缓冲区  <code>(第三次上下文切换,第三次数据拷贝)</code></li><li>内核态将内核缓冲区内的数据,拷贝到网卡的套接字缓冲区 <code>(第四次数据拷贝)</code></li><li>内核态完成 <code>write()</code> 调用,返回用户态 <code>(第四次上下文切换)</code></li></ol><p>可以看到一次普通的读盘后写盘操作,需要四次上下文切换,四次数据拷贝,而让宝贵的 CPU 去进行数据拷贝这样的阻塞操作,是很难接受的</p><p>引入 <code>DMA</code> 总线控制器后,CPU 就不再直接参与磁盘的读取和数据拷贝了,而是通过 <code>DMA</code> 的完成事件通知异步的将磁盘缓冲区内的数据拷贝到内核缓冲区</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85k2p62j6j30id0bzq51.jpg" alt="img_1.png"></p><p>对于上下文切换和拷贝次数并没有优化,仅仅是把 CPU 从阻塞的磁盘 IO 中解放出来可以继续做其他计算工作</p><h4 id="虚拟内存映射-mmap"><a href="#虚拟内存映射-mmap" class="headerlink" title="虚拟内存映射 mmap"></a>虚拟内存映射 mmap</h4><p>Linux 提供了一种内存映射的机制,可以把内核缓冲区所在的地址空间与用户缓冲区所在的地址空间进行一次映射,这个技术使得 <code>用户态可以直接访问内核缓冲区内的数据</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85k2uq1bfj30ip0caad7.jpg" alt="img_2.png"></p><p>虚拟地址映射时,有两次上下文切换 <code>(用户态调用 write 和 write 调用返回内核态)</code>,一次 CPU 拷贝,两次 DMA 拷贝</p><h4 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h4><p>Linux 2.1 版本以后还提供了 <code>sendfile</code> 的方式,可以进一步减少拷贝次数,但问题就是由于 <code>sendfile</code> 不经过用户态,所以无法修改数据只能进行数据发送</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85k301thaj30hy0bt40s.jpg" alt="img_3.png"></p><p>在 <code>sendfile</code> 函数调用下,仅有两次上下文切换 <code>(用户态调用 sendfile 和 sendfile 调用返回用户态)</code>,一次 CPU 拷贝,两次 DMA 拷贝</p><h4 id="sendfile-DMA-直接拷贝"><a href="#sendfile-DMA-直接拷贝" class="headerlink" title="sendfile + DMA 直接拷贝"></a>sendfile + DMA 直接拷贝</h4><p>Linux 2.4 以后,对 <code>sendfile</code> 进行了优化,进一步减少了 CPU 的拷贝次数; <code>DMA</code> 通过记录内核缓冲区内的地址和偏移量,直接将数据拷贝到网卡缓冲内</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h85k34q0uuj30if0bhwgy.jpg" alt="img_4.png"></p><p>可以看到本质还是 <code>sendfile</code> 所以仍然无法进行数据修改</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(一)redis 底层数据结构</title>
    <link href="/2022/11/09/redis/(%E4%B8%80)redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <url>/2022/11/09/redis/(%E4%B8%80)redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h3 id="redis-对外提供的上层数据结构"><a href="#redis-对外提供的上层数据结构" class="headerlink" title="redis 对外提供的上层数据结构"></a>redis 对外提供的上层数据结构</h3><ol><li>String</li><li>List</li><li>Hash</li><li>Set</li><li>Sorted Set</li></ol><p>这五大基本类型是 redis 对外提供的数据结构,在底层 redis 分别有自己实现的底层数据结构去对应这些基本类型,分别是:</p><ol><li>简单动态字符串</li><li>压缩列表</li><li>双向链表</li><li>哈希表</li><li>跳表</li><li>整数数组</li></ol><h3 id="redis-所有的-kv-通过什么形式组织"><a href="#redis-所有的-kv-通过什么形式组织" class="headerlink" title="redis 所有的 kv 通过什么形式组织"></a>redis 所有的 kv 通过什么形式组织</h3><p>redis 内部维护了一个巨大的 <code>hash</code> 表,这个 <code>hash</code> 表记录了实例里面的所有键值对</p><p>这个巨大的 <code>hash</code> 表其实就是一个数组,而数组每个元素都是一个 <code>hash</code> 桶,每个 <code>hash</code> 桶里面才保存了键值对数据</p><p>每个 <code>hash</code> 桶内其实也不是保存的真正的键值对,而是维护的指向键值对的指针,即 <code>*key</code> 和 <code>*value</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfxowfbj30j609dgnk.jpg" alt="img.png"></p><p>全局哈希表可以在 <code>O(1)</code> 的时间内快速查找到对应的键值对,只需要由 <code>hash</code> 函数计算出 <code>key</code> 的位置就能找到 <code>hash</code> 桶的位置,然后访问 <code>hash</code> 桶内的 <code>*value</code> 指针即可找到对应的值</p><h4 id="简单动态字符串-SDS"><a href="#简单动态字符串-SDS" class="headerlink" title="简单动态字符串 (SDS)"></a>简单动态字符串 (SDS)</h4><p><code>SDS</code> 并不是一个简单的以 <code>\0</code> 结尾的字符数组,而是一个有着相对复杂结构的抽象类型,并且支持动态扩展</p><p>一个 <code>SDS</code> 的结构如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sdshdr</span> &#123;</span><br>    <span class="hljs-comment">// 记录buf数组中已使用字节的数量，即SDS所保存字符串的长度</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> len;<br>    <span class="hljs-comment">// 记录buf数据中未使用的字节数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-built_in">free</span>;<br>    <span class="hljs-comment">// 字节数组，用于保存字符串</span><br>    <span class="hljs-type">char</span> buf[];<br>&#125;;<br></code></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqevfpm1j30jv0dvgp1.jpg" alt="img_6.png"></p><p><code>raw</code> 类型的 <code>redisObj</code> 和 <code>SDS</code> 内存不连续,需要两次内存分配</p><p><code>EMBSTR</code> 的 <code>redisObj</code> 和 <code>SDS</code> 内存连续,只需要一次内存分配</p><p>但是 <code>EMBSTR</code> 用来保存短字符的优化,如果字符串长度增加需要重新分配时,整个 <code>redisObj</code> 和 <code>SDS</code> 都需要重新分配</p><ol><li>获取字符串长度的时候,不用遍历底层的字符数组,只需要取出 <code>len</code> 属性即可</li><li>杜绝缓冲区溢出,在做字符串拼接的时候,首先会检查 <code>len</code> 和 <code>free</code> 判断内存是否满足需要;如果内存不足,则会对 <code>SDS</code> 做扩展后在才做</li><li>减少字符串的重新分配次数; 字符串扩展时,实际的内存分配会比对应的长度更多,减少连续扩展的内存分配次数; 字符串缩短时,已经分配的内存空间不会立即回收,以免下次需要用的时候再次分配内存</li><li>保证二进制文件安全,不通过 <code>\0</code> 判断是否达到末位,而是通过 <code>len</code> 和 <code>free</code> 属性计算末尾</li></ol><p>在实际做字符串扩展的时候,如果新字符串长度小于 <code>1M</code> 时,扩展会分配一倍大小的空间,如果超过了 <code>1M</code> 则每次多分配 <code>1M</code> 的空间</p><h4 id="压缩列表-zlist"><a href="#压缩列表-zlist" class="headerlink" title="压缩列表 zlist"></a>压缩列表 zlist</h4><p>一个 <code>zlist</code> 的结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqf2b902j30f102nabh.jpg" alt="img_1.png"></p><ul><li>zlbytes: 记录了整个压缩列表占用的字节数</li><li>zltail: 记录了压缩列表最后一个元素的偏移量,用于快速定位列表尾部</li><li>zllen: 记录了压缩列表实际保存的元素 <code>entry</code> 个数 (类似于 <code>SDS</code> 的 <code>len</code> 属性)</li><li>entry…: 压缩列表实际存储每个元素</li><li>zlend: 压缩列表尾部的终止符 (类似于 <code>\0</code> 的作用),标记一个压缩列表结束</li></ul><p><code>entry</code> 的结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqf7rasoj30fe03sta9.jpg" alt="img_2.png"></p><ol><li>一般情况下</li></ol><ul><li>prevlen: 上一个 <code>entry</code> 的大小</li><li>encoding: 当前 <code>entry</code> 的编码格式</li><li>entry-data: 当前 <code>entry</code> 实际存储的内容</li></ul><ol start="2"><li>如果保存的是整数类型<ul><li><code>encoding</code> 和 <code>entry-data</code> 会合并在 <code>encoding</code> 里面,通过前几位判断整型长度,用于节约空间</li><li>且会尝试把 <code>int</code> 转化为 <code>string</code> 类型</li></ul></li></ol><p>压缩列表的设计就是为了节省内存,顺序数组由于每个元素的类型和大小都是固定的,会导致内存使用率低</p><p>而压缩列表的每个节点 <code>entry</code> 通过保存编码让节点刚好分配够用的长度,来达到提高内存使用率的效果;同时由于每个 <code>entry</code> 的长度不一样,就必须记录上一个 <code>entry</code> 的偏移量,这样才能在链表里面完成寻址遍历</p><p>压缩列表的缺点:</p><ol><li>在做缩容的时候,会直接回收对应的内存空间,而不是类似 <code>SDS</code> 会保留; 这样每次新添加元素的时候都会产生一次内存分配</li><li>如果上一个节点的长度超过了 254 个字节,将会导致扩容,而扩容后的 <code>entry</code> 长度由于超过了 254 字节,下一个节点的 <code>prevlen</code> 属性无法保存 254 字节的信息,就只能跟着扩容; 这样容易引起一整条链路上的所有节点都对 <code>prevlen</code> 属性进行扩容操作</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfdaf2tj30u70gbq89.jpg" alt="img_7.png"></p><h4 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h4><p>在压缩列表 <code>zlist</code> 的基础上,每个节点都有维护指向上一个节点 <code>*prev</code> 和下一个节点 <code>*next</code> 的指针,构成一个双向链表</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfhppbkj30m20b7mzk.jpg" alt="img_3.png"></p><p>可以看到,在双向链表的每个节点 <code>quicklistEntry</code> 上,其实保存的实质性内容就是一个 <code>zlist</code> 压缩列表</p><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><p>字典的结构如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictht</span>&#123;</span><br>    <span class="hljs-comment">//哈希表数组</span><br>    dictEntry **table;<br>    <span class="hljs-comment">//哈希表大小</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> size;<br>    <span class="hljs-comment">//哈希表大小掩码，用于计算索引值</span><br>    <span class="hljs-comment">//总是等于 size-1</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> sizemask;<br>    <span class="hljs-comment">//该哈希表已有节点的数量</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> used;<br> <br>&#125;dictht<br></code></pre></td></tr></table></figure><p>可以看到字典其实是由 <code>dictEntry</code> 组成的数组构成,而 <code>dictEntry</code> 的结构如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span>&#123;</span><br>     <span class="hljs-comment">//键</span><br>     <span class="hljs-type">void</span> *key;<br>     <span class="hljs-comment">//值</span><br>     <span class="hljs-class"><span class="hljs-keyword">union</span>&#123;</span><br>          <span class="hljs-type">void</span> *val;<br>          uint64_tu64;<br>          int64_ts64;<br>     &#125;v;<br> <br>     <span class="hljs-comment">//指向下一个哈希表节点，形成链表</span><br>     <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">dictEntry</span> *<span class="hljs-title">next</span>;</span><br>&#125;dictEntry<br></code></pre></td></tr></table></figure><p>每个 <code>dictEntry</code> 都包含一个 <code>kv</code> 对,还包含一个指向下一个节点的 <code>*next</code> 指针,这说明 redis 在解决哈希冲突的问题上,采取的是 <code>拉链法</code> </p><p>当 <code>dictEntry</code> 节点个数在不停地增加时,哈希碰撞的概率也会加大,最严重的时候会导致字典退化为一个单链表,所以 redis 通过 <code>rehash</code> 操作来扩展字典的大小,将原来集中的 <code>kv</code> 再次分散到不同的 <code>dictEntry</code> 上,减小哈希碰撞的发生</p><p>redis 内部维护了两个全局的 <code>hash table</code> 起作用类似于 <code>AB</code> 表,当发生 <code>rehash</code> 时,就对新 <code>table</code> 做扩容操作,然后把旧 <code>table</code> 的数据全部拷贝过去,再释放旧 <code>table</code> 的空间</p><p>对于少量数据,这个操作可以瞬间完成; 对于大量数据的全量拷贝,势必造成 redis 的阻塞; 所以 redis 引入了 <code>渐进式 rehash</code></p><ol><li>对新 <code>table</code> 进行扩容操作,但是并不立即拷贝旧的数据</li><li>对旧 <code>table</code> 做读取操作时,每次读出的 <code>hash</code> 桶就会拷贝到新 <code>table</code> 上尽行 <code>rehash</code></li></ol><p>这样每次写都是写旧的 <code>table</code>  而读可能新旧 <code>table</code> 都能提供服务; 减少了一次性全量数据拷贝阻塞 redis 的风险</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfn2s4oj30x10jkqa6.jpg" alt="img_8.png"></p><h4 id="整数数组"><a href="#整数数组" class="headerlink" title="整数数组"></a>整数数组</h4><p>数组的结构很简单:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">intset</span> &#123;</span><br>    <span class="hljs-type">uint32_t</span> encoding;<br>    <span class="hljs-type">uint32_t</span> length;<br>    <span class="hljs-type">int8_t</span> contents[];<br>&#125; intset;<br></code></pre></td></tr></table></figure><p>一个记录长度的变量 <code>len</code> 一个记录编码的变量 <code>encoding</code> 一个实际保存变量的整型数组 <code>contents</code> </p><h4 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h4><p>跳表可以说是 redis 最复杂的数据结构了,要好好理解下</p><p>考虑压缩列表或者双端列表的场景,由于这两者都不支持随机访问,如果要查找某个元素的话,只能从头到尾依次遍历</p><p>而作为有序集合,其性质本身保证了有序,对于有序的查找,使用二分查找能加快查找进度</p><p>跳表在原来一层链表的基础上,引入了多层索引结构,每次从最高层最左端开始查找,其查找过程类似于二分查找</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7zqfs56nnj30k60cqq53.jpg" alt="img_5.png"></p><p>在 redis 的实际运用当中,跳表 <code>zskiplist</code> 由指向头部的指针 <code>*header</code>, 指向尾部的指针 <code>*tail</code>, 当前跳表内最高的节点层数(表头节点不算) <code>level</code>, 当前跳表的长度(即节点个数,表头节点不算) <code>length</code></p><p>跳表的结构定义如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* ZSETs use a specialized version of Skiplists */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> &#123;</span><br>    sds ele;  <span class="hljs-comment">// 跳表节点保存的数据,一个 SDS 简单动态字符串</span><br>    <span class="hljs-type">double</span> score;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">backward</span>;</span>  <span class="hljs-comment">// 当前节点的前驱节点</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistLevel</span> &#123;</span>  <span class="hljs-comment">// 当前节点所属的层级</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">forward</span>;</span><br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> span;<br>    &#125; level[];<br>&#125; zskiplistNode;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplist</span> &#123;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">zskiplistNode</span> *<span class="hljs-title">header</span>, *<span class="hljs-title">tail</span>;</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> length;<br>    <span class="hljs-type">int</span> level;<br>&#125; zskiplist;<br></code></pre></td></tr></table></figure><p><code>zskiplist</code> 跳表定义了两个指针,分别指向跳表的头部 <code>*header</code> 和尾部 <code>*tail</code> ,类型是跳表节点 <code>zskiplistNode</code></p><p><code>level[]</code> 表示当前节点在哪些层里面出现,例如上图的节点 <code>o1</code> 就出现在 <code>L1,L2,L3,L4</code> 当中,而节点 <code>o2</code> 自出现在 <code>L1,L2</code> 当中</p><p><code>obj</code> 跳表节点存储的实际数据</p><p><code>*backward</code> 后退指针,当检索跳表节点时,若发现当前节点大于检索值,则需要后退并且进入下一层检索</p><p><code>score</code> 跳表的节点按照分值从小到大有序排列</p><p>对于层 <code>level</code>:</p><p><code>*forward</code> 前进指针用于检索下一个节点</p><p><code>span</code> 跨度,表示当前节点在当前层的下一个节点与当前节点之间有多少步长,例如对于节点 <code>o1</code> 在 <code>L4</code> 的节点来说,其跨度就是 <code>2</code> (走两步到当前层的下一个节点); 所有指向 <code>NULL</code> 的节点跨度为 <code>0</code></p><p>跳表插入节点时,如果数据比较几种,可能会退化成一条单链表; 所以必须在插入时更新节点的层数,redis 通过一个随机函数来决定插入节点在下一层是否应该继续插入,每次进入下一层的概率大概为 <code>1/4</code></p><p>为何 redis 选用跳表而不是红黑树</p><p>因为红黑树在做插入和删除时,涉及到树的旋转,其效率并不如跳表操作指针高; 而且在查询效率上分布均匀的跳表和红黑树几乎没有区别</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十六)mysql 读写分离</title>
    <link href="/2022/11/08/mysql/(%E5%8D%81%E5%85%AD)mysql%20%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"/>
    <url>/2022/11/08/mysql/(%E5%8D%81%E5%85%AD)mysql%20%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/</url>
    
    <content type="html"><![CDATA[<h3 id="一主多从架构下的读写分离"><a href="#一主多从架构下的读写分离" class="headerlink" title="一主多从架构下的读写分离"></a>一主多从架构下的读写分离</h3><p>先回顾下一主多从的结构图</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y196hmklj30j00cttan.jpg" alt="img.png"></p><p>读写分离的主要目的就是为了 <strong>分摊主库上的请求压力</strong> ,上面的架构主要是在 <code>client</code> 客户端主动做负载均衡; 在这种模式下,会把数据库的配置信息放到客户端的连接层,由客户端主动选择处理写请求和读请求的数据库实例</p><p>还有一种就是在客户端和数据库之间新增一个代理网关(正向代理:发送方不知道实际处理方是谁,只知道一个处理方代理),这样客户端就不用区分读写请求,只需要把请求全部发送给代理即可; 具体的读写请求分发到主库还是从库全部由代理判断</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19d7bvhj30hb0dvq4f.jpg" alt="img_1.png"></p><p>无论是那种架构,都存在一个问题: <strong>由于存在主从延迟,客户端刚刚写入一条数据后马上发起查询请求,此时处理读请求的从库很可能还没来得及完成主从同步,导致数据不一致</strong></p><p>读写分离解决数据不一致的方案主要有以下几种:</p><ol><li>强制查主库</li><li><code>sleep</code> 等待</li><li>判断是否存在主从延迟</li><li><code>semi-sync</code></li><li>等待主库位点</li><li>等待主库 <code>GTID</code></li></ol><h4 id="强制查主库"><a href="#强制查主库" class="headerlink" title="强制查主库"></a>强制查主库</h4><p>业务方将请求分为以下两类:</p><ol><li>有强一致性要求的请求,强制把这部分读请求打到主库上,保证数据一致性</li><li>接受一定时间内数据不一致的请求,把这部分读请求打到从库上,由主从同步保证一定时间内的最终一致性即可</li></ol><p>考虑一种极端场景,所有的请求都有强一致性要求; 这样一主多从的读写分离结构就退化为只有一个主库的单节点结构; 失去了读写分离的意义</p><h4 id="sleep-等待"><a href="#sleep-等待" class="headerlink" title="sleep 等待"></a>sleep 等待</h4><p>在主库完成写请求之后,下一个强一致性读请求到达业务方,在发送到从库之前先 <code>sleep(x)</code> 等待一段时间 <code>x</code></p><p>假设当前的主从延迟在 <code>2s</code> 以内,这样 <code>sleep(2)</code> 之后就可以认为从库已经同步了刚刚最新的写请求,此时业务方再把读请求发送到从库上,有很大概率能拿到最新的数据</p><p>这个方案仍然是不可靠的,假如主从延迟并不稳定在固定值之内</p><ol><li>如果主从延迟只有 <code>0.5s</code> 了,此时等待 <code>2s</code> 显然时间过长</li><li>如果主从延迟超过了 <code>2s</code>, 即使有等待的时间,还是会读取到历史脏数据,导致数据不一致的问题</li></ol><h4 id="判断是否存在主从延迟"><a href="#判断是否存在主从延迟" class="headerlink" title="判断是否存在主从延迟"></a>判断是否存在主从延迟</h4><ol><li>通过主从延迟时间判断是否存在主从延迟,每次查询前,先获取 <code>seconds_behind_master</code> 值,判断主从延迟的时间是否等于 0; 如果等于 0 就发起读请求,否则就等待主从延迟的时间变为 0 后才执行查询</li><li>通过位点判断是否存在主从延迟,查询主库上的最新位点和从库上的最新位点,如果两个位点相同,则认为没有主从延迟可以执行查请求;否则就等待直到位点相同后才执行查询</li><li>通过 <code>GTID</code> 判断是否存在主从延迟,查询主库的 <code>GTID</code> 集合与从库的 <code>GTID</code> 集合是否相同; 若相同则执行查询请求;否则就等待直到相同后才执行查询</li></ol><p>每次判断是否存在主从延迟,无论选用那种方式判断,也都还是会发生数据不一致的问题</p><p>考虑如下场景,主库 A 已经写入 2 个事务到 <code>binlog</code> ,并且发送了前两个事务到从库 B 里面,且从库 <code>B</code> 也已经同步完成; 此时主库 A 上一个新事务 3 刚刚写入完成,还没来得及发送</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19iv59mj30bq0a6wfe.jpg" alt="img_2.png"></p><p>此时无论是位点还是 <code>GTID</code> 都会认为没有发生主从延迟,但严格上来说此时的读请求,在从库上仍然是查询不到事务 3 的</p><h4 id="semi-sync-半同步"><a href="#semi-sync-半同步" class="headerlink" title="semi-sync 半同步"></a>semi-sync 半同步</h4><p><code>semi-sync</code> 半同步的设计如下:</p><ol><li>事务提交后,主库把 <code>binlog</code> 发送给从库</li><li>从库收到 <code>binlog</code> 在消费 <code>relay log</code> 并完成从库 <code>binlog</code> 的写入后,会给主库发送一个 <code>ack</code> 表示完成当前事务的同步</li><li>主库收到 <code>ack</code> 之后,才会返回给客户端表示当前事务已经完成</li></ol><p>也就是说 <code>semi-sync</code> 半同步机制保证了所有返回给客户端的事务请求,都是在从库上完成了同步的</p><p>在一主多从结构下,<code>semi-sync</code> 也可能会犯错</p><p>如果一个从库收到同步 <code>binlog</code> 的请求后,完成同步并向主库回复了 <code>ack</code>; 此时主库认为这个事务的同步已经完成,则向客户端回复成功; 假如针对这个事务数据的读请求进来,被代理分配到一个还没有完成同步的从库上,此时又产生了数据不一致的问题</p><p>而且如果是基于位点或者 <code>GTID</code> 的半同步,如果主库压力很大其不停地在推进位点或者 <code>GTID</code> 而从库可能会一直在追赶主库的同步进度</p><p>由于主从延迟加上 <code>semi-sync</code> 半同步机制,对于一个事务来说,从库迟迟不会向主库回复 <code>ack</code> ,从而主库不会向客户端回复成功; 导致整个业务阻塞</p><p>对于一笔刚写入完成的事务,并不需要完全等待从库完成同步后,才回复 <code>ack</code> 可以看一下主从同步之间的中间状态</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19r2wa6j30oe0ixdk3.jpg" alt="img_3.png"></p><p>对于等待位点检测主从延迟的方案来说,上面的请求中,从库和主库的位点一直都不相同; 如果一个查询必须要等待同步完成才能响应的话,上面的步骤将会导致整个查询不可用</p><p>其实当一个事务已经同步写入从库的 <code>binlog</code> 当中并完成刷盘,此时就可以认为这个事务的同步已经完成了; 至于其他事务导致的主从延迟,其实和当前已同步完成的事务无关</p><p>总结,使用 <code>semi-sync</code> 且检测主从延迟的方案,存在两个问题</p><ol><li>一主多从,从某些还未来得及同步主库的从库查询时,可能查到没有更新的历史数据</li><li>如果出从延迟持续存在,从库等延迟结束,主库等从库回复 <code>ack</code> ,这里可能导致长时间的等待</li></ol><h4 id="等待主库位点的操作"><a href="#等待主库位点的操作" class="headerlink" title="等待主库位点的操作"></a>等待主库位点的操作</h4><p>从库上有一条指令,可以用于主动检测与主库之间位点的差异</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> master_pos_wait(file, pos, timeout)<br></code></pre></td></tr></table></figure><ol><li><code>file</code> 指定了检测主库的 <code>binlog</code> 文件, <code>pos</code> 指定了检测事务的位置</li><li><code>timeout</code> 制定这个函数检测时的超时时间</li></ol><p>这条命令的返回值如下:</p><ol><li>正常返回一个正整数 <code>M</code> 表示从命令开始执行,到同步 <code>file</code> 的 <code>pos</code> 位置时,执行了多少个事务</li><li>如果主从同步发生异常,返回 NULL</li><li>如果超时,返回 <code>-1</code></li><li>如果开始执行的时候,就已经超过 <code>pos</code> 位置,返回 0</li></ol><p>对于上面 <code>semi-sync</code> 产生的问题,看看等待主库位点如何解决</p><ol><li>主库事务 <code>trx1</code> 执行完成之后,立马查询当前主库的 <code>binlog</code> 文件 <code>file</code> 和最新的位点 <code>pos</code></li><li>随机选择一个从库进行查询</li><li>从库查询前先执行上述语句,检测主从同步之间的位点差异</li><li>如果返回值 <code>&gt;=0</code> 则表示当前从库对于主库刚刚执行的事务 <code>trx1</code> 已经执行过了,可以由从库返回读请求</li><li>否则说明当前从库还未来得及同步刚刚主库的事务,此时读请求交给主库响应</li></ol><ul><li><p>假设检测主从延迟的等待时长为 <code>1s</code> ,如果这 <code>1s</code> 内,返回了大于 0 的整数 <code>M</code> ,则说明在这 <code>1s</code> 内,从库从某个之前的位置同步到 <code>pos</code> 时,应用了 <code>M</code> 个事务; 虽然等待了一些时间,但是好歹追上了主从延迟,所以从库可以相应对应的读请求</p></li><li><p>如果返回值等于 0,则表示从库当前同步主库的位点已经领先于主库执行事务 <code>trx1</code> 时的位点,此时从库肯定也是完成了事务 <code>trx1</code> 的同步,可以响应读请求</p></li><li><p>如果返回值等于 <code>-1</code> 或者 <code>NULL</code> 则说明在等待时间内从库都没能追上主从延迟,此时记录的肯定是历史数据,必须交给主库响应当前查询请求</p></li></ul><p>图例如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y19xa2l8j30mh0g5n2i.jpg" alt="img_4.png"></p><p>退化到主库查询是一种通用的兜底方案,因为读请求不可能无限等待从库去追赶主从延迟;超时后就必须要由主库响应请求</p><h4 id="等待-GTID-的操作"><a href="#等待-GTID-的操作" class="headerlink" title="等待 GTID 的操作"></a>等待 GTID 的操作</h4><p>同理,从库通过主库发送过来的事务 <code>GTID</code> ,判断自己当前的 <code>GTID</code> 集合是否包含对应事务的 <code>GTID</code> </p><p>同样,超时后结束等待; 或者在等待时事务的 <code>GTID</code> 加入当前集合; 或者在检测时当前集合就已经包含了 <code>GTID</code> </p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十五)mysql 一主多从如何进行主从切换</title>
    <link href="/2022/11/07/mysql/(%E5%8D%81%E4%BA%94)mysql%20%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/"/>
    <url>/2022/11/07/mysql/(%E5%8D%81%E4%BA%94)mysql%20%E4%B8%80%E4%B8%BB%E5%A4%9A%E4%BB%8E%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%B8%BB%E4%BB%8E%E5%88%87%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h3 id="一主多从的结构"><a href="#一主多从的结构" class="headerlink" title="一主多从的结构"></a>一主多从的结构</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7xg26tow1j30il0dxq6q.jpg" alt="img.png"></p><p>其中 A 和 A’ 互为主备关系(即双 M 结构),BCD 三个从库同步主库 A 的数据,只提供读服务</p><p>当发生主从切换的时候,从库 A’ 当选新的主库,此时 BCD 三个库需要重新连接到新的主库 A’ 上</p><h3 id="基于位点的朴素主从切换"><a href="#基于位点的朴素主从切换" class="headerlink" title="基于位点的朴素主从切换"></a>基于位点的朴素主从切换</h3><p>以从库 B 为例,当需要把 B 的主库切换到 A’ 时,需要执行 <code>change master</code> 指令,然后需要指定新主库的 <code>ip,端口,用户名,密码,binlog 日志,以及 binlog 日志位点</code> 这 6 个值</p><p>其中 <code>binlog</code> 日志位点是比较关键的信息,包含了从库 B 应该从新的主库的 <code>binlog</code> 日志的那个位置开始同步</p><p>如果这个位置选早了,会导致重复的事务再次被同步; 如果选晚了,会导致有些事务丢失</p><p>一种同步方式为:</p><ol><li>等待新主库 A’ 完成 <code>relay log</code> 的消费</li><li>通过工具解析原主库的最后一条事务记录,得到发生主从切换时的 <code>binlog</code> 日志和对应的位点</li><li>新主库 A’ 将这个位点发给从库 B 告知从库从这里开始往后解析 <code>binlog</code></li></ol><p>这种统计方式并不准确:</p><p>假如在原来的主库在执行事务 R 之后,已经将 <code>binlog</code> 发送给从库 A’ 和从库 B,在这个 T 时刻发生了主从切换</p><p>此时 A’ 还在继续消费 A 的中转日志,从库 B 已经把刚刚接收到的事务 R 同步到自己的实例当中; 当发生主从切换时,新的主库 A’ 告知从库 B 应当从最新的位点,即原来主库的最后一条事务 R 开始执行; 这样因为从库 B<br>已经执行过事务 R 了,会产生主键重复的错误</p><p>在主从切换遇到主键冲突一般有两种解决方案:</p><ol><li>手动跳过一个事务</li><li>设置跳过指定类型的错误:例如唯一键冲突,或者删除行不存在</li></ol><p>对于第二种方案,在主从切换稳定下来之后需要再次关闭,避免真正产生数据不一致后被跳过</p><h3 id="GTID-全局事务-id"><a href="#GTID-全局事务-id" class="headerlink" title="GTID 全局事务 id"></a>GTID 全局事务 id</h3><p>根据前面事务的介绍,InnoDB 会在每个事务创建的时候,为其分配一个自增的 <code>long</code> 类型的事务 <code>trx_id</code>, 在配合上当前数据库实例的唯一 <code>server_id</code> 就构成了 <code>GTID</code><br>其定义为: <code>GTID=server_id:trx_id</code></p><p>在启动 <code>GTID</code> 之后,每个事务都有一个唯一确定的 <code>GTID</code>,有两种分配方式:</p><ol><li><code>gtid_next=automatic</code> 自增分配</li><li><code>gtid_next=&#39;current_gtid</code> 手动指定一个事务的 <code>GTID</code> 值<ul><li>若这个 <code>current_gtid</code> 已经存在于当前实例的 <code>GTID</code> 集合里面,则当前实例在拿到这条事务后会跳过不执行</li><li>若不存在于当前实例的 <code>GTID</code> 集合,则把这个 <code>GTID</code> 分配给当前即将执行的事务,然后在分配下一个 <code>GTID</code> 给下一个事务</li></ul></li></ol><p>每个实力都维护了一个 <code>GTID</code> 集合,用来记录 <strong>当前实例已经执行过的所有事务</strong></p><p>举个简单的例子:</p><p>假设实例 X 已经插入了数据 <code>(1,1)</code> 且 <code>binlog</code> 里面记录的实例 X 的 <code>insert</code> 语句之前有一条 <code>SET</code> 语句,为这个事务设置了 <code>GTID=xxx</code></p><p>实例 X 是实例 Y 的从库,而且主库 Y 也插入了一条记录 <code>(1,1)</code> 且 <code>binlog</code> 里面 <code>insert</code> 语句之前也有一条 <code>SET</code> 语句,为这个事务设置了 <code>GTID=yyy</code></p><p>若此时主库 Y 将自己的 <code>binlog</code> 发送给从库 X 进行同步,显然从库 X 会发生主键冲突的错误,导致主从同步停止</p><p>根据上面 <code>GTID</code> 分配方式的,第二种,可以手动为从库 X 将产生主键冲突的事务 <code>GTID</code> 加入到实例 X 维护的 <code>GTID</code> 集合里面,来达到跳过这条主键冲突的事务</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> gtid_next<span class="hljs-operator">=</span>yyy;<br><span class="hljs-keyword">begin</span>;<br><span class="hljs-keyword">commit</span>;<br><span class="hljs-keyword">set</span> gtid_next<span class="hljs-operator">=</span>automatic;<br></code></pre></td></tr></table></figure><p>这样通过提交一个 <strong>空事务</strong> 来把产生冲突的 <code>GTID</code> 加入到实例 X 维护的 <code>GTID</code> 集合里面,这样同步实例 Y 的语句时,就会跳过这条事务,也就不会再出现主键冲突; 并且在手动 <code>SET</code> 之后,还将 <code>GTID</code> 更新设置自增,这样 mysql 就可以继续按照原有的序号分配新的 <code>GTID</code> 给新的事务</p><h3 id="基于-GTID-的主从切换"><a href="#基于-GTID-的主从切换" class="headerlink" title="基于 GTID 的主从切换"></a>基于 GTID 的主从切换</h3><p>当启动了 <code>GTID</code> 后,假设新主库 A’ 的 <code>GTID</code> 集合为 <code>set_a</code>, 从库 B 的 <code>GTID</code> 集合为 <code>set_b</code></p><p>此时主从切换的过程如下:</p><ol><li>从库 B 指定新的主库 A’</li><li>从库 B 把自己的 <code>set_b</code> 发送给主库 A’</li><li>主库 A’ 计算出 <code>set_a</code> 和 <code>set_b</code> 之前的差异,找到所有存在于 <code>set_a</code> 但是不存在于 <code>set_b</code> 的集合 <code>set_a&#39;</code> ,并且判断主库 A’ 上面的 <code>binlog</code> 里面是否包含 <code>set_a&#39;</code><ul><li>如果 <code>binlog</code> 包含所有 <code>set_a&#39;</code>,就找到 <code>set_b</code> 第一个不存在的事务,并把这个事务的 <code>GTID</code> 发送给 B</li><li>如果 <code>binlog</code> 不包含,则认为 <code>binlog</code> 数据不完整,直接报错</li></ul></li><li>主库 A 从 <code>set_a&#39;</code> 里面第一个不存在于 <code>set_b</code> 的事务开始,顺序读取 <code>binlog</code> 发送给从库 B 进行主从同步</li></ol><p>这里有个大前提保证: <strong>只要产生主从关系,就必须保证主库发送给从库的 <code>binlog</code> 是完整的,否则会导致主从数据不一致</strong></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十四)mysql 如何保证高可用</title>
    <link href="/2022/11/07/mysql/(%E5%8D%81%E5%9B%9B)mysql%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
    <url>/2022/11/07/mysql/(%E5%8D%81%E5%9B%9B)mysql%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="双-M-结构"><a href="#双-M-结构" class="headerlink" title="双 M 结构"></a>双 M 结构</h3><p>双 M 主从切换是目前比较常用的结构,这种结构使得数据库之间互相进行同步,通过属性 <code>readonly</code> 来决定逻辑上的主库</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbhy4xwmj30g6065jsl.jpg" alt="img.png"></p><h3 id="主从延迟"><a href="#主从延迟" class="headerlink" title="主从延迟"></a>主从延迟</h3><p>mysql 在做主从同步的时候,有几个关键的时间点如下:</p><ol><li>主库执行完成一个事务,写入 <code>binlog</code> 这个时间点记为 <code>T1</code></li><li>主库通过 <code>dump_thread</code> 将 <code>binlog</code> 发送给备库,备库通过 <code>io_thread</code> 将接收到的 <code>binlog</code> 写入中转日志 <code>relay log</code> 这个时间点记为 <code>T2</code></li><li>备库通过 <code>sql_thread</code> 线程消费中转日志 <code>relay log</code> 完成当前事务的时间点记为 <code>T3</code></li></ol><p>那么一个事务从主库到备库的 <strong>主从延迟</strong> 可以通过 <code>T1-T3</code> 得到</p><p><code>binlog</code> 里每个事务有个时间段字段,这是主库执行事务写入 <code>binlog</code> 的时间,备库在做同步的时候取出这个字段和自己的服务器本地时间作对比,计算出主从延迟的具体值即为 <code>T3-T1</code></p><p>如果主从库之间的系统时间不一致,备库每次同步的时候,都会向主库执行 <code>select unix_timesatmp()</code> 来获取主库的系统时间,在计算主从延迟的时候也会把这个时间加入一起计算</p><p>通常来说,在网络正常的情况下, <code>T2-T1</code> 的值非常小; 即主从延迟通常体现在备库太慢上,最主要的原因就是 <strong>备库消费中转日志的速率小于主库生产 binlog 的速率</strong> </p><h3 id="主从延迟的原因"><a href="#主从延迟的原因" class="headerlink" title="主从延迟的原因"></a>主从延迟的原因</h3><h4 id="备库的机器性能比主库差"><a href="#备库的机器性能比主库差" class="headerlink" title="备库的机器性能比主库差"></a>备库的机器性能比主库差</h4><p>相同的 sql 语句可能因为备库的机器性能较差从而导致备库执行的时间长于主库执行的时间,最终引发主从延迟</p><p>现在几乎都是主从的机器配置保持一样,采用对称配置,避免发生主从切换时,备库的性能问题拖垮整个服务</p><h4 id="备库压力过大"><a href="#备库压力过大" class="headerlink" title="备库压力过大"></a>备库压力过大</h4><p>在对称部署之后,仍然有主从延迟,还有个很常见的原因就是,备库有很多离线的计算任务</p><p>通常主库对外提供服务,而备库只读,所以很多时候会把一些分析任务放到备库里面跑,结果反而占用了备库大量的 CPU 资源,最终影响到主从同步,导致主从延迟发生</p><p>解决方案可以分为以下几种:</p><ol><li>一主多从: 使用多个备库一起分担这种需要耗费大量 CPU 资源的离线读任务</li><li>将 <code>binlog</code> 直接输出到外部系统,让外部系统直接提供解析 <code>binlog</code> 的能力</li></ol><h4 id="大事务"><a href="#大事务" class="headerlink" title="大事务"></a>大事务</h4><p>即使配置了一主多从,保证备库的压力不会超过主库,仍然还是可能发生主从延迟</p><p>如果说主库上运行了一个大事务,长达 <code>10min</code> ,那么备库在同步执行这个大事务的时候很有可能会导致主从延迟 <code>10min</code> 以上</p><p>最常见的场景就是一次性使用 <code>delete</code> 语句删除大量数据,这是个典型的大事务; 包括一次性归档大量数据等</p><p>最好是控制单次删除数据的量,分成多批次删除,降低事务的处理时间</p><p>另一种常见的大事务场景就是对一张大表做 <code>DDL</code> 操作</p><h4 id="从库的并行复制能力"><a href="#从库的并行复制能力" class="headerlink" title="从库的并行复制能力"></a>从库的并行复制能力</h4><p>如果一个从库消费中转日志 <code>relay log</code> 的速率小于主库生产 <code>binlog</code> 的速率,很有可能永远都追不上主库,导致长时间的主从延迟,如下图所示</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbi9bictj30ul0jjdnk.jpg" alt="img_4.png"></p><p>在 mysql 5.6 版本之前,从库的 <code>sql_thread</code> 只支持单线程,因此在主库并发高的情况下,会导致严重的主从延迟问题</p><p>5.6 之后引入了多线程模型,用于解决单线程消费中转日志 <code>relay log</code> 过慢的场景</p><p>类似于 <code>Netty</code> 或者 <code>Redis</code> 的网络模型,通常都是将接受网络请求的线程设为 1 个,而处理网络请求的线程设为若干个; 如果直接由若干个处理请求并发消费 <code>relay log</code> 每个线程之间都无法知道哪些日志是被消费过的,哪些日志是没有消费过的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbih0idbj30rs0jaju0.jpg" alt="img_5.png"></p><p>这里面的 <code>worker</code> 数量也不能过大,因为在读写分离场景下,从库还需要提供查询能力,如果仅仅由主从同步就将全部 CPU 资源占用了的话,从库的读取能力将大幅下降</p><p>mysql 在将 <code>relay log</code> 分发给不同的 <code>worker</code> 时需要满足以下两个要求</p><ol><li>不能造成覆盖更新,也就是更新同一行数据的多个事务,必须由一个 <code>worker</code> 顺序执行,否则将会出现其他 <code>worker</code> 的更新丢失或者覆盖当前数据</li><li>同一个事务不能再拆分</li></ol><h4 id="按表分发策略"><a href="#按表分发策略" class="headerlink" title="按表分发策略"></a>按表分发策略</h4><p>如果说一个两个事物分别更新两个不同的表,那么可以认为是这两个事务互不影响,可以由两个 <code>worker</code> 并行执行; 但是如果事务涉及到了跨表操作,还是需要把涉及到的多张表放到一个 <code>worker</code> 执行</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbin3yf4j30dl0edabx.jpg" alt="img_6.png"></p><p>可以看到每个 <code>workder</code> 都维护了一个 hash 表,里面维护的是当前 <code>worker</code> 的队列里面的事务所涉及到的表, <code>key</code> 是表名, <code>value</code> 是有多少个事务涉及到</p><p>当有新的事务被分配给 <code>worker</code> 时,事务里面涉及到的表就会被添加到对应的 hash 表里面, <code>worker</code> 执行完成之后就会把对应的 hash 记录移除掉</p><p>图中 <code>hash_table 1</code> 表示当前 <code>worker</code> 的工作队列里面有 4 个事务涉及到 <code>db1.t1</code> 表; 有 1 个事务涉及到 <code>db1.t2</code> 表</p><p><code>hash_table 2</code> 表示当前 <code>worker</code> 的工作队列里面有 1 个事务涉及到 <code>db1.t3</code> 表</p><p>假设分发者从 <code>relay log</code> 日志里面消费到一个新的事务 T,这个事务的修改涉及到 <code>t1 和 t3</code> 表</p><ol><li>根据第一个要求,这个事务涉及到的两个表 <code>t1 和 t3</code> 需要检查这两张表上是否有其他事务正在执行</li><li><code>t1</code> 表由 <code>worker1</code> 正在执行,检查 <code>t3</code> 发现正在由 <code>worker2</code> 执行,由于涉及到多表的事务只能由 1 个 <code>worker</code> 执行,所以分发者不能将 T 单独分配给 <code>worker1 或者 worker2</code> 只能等待下一次轮训</li><li>假设 <code>worker2</code> 的工作先结束,从 hash 表里面移除了 <code>t3</code> 的相关记录,此时分发者发现这个多表事务只有 <code>worker1</code> 有涉及到到,就把事务 T 分发给 <code>worker1</code></li><li>分发者继续处理中转日志当中的其他事务</li></ol><p>对于分发者来说,他的选择策略如下:</p><ol><li>如果当前事务跟所有 <code>worker</code> 都不冲突,则把它分给最闲的一个 <code>worker</code> 处理, 即 hash 表里面的字段最少的</li><li>如果当前事务跟多个 <code>worker</code> 冲突,则等待下一次轮训,直到有且只有 1 个 <code>workder</code> 冲突时,把事务分给当前 <code>worker</code></li><li>如果当前事务只有 1 个 <code>worker</code> 跟他冲突,则直接分给那个 <code>worker</code></li></ol><p>很明显,对于表请求负载均衡的场景,这个策略可以很好的胜任工作; 但是如果遇到一张热点表,即大量事务的更新都涉及到这一张表,此时就会把所有事务分配给同一个 <code>worker</code> ,这个模型就退化成单线程模型</p><h4 id="按行分发策略"><a href="#按行分发策略" class="headerlink" title="按行分发策略"></a>按行分发策略</h4><p>按行分发策略要求如果两个事务没有更新到相同的行,则他们可以并发执行; 由于要检测事务里面的更新涉及到的具体行信息,显然 <code>binlog</code> 只能设置为 <code>row</code> 模式,因为 <code>statement</code> 模式记录的原始 sql 不会涉及到具体的行</p><p>因此 <code>worker</code> 维护的 hash 表里面,就必须保存数据行的唯一性特征,这里的唯一性特征,不仅仅是主键 id,还要把表里面的唯一性索引全都考虑进去,避免出现唯一性校验不通过的情况</p><p>可以看到按行分发在解析 <code>binlog</code> 时,会耗费更多的 cpu 资源,且要求表必须有主键,不得有外键,因为外键上的级联更新不会记录到 <code>binlog</code> 里面,会导致冲突检测不准确,还要求 <code>binlog</code> 格式必须是 <code>row</code></p><h4 id="按库分发策略"><a href="#按库分发策略" class="headerlink" title="按库分发策略"></a>按库分发策略</h4><p>实际上,mysql 既没有采用按行分发,也没有采用按表分发,而是 <strong>按库分发</strong></p><ul><li><p>这样在构造 hash 表的时候就会非常快,而且占用的资源少,因为一个 db 实例上的库毕竟不会太多</p></li><li><p>对于 <code>binlog</code> 的格式也没有具体要求</p></li></ul><h3 id="由于主从延迟-主从切换时应当选择什么样的策略"><a href="#由于主从延迟-主从切换时应当选择什么样的策略" class="headerlink" title="由于主从延迟,主从切换时应当选择什么样的策略"></a>由于主从延迟,主从切换时应当选择什么样的策略</h3><h4 id="可靠性优先策略"><a href="#可靠性优先策略" class="headerlink" title="可靠性优先策略"></a>可靠性优先策略</h4><p>双 M 部署的结构,具体的主从切换过程如下</p><ol><li>从库判断当前与主库的主从延迟时间,如果超过某个值,则不进行出从切换,循环执行当前步骤直到小于某个可以接受的时间值</li><li>将主库改为只读状态 <code>readonly=true</code></li><li>由于停止了对主库的写入操作,此时主从同步会慢慢地赶上进度,直到完全同步,即主从延迟时间等于 0</li><li>将从库的状态改为读写 <code>readonly=false</code>,将请求切换到从库上,完成主从切换</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbivgw6dj30nr079wgm.jpg" alt="img_1.png"></p><p>可以看到在 <strong>可靠性优先策略</strong> 的前提下,会有一个不可用的阶段,其长度等于设定的某个可以接受的主从延迟时间值</p><h4 id="可用性优先策略"><a href="#可用性优先策略" class="headerlink" title="可用性优先策略"></a>可用性优先策略</h4><p>如果非要把这个不可用时间降低到 0,那只能把第 4 步提前执行; 也就是不等待主从完成同步,直接让从库状态变为读写,然后把请求切到从库</p><p>这虽然避免了不可用的情况发生,但是会出现比较严重的数据不一致问题</p><p>假如表 <code>t (id, c)</code> 有两个字段,且主从库里面同时记录了 3 条数据 <code>(1,1)(2,2)(3,3)</code></p><p>此时业务正在往主库里面写入两条数据分别是 <code>insert c=4, insert c=5</code></p><p>如果此时已经有 <code>5s</code> 的主从延迟,当业务对主库写入 <code>c=4</code> 之后,发生主从切换,根据可用性优先策略,此时请求会立马切换到从库,即 <code>c=5</code> 的数据是向从库写入的</p><p>如果此时的 <code>binlog_format=STATEMENT</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbj1adzyj30og0j6q8r.jpg" alt="img_2.png"></p><p>根据主键自增的特性,在 <code>c=4</code> 写入主库时,插入的主键 <code>id=4</code> 实际写入数据 <code>(4,4)</code>, 而发生主从切换之后 <code>c=5</code> 写入从库时,插入的主键 <code>id=4</code> 也等于 4,实际写入的数据是 <code>(4,5)</code> </p><p><code>STATEMENT</code> 格式的 <code>binlog</code> 记录了原始 sql 语句,即 <code>insert id=4</code></p><p>那么在做出从同步时,新的主库接收到 <code>insert id=4</code> 由于主键 id 自增的特性,实际写入的数据是 <code>(5,4)</code></p><p>而新的从库接收到 <code>insert id=5</code> 由于主键 id 自增的特性,实际写入的数据是 <code>(5,5)</code> </p><p>可以看到,在 <code>id=4</code> 这条数据上,主从切换后产生了数据不一致</p><p>如果说将 <code>binlog</code> 格式改为 <code>ROW</code> 呢,由于 <code>ROW</code> 格式的 <code>binlog</code> 会记录插入行的所有字段值,那么在最后的同步过程当中,会报错 <strong>主键重复</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7wbj6jomqj30gg08vmzj.jpg" alt="img_3.png"></p><p>因为新主库发送的 sql 里面,包含了主键信息,可以理解为 <code>insert (id,c) value (4,5)</code></p><p>新从库发送的 sql 也包含了主键信息,可以理解为 <code>insert (id,c) value (4,4)</code></p><p>这样两个库都会因为重复的主键 <code>id=4</code> 而报错</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><code>row</code> 格式的 <code>binlog</code> 在做主从切换的时候,如果有数据不一致的问题很快就能通过报错发现</p><p>而 <code>statement</code> 格式的 <code>binlog</code> 在上述情况下是可以完成主从切换的,数据不一致的问题悄悄地发生了,严重的话可能要很久之后才会发现</p><p>所以 <code>binlog</code> 配置大多数时候还是以 <code>row</code> 格式为主</p><p>而且大多数时候数据的可靠性是优先于服务的可用性的,除非有特殊场景基本上都使用 <strong>可靠性优先策略</strong></p><h3 id="mysql-如何检测一个库是否可用"><a href="#mysql-如何检测一个库是否可用" class="headerlink" title="mysql 如何检测一个库是否可用"></a>mysql 如何检测一个库是否可用</h3><h4 id="select-1"><a href="#select-1" class="headerlink" title="select 1"></a>select 1</h4><p>如何判断一个库是否可用,最容易想到的办法就是 <code>select 1</code> 这样类似的心跳包</p><p>如果通过参数设置 mysql 的 <code>并发查询</code> 数最大只能为 3,那么下面的 <code>select 1</code> 语句将失去作用</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7y2ezbvi8j30mg075wf8.jpg" alt="img_4.png"></p><p>可以看到会话 ABC 分别开启了查询的事务,但是没有提交结束事务; 此时会话 D 的心跳语句 <code>select 1</code> 是可以正常返回的,因为 <code>select 1</code> 不是一条查询语句,mysql 直接返回 1 就结束了; 而真正的查询语句会被阻塞掉</p><p>此时通过 <code>select 1</code> 判断主库是否可用的手段就失效了, <code>select 1</code> 只能检测进程是否存在,对于主库是否健康起不到检测作用</p><h4 id="select-查表语句"><a href="#select-查表语句" class="headerlink" title="select 查表语句"></a>select 查表语句</h4><p>如果执行一条真正的查表语句呢? 通常在数据库里面多放一张检测心跳的表,里面就一行记录; 这样心跳包就通过对这条记录反复执行 <code>select</code> 操作,即可检测数据库实例是否健康</p><p>考虑如下场景,所有的更新操作都会写 <code>redo log</code> 和 <code>binlog</code> 那如果磁盘被日志文件写满了,此时所有的更新操作都会被阻塞; 但查询语句不需要写盘,查询仍然是可用的</p><p>所以通过普通的 <code>select</code> 语句也不能真正检测出一个数据库是否可用</p><h4 id="update-更新语句"><a href="#update-更新语句" class="headerlink" title="update 更新语句"></a>update 更新语句</h4><p>如果执行一条更新语句呢? 在心跳检测表放一条数据,每次心跳检测都去更新这条记录,通常以写入时间戳 <code>timestamp</code> 来达到更新的操作</p><p>由于一主多从结构下,主库通常有一个双 <code>M</code> 结构的从库与之进行互相同步; 写入主库 A 的 <code>binlog</code> 会发送给从库 <code>A&#39;</code>, 而写入从库 <code>A&#39;</code> 的 <code>binlog</code> 也会发送给主库 <code>A&#39;</code> 如果只有一行记录的话,很有可能产生行冲突</p><p>由此可见,需要更新多行记录</p><p>在心跳检测表里面插入两行记录,分别以主库和从库的 <code>server_id</code> 作为主键; 由于主从关系 mysql 保证了其 <code>server_id</code> 一定不一样; 这样各自写自己的主键 id 即可避免主键冲突</p><p>多行更新仍然存在一个问题,就是判定主库不可用的时间可能会很慢</p><p>正常来说当一个主库正在经历非常大压力是,其 CPU 资源几乎被大量复杂业务查询占用完; 而心跳检测只需要一条简简单单的 <code>update</code> 语句,其占用的 CPU 资源是非常少的</p><p>如果心跳检测在得到一个 CPU 时间片后立马就执行成功了,此时外部仍然是认为主库可用的; 然而实际上此时主库正在经历前所未有的压力呢</p><h4 id="mysql-内部的检测方法"><a href="#mysql-内部的检测方法" class="headerlink" title="mysql 内部的检测方法"></a>mysql 内部的检测方法</h4><p>上面几种都是通过外部系统去检测 mysql 是否可用,而引入外部系统必将导致系统的复杂度和不可靠度</p><p>mysql 提供了内置的用于检测数据库是否可用的能力: <code>performance_schema</code> 性能检测表</p><p>这张表里面记录了 IO 操作的平均耗时,最大耗时,最小耗时等等性能指标; 这样可以通过外部系统去定时采集这张表的指标数据,来检测是否可用; 避免了通过外部手段检测带来的不确定性</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十三)mysql 主备同步</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%B8%89)mysql%20%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%B8%89)mysql%20%E4%B8%BB%E5%A4%87%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h3 id="mysql-主备同步的过程"><a href="#mysql-主备同步的过程" class="headerlink" title="mysql 主备同步的过程"></a>mysql 主备同步的过程</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vlun7uysj30rm0h5dlk.jpg" alt="img.png"></p><p>对于主节点 A 来说,记录一个事务的过程依然符合两阶段提交,只不过多了一个 <code>dump_thread</code> 线程将 <code>binlog</code> 定时同步给从库 B</p><p>从库 B 通过 <code>io_thread</code> 与主库维持一个长连接接收从主库发过来的 <code>binlog</code>, 然后有多个 <code>sql_thread</code> 线程同步 <code>binlog</code> 里面的内容到数据库当中 </p><h3 id="binlog-的存储格式"><a href="#binlog-的存储格式" class="headerlink" title="binlog 的存储格式"></a>binlog 的存储格式</h3><ol><li>statement</li><li>row</li><li>mixed</li></ol><h4 id="statement"><a href="#statement" class="headerlink" title="statement"></a>statement</h4><p><code>statement</code> 模式会如实的记录每一条执行的 sql,例如</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vlutt4h1j314q05vjxi.jpg" alt="img_1.png"></p><p>注意一个问题,使用 <code>statement</code> 格式的时候,如果 <code>delte</code> 语句带有 <code>limit</code> 的话,很可能会导致主备不一致</p><p>因为 <code>delete</code> 后面如果有多个 <code>where</code> 条件,在主库和从库上分别执行这条 sql 语句是,很有可能两个库选择的索引不一致</p><p>这是因为 <code>statement</code> 记录的是原始 sql,当主库执行时,走索引 <code>a</code>,当从库执行时走索引 <code>t_modified</code>, 这是完全可能发生的情况</p><h4 id="row"><a href="#row" class="headerlink" title="row"></a>row</h4><p><code>row</code> 模式不会记录原始 sql 语句,而是记录每条 sql 语句实际操作的行</p><p><strong>这里因为我的 Mac 是 M1 arm64 架构的,而 docker 支持 arm64 架构的 image 都不带 mysqlbinlog 工具,唯一支持 mysqlbinlog 工具的镜像是 mysql-debian,然而 mysql-debian 仅支持 amd64 架构</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vluz1purj30sg09sn5a.jpg" alt="img_2.png"></p><p>实际上可以看到最终执行的语句里面其实是删除 <code>id=4</code> 的记录</p><h3 id="循环复制"><a href="#循环复制" class="headerlink" title="循环复制"></a>循环复制</h3><p>如果说主从之间互为主备关系,即 <code>binlog</code> 文件会互相发给对方用于同步</p><p>对于同一行更新语句生成的 <code>binlog</code> 记录,如何解决循环复制的问题</p><ol><li>规定两个库的 <code>server id</code> 必须不同</li><li>从库收到日志后,重放过程记录 <code>binlog</code> 时生成与原 <code>server id</code> 相同的日志</li><li>收到从库发过来的日志后,判断日志里面记录的 <code>server id</code> 是否是自己的; 如果是自己生成的则丢弃日志;否则进行同步</li></ol>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十二)mysql 日志写入时机</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%BA%8C)mysql%20%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E6%97%B6%E6%9C%BA/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%BA%8C)mysql%20%E6%97%A5%E5%BF%97%E5%86%99%E5%85%A5%E6%97%B6%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>mysql 操作日志的步骤当中,几乎都有为日志文件添加对应的缓存,由此可见 mysql 最大程度上在利用缓存来平衡内存和磁盘间写入速率的差距</p><p>同样的 <code>binlog</code> 也有自己的 <code>binlog buffer</code>, mysql 为每个事务都分配了对应的 <code>binlog buffer</code> 当事务执行时,都是先写入 <code>binlog buffer</code>, 当事务提交的时候才把 <code>binlog buffer</code> 写入 <code>binlog</code></p><p>根据以前的知识,这里写入的 <code>binlog file</code> 其实也还没有真正写入磁盘</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5h2r8mj30ca0a4tau.jpg" alt="img.png"></p><p>与这张图类似,都是将用户态的 <code>buffer</code> 写入 <code>os buffer</code> 然后调用 <code>fsync()</code> 刷入磁盘</p><p>同样的,有三种写入机制</p><ol><li>延时写,事务提交后,只写入 <code>os buffer</code>,不调用 <code>fsync()</code> 数据可靠性最低</li><li>实时写,实时刷,事务提交后,写入 <code>os buffer</code>,立即调用 <code>fsync()</code> 数据可靠性最高</li><li>实时写,延时刷,事务提交后,写入 <code>os buffer</code> ,积攒 <code>N</code> 个事务后一次性刷盘, 可能会丢失 <code>N</code> 个事务的记录</li></ol><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>同样的, <code>redo log</code> 也由两个部分组成 <code>redo log buffer</code> 和 <code>redo log file</code>,与 <code>binlog</code> 差不多,每次都是先写入 <code>buffer</code> 然后写入 <code>os buffer</code> 再调用 <code>fsync()</code> 刷盘</p><p><code>redo log</code> 也有三种写入机制:</p><ol><li>延时写,只写入 <code>redo log buffer</code>,由后台进程每秒写入 <code>os buffer</code> 然后再刷盘,可能丢失 1s 以内的数据</li><li>实时写,实时刷,每次写入 <code>redo log buffer</code> 后立即写入 <code>os buffer</code> 并且刷盘,数据可靠性最高</li><li>实时写,延时刷,每次写入 <code>redo log buffer</code> 后立即写入 <code>os buffer</code> 但是并不立即刷盘,由后台进程每 1s 进行刷盘操作,可能丢失 1s 以内的数据</li></ol><p>根据 <strong>两阶段提交</strong> 的原则,实际上在事务提交的过程中,需要先将 <code>redo log</code> 写为 <code>prepare</code> 状态,再写 <code>binlog</code> 最后将 <code>redo log</code> 写为 <code>commit</code> 状态</p><p>所以在实际的写盘时,在 <code>prepare</code> 阶段就要进行一次持久化操作</p><p>mysql 数据最可靠的配置,就是 <code>binlog</code> 每次提交事物前刷盘, <code>redo log</code> 的 <code>prepare</code> 也刷盘</p><h3 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h3><p>由于 mysql 最可靠的刷盘配置会在一次事务过程当中进行两次刷盘,为了尽可能提高写磁盘的性能,会将多次写盘操作合并为一次进行组提交</p><p><code>LSN</code> 日志逻辑序号,例如 3 个并发事务都提交了 <code>prepare</code> 的日志,需要完成刷盘操作,根据先后顺序分别是 <code>LSN=50</code> 的事务 1, <code>LSN=120</code> 的事务 2, <code>LSN=160</code> 的事务 3</p><p>当 InnoDB 刷新 <code>redo log</code> 的后台进程开始刷盘时,发现需要刷入的日志尾序号是 <code>LSN=160</code>, 头部是 <code>LSN=50</code> 那么这一次刷盘就会把三个事务的请求合并一起刷入磁盘,尽可能的减少了刷盘的次数</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vjetd1mdj30gq0bfdho.jpg" alt="img.png"></p><p>mysql 为了尽可能的提高一次刷盘的组大小,采用最简单的办法 <code>拖时间</code>, 只要尽可能的晚调用 <code>fsync()</code> 那么一次刷盘的组成员就会越大,所以在事务的两阶段提交过程,也采取了对应的优化措施</p><p>两阶段提交: 存储引擎更新 <code>buffer pool</code> 里面的数据,写入 <code>redo log</code> 为 <code>prepare</code> 状态, 返回 <code>Server</code> 将记录写入 <code>binlog</code> 后提交事务, 存储引擎写入 <code>redo log</code> 为 <code>commit</code></p><p>为了尽可能的利用组提交,mysql 实际上将 <code>binlog</code> 写入 <code>os buffer</code> 这一步提前,放到 <code>热到 log</code> 刷入 <code>prepare</code> 之后</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vjf05oe6j30g50i9wiv.jpg" alt="img_1.png"></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十一)mysql 幻读和 next-key lock</title>
    <link href="/2022/11/06/mysql/(%E5%8D%81%E4%B8%80)mysql%20%E5%B9%BB%E8%AF%BB%E5%92%8C%20next-key%20lock/"/>
    <url>/2022/11/06/mysql/(%E5%8D%81%E4%B8%80)mysql%20%E5%B9%BB%E8%AF%BB%E5%92%8C%20next-key%20lock/</url>
    
    <content type="html"><![CDATA[<h2 id="什么是幻读"><a href="#什么是幻读" class="headerlink" title="什么是幻读"></a>什么是幻读</h2><p>幻读的定义: 事务在执行过程前后两次查询同一个范围内的数据时,后一次读到了前一次没有读到的结果</p><p>在可重复读级别下,普通的查询时 <strong>快照读</strong> 是不会观测到其他事务在其中插入的数据的,因此 <strong>幻读</strong> 仅发生在 <strong>当前读</strong> 的操作下</p><h3 id="幻读带了什么问题"><a href="#幻读带了什么问题" class="headerlink" title="幻读带了什么问题"></a>幻读带了什么问题</h3><p>假设有如下三个会话,并且没有针对幻读采取任何措施</p><p>且表里面只有 2 条记录 <code>id = 5, d = 5</code>, <code>id = 0, d = 0</code>, 执行顺序如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vflq7ab8j30rz0f1grs.jpg" alt="img.png"></p><p>从语义上来说,会话 A 开启了 <strong>当前读</strong> ,所以三次 <code>select</code> 查询得到不同的结果,在这个场景下看起来是符合语义的,当前读就是能看到其他未提交会话的更新操作</p><p>如果会话 A 在 T1 时刻查询后执行了一次 <code>update</code> 操作 <code>update t set d = 100 where d = 5</code></p><p>由于会话 B 和 C 都是执行一条 sql 语句,会在执行完成后立马提交事务,而会话 A 因为是通过 <code>begin</code> 开启的事务,所以必须在显式声明 <code>commit</code> 后才会提交事务,那么 <code>binlog</code> 的记录会是什么样的呢</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 会话 B</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id <span class="hljs-operator">=</span> <span class="hljs-number">0</span>    <span class="hljs-comment">-- (0,0,5)</span><br><br><span class="hljs-comment">-- 会话 C</span><br>inserst <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>)       <span class="hljs-comment">-- (1,1,5)</span><br><br><span class="hljs-comment">-- 会话 A</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span>   <span class="hljs-comment">-- (5,5,100) (0,0,100) (1,1,100)</span><br></code></pre></td></tr></table></figure><p>如果使用这份 <code>binlog</code> 去做主备同步或者备份数据库的话,会导致 <code>id = 0 和 id = 1</code> 的数据发生不一致的现象</p><p>很明显,会话 A 的 <strong>当前读</strong> 语义上是要对所有 <code>d = 5</code> 的数据加上锁,但是后来发现会话 B 将原来 <code>d != 5 的 id = 0</code> 的记录给更新为 <code>d = 5</code>,而且会话 C 更是插入了一条 <code>id = 1 且 d = 5</code> 的数据,这根原来会话 A 给 <code>d = 5</code> 加锁的语义发生了冲突</p><p>显然会话 A 并没有为所有 <code>d = 5</code> 的记录加上行锁,仅仅是锁住了 <code>id = 5, d = 5</code> 这一行数据; 如果进一步假设锁的范围变得更加严格,让所有被扫描过的 <code>d = 5</code> 的记录加上行锁</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vflvnhywj30lb0990vu.jpg" alt="img_1.png"></p><p>但是对于会话 C 呢,由于 <code>id = 1</code> 的记录之前并不存在所以自然而言也没有对 <code>id = </code> 的记录加锁,所以会话 C 仍然能够执行,此时 <code>binlog</code> 日志记录如下:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 会话 B 被阻塞,</span><br><span class="hljs-comment">-- update t set d = 5 where id = 0    -- (0,0,5)</span><br><br><span class="hljs-comment">-- 会话 C 因为 id = 0 的记录不存在,自然也没有锁,能够正常插入</span><br>inserst <span class="hljs-keyword">into</span> t <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>)       <span class="hljs-comment">-- (1,1,5)</span><br><br><span class="hljs-comment">-- 会话 A</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">100</span> <span class="hljs-keyword">where</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span>   <span class="hljs-comment">-- (5,5,100) (0,0,0) (1,1,100)</span><br><br><span class="hljs-comment">-- 会话 B 在会话 A 提交后才能得以更新</span><br><span class="hljs-keyword">update</span> t <span class="hljs-keyword">set</span> d <span class="hljs-operator">=</span> <span class="hljs-number">5</span> <span class="hljs-keyword">where</span> id <span class="hljs-operator">=</span> <span class="hljs-number">0</span>    <span class="hljs-comment">-- (0,0,5)</span><br></code></pre></td></tr></table></figure><p>显然,会话 B 的问题解决了,但是会话 C 的问题还没有解决</p><p>可以看到给单独的行加上行锁,或者给扫描过行加上行锁,在 <strong>当前读</strong> 的场景下都无法解决幻读的问题</p><h3 id="如何解决幻读"><a href="#如何解决幻读" class="headerlink" title="如何解决幻读"></a>如何解决幻读</h3><p>InnoDB 引入 <code>间隙锁</code> 的概念来解决行锁,先说下 <code>间隙</code> 是什么</p><p>对于上面的表,只有两条记录的时候 <code>id = 0, d = 0</code> 和 <code>id = 5, d = 5</code>, 此时把主键 id 放到一条数轴上,有如下表示:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfm2gsxnj30fa03cjrd.jpg" alt="img_2.png"></p><p>InnoDB 规定 <code>间隙</code> 的区间端点为 <code>左开右闭</code> ,对于正无穷为了让右区间为闭区间,InnoDB 约定了一个固定的最大值</p><p>对于 <code>间隙</code> 上面的加锁,就叫做 <code>间隙锁</code></p><p>在有了 <code>间隙锁</code> 之后,会话 A ,就会为数据两边的 <code>间隙</code> 都加上 <code>间隙锁</code>,如下图所示</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfm95entj30om08awfj.jpg" alt="img_3.png"></p><p>可以看到当会话 A 查询 <code>id = 3</code> 的记录时 <code>for update</code> 不仅仅为当前记录加锁,还把周围的间隙也加上了锁; 这样会话 B 在这个间隙里插入记录的时候会被阻塞掉</p><h3 id="间隙锁和死锁问题"><a href="#间隙锁和死锁问题" class="headerlink" title="间隙锁和死锁问题"></a>间隙锁和死锁问题</h3><p>考虑如下场景</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vfme14t9j30rl0ah76b.jpg" alt="img_4.png"></p><p>对于会话 A,锁住的间隙是 <code>(5,max]</code>, 对于会话 B,锁住的间隙也是 <code>(5,max]</code>,可以看到同一个间隙锁可以被多个会话同时加锁,它们之间并不互斥,与间隙锁发生互斥的条件仅仅是 <strong>往间隙当中插入新数据</strong> </p><p>紧接着会话 B 插入数据,由于会话 A 持有了间隙锁,所以会话 B 被阻塞</p><p>同理会话 A 插入数据时也因为间隙锁导致阻塞,这里 mysql 的主动死锁检测立马就会返回报错</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>InnoDB 如何解决幻读问题</p><ul><li>对于快照读, <code>MVCC</code> 可以保证幻读不会产生</li><li>对于当前读, <code>间隙锁</code> 保证幻读不会产生</li></ul><h3 id="next-key-lock-加锁机制"><a href="#next-key-lock-加锁机制" class="headerlink" title="next-key lock 加锁机制"></a>next-key lock 加锁机制</h3><p>对于行锁和间隙锁,结合起来称为 <code>next-key lock</code></p><p>对于 <code>next-key lock</code> 的加锁规则,遵循一下 5 个原则</p><ol><li>加锁的基本单位是 <code>next-key lock</code>,符合 <strong>前开后闭</strong> 原则</li><li>在查询过程当中只对访问到的记录加锁,没有访问的记录不会加锁</li><li>等值查询下,如果是唯一索引加锁, <code>next-key lock</code> 退化为 <code>行锁</code></li><li>等值查询下,向右遍历到第一个不满足条件的记录时, <code>next-key lock</code> 退化为 <code>间隙锁</code></li><li>唯一索引上的范围查询会遍历到第一个不满足条件的记录为止</li></ol><p>假设表有 <code>id,c,d</code> 三个记录,主键 <code>id</code> 和 普通索引 <code>c</code></p><p>并且有记录 <code>(0,0,0)(5,5,5)(10,10,10)(15,15,15)(20,20,20)(25,25,25)</code></p><h4 id="1-唯一索引的等值查询"><a href="#1-唯一索引的等值查询" class="headerlink" title="1. 唯一索引的等值查询"></a>1. 唯一索引的等值查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh481j86j30p008gdgu.jpg" alt="img.png"></p><ol><li>会话 A 的对 <code>(5,10]</code> 加上 <code>next-key lock</code></li><li><code>id=7</code> 是一个等值查询,且主键 <code>id</code> 是一个唯一索引,所以 <code>next-key lock</code> 退化为 <code>行锁</code>,由于不存在 <code>id=7</code> 的记录,所以往右查找到第一个不满足条件的位置 <code>id=10</code> 退化为 <code>间隙锁</code> ,即 <code>(5,10)</code> </li><li>最终的加锁范围 <code>(5,10)</code></li></ol><p>由此可见会话 B 插入 <code>id=8</code> 会被阻塞,会话 C 更新 <code>id=10</code> 可以成功</p><h4 id="2-非唯一索引的等值查询"><a href="#2-非唯一索引的等值查询" class="headerlink" title="2. 非唯一索引的等值查询"></a>2. 非唯一索引的等值查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4fk7w1j30ou099wfo.jpg" alt="img_1.png"></p><ol><li>会话 A 对 <code>(0,5]</code> 加上 <code>next-key lock</code></li><li><code>c=5</code> 是一个等值查询,且 <code>c=5</code> 是非唯一索引,向右查找到第一个不满足条件的记录 <code>(10,10,10)</code> 这个查找过程中都会加上间隙锁 <code>(5,10]</code> ,而且 <code>c=10</code> 的记录会退化为 <code>间隙锁</code> ,即 <code>(5,10)</code></li><li>最终的加锁范围 <code>(0,10)</code></li></ol><p>为什么 B 更新 <code>id=5</code> 的记录能够成功,不是已经有 <code>(0,10)</code> 的间隙锁吗</p><p>需要注意的是,根据第 2 条原则,只对访问过的记录才加锁; 由于绘画 A 的 sql 是 <code>select id xxx</code> 可以看到通过索引 <code>c</code> 是覆盖索引的,此时不需要回表查询主键索引</p><p>相当于会话 A 的查找记录只使用索引 <code>c</code> 而没有用到主键索引,所以会话 A 的加锁仅仅在索引 <code>c</code> 上生效,而会话 B 通过主键 id 更新时,是没有 <code>next-key lock</code> 存在的,所以会话 B 能够成功执行</p><p>同理,会话 C 因为插入 <code>c=7</code> 的记录,会被会话 A 创建的 <code>next-key lock</code> 锁住,所以会话 C 被阻塞</p><p>这个例子说明两点:</p><ul><li><code>lock in share mode</code> 只会锁定覆盖索引,而 <code>lock for update</code> 会把涉及到的主键索引一起加锁</li><li>如果要避免 <code>lock in share mode</code> 加读锁但是数据被更新的话,就必须绕开覆盖索引,重新回表让主键索引一起加锁</li></ul><h4 id="3-主键索引的范围查询"><a href="#3-主键索引的范围查询" class="headerlink" title="3. 主键索引的范围查询"></a>3. 主键索引的范围查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4letudj30ou0ebq4k.jpg" alt="img_2.png"></p><ol><li>会话 A 对 <code>(5,10]</code> 加上 <code>next-key lock</code> ,由于 <code>id=10</code> 是等值查询, 且是唯一索引,所以退化成 <code>行锁</code> ,即 <code>[10,10]</code> 这一行</li><li>会话 A 对 <code>(10,15]</code> 加上 <code>next-key lock</code> ,由于 <code>id&lt;11</code> 是范围查询,所以会遍历到第一个不满足条件的记录位置,即 <code>(15,15,15)</code> ,此时 <code>next-key lock</code> 为 <code>(10,15]</code> </li><li>最终的加锁范围 <code>[10,15]</code></li></ol><p>会话 B 插入 <code>id=8</code> 的记录不在 <code>next-key lock</code> 当中,操作成功,更新 <code>id=13</code> 的记录被锁住,失败阻塞</p><p>会话 C 更新 <code>id=15</code> 的记录被锁住,失败阻塞</p><h4 id="4-非唯一索引的范围查询"><a href="#4-非唯一索引的范围查询" class="headerlink" title="4. 非唯一索引的范围查询"></a>4. 非唯一索引的范围查询</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7vh4rrlerj30ou0b2mya.jpg" alt="img_3.png"></p><ol><li><code>c&gt;=10</code> 是范围查询, 会话 A 对 <code>(5,10]</code> 加上 <code>next-key lock</code>, 因为 <code>c</code> 是非唯一索引,不会退化为 <code>间隙锁</code></li><li><code>c&lt;11</code> 也是范围查询,会话 A 对 <code>(10,15]</code> 加上 <code>next-key lock</code>, 同样因为 <code>c</code> 是非唯一索引,不会退化为 <code>间隙锁</code></li><li>最终的加锁范围 <code>(5,10]∪(10,15] = (5,15]</code></li></ol><p>会话 B 插入 <code>c=8</code> 的记录被锁住,失败阻塞</p><p>会话 C 更新 <code>c=15</code> 的记录被锁住,失败阻塞</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(十)mysql 索引失效的场景</title>
    <link href="/2022/11/05/mysql/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/"/>
    <url>/2022/11/05/mysql/(%E5%8D%81)mysql%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E7%9A%84%E5%9C%BA%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-当中索引失效的场景"><a href="#mysql-当中索引失效的场景" class="headerlink" title="mysql 当中索引失效的场景"></a>mysql 当中索引失效的场景</h2><h3 id="索引字段使用函数"><a href="#索引字段使用函数" class="headerlink" title="索引字段使用函数"></a>索引字段使用函数</h3><p>思考下 mysql 为何能够通过索引快速定位数据,是因为 <code>B+</code> 同层节点的有序性</p><p>如果说某些操作打破了这种有序性,那么就无法利用索引树来检索数据了,只能走全表扫描</p><p>例如 <code>select a from t where sum(a) &gt; 5</code> 这种对索引列做函数操作的,很有可能破坏索引的有序性</p><p>其实并不是说 mysql 对于这种函数操作完全放弃了索引,即使走全表扫描,仍然可以优化具体使用什么索引树来做全盘扫描</p><p>如果字段 <code>a</code> 上建立了索引,那么扫描索引 <code>a</code> 显然比扫描主键索引更快,这是因为 <code>索引覆盖</code> 带来的优化,不用取出整行数据,索引 <code>a</code> 已经包含了列 <code>a</code> 所需要的所有数据</p><p>同样的,还有更加隐蔽的操作也会导致索引失效</p><p>例如 <code>select * from t where id + 1 = 10000</code> 这里 <code>+1</code> 不会破坏有效性,但是仍然无法通过 id 定位到 <code>9999</code> 这一行 因为 mysql 无法计算 <code>多少 id +1 才能等于 10000</code><br>,还是需要全表扫描</p><p>如果改为 <code>where id = 10000 -1</code> 那么即可快速通过索引定位到 <code>9999</code> 行</p><h3 id="隐式类型转换会导致索引失效"><a href="#隐式类型转换会导致索引失效" class="headerlink" title="隐式类型转换会导致索引失效"></a>隐式类型转换会导致索引失效</h3><p>假如存在一个 <code>varchar()</code> 类型的列 <code>order_id</code> 上建有索引, 以下 sql 会让索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> order_id <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>注意到 <code>order_id</code> 本身是 <code>varchar()</code> 类型,但是 sql 语句里面却是用 <code>int</code> 整型变量在做比较,这会导致发生 <strong>隐形类型转换</strong> 从而导致索引失效</p><p><strong>mysql 将数字和字符串作为比较的话,会把字符串转换为数字</strong></p><p>为何隐式类型转换会导致索引失效</p><p>在了解到字符串如果和数字作对比,会把字符串转换为数字之后,上面 sql 的本质就发生了改变</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> orders <span class="hljs-keyword">where</span> <span class="hljs-built_in">CAST</span>(order_id <span class="hljs-keyword">AS</span> <span class="hljs-type">int</span>) <span class="hljs-operator">=</span> <span class="hljs-number">12345</span><br></code></pre></td></tr></table></figure><p>可以看到这里的隐式类型转换实际上是对字符串调用了 <code>CAST()</code> 函数,而之前说过,如果在索引列上有函数操作的话,可能会破坏索引树的有序性,从而 mysql 不使用索引改用全表扫描</p><p>同样的,如果在做关联查询的时候,两个连接的字段的字符编码不相同,也会触发隐式类型转换,从而导致索引失效</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>如果存在联合索引,则查询列里面的索引必须从最左侧开始且不允许跳过中间的索引列</p><p>例如存在联合索引 <code>a,b,c</code> ,如下 sql 语句属于 <strong>全值匹配</strong> 可以命中索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>这里跟查询列的顺序无关,只要在逻辑上满足索引列从左到右的匹配顺序即可,myslq 优化器会在内部自动调整索引的顺序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><strong>非全值匹配</strong> 只要满足从左到右的前缀即可</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>但是不能出现缺少或者跳过,这样会导致最左前缀原则失效,从而导致索引失效</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 从左往右缺少 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <br><span class="hljs-comment">-- 跳过 b</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>同样对于模糊查找也必须满足最左前缀原则</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 模糊检索最左前缀 a 是确定的,后面 % 才是通配符,符合最左前缀原则,可以命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;a%&#x27;</span><br><br><span class="hljs-comment">-- 最左前缀 % 是通配符,属于不确定的,破坏了最左前缀原则,不能命中索引 a</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;%a&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="使用-OR-关键字"><a href="#使用-OR-关键字" class="headerlink" title="使用 OR 关键字"></a>使用 OR 关键字</h3><p>例如只有列 <code>a</code> 有索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>此时会导致索引失效,假设只有 <code>where b = 2</code> 此时肯定是全表扫描,已经得到 <code>a,b</code> 的值,就不用再遍历 <code>a</code> 的索引了; 否则使用 <code>a</code> 的索引后还需要一次全表扫描才能判断 <code>b</code> 的条件</p><p>使用 <code>or</code> 关键字的时候,必须保证两边都有索引才可以</p><h3 id="负向查询"><a href="#负向查询" class="headerlink" title="负向查询"></a>负向查询</h3><p>常见的负向查询有 <code>NOT, IS NOT NULL, !=, NOT IN, NOT LIKE</code> 等</p><p>这些查询不一定会导致索引失效,mysql 在实际执行的过程当中,根据优化器的判断决定是否选择索引,亦或者是全表扫描</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(九)mysql order by 原理细节</title>
    <link href="/2022/11/05/mysql/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/"/>
    <url>/2022/11/05/mysql/(%E4%B9%9D)mysql%20order%20by%20%E5%8E%9F%E7%90%86%E7%BB%86%E8%8A%82/</url>
    
    <content type="html"><![CDATA[<h2 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h2><p>假设有一张城市表,记录了城市里面每个人的名字,你年龄的信息</p><p>现在需要对城市是 <code>杭州</code> 的所有人,按照年龄排序后返回前 1000 人</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> city,name,age <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> city<span class="hljs-operator">=</span><span class="hljs-string">&#x27;杭州&#x27;</span> <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> name limit <span class="hljs-number">999</span>;<br></code></pre></td></tr></table></figure><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>为了避免扫描全表,很自然的在 <code>where</code> 语句查询的字段 <code>city</code> 上加上索引</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsbrl2wj30th0fbjuw.jpg" alt="img.png"></p><p>使用 <code>explain</code> 指令查看执行情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsiczttj31bh041jxx.jpg" alt="img_1.png"></p><p>在 <code>extra</code> 一列里面可以看到 <code>using filesort</code> 表示进行了排序,实际 mysql 会为每个需要排序的线程分配一块内存区域专门用来加速排序,称为 <code>sort_buffer</code></p><p>一个完整的查询流程如下:</p><ol><li>初始化 <code>sort_buffer</code> ,里面有 3 个字段分别是 <code>city,name,age</code> </li><li>从 <code>city</code> 索引开始查找,找到第一个满足条件的主键 id ,即 <code>id_x</code></li><li>回表得到 <code>id_x</code> 对应的完整数据,取出 <code>name,age</code> 和 <code>city</code> 一起放入 <code>sort_buffer</code></li><li>从 <code>city</code> 索引继续取出下一个满足条件的主键 id,重复 34 过程,直到 <code>city</code> 不再满足条件</li><li>对 <code>sort_buffer</code> 里面的所有数据做快速排序</li><li>将排序结果前 1000 条返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugsnhzo9j30m60gbtd4.jpg" alt="img_2.png"></p><p>需要注意的是,由于每次分配的 <code>sourt_buffer</code> 大小是固定的,其不一定能够完全放下所有需要排序的记录; 所以 mysql 会根据实际情况,在内存中完成排序,或者在磁盘上完成排序; 如果在磁盘上进行排序,就不得不依赖磁盘创建临时文件辅助排序</p><p>打开 msyql 的 <code>optimizer_trace</code> 查看优化器的输出</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt1fzvoj30mt05twgy.jpg" alt="img_3.png"></p><p>可以看到在磁盘排序时,使用了 12 个临时文件,这是因为在磁盘上排序一般使用 <strong>归并排序</strong> ,将整个数据集分为若干个子文件,对子文件进行排序后再合并为一个有序的大文件</p><h3 id="rowid-排序"><a href="#rowid-排序" class="headerlink" title="rowid 排序"></a>rowid 排序</h3><p>上面的全字段排序会将所有需要排序的字段取出放到 <code>sort_buffer</code> 里面,如果字段多,数据行多的话,就会导致 <code>sort_buffer</code> 里面要保存的数据太多,由于内存是有限制的,所以很快 <code>sort_buffer</code> 就会被占满,这样就需要把数据分散到多个临时文件里面做归并排序,其性能会差很多</p><p>可以通过修改 mysql 控制排序数据行长度的参数,让 myslq 选择另一种排序方式 <code>rowid</code> 排序</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> max_length_for_sort_date<span class="hljs-operator">=</span><span class="hljs-number">16</span><br></code></pre></td></tr></table></figure><p>如果单行总长度超过这个值,就该用 <code>rowid</code> 排序</p><p><code>rowid</code> 排序不把单行所有字段放入 <code>sort_buffer</code> 里面,仅仅把主键 id 和需要排序的列放入 <code>sort_buffer</code>, 由于 <code>sort_buffer</code> 里面缺少了单行的所有信息,所以不能够在完成排序后直接返回,需要多添加一步回表查询的过程</p><p>当 <code>sort_buffer</code> 完成排序后,遍历前 1000 条记录,通过主键 id 再次回表查询得到所有的数据行返回</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugst18g8j30n10hhtf6.jpg" alt="img_4.png"></p><h3 id="全字段排序和-rowid-排序"><a href="#全字段排序和-rowid-排序" class="headerlink" title="全字段排序和 rowid 排序"></a>全字段排序和 rowid 排序</h3><p>如果 mysql 检测到内存足够,就会使用全字段排序,因为这样能够节省一次回表的查询开销</p><p>如果内存不足,则会改用 <code>rowid</code> 排序,这样可以提高一次性排序的行数,但是对应的代价就是多了一次回表查询</p><p>总的来说,mysql 体现了一个原则就是: 内存够用就要尽可能利用内存,减少磁盘的访问</p><h3 id="使用索引覆盖来加速排序过程"><a href="#使用索引覆盖来加速排序过程" class="headerlink" title="使用索引覆盖来加速排序过程"></a>使用索引覆盖来加速排序过程</h3><p>如果查询的列天然有序,则可以进一步提高 <code>order by</code> 语句的效率</p><p>对于仍然是查询 <code>city</code>, <code>name</code>, <code>age</code> 的 sql,如果在 <code>city</code> 和 <code>name</code> 上建立联合索引</p><p>这样 <code>where</code> 语句使用 <code>city</code> 索引检索的时候, <code>name</code> 也是自然有序的,这样可以节省排序的步骤,只需要一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugt8teb7j30lq08xacf.jpg" alt="img_5.png"></p><p>如果在 <code>city</code>, <code>name</code>, <code>age</code> 三个字段上建立联合索引,这样检索的时候,索引树里面就已经全部包含了所有需要查询的数据,而且自然有序,这样的索引覆盖还能再减少一次回表查询即可返回结果集</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ugtf3quvj30he09cmyt.jpg" alt="img_6.png"></p><h3 id="随机排序"><a href="#随机排序" class="headerlink" title="随机排序"></a>随机排序</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand()<br></code></pre></td></tr></table></figure><p>当添加上 <code>rand()</code> 随机函数之后,如果再使用 <code>explain</code> 查看执行过程的话,会发现 <code>extra</code> 列上多了个 <code>using temporary</code> 表示当前查询会使用 <strong>临时表</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsdqh5nj307w01yq3k.jpg" alt="img_7.png"></p><p>对于带有临时内存表的排序,mysql 应当选择何种排序算法:</p><ol><li>如果是 <code>InnoDB</code> 为了减少磁盘访问,优先选择全字段排序</li><li>如果是带有临时内存表的排序,回表相当于访问内存,其性能几乎不会受到影响,此时会选择 <code>rowid</code> 排序</li></ol><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> word <span class="hljs-keyword">from</span> t <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> rand() limit3<br></code></pre></td></tr></table></figure><p>其排序的查询过程如下:</p><ol><li>创建一张临时内存表,表里面保存两个字段 浮点数 <code>R</code> 和 字符串 <code>W</code></li><li>从主表中按照主键顺序取出 <code>word</code>,并且调用 <code>rand()</code> 函数生成一个随机浮点数,将这个随机浮点数和 <code>word</code> 放入内存表的 <code>R</code> 和 <code>W</code> 字段</li><li>在内存表上排序,初始化 <code>sort_buffer</code>, 其包含两个字段 浮点数和字符串</li><li>从内存表中一行一行地取出 <code>R</code> 和 <code>位置信息</code> 将其放入 <code>sort_buffer</code>,然后在 <code>sort_buffer</code> 里面完成排序</li><li>排序完成后,取前 3 个数据返回</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhskxbg6j30o30hrjvf.jpg" alt="img_8.png"></p><p>其中内存表的 <code>内存信息</code> 就是 mysql 为我们隐式生成的 <code>rowid</code>, 其实如果一张表没有显式指出主键的话,mysql 就会隐式的创建 <code>rowid</code> 当做主键 id 使用</p><p>如果单行数据超过了 mysql 配置的最大单行数据长度,则全字段排序会被转换为 <code>rowid</code> 排序,会导致在磁盘上通过临时文件进行归并排序</p><p>对于 <strong>随机排序</strong> 且还带有 <code>limit</code> 关键字的情况,归并排序完成后所有的数据都是有序的,此时只用取前 <code>limit</code> 个,但是实际上除了前 <code>limit</code> 个以外的数据,并不关系其是否有序,所以 mysql 在 5.6 版本引入了 <code>堆排序</code> </p><p>构造最大堆或者最小堆,初始化容量为 <code>limit</code> 个元素,将后续的元素依次添加到堆里,完成遍历后,堆里就保留了 <strong>最大</strong> 或者 <strong>最小</strong> 的前 <code>limit</code> 个元素,而后面的则无需关心是否有序</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uhsquhy8j30o00dqagy.jpg" alt="img_9.png"></p><p>无论如何,使用 <code>order by rand()</code> 都会导致复杂的排序计算</p><p>优雅的随机排序应当使用如下操作</p><ol><li>统计表的总行数 <code>C</code></li><li>计算随机数 <code>R = floor(C*rand())</code> 其中 <code>floor()</code> 函数负责向下取整</li><li><code>select xxxx limit Y,1</code> 表示从 <code>Y</code> 开始取出 <code>offer = </code> 即 <code>Y+1</code> 行</li></ol><p>若要得到 <code>X</code> 个随机记录,则将上述操作重复 <code>X</code> 次,这样可以避免主键空洞导致的伪随机</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(八)mysql count 函数机制</title>
    <link href="/2022/11/05/mysql/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/mysql/(%E5%85%AB)mysql%20count%20%E5%87%BD%E6%95%B0%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="count-的实现原理"><a href="#count-的实现原理" class="headerlink" title="count(*) 的实现原理"></a>count(*) 的实现原理</h3><ol><li>在 <code>Myisam</code> 上,每个表的总行数保存在了磁盘上,因此 <code>count(*)</code> 可以在 O(1) 的时间复杂度之内得到,效率非常高</li><li>在 <code>InnoDB</code> 上,不会单独保存表的总行数,因此只能通过遍历所有数据,完成统计得到</li></ol><p>为什么 <code>InnoDB</code> 不保存总记录数,因为 <code>MVCC</code> 多版本并发控制导致,即使每次执行 <code>count(*)</code> 语句时,快照读返回的行数都不一定是准确的</p><p>例如事务 A 快照读的时候得到行数 10000,在这个过程中事务 B 插入了 1 行,因为快照读的原因事务 A 并不能观察到这 1 行,所以返回的行数并不准确</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubro5pldj30ne08yjuu.jpg" alt="img.png"></p><p>具体 mysql 是怎么实现 <code>count(*)</code> 的计算过程呢</p><p>由于只能一行一行地遍历所有数据,那么就需要从索引树的叶子节点的链表开始遍历; 前面说过,聚簇索引的叶子节点保存的是 <code>主键 id 和完整数据行</code>; 而非聚簇索引的叶子节点保存的是 <code>索引列和主键 id</code>; 这样对于相同大小的页,后者能够放下更多的节点</p><p>因此 myslq 实际上在做 <code>count(*)</code> 的时候,会选择最小的索引树进行遍历,加快遍历的速度</p><h3 id="使用缓存系统保存总数"><a href="#使用缓存系统保存总数" class="headerlink" title="使用缓存系统保存总数"></a>使用缓存系统保存总数</h3><p>如果有个业务需要频繁的访问表的总记录数,而数据又非常多,那么 <code>count(*)</code> 势必导致性能问题</p><p>考虑设计一个缓存系统来保存总数,每次增删记录的时候,同时更新缓存里面的总数</p><p>实际上并不能通过 redis 来完成这个缓存系统,因为总是存在数据不一致,有点类似幻读的感觉,例如下面两个例子</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubru7q69j30nc08yaay.jpg" alt="img_1.png"></p><p>实际上会话 B 在查询最近 100 条记录的时候,会把会话 A 插入的新数据查询出来,但是会话 B 访问 redis 的时候总计数却不包含这一条,因为此时会话 A 还没来得及更新 redis</p><p>如果反过来</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubrzdpldj30n809pt9j.jpg" alt="img_2.png"></p><p>会导致会话 B 从 redis 里面已经得到的总数已经新增了一条,但是最近 100 条记录里面却不包含这新增的一条,再次发生数据不一致的问题</p><p>这些都是因为缓存系统无法完全保证数据实时一致性,考虑使用数据库当做缓存系统使用</p><p>将对 redis 的操作更换为数据库操作,同时为其加上事务</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7ubs4hin0j30n50ci0ts.jpg" alt="img_3.png"></p><p>根据 <code>MVCC</code> 会话 B 读到的总数并不包含会话 A 新增的总数,而且前 100 条记录也不包含回话 A 新增的数据; 这是由 <code>MVCC</code> 的快照读保证的一致性</p><h3 id="不同的-count-函数使用方式"><a href="#不同的-count-函数使用方式" class="headerlink" title="不同的 count 函数使用方式"></a>不同的 count 函数使用方式</h3><p>不仅仅有 <code>count(*)</code> 能够统计行数,还有 <code>count(1)</code>, <code>count(主键)</code>, <code>count(字段)</code> 等等</p><p>其原理都差不多,<code>count()</code> 本身是一个聚合函数,起作用就是对于返回的结果集进行遍历,如果参数不是 <code>NULL</code> 就将结果值+1,所以上面那么多不同的 <code>count()</code> 操作,其本质就是在计算返回的结果集对应的参数不是 <code>NULL</code> 的总数</p><p>记住以下原则 <code>Server</code> 层要什么,存储引擎就给什么</p><ul><li><code>count(主键)</code> 存储引擎遍历整张表,把每一行的主键 <code>id</code> 取出来返回给 <code>Server</code> 层将,然后 <code>Server</code> 判断是否为 <code>NULL</code> 并计数</li><li><code>count(1)</code> 存储引擎遍历整张表,但是不取具体值,而是对每一行返回一个 1,由 <code>Server</code> 层判断是否为 <code>NULL</code> 并计数</li><li><code>count(字段)</code> 如果这个字段定义为 <code>NOT NULL</code> 非空的话,原理同 <code>count(主键)</code>; 如果定义允许 <code>NULL</code>,则需要对每一行判断是否为 <code>NULL</code> 后计数</li><li><code>count(*)</code> 优化器做了专门的优化,不会取所有值</li></ul><p>从性能层面来说 : <code>count(*) ≈ count(1) &gt; count(主键) &gt; count(字段)</code></p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(七)mysql 表空间回收</title>
    <link href="/2022/11/05/mysql/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/"/>
    <url>/2022/11/05/mysql/(%E4%B8%83)mysql%20%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="表空间的存储设置"><a href="#表空间的存储设置" class="headerlink" title="表空间的存储设置"></a>表空间的存储设置</h3><p>首先有个设置 <code>innodb_file_per_table</code> 表示是否把表数据存储为单个文件,否则的话就放在共享表空间里</p><p>明确一点,单独存放为一个文件更好,因为这样更便于管理; 而且 <code>drop</code> 命令执行时会删除对应的表文件,如果放在共享空间里, <code>drop</code> 命令不会回收表空间</p><h3 id="delete-语句为何不会回收表空间"><a href="#delete-语句为何不会回收表空间" class="headerlink" title="delete 语句为何不会回收表空间"></a>delete 语句为何不会回收表空间</h3><p><strong>可以结合前面讲的索引复习</strong>, 都知道 mysql 的索引是用 <code>B+</code> 树实现的,由于 <code>B+</code> 树也是一种自平衡的树,所以在对某些索引进行删除或者插入的时候,由于单个节点存储的索引有限,势必会导致单个节点的分裂或者多个节点的重组</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatmc03pj30ex0bjjt2.jpg" alt="img.png"></p><p>假设需要删除 <code>R4</code> 这条记录,此时并不会实际操作磁盘,而是把页里面的 <code>R4</code> 标记为删除,这是一种 <strong>软删除</strong> 或者叫做 <strong>逻辑删除</strong></p><p>后面如果插入 <code>300</code> 到 <code>600</code> 的记录,是完全可以继续复用这个位置的</p><p>同理当插入一条记录的时候,如果此时页里面已经放满了数据,就会导致当前节点分裂为多个节点,将原先的页按照一定规则重新放到多个节点上</p><p>这里需要注意一点:</p><p>记录的删除仅仅是在页里面将当前数据的位置标记为可复用,而页的删除则是将里面所有的数据标记为可复用</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uattc0hej30oc0fjdk8.jpg" alt="img_1.png"></p><p>例如插入 <code>550</code> 的记录,此时由于页里面已经放满了索引此时需要把原来的页 A 一部分索引数据拆分到一个新的页 B 里面去;这里的拆分和重组由 <code>B+</code> 树的插入和删除性质计算的到</p><p>此时会导致原来完整的 A 出现了 <strong>数据空洞</strong>, 同时新页 B 也产生了 <strong>数据空洞</strong> ; 当一张表经过大量的增删改操作之后,很有可能存在不少的 <strong>数据空洞</strong> </p><p>总结来说,<code>delete</code> 语句仅仅是将页里面的记录位置标记为可以复用,而不是真正的删除页释放空间; 所以执行 <code>delete</code> 语句是无法回收表空间的</p><h3 id="重建表解决表空间空洞的问题"><a href="#重建表解决表空间空洞的问题" class="headerlink" title="重建表解决表空间空洞的问题"></a>重建表解决表空间空洞的问题</h3><p>利用 AB 表的思想,创建一张结构与 A 表相同的 B 表,依次扫描 A 表并顺序插入在 B 表当中, 这样处理过后 B 表的主键就是紧凑没有数据空洞的,数据页的利用率也更高; 操作完成后把流量切到 B 表,然后再删除 A 表即可</p><p>或者直接用 myslq 提供的指令 <code>alter table A engin = InnoDB</code> 进行表的重建</p><p>重建过程当中,如果有新数据写入旧表的话,是不会同步到新表的,此时会导致数据丢失,更新也一样; 所以整个重建过程,必须保证旧表处于只读状态</p><p>如果说保持表 A 的只读状态,那么此时的 <code>DDL</code> 操作就不是 <code>Online</code> 的</p><p>在 mysql 5.6 开始引入 <code>Online DDL</code> ,即重建过程当中,也支持对表 A 的写操作</p><p>基本原理如下:</p><ol><li>扫描表 A 的所有数据页,重新生成对应的 B+ 树,存储到临时文件当中</li><li>生成临时文件的过程中,如果有对表 A 的写操作,则记录在 <code>row log</code> 的日志文件当中</li><li>临时文件生成后,与 <code>row log</code> 的记录进行 <code>merge</code> 操作,得到最终的临时文件</li><li>将最终的临时文件应用到表 A 上</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7uatzz998j30o70ehdmc.jpg" alt="img_2.png"></p><p>前面说过表级锁有表锁和 <code>MDL</code> 锁,其中 <code>MDL</code> 写锁就是为了防止在查询过程当中表结构发生变化</p><p>而此时的 <code>DDL</code> 重建表操作就会申请到 <code>MDL</code> 写锁,按照其定义,后续对表 A 的读写请求应该都被阻塞了才对</p><p>其实实际重建表的过程当中,这里的 <code>MDL</code> 写锁在 <code>alter</code> 语句开始执行后,真正拷贝数据之前就已经退化成 <code>MDL</code> 读锁了,这样做重建的时候不会阻塞其他的增删改查操作</p><p>此时也不能直接释放 <code>MDL</code> 锁,这样是为了保护不受其他后面的 <code>DDL</code> 影响</p><p>在整个重建过程中,最耗时的是数据拷贝到临时表的过程,这里退化成读锁也不会阻塞其他正常请求,而到了真正需要拷贝数据的时候,相对于整个过程, <code>MDL</code> 写锁的持有过程相对来说并不长,可以近似认为是 <code>Online</code> 的</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(六)mysql 刷盘机制</title>
    <link href="/2022/11/05/mysql/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/11/05/mysql/(%E5%85%AD)mysql%20%E5%88%B7%E7%9B%98%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h3 id="mysql-的抖动"><a href="#mysql-的抖动" class="headerlink" title="mysql 的抖动"></a>mysql 的抖动</h3><p>在日常工作当中,监控 mysql 的 cpu 状况一般可以发现几个特征</p><ol><li>随着流量高峰导致的使用率上升,这种随着业务的频繁访问而上升,随着业务冷却的下降,属于正常波动</li><li>在平滑的曲线当中,经常会出现 <code>突刺</code> 般的抖动</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37pk9brj30me05s3yx.jpg" alt="img.png"></p><p>这种短暂的 <code>突刺</code> 抖动,一般情况都是因为 mysql 在做 <strong>刷盘</strong> 操作引起的</p><h3 id="结合日志系统理解刷盘"><a href="#结合日志系统理解刷盘" class="headerlink" title="结合日志系统理解刷盘"></a>结合日志系统理解刷盘</h3><p>对于前面提到的 mysql 的日志系统,以 <code>redo log</code> 为例,前面介绍过分为两个部分 <code>redo log buffer</code> 和 <code>redo log file</code></p><p><code>buffer</code> 保存在内存里, <code>file</code> 保存在磁盘上,这也是为了平衡内存和磁盘访问速率不统一的问题</p><p>但是保存在内存里的数据终究是不可靠的,会随着断电而丢失,所以必须在适当的时机将内存里的数据写入磁盘完成持久化操作,保证数据的安全</p><h4 id="脏页和干净页"><a href="#脏页和干净页" class="headerlink" title="脏页和干净页"></a>脏页和干净页</h4><p>当内存里面的数据页和磁盘里面的对应数据页内容不一致的时候,这个内存页就被称为 <code>脏页</code></p><p>反之若保持一致,则称内存页为 <code>干净页</code></p><p>回顾一下之前的数据写入过程,首先记录 <code>redo log</code> 这是由 mysql 写前日志的特性保证,然后将改动在 <code>buffer pool</code> 里面写入,这里可以结合缓存相关的东西一起复习,最后 mysql<br>找一个合适的时机,将 <code>redo log</code> 里面记录的操作写入磁盘完成持久化</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u37w4jo6j30mt0d976q.jpg" alt="img_1.png"></p><h3 id="什么时候触发刷盘操作"><a href="#什么时候触发刷盘操作" class="headerlink" title="什么时候触发刷盘操作"></a>什么时候触发刷盘操作</h3><ol><li>当 <code>redo log</code> 的 <code>write_pos</code> 已经追上 <code>check_point</code> 的时候,表明 <code>redo log</code> 已经写满了无法再继续写入新数据,此时整个数据库的写操作都将被阻塞,必须要将 <code>check_point</code> 后面的数据刷入磁盘,以腾出空间让 <code>redo log</code> 恢复继续写入</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7u38318laj30gb0fkace.jpg" alt="img_2.png"></p><p>当 <code>check_point</code> 的位置从 <code>cp</code> 推进到 <code>cp&#39;</code> 的时候,就必须把这个区间内的所有的日志(浅绿色部分)都刷入磁盘,当完成刷盘操作后,<code>check_point</code>的位置推进到 <code>cp&#39;</code> 这样就空出来新的位置给 <code>write_pos</code> 继续推进</p><ol start="2"><li>当缓冲池内存不足的时候,此时就必须要淘汰掉里面的部分数据页(对应可以结合 mysql 的缓存机制复习),如果从 <code>LRU</code> 里面淘汰的是干净页那还好说,直接移出 <code>LRU</code> 即可; 如果淘汰的是脏页,就必须要刷盘</li></ol><p>为何不考虑直接丢弃脏页,下次从磁盘读取旧的内存页,然后和 <code>redo log</code> 里面的操作结合返回呢</p><p>从性能角度上来说, 这里的 <code>merge</code> 操作对于读取页来说相对复杂了</p><p>而且刷盘能够保证一致性:</p><ul><li>若内存页里有数据,无论是脏页还是干净页,一定是最新的正确数据,命中缓存后直接返回</li><li>若内存页里没有数据,那么磁盘里面的一定是正确数据,从磁盘读入内存后直接返回即可,也不需要额外的 <code>merge</code> 操作</li></ul><ol start="3"><li><p>当 mysql 检测到系统负载不高的时候,也会进行刷盘操作; 即使系统的负载很高,也要见缝插针的刷脏页,避免造成内存不够或者 <code>redo log</code> 写满的情况发生(这个频率是每秒 1 次)</p></li><li><p>最后,当 mysql 需要停机的时候,关闭 mysql 进程之前,会将内存里面的所有脏页一次性全部刷入磁盘,避免内存里面的数据丢失</p></li></ol><h3 id="着重考虑下第-2-点的刷盘情况"><a href="#着重考虑下第-2-点的刷盘情况" class="headerlink" title="着重考虑下第 2 点的刷盘情况"></a>着重考虑下第 2 点的刷盘情况</h3><p>结合之前的缓存技术一起复习,当需要访问数据的时候,先检查缓存池里是否已有对应的页,若命中缓存则快速返回; 否则从磁盘里面读取对应的内存页</p><p>如果此时缓存池还没有写满,那么直接放入 <code>LRU</code> 即可</p><p>如果缓存池已经写满,就需要根据 <code>LRU</code> 淘汰页; 淘汰的是脏页,必须刷盘; 淘汰的是干净页,无需刷盘</p><p>mysql 通过两个参数来控制刷脏页的速率</p><ol><li>当前 <code>buffer pool</code> 里面的脏页比例 M</li><li>当前 <code>redo log</code> 的写盘速度 N</li></ol><p>简单来说就是取 <code>R = max(M, N)</code>,然后 mysql 就以 <code>R% * 磁盘写入能力</code> 的速率刷新脏页</p><h3 id="连坐刷新"><a href="#连坐刷新" class="headerlink" title="连坐刷新"></a>连坐刷新</h3><p>若一次请求需要刷新一个脏页,根据局部性原理,mysql 会判断当前页旁边的数据页是否也是脏页,如果也是脏页,就一起刷新掉; 而且这个判断机制会蔓延下去,也就是说如果邻居是脏页,还要继续判断邻居的邻居</p><p>这样最终可能导致一次简单的请求,原本刷新一个脏页就可完成,最后刷新的大批量的脏页,反而拖慢了整体查询的性能</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(五)mysql 锁</title>
    <link href="/2022/11/04/mysql/(%E4%BA%94)mysql%20%E9%94%81/"/>
    <url>/2022/11/04/mysql/(%E4%BA%94)mysql%20%E9%94%81/</url>
    
    <content type="html"><![CDATA[<h2 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h2><p>锁是用来保证事务并发,数据安全的一种手段</p><p>mysql 有三种类型(注意:是 <strong>三种类型</strong> 而非 <strong>三种</strong>):</p><ol><li>全局锁</li><li>表级锁</li><li>行级锁</li></ol><h3 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h3><p>全局锁就是对 <strong>整个数据库实例</strong> 加锁,在此期间,整个数据库处于 <strong>只读</strong> 状态,除了读其他所有操作都会被拒绝</p><p>全局锁的作用几乎都是用来做 <strong>整库备份</strong>, 如果在做整库备份的时候,没有加上全局锁,这个时候表仍然可以写,就会出现备份前后数据不一致的情况</p><p>在事务里面,mysql 通过 <code>MVCC</code> 多版本并发控制来保证事务的隔离性,用到的数据结构是 <code>视图</code>,这个视图保证了在启动事务的时候,是处于一个 <strong>静止状态的逻辑时间点</strong></p><p>参考事务,在做全局备份的时候,也生成一张视图,这样后续的读写请求都不会因为全局锁而阻塞; 既然有视图的存在,为何备份的时候还需要全局锁呢</p><p>考虑到有些存储引擎, 例如 <code>Myisam</code>, 它不支持事务; 这样在备份的时候仍然能取到最新的数据,破坏了数据的一致性</p><p>还有一种方式也能够实现类似于 <strong>全局锁</strong> 的能力,那就是 <strong>将数据库设置为只读状态</strong></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> <span class="hljs-keyword">global</span> readonly <span class="hljs-operator">=</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><p>但是仍然不建议使用将数据库设置为只读状态来进行整库备份</p><ol><li>客户端连接数据库实例后,加上全局锁进行备份,如果中间发生异常导致客户端断开连接,这个时候数据库也能将全局锁自动恢复,以保证数据库实例能够继续对外提供服务</li><li>如果是通过设置只读的状态,如果连接在中途断开后,数据库是不会从只读状态中恢复的,此时会导致整个数据库对外停止服务</li><li>有些数据库框架可能会用 <code>readonly</code> 字段做业务逻辑,例如判断是否是主库,是否是从库; 改变这个值可能会引起主从判断的逻辑</li></ol><h3 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h3><p>表级锁有两种:</p><ol><li>表锁</li><li>元数据锁</li></ol><h4 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h4><p>表锁的使用限制非常严格,例如</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">lock tables t1 read, t2 write<br></code></pre></td></tr></table></figure><p>如果线程 A 在某个时刻执行上述语句后, 其他线程写 t1 ,读写 t2 的请求都会被阻塞,这个很好理解</p><p>但是对于线程 A 来说,就更加严格,它只能够读取 t1,连写 t1 都不行; 对于 t2 来说,线程 A 能够读写; 而且线程 A 也不能访问其他表</p><h4 id="MDL-元数据锁"><a href="#MDL-元数据锁" class="headerlink" title="MDL 元数据锁"></a>MDL 元数据锁</h4><p><code>MDL</code> 锁是不需要显式声明的,在访问一张表的时候,数据库会自动为这张表加上 <code>MDL</code> 锁</p><p>简单来说, <code>MDL</code> 锁是为了保障表结构的完整性不受到影响</p><p>例如当一个线程正在查询表 A 里面的 c1,c2,c3 三列数据列,此时另外一个线程却对表 A 执行了一条 <code>alter</code> 语句,结果是删掉了 c3 列</p><p>这就导致原来的线程在获取道德数据跟原来的表结构不一致了</p><p>mysql 引入了 <code>MDL</code> 锁,分为 <code>MDL</code>读和写两种子类型:</p><ul><li>读锁之间互不影响,也就是说对于同一张表, 每个线程都可以持有对应的 <code>MDL</code> 读锁,所以每个线程之间的读请求互不受到影响</li><li>写锁之间和读写锁之间互斥, 一旦有一个线程正在修改表结构,此时其他所有的读请求和写请求都会被阻塞掉,只有等待写锁释放后,才能进行后面的操作</li></ul><p>介绍一个由 <code>MDL</code> 锁导致的故障问题,假设有如下 4 个会话执行顺序如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgl1480lj30j30bvdih.jpg" alt="img.png"></p><p>会话 A,B 分别执行查询语句,申请 <code>MDL</code> 读锁,这没问题; 会话 C 执行 <code>alert</code> 语句申请 <code>MDL</code> 写锁,此时阻塞</p><p>问题来了,如果仅仅是会话 C 阻塞还好,可如果后面还有其他请求进来访问表,都会被会话 C 阻塞掉</p><p>为什么说会话 C 申请写锁被阻塞之后,还会继续阻塞其他读写锁的申请呢</p><p>mysql 在内部使用 <strong>优先队列</strong> 来维护所有的 <code>MDL</code> 锁申请,而且,而且 <strong>写锁的申请优先级高于读锁</strong></p><p>这就解释了为什么会话 C 的写锁申请阻塞,会导致后续的读写锁申请都被阻塞: <strong>因为有一个高优先级的申请在前面,所以队列后面的请求只能一直等待即使有相同的优先级</strong></p><h3 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h3><p><code>MDL</code> 锁是有 <code>Server</code> 层提供的能力,而行级锁是由存储引擎提供的能力,有些例如 <code>Myisa</code> 就不支持行级锁</p><h4 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h4><p><strong>先说结论: 在 InnoDB 事务当中,行锁是在需要的时候才加上,而要等到事务提交后才释放锁, 这个叫做两阶段锁协议</strong></p><p>起作用就是,当事务需要持有多把锁时,要尽可能把最可能影响并发度的锁放到后面</p><p>举个简单的例子:</p><ol><li>客户使用账户 A 购买商家的东西,要在账户 A 上扣款</li><li>商家使用账户 B 进行收款</li><li>商家记录一笔交易记录</li></ol><p>可以看到上面的三步操作肯定是在一个事务里面执行,其中 1,2 分别是 <code>update</code> 操作,3 是 <code>insert</code> 操作,且 3 和 1,2 之前没有先后依赖关系</p><p>如果这个时候有另外一个客户也在商家这里购买东西,那么这也是 <code>update</code> 操作,且和前面的 1,2 步骤 <code>update</code> 的是同一个账户</p><p>为了使都操作账户 B 带来的并发等待最小,第一个客户应当对步骤进行重新排序,例如 3,1,2 这样把存在锁竞争的步骤 2 放到了最后面,这样第一个客户持有账户 B 的锁时间被降低到了最短,尽可能地降低锁导致的并发问题的影响</p><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><p>什么是死锁: 当并发系统中几个线程出现 <strong>循环等待</strong> 资源,涉及到的线程都在等待别人释放自己需要的资源,且 <strong>一直等待</strong> 下去的现象,称为死锁</p><p>死锁发生的 3 个必要条件:</p><ol><li>互斥条件:一个资源只能被一个线程使用,其他线程只能等待释放</li><li>请求和保持:一个线程请求其他互斥资源时,不会释放自己手里的资源</li><li>不可抢占:线程不能强行从其他线程那里获取自己需要的资源,只能等待其释放</li><li>循环等待:存在循环链,使得每个线程都在等待别人释放自己需要的资源</li></ol><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7tgkpg18ij30jh0c6juh.jpg" alt="img_1.png"></p><p>可以看到事务 A 启动后申请对 id&#x3D;1 的资源的锁,事务 B 启动后申请对 id&#x3D;2 的资源的锁</p><p>然后事务 A 申请 id&#x3D;2 的锁,发现被事务 B 持有,此时事务 A 阻塞等待事务 B 释放 id&#x3D;2 的锁</p><p>接着事务 B 申请 id&#x3D;1 的锁,发现被事务 A 持有,此时事务 B 阻塞等待事务 A 释放 id&#x3D;1 的锁</p><p>这样两个事务都在等待对方释放自己的资源,进入死锁状态</p><h4 id="mysql-如何解决死锁"><a href="#mysql-如何解决死锁" class="headerlink" title="mysql 如何解决死锁"></a>mysql 如何解决死锁</h4><ol><li>超时等待</li></ol><p>mysql 有个超时等待时间,默认值为 50s,意味着一个线程进入等待后 50s 没有拿到资源,就放弃等待</p><p>50s 的等待时长一般难以接受,太小的话容易误伤正常的锁等待,所以这个策略很少使用</p><ol start="2"><li>主动死锁检测</li></ol><p>当一个事务发生等待时,会主动检测事务所依赖的所有线程是否有被其他线程锁住,以此循环下去最后判断是否出现了死锁</p><p>主动死锁检测虽然可以发现死锁,但是也存在性能问题</p><p>假如有 100 个线程同时更新 1 个资源,第一个拿到锁的线程开始处理,后面每个进来的新线程都要等待第一个线程释放锁,每个线程都要做一次死锁检测,而每次都会循环检查其他的线程,相当于最后产生了 10000 次死锁检查</p><p>最终的检测结果是没有发生死锁,但是这个过程却是相当耗费 cpu 资源的</p><h4 id="如何减少主动死锁检测带来的-cpu-性能消耗问题"><a href="#如何减少主动死锁检测带来的-cpu-性能消耗问题" class="headerlink" title="如何减少主动死锁检测带来的 cpu 性能消耗问题"></a>如何减少主动死锁检测带来的 cpu 性能消耗问题</h4><p>对于这种 <strong>热点数据</strong> 的并发更新,死锁检测往往会占用大量的 cpu 资源</p><ol><li>从源头上控制,假如能够限制客户端的并发,例如一个客户端发起 5 个链接,那么死锁检测的成本就很低能够接受</li></ol><p>但是难以避免出现大量客户端发起连接更新热点数据,即使单个客户端的并发数很小,但是客户端数量过多仍然会导致死锁检测耗费大量 cpu 资源</p><ol start="2"><li>在业务上做出拆分,将原来一整块的并发资源,拆分为多个子集</li></ol><p>例如原来的一个账户,拆分为 100 个账户的总和,每次更新总账户的时候,实际上是随机更新一个子账户</p><p>这样可以将一个资源面临的大量访问均分到多个资源上,减少单个资源的并发度,降低死锁检测的 cpu 消耗</p><p>但是这样要考虑如何汇总零散的资源,以及单个资源的上出现的特殊情况,这样的做法会导致业务的复杂程度变高</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(四)mysql 的各种缓存技术</title>
    <link href="/2022/11/03/mysql/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/"/>
    <url>/2022/11/03/mysql/(%E5%9B%9B)mysql%20%E7%9A%84%E5%90%84%E7%A7%8D%E7%BC%93%E5%AD%98%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h3 id="预读-局部性原理"><a href="#预读-局部性原理" class="headerlink" title="预读 局部性原理"></a>预读 局部性原理</h3><p>操作系统有个很经典的理论,叫做 <strong>局部性原理</strong> ,意思就是说如果使用了一些数据,那么大概率接下来还会使用这些数据附近的其他数据</p><p>同时,磁盘的读写并不是按需读取,也就是说并不是需要什么数据就读取什么数据; 而是按照一定大小的页,一次性读取到内存当中,通常这个页的大小默认为 <code>4K</code></p><p>因为根据局部性原理,访问了数据 x 之后,大概率还会访问 x 附近的其他数据; 而如果是按需读取的话,在访问 x 之后,继续访问 y 和 z 又要进行磁盘操作,这无疑增大了 io 的消耗</p><p>对于按页读取 ,可以一次性将 x 所在的那一页都放到内存里,这样以后再访问 y 或者 z,就可以直接从内存里读取,无需磁盘操作</p><p>可能有疑问就是,如果 x 正好在当前页的最后一条记录,那么访问 y 或者 z 必然要再读取下一页; 实际上这种情况发生的概率非常小,即使如此,再读取下一页也比每次都访问磁盘的效率高得多,是值得接受的必要 io 消耗</p><p>mysql 为了利用磁盘按页读取的能力,在其内存缓存池里面,也是按照页为单位来加载磁盘上的数据</p><h3 id="mysql-如何管理缓存-读缓存-buffer-pool"><a href="#mysql-如何管理缓存-读缓存-buffer-pool" class="headerlink" title="mysql 如何管理缓存 读缓存(buffer pool)"></a>mysql 如何管理缓存 读缓存(buffer pool)</h3><p>管理缓存有个非常经典的算法, <code>LRU</code> 最近最少使用算法</p><p>最常见的实现就是通过一个固定大小的双向链表,将最近一次访问的页放到链表头,这样链尾上的最长时间没有使用的页就会被淘汰置换出链表</p><p><code>LRU</code> 在更新内存页的时候,又分为两种情况</p><ul><li>当前命中的页已经在缓存里面了,这时只需要把命中页置换到头部即可</li><li>当前命中的页还不在缓存里面,这时需要通过一次磁盘 io 把磁盘页读取出来放到缓存头部</li></ul><p>对于一个已经装满的缓存,第一种情况只会发生置换页的操作,不会有页被淘汰;第二种情况则是会淘汰尾部的最后一页</p><p>朴素 <code>LRU</code> 在很多内存缓存里面,例如 <code>MemoryCache</code> 运用的很多,但是 mysql 并没有选择朴素 <code>LRU</code> 算法,这是因为有以下两个问题</p><ol><li>预读失效</li><li>缓存污染</li></ol><h4 id="预读失效"><a href="#预读失效" class="headerlink" title="预读失效"></a>预读失效</h4><p>由于 mysql 预读将部分磁盘页放到缓存里面,但是因为某些原因,这些预读出来的页并没有实际访问到,导致预读失效</p><p>假设缓存大小等于 <code>10 ,且磁盘页 </code>50&#96; 被预读放入缓存,考虑如下情况</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6j8tn3ij30an02maa7.jpg" alt="img.png"></p><p>此时预读出来的页 <code>50</code> 被放到缓存头部,但是后续再也没有发生过对 <code>50</code> 的访问,这导致预读出来的数据 <code>50</code> 需要被置换 10 次后才能够被淘汰掉</p><p>这使得这些未命中的预读页,在缓存里面的停留时间过长</p><p>mysql 采用 <strong>改良的 LRU 算法</strong> ,将普通缓存改为 <strong>分代</strong> 设计,分为 <strong>新生代</strong> 和 <strong>老年代</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6jirxpjj30b504lmxj.jpg" alt="img_1.png"></p><ul><li>缓存被分为两个部分 <strong>新生代</strong> 和 <strong>老年代</strong></li><li>实际上是通过 4 个指针,分别维护新生代头尾和老年代头尾</li><li>新页在放入缓存的时候,首先放入 <strong>老年代</strong></li><li>如果 <strong>老年代</strong> 里面的页发生了命中,才会加入 <strong>新生代</strong></li><li>如果 <strong>老年代</strong> 里面的页没有发生命中,那么在 <strong>更短的时间内</strong> 它将被移除缓存</li></ul><p>这样使得那些被预读放入缓存,但是又长时间没被使用过的页,能够尽快的从老年代里面淘汰出去</p><h4 id="缓存污染"><a href="#缓存污染" class="headerlink" title="缓存污染"></a>缓存污染</h4><p>什么是缓存污染: <strong>当 mysql 发生大面积扫描数据行的时候,会将大量数据页放入缓存后,立马又再次换入新的数据页; 导致每页只在缓存里面停留非常短的时间就被置换出去</strong></p><p>缓存污染将会显著导致 mysql 的性能下降</p><p>例如一次全表扫描时:</p><ol><li>将预读页放入老年代</li><li>从老年代里面访问页加入新生代</li><li>下一次预读又会将全新的页刷入老年代</li><li>重复 123 步骤,直到完成全表扫描</li></ol><p>可以看到在这样的场景下,所有的页都被放入缓存 1 次后,立马又被新的页置换掉; 从而导致原本缓存里面真正的 <strong>热数据</strong> 被大量新页挤出缓存,从而导致 mysql 的性能下降</p><p>mysql 为了解决缓存污染问题,引入了 <strong>老年代停留窗口</strong> 的概念</p><p>放入老年代后,如果再次命中,并不会立即放入新生代,而是要求在老年代待满多少时间后才允许进入新生代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6joyl78j30ci082js4.jpg" alt="img_2.png"></p><p>假设有大量需要扫描的页需要进入缓存,此时首先进入的是老年代</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6k1gfkzj30hw05fq47.jpg" alt="img_3.png"></p><p>如果老年代里面装不下,即使页被访问了,也会被缓存淘汰掉</p><p>这个时候缓存头部的那些高频命中的新生代热点数据,不会立马被这种大批量扫描的页给置换出去</p><p>对于能够命中新生代的查询来说,此时缓存依然能够提供服务,并且性能依旧高效</p><p>而对于老年代里面的页,命中后需要判断是否满足 <strong>老年代停留窗口</strong> 的时长 <code>T</code></p><ul><li>如果 <code>停留时长 &gt;= T</code>,则将其置换到新生代的头部,此时新生代的尾部页面会进入老年代作为的老年代的头部</li><li>如果 <code>停留时长 &lt; T</code>,则只会将其置换到老年代的头部,不会进入新生代</li></ul><h3 id="mysql-如何管理写缓存-change-buffer"><a href="#mysql-如何管理写缓存-change-buffer" class="headerlink" title="mysql 如何管理写缓存 (change buffer)"></a>mysql 如何管理写缓存 (change buffer)</h3><p>简单回顾下读缓存在 mysql 保存了什么内容</p><ol><li>索引页</li><li>索引页对应的数据页</li></ol><p>对于读请求,<code>buffer pool</code> 通过改进后的 <code>LRU</code> 算法实现缓存管理,解决 <code>预读失效</code> 和 <code>缓存污染</code> 的问题</p><p>对于写请求,究竟该如何管理缓存呢,以几个例子分别分析下</p><h4 id="写的页正好在-buffer-pool-里"><a href="#写的页正好在-buffer-pool-里" class="headerlink" title="写的页正好在 buffer pool 里"></a>写的页正好在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6ju3go6j308p072gmf.jpg" alt="img_4.png"></p><ol><li>直接在页上写入数据</li><li>然后写入 <code>redo log</code></li></ol><p>是否会出现一致性问题呢: <strong>不会</strong></p><ol><li>读取,会命中缓存池的页</li><li>缓存池 <code>LRU</code> 数据淘汰,会将 <code>脏页</code> 刷回磁盘</li><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li></ol><h4 id="写的页不在-buffer-pool-里"><a href="#写的页不在-buffer-pool-里" class="headerlink" title="写的页不在 buffer pool 里"></a>写的页不在 buffer pool 里</h4><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kjgoolj308j06vaaw.jpg" alt="img_5.png"></p><ol><li>一次随机磁盘访问,将需要写入的页加载到缓存池里</li><li>在缓存池里写入数据</li><li>写入 <code>redo log</code></li></ol><p>由于写入页不在缓存池里,多了一次从磁盘读取对应页的操作,mysql 为了减少这一次磁盘操作,引入了写缓存 <code>change buffer</code> 的概念</p><p><strong>定义:当对一张不在缓存池里且 <code>非唯一索引</code> 的页进行写入操作是时,并不会立即从磁盘里加载对应的页,而是通过在写缓存 <code>change buffer</code> 里 <code>记录</code> 当前操作,直到后面需要访问这张页的时候,在进行合并 <code>merge</code> 操作</strong></p><p>这样对流程上来说带来的改变如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7t6kq2mdfj30bf06xmya.jpg" alt="img_6.png"></p><ol><li>没有立即从磁盘里面加载对应的数据页,而是在 <code>change buffer</code> 里面记录了一次操作</li><li>写入 <code>redo log</code></li></ol><p>可以看到因为有写缓存的存在,其性能与读请求几乎一致</p><p>同样可以分析下是否会产生一致性问题: <strong>同样也不会</strong></p><ol><li>数据库宕机,能够从 <code>redo log</code> 中恢复数据</li><li>读取刚刚写入的数据,会有其他机制保证从磁盘里面取出旧的数据页,并和 <code>change buffer</code> 里面的记录完成合并</li><li>会有机制保证 <code>change buffer</code> 里面的改动在适当的实际刷入磁盘</li></ol><p>如果此时发生读取操作,会发生什么呢</p><ol><li>发现缓存里没有对应的页,从磁盘里面随机读取一次拿到对应的页放入缓存</li><li>将磁盘里面读出来的页和写缓存 <code>change buffer</code> 里面的操作进行合并 <code>merge</code> </li><li>将 <code>merge</code> 后的页根据 <code>LRU</code> 算法放入缓存池的对应位置 (老年代)</li></ol><p>可以看到: 再写操作发生时,并不会从磁盘里面加载页到缓存里面; 实际上是在读操作到来时,才会从磁盘里面真正加载到缓存里面然后进行 <code>merge</code> 操作</p><h4 id="为什么说写缓存只能用于-“非唯一索引”"><a href="#为什么说写缓存只能用于-“非唯一索引”" class="headerlink" title="为什么说写缓存只能用于 “非唯一索引”"></a>为什么说写缓存只能用于 “非唯一索引”</h4><p>这是由 <strong>一致性</strong> 决定</p><p>什么是一致性? 简单回顾下: 数据库保证数据能够从一个正确的状态转换为另一个正确的状态</p><p>为什么说 <code>change buffer</code> 写缓存在对于 <strong>唯一索引</strong> 的写操作时,没法保证一致性</p><p>由于 <strong>唯一索引</strong> 在写入数据时,需要保证数据的 <strong>唯一性</strong>, 而 <code>change buffer</code> 在记录写入操作时,并没有去校验这条记录 <strong>是否已经存在</strong></p><p>要校验数据的唯一性,必须要从磁盘里面读取出对应的索引页,以检查数据是否存在</p><p>既然这次磁盘操作必不可免,那为什么不直接从磁盘里面读出放到 <code>buffer pool</code> 里,然后直接对页进行修改</p><p>这样看来在中间添加一个 <code>change buffer</code> 写缓存,对于校验索引的唯一性来说,就显得毫无作用了</p><h3 id="什么场景适合开启写缓存"><a href="#什么场景适合开启写缓存" class="headerlink" title="什么场景适合开启写缓存"></a>什么场景适合开启写缓存</h3><p>根据上面的分析,有以下场景适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>非唯一索引</strong></li><li>写多读少</li></ol><p>什么时候不适合开启写缓存</p><ol><li>数据库里面大多都是 <strong>唯一索引</strong></li><li>读多写少 或者说 写入一个数据后,立马读它(因为写缓存没有实际写页,缓存池里面也没有页,只能从磁盘里面加载,这就导致写缓存失效)</li></ol>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(三)mysql 索引深入浅出</title>
    <link href="/2022/11/03/mysql/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/"/>
    <url>/2022/11/03/mysql/(%E4%B8%89)mysql%20%E7%B4%A2%E5%BC%95%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="mysql-的索引"><a href="#mysql-的索引" class="headerlink" title="mysql 的索引"></a>mysql 的索引</h2><h3 id="索引数据结构的发展"><a href="#索引数据结构的发展" class="headerlink" title="索引数据结构的发展"></a>索引数据结构的发展</h3><p>索引是一种数据结构,用来提高查询效率,常见的用于提高查询效率的数据结构大致可分为以下三种</p><ol><li>hash</li><li>有序数组</li><li>搜索树</li></ol><h4 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h4><p>hash 表提供一种 <code>k-v</code> 的关系,当输入 <code>key</code> 值,可以在 <code>O(1)</code> 的时间复杂度内返回对应的 <code>value</code> 值</p><p>但是 hash 表本身是无序的,也就是说对于确定的 <strong>等值</strong> 查询,即检索在不在,有没有这种情况来说,hash 表能够胜任</p><p>但是对于范围查询,hash 表的性能表现就会非常差,因为 hash 表无法确定数据的范围,所以在对范围查询时,需要遍历整个 hash 表</p><h4 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h4><p>有序数组的结构本身也很简单,他对范围查询提供很好的性能表现,对于等值查询,则可以借助有序的特点,使用 <code>二分查找</code> 提高查找效率</p><p>但是数组的问题就在于对于元素的删除和增加操作非常麻烦,通常需要大批量连续移动若干个节点,才能保证数组的数据结构不被破坏</p><p>如果采用有序链表,虽然能够提高插入和删除操作,但代价就是失去了随机访问的能力,对于 <strong>等值查询</strong> 链表则需要遍历所有节点</p><h4 id="搜索树"><a href="#搜索树" class="headerlink" title="搜索树"></a>搜索树</h4><p>对于二叉搜索树来说,每个左孩子都小于父节点,每个右孩子都大于父节点,可以看做是二分查找的运用,其搜索一个节点是否存在的时间复杂度是 <code>O(logn)</code></p><p>考虑最极端的情况,如果所有节点都只有左孩子,那么整棵树将退化成一条链表,此时时间复杂度退化为 <code>O(n)</code></p><p>所以为了平衡这些极端情况,维持 <code>O(logn)</code> 的时间复杂度,需要树能够做出自平衡,所谓平衡就是说树中每个节点的左子树和右子树的深度之差不超过 1</p><p>这种具有自平衡的二叉搜索树叫做 <code>AVL</code> 树</p><p>但是数据库也放弃使用 <code>AVL</code> 树当做索引,原因如下:</p><p><code>AVL</code> 树是一棵 <strong>二叉树</strong> ,每个节点只能保存两个孩子节点,如果说数据量过大,那么二叉树的深度将会变得非常深</p><p>索引数据并非只存在于内存里,还需要保存到磁盘上;每个节点在磁盘上的位置并不是连续的,如果对于非常靠近叶子节点的位置,其搜索次数能够轻松达到几十上百次</p><p>这样就会导致几十上百次磁盘的访问,整体的检索性能会严重被树深影响</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B 树"></a>B 树</h4><p>为了解决 <code>AVL</code> 树二叉导致磁盘访问频繁的问题,引入 <strong>N 叉树</strong> 的概念</p><p>根据经验, innoDB 里面的 <code>N</code> 大概在 1200 左右,对于一棵树深高度为 3 的 N 叉树,其能够保存接近 17 亿的数据</p><p>这样查询一个节点,其最多也就访问 3 次磁盘而已,极大地减少了对磁盘的访问</p><p>B 树在普通 N 叉树的基础上,会在节点里面同时保存数据,也就是说一个 B 树的节点不仅仅会保存索引值,还会保存对应的数据</p><p>这就导致了空间的浪费,也会拖慢检索速度,举个简单的例子说明,假说一个节点值保存 8k 的内容</p><p>如果节点里面的数据占用了 3k,那么剩下的索引值就只有 5k,如果本可以通过一次查询得到的索引值,由于节点上保存了数据,导致需要多次查询才能得到对应的索引值</p><p>至此 mysql 索引的终极解决方案 B+ 树横空出世</p><h4 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B+ 树"></a>B+ 树</h4><p>B+ 树在 B 树的基础上,将中间节点保存的数据全部移除,这样中间节点就只负责保存索引值</p><p>所有的数据都落到叶子节点上,这样每次查询的次数都是相同的,提高了查询的稳定性</p><p>对于 B 树来说,有些数据可能在根节点,有些数据可能在叶子节点,不同的查询可能根据位置不同有较大的差异</p><p>B+ 树的叶子节点按照关键字,从小到大顺序排列,并且通过前驱和后继两个指针,构成一个 <strong>双向链表</strong></p><p>由于是有序排列,所以 B+ 树也能够应对范围查询</p><p>对比 B 树,B+ 树的优点如下:</p><ol><li>由于数据按照双向链表有序组织,区间查询的性能比 B 树高</li><li>所有数据分布在叶子节点上,每次查询的次数相等,稳定性比 B 树高</li><li>遍历所有数据时,只需要遍历叶子节点下面的双向链表即可,不用扫描整棵树,而 B 树需要扫描整棵树</li></ol><h4 id="B-树-2"><a href="#B-树-2" class="headerlink" title="B* 树"></a>B* 树</h4><p>B* 树是在 B+ 树的基础上,更进一步</p><p>B+ 树在插入和删除节点时,分裂与合并节点带来性能开销,为了减少节点的操作次数,B* 树在每个非叶子节点上保存了相邻兄弟节点的指针</p><p>同时在初始化节点中关键字数量上,由 B+ 树的 <code>ceil(m/2)</code> 改为 <code>ciel(2m/3)</code></p><p>当某个节点的关键字个数达到 <code>2m/3</code> 时,会查询相邻兄弟节点之间是否还有空余,如有的话则插入关键字向兄弟节点转移,减少了节点的分裂次数</p><h3 id="聚簇索引和非聚簇索引"><a href="#聚簇索引和非聚簇索引" class="headerlink" title="聚簇索引和非聚簇索引"></a>聚簇索引和非聚簇索引</h3><p>假设当前表里存在一个主键列 id,和一个字段列 k,同时对于字段列 k 建立索引</p><p>此时表的索引结构如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjjearwj30k708hdie.jpg" alt="img.png"></p><p>可以看到,对于主键列的索引,叶子节点保存的内容为 <code>id - 数据</code> ,而对于非主键索引 k 来说,里面记录的内容为 <code>k - id</code></p><p>根据索引的叶子节点保存的东西不同,可以把索引分为两大类</p><ol><li>聚簇索引: 保存数据的索引</li><li>非聚簇索引: 保存主键的索引</li></ol><p>对于 <strong>聚簇索引和非聚簇索引,其检索有何区别</strong></p><p>简单来说,在聚簇索引上的查询,只需要通过查找主键 id 就可以得到具体的数据,一次索引树的访问即可</p><p>而非聚簇索引上的查询,则必须要先通过字段列查找到主键 id,然后再通过主键 id 去查找对应的数据,需要 2 次索引树的访问</p><p>对于非聚簇索引上的第二次查找主键 id 的过程,称为 <strong>回表</strong></p><p>由于回表多了一次索引树的查找,所以尽可能使用聚簇索引来完成数据检索</p><h3 id="索引覆盖"><a href="#索引覆盖" class="headerlink" title="索引覆盖"></a>索引覆盖</h3><p>假设存在如下 sql 语句,会执行多少次查询</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><ol><li>从非聚簇索引 k 里面查找到 k&#x3D;3 的记录,得到主键 id&#x3D;300</li><li>从聚簇索引里面查找到主键 id&#x3D;300 的记录,得到数据 R3 返回</li><li>继续遍历 k&#x3D;3 的下一个数据,k&#x3D;5,得到主键 id&#x3D;500</li><li>从聚簇索引里面查找到主键 id&#x3D;500 的记录,得到数据 R4 返回</li><li>继续遍历 k&#x3D;5 的下一个数据,k&#x3D;6,不在查询范围内,结束</li></ol><p>由上一节可知,通过非聚簇索引查询聚簇索引的现象称为 <strong>回表</strong></p><p>上面 5 个查询过程当中,2,4 发生 <strong>回表</strong> 查询,1,3,5 在索引列 k 上发生普通查询</p><p>由于索引列 k 里面的数据只记录了主键 id,并不包含 <code>select</code> 语句后面 <code>*</code> 里面的所有数据</p><p>所以不得不通过 <strong>回表</strong> 查询主键索引得到完整的数据</p><p>假如我们的 sql 发生一点小小的改动</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> k <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> k <span class="hljs-keyword">between</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>此时 <code>select</code> 语句后面只需要查询 <code>k</code> 字段列即可,通过在 k 上面的普通索引,已经包含查询的所有信息了,此时无需再回表查询其他数据</p><p>这种 <strong>索引列 k 已经覆盖查询请求</strong> 的现象,称为 <strong>索引覆盖</strong></p><p><strong>索引覆盖能够有效的减少回表查询的次数,因此是一种提升性能的常用手段</strong></p><p><em>存储引擎和 Server 层的数据扫描统计</em></p><p>需要注意的是,在上面 <strong>索引覆盖</strong> 的查询过程当中</p><p>存储引擎实际扫描了 3 次,即 k&#x3D;3,&#x3D;5,&#x3D;6 然后返回数据 k&#x3D;3 和 k&#x3D;5</p><p>而对于 Serve 层来说,它只从存储引擎哪里拿到了 2 条记录,所以 Server 层认为实际扫描行数只有 2 条</p><h4 id="联合索引通过索引覆盖来提高查询效率"><a href="#联合索引通过索引覆盖来提高查询效率" class="headerlink" title="联合索引通过索引覆盖来提高查询效率"></a>联合索引通过索引覆盖来提高查询效率</h4><p>考虑如下场景,对于每个学生来说,都有 <code>学号</code>, <code>姓名</code>, <code>年龄</code>,</p><p>通常来说,通过 <code>学号</code> 已经能够唯一定位到一个学生,因此一般都选择在 <code>学号</code> 上建立主键索引</p><p>在 <code>姓名</code> 上,也创建普通索引</p><p>此时查询所有姓张的同学的 <code>姓名</code> 和 <code>年龄</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> name, age <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span><br></code></pre></td></tr></table></figure><p>此时是能通过 <code>姓名</code> 的索引找到所有姓张的主键 id,在通过主键 id 得到完整的数据行,最后取出 <code>姓名</code> 和 <code>年龄</code> 返回结果</p><p>若存在大量的这种查询,则 <strong>回表</strong> 会明显的拖慢查询的性能</p><p>若在 <code>姓名</code> 和 <code>年龄</code> 上建立联合索引 <code>name_age</code> 则查询就会变为在索引 <code>name_age</code> 里面查找姓张的同学和年龄,而索引 <code>name_age</code> 正好又包含了查询所需要的数据,此时就不用发生 <strong>回表</strong> 查询</p><p>这样的联合索引,通过 <strong>索引覆盖</strong> 实现了性能的优化和提升</p><h4 id="联合索引的-“最左匹配原则”-和-“最左前缀原则”"><a href="#联合索引的-“最左匹配原则”-和-“最左前缀原则”" class="headerlink" title="联合索引的 “最左匹配原则” 和 “最左前缀原则”"></a>联合索引的 “最左匹配原则” 和 “最左前缀原则”</h4><p><strong>定义:在联合索引列上,从左左侧的字段开始一直向右匹配索引,直到遇到范围查询(&gt;,&lt;,between,like),此时停止对后面的索引列的匹配</strong></p><p><strong>定义:最左匹配原则同样也满足最左前缀原则</strong></p><p>即对于索引 <code>name, age</code> 来说, 查询 <code>name like (&#39;张%)</code> 也能够用上索引</p><p>但是对于如下查询 <code>name like (%三)</code> 此时联合索引左侧的索引列 <code>name</code> 的查询条件前缀是不确定的 <code>%</code> 通配符,此时会导致 <strong>最左前缀原则</strong> 失效,从而导致 <strong>索引失效</strong></p><p>假如有联合索引 <code>(a,b,c,d)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">&gt;</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">4</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">5</span><br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;h%&#x27;</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;123&#x27;</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;456&#x27;</span><br></code></pre></td></tr></table></figure><p>这里联合索引的顺序为 a&gt;b&gt;c&gt;d,所以 <code>where</code> 语句从 <code>a</code> 开始从左往右查找是否有索引列匹配</p><p><code>a &gt; 3</code> 和 <code>a like &#39;h%&#39;</code> 都是范围查询,所以根据定义可知,后面的索引列就不再匹配</p><p>所以以上 2 条 sql 只有 <code>a</code> 用上了索引, <code>b</code> 和 <code>c</code> 都没有用上索引</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>                        <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> nothing<br></code></pre></td></tr></table></figure><p>特殊情况</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span>              <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">where</span> a <span class="hljs-operator">=</span> <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> c <span class="hljs-operator">=</span> <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> b <span class="hljs-operator">=</span> <span class="hljs-number">2</span>    <span class="hljs-operator">/</span><span class="hljs-operator">/</span> a,b,c<br></code></pre></td></tr></table></figure><p>上面 2 条 sql 语句,mysql 的优化器会自动调整字段的位置,从而使用上联合索引加快查询速度</p><p><strong>总结</strong></p><p>根据 <strong>空间</strong> 来决定是否需要在联合索引上,为那些不满足 <strong>最左匹配原则</strong> 的字段列再次单独建立联合索引或者单独的索引</p><p>即是否又需要建立 <code>(b,d)</code> 或者 <code>(c)</code> 这样的联合索引或者单独索引,这取决于查询的频率以及是否满足 <strong>索引覆盖</strong> 来优化查询</p><h3 id="索引下沉-也称为索引下推"><a href="#索引下沉-也称为索引下推" class="headerlink" title="索引下沉(也称为索引下推)"></a>索引下沉(也称为索引下推)</h3><p>对于那些不满足 <strong>最左匹配原则</strong> 的查询,用不上索引的字段列究竟如何完成检索</p><p>考虑如下 sql ,同时有联合索引 <code>(name, age)</code></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> students <span class="hljs-keyword">where</span> name <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;张%&#x27;</span> <span class="hljs-keyword">and</span> age <span class="hljs-operator">=</span> <span class="hljs-number">15</span><br></code></pre></td></tr></table></figure><p>根据 <strong>最左匹配原则</strong> 可以用到 <code>name</code> 这个索引,因为 <code>name</code> 后面有 <code>like</code> 语句,表明这是一个范围查询,所以后面的索引列停止匹配</p><p>此时假设存在以下数据:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7scjt909lj30lj07v41k.jpg" alt="img_1.png"></p><ul><li>在 mysql 5.6 版本以前,这样的查询只能通过在联合索引 <code>(name, age)</code> 上,通过 <code>name</code> 检索到第一个姓张的同学,得到对应的主键 id,然后回表查询对应的数据行,最后取出 <code>age</code> 字段返回结果集; 接着就是从 <code>name</code> 索引上依次遍历符合条件的主键 id,然后依次回表查询得到最终的完整数据</li></ul><p>可以看到的就是,每次查询都存在一个与之对应的回表操作,这无疑降低了查询的性能</p><ul><li>在 mysql 5.6 及以后的版本中,添加了一个新特性 <strong>索引下沉</strong></li></ul><p><strong>定义:将本来应该在 Server 层进行的过滤操作,下沉到存储引擎层完成; 在遍历索引的过程当中,预先过滤掉不满足索引条件的记录行,减少回表的次数</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7sck49cfpj30lp07zn0d.jpg" alt="img_2.png"></p><p>如果不使用索引下沉优化,则存储引擎只会根据索引 <code>name</code> 查找到所有姓张的同学,并依次回表查询到完整数据行返回给 Server 层</p><p>然后在 Server 层对结果集做 <code>age = 15</code> 的判断,筛选出满足查询条件的结果集</p><p>而对于使用索引下沉的优化来说,在检索联合索引 <code>(name,age)</code> 的时候,存储引擎就预先将 <code>age</code> 不满足条件的记录过滤掉; 将本来在 Server 层做的操作下沉到存储引擎层</p><p>这样最终需要回表的操作就只有 2 次了,减少了回表的次数,提高查询的性能</p><p><strong>索引下沉的条件,索引列中包含有待查询的字段,这样可以提前放到存储引擎来判断索引条件是否满足查询条件</strong></p><p>如果查询的是 <code>name</code> 和 <code>gender</code> ,由于索引列里面不包含 <code>gender</code> 即使将 <code>gender = 1</code>下沉到存储引擎,也无法通过索引覆盖得到 <code>gender</code> 值,还是需要依次回表查询才行</p><p>此时就失去了索引下沉的优化</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(二)mysql 事务隔离原理</title>
    <link href="/2022/11/03/mysql/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/"/>
    <url>/2022/11/03/mysql/(%E4%BA%8C)mysql%20%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="数据库事务的四大特性"><a href="#数据库事务的四大特性" class="headerlink" title="数据库事务的四大特性"></a>数据库事务的四大特性</h2><ol><li>原子性:事务里一组操作要么全部成功,要么全部失败,不会出现一半成功一般失败的情况</li><li>持久性:事务一旦提交后,其变更就会永久保存下来,即使发生宕机也不会出现数据丢失的情况</li><li>隔离性:不同的事务在并发提交时,其表现的结果看起来是串行化操作的结果</li><li>一致性:数据保证数据从一个正确的状态转移到另一个正确的状态</li></ol><p>一致性难以理解:它为数据库提供了一种 <strong>约束</strong> ,就是说每时每刻数据库都按照正确的方式运行</p><p>比如说我们约定某个字段不能等于 0,那么当我们执行插入 0 值,或者更新为 0 值时,数据库就不允许这种操作发生,因为违反了一致性</p><h3 id="事务的隔离级别"><a href="#事务的隔离级别" class="headerlink" title="事务的隔离级别"></a>事务的隔离级别</h3><ol><li>读未提交:最低的安全级别,事务当中还没有提交的改动能够被其他事务观察到</li><li>读已提交:一个事务的操作只有提交之后才能被其他事务观察到</li><li>可重复读:一个事务在执行过程中看到的数据,总是跟这个事务启动前的结果保持一致</li><li>串行化:所有的事务通过 <strong>加锁</strong> 完成同步操作,出现竞争时必须等待其他事务释放锁资源</li></ol><p>假设数据库只存在一条记录,事务启动前值为 1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofspyx5j309205ugm5.jpg" alt="img_3.png"></p><ol><li><p>读未提交时: 事务 A 的 v1 值已经可以查询得到 2,因为这个级别下可以观察到其他未提交事务发生的改动,所以 v1 &#x3D; v2 &#x3D; v3 &#x3D; 2</p></li><li><p>读已提交级别时: 事务 A 的 v1 值仍然是 1,因为这个级别下只能观察到其他已经提交事务的改动,而 v1 时事务 B 还没有提交,所以事务 B 的改动事务 A 并不能观察到</p></li></ol><p>当事务 B 提交后, v2 &#x3D; v3 &#x3D; 2</p><ol start="3"><li>可重复读:先说结论,v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 2</li></ol><p>可重复读保证了事务在执行过程中观察到的数据和其执行前保持一致,对于事务 A 来说,启动事务前观察到值为 1,那么在执行事务过程当中,再去观察仍然还是得到 1</p><p>只有当事务 A 提交后,再去查询才能得到 v3 &#x3D; 2</p><ol start="4"><li>串行化,由于事务 A 先查询值,所以当事务 B 更新值的时候,必须等待事务 A 执行完成之后才能继续操作</li></ol><p>所以 v1 &#x3D; v2 &#x3D; 1, v3 &#x3D; 1</p><h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>在实际数据库查询时,会创建一个 <strong>视图</strong> ,其作用可以理解为启动前所有数据的一个 <strong>快照</strong> ,并且这个 <strong>快照</strong> 在整个事务的执行过程中,不会被其他事务影响到</p><ol><li>读未提交:没有快照,直接读取数据的上一个最新状态</li><li>读已提交:每次执行 sql 前,创建快照</li><li>可重复读:每次事务启动前,创建快照</li><li>串行化:没有快照,通过加锁保证穿行操作</li></ol><h3 id="mysql-具体的隔离级别是如何实现的-以-可重复读-为例"><a href="#mysql-具体的隔离级别是如何实现的-以-可重复读-为例" class="headerlink" title="mysql 具体的隔离级别是如何实现的 以 可重复读 为例"></a>mysql 具体的隔离级别是如何实现的 以 <strong>可重复读</strong> 为例</h3><p>mysql 在每条记录发生操作之前,都会提前记录一个 <strong>回滚段</strong> 的日志 也被称为 <code>undo log</code> ,充分体现了 mysql 写前日志的特性,任何数据发生改变前,都要先记录日志</p><p>这个 undo log 类似于一条链表,记录了数据每个发生变更时的上一个状态</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rofzj9dkj30h4078abq.jpg" alt="img_4.png"></p><p>通过回滚操作,当前值 4 的状态可以回滚到之前记录过的任何一个状态</p><p>对于这条记录,处于不同时刻创建的事务,事故观察到的记录的状态均不一样</p><p>对于事务 A,B,C 来说,他们在启动时观察到的记录的值分别为 1,2,4, 这个特性就是 mysql 的 <strong>MVCC(多版本并发控制)</strong></p><p>同时根据视图快照的特性,对于视图 B 来说,如果有其他事务正在操作记录变更为 5,事务 B 也观察不到视图外面的改动</p><p><strong>注意,为什么说尽可能避免长事务,就是因为有 undo log 的存在,可能导致回滚链路非常长,造成磁盘空间的浪费</strong></p><p>详细说明一下这个 undo log 的组成</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rog6bdhhj30tw02ngmn.jpg" alt="img_5.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogb06x9j30fq02vt8z.jpg" alt="img_6.png"></p><p>第一部分主要是 undo log 记录的数据变更的具体信息等,用于回滚时反向操作数据用</p><p>第二部分则是构成回滚链的关键点,包含两个值</p><ol><li>trx_id: myslq 会为每一个事务分配一个 long 类型的唯一 id,这个 id 是递增的</li><li>roll_point: 这是一个只想 undo log 类型的指针,指向上一个旧数据版本的 undo log</li></ol><p>对于一个事务(trx_id &#x3D; 10)来说,在某一时刻操作数据,就会产生一条 trx_id &#x3D; 10,且 roll_point 指向上一个数据的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogfsah8j30ie05wgmn.jpg" alt="img_7.png"></p><p>若紧跟后面的事务(trx_id &#x3D; 18)也访问这条数据,那么就会产生一条 roll_point 指向 trx_id &#x3D; 10 的 undo log</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogkelk4j30ia07640c.jpg" alt="img_8.png"></p><p>对于事务 A 来说,他是观察不到事务 B 的任何操作的</p><h3 id="视图-快照"><a href="#视图-快照" class="headerlink" title="视图(快照)"></a>视图(快照)</h3><p>再有了 <code>undo log</code> 日志链之后,myslq 基于 <code>undo log</code> 实现了另一种数据结构 <strong>视图</strong> 也可称为 <strong>快照</strong></p><p>视图主要包含以下几个变量:</p><ol><li>创建视图时,当前正处于活跃状态的事务(即还没有提交的事务) ids 集合</li><li>活跃事务 ids 集合里面最小的事务 id, <code>min_id</code></li><li>活跃事务 ids 集合里面 <strong>下一个要生成的事务</strong> id,即当前 ids 里面最大的事务 id + 1, <code>max_id</code>, 这样下一个事务 id 一定比当前所有活跃事务的 id 都要大</li><li>创建当前视图的事务 id, <code>created_trx_id</code></li></ol><p>其中 <code>min_id</code> 也称为 <code>低水位</code>, 同理 <code>max_id</code> 称为 <code>高水位</code></p><p>现在使用两个事务 A,B 来模拟可重复读场景下, 视图是如何工作的; 假设事务 A 在提交之前反复读取数据; 事务 B 在提交之前修改数据</p><h4 id="快照读"><a href="#快照读" class="headerlink" title="快照读"></a>快照读</h4><p>此时事务 A 创建时,有两个事务正处于活跃状态,id&#x3D;10 和 id&#x3D;18</p><p>自然事务 A 此时创建的视图数据:ids&#x3D;[10,18], min&#x3D;10, max&#x3D;18+1&#x3D;19, created_trx_id&#x3D;10</p><p>还记得之前说过的吗,每条记录被写之前,都会产生一条 <code>undo log</code>,用于记录数据的旧值</p><p>此时事务 A 访问记录,将事务 A 指向最新的 <code>undo log</code>,里面保存了最后一个访问记录的状态,假设最后一个访问记录的事务 id &#x3D; 8,此时的 undo log 如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogpfk8aj30iz04emyi.jpg" alt="img_9.png"></p><p>事务 A 的 <code>undo log</code> 保存的最后一个访问记录的事务 id &#x3D; 8,意味着什么</p><p>之前也说过,myslq 会为每个创建出来的事务分配一个 long 类型的事务 id 即 trx_id ,这个 id 随着时间先后顺序依次递增</p><p>当前事务 A 的 trx_id &#x3D; 10,而 <code>undo log</code> 里面记录的最后一个事务的 trx_id &#x3D; 8</p><p>这说明这条记录是在事务 A 创建之前就已经提交过的了,自然 事务 A 是能够访问到这条记录的值 X</p><p>此时,事务 B 启动,并且去更新记录的值为 B,这个时候由于写操作产生,会提前记录一条 <code>undo log</code></p><p>其内容很好分析,创建 <code>undo log</code> 的 trx_id 等于操作的事务 trx_id 即 18,且 <code>undo log</code> 的回滚指针 <code>roll_point</code> 指向上一个旧数据,也就是值 X 时的记录</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogum90bj30if07zmyz.jpg" alt="img_10.png"></p><p>此时,在事务 B 更新了数据之后,事务 A 再次去查询记录,发现 <code>undo log</code> 链路上有最新的节点,即 trx_id &#x3D; 18 的记录</p><p>但是事务 A 并不能立马认为记录就被更新为 B 了,因为它还需要根据快照里面保存的内容去判断这条更新操作究竟能不能够被它访问到,过程如下</p><ol><li>事务 A 发现最新记录 <code>undo log</code> 里面更新的事务 trx_id &#x3D; 18</li><li>事务 A 查询自己的视图里面的活跃事务 ids 集合,发现有 trx_id &#x3D; 18 的记录存在</li><li>这说明事务 A 创建视图的时候,trx_id &#x3D; 18 的事务跟自己一样处于活跃状态,也就是 <strong>未提交</strong> 状态</li><li>这个时候的记录 B 是由未提交的其他事务产生的,在当前视图下是不可观察到的</li><li>所以事务 A 根据 <code>undo log</code> 的 <code>roll_point</code> 查看上一个旧的记录,发现 trx_id &#x3D; 8,小于自己的低水位</li><li>说明 trx_id &#x3D; 8 的记录是由已经提交的事务产生,在当前视图下是可以观察到的</li><li>最终事务 A 第二次查询记录得到的值仍然是 X</li></ol><p>简单总结如下:</p><ul><li>如果 trx_id 小于低水位,表示这个版本在事务启动前已经提交,可见</li><li>如果 trx_id 大于高水为,表示这个版本在事务启动后生成,不可见</li><li>如果 trx_id 大于低水位,小于高水位,分为两种情况:</li></ul><ol><li>若 trx_id 在数组中,表示这个版本在事务启动时还未提交,不可见</li><li>若 trx_id 不在数组中,表示这个版本在事务启动时已经提交,可见</li></ol><p>这就通过视图实现了可重复读的效果</p><h4 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h4><p>来看另一种情况,在可重复读级别下会发生什么</p><p>假设有 A,B,C 三个事务按照下图所示的方式操作数据</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rogzt3naj30fa0afwf7.jpg" alt="img_11.png"></p><p>假设此时 A,B,C 三个事务创建时,活跃的事务只有 trx_id &#x3D; 99,那么此时的快照分别如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7roh4s1lyj30et06ogo5.jpg" alt="img_12.png"></p><p>首先分析 A:</p><ol><li>get K 时,发现 k 的 undo log 指向数据为 (1,3) 的版本,且 trx_id &#x3D; 101</li><li>trx_id &#x3D; 101 大于事务 A 的高水位 100,说明这个版本不可见,往上查找 undo log</li><li>trx_id &#x3D; 102 大于事务 A 的高水位 100,同样不可见,继续网上查找 undo log</li><li>trx_id &#x3D; 90 小于事务 A 的低水位,可见,此时事务 A get k 的结果为 (1,1)</li></ol><p>接着分析 B:</p><ol><li>set K 时,创建新的 <code>undo log</code>,其 trx_id &#x3D; 当前更新数据的事务 id 101</li></ol><p>当按照一致性读的时候,写入 k 之前肯定要得到 k 的值,这里问题来了</p><p>事务 B 的高水位为 101,写入 k 之前的 <code>undo log</code> 版本为 102,此时是高于 B 的高水位的</p><p>也就是说如果按照一致性读来解释的话,B 应该只能拿到 90 版本的值 (1,1) ,从而在写之后更新版本 101 的值为 (1,2)</p><p>思考一个问题: C 在 B 之前已经更新了 k 值为 (1,2) 如果此时 B 按照一致性读取更新 K 值为 (1,2) 会导致 C 的更新丢失了</p><p>为了解决这个问题,mysql 引入了一个新的概念: <strong>当前读</strong></p><p>其含义就是: 所有的更新操作都是 <strong>先读后写</strong> ,而这个 <strong>读</strong> 必须是读取 <strong>当前最新的值</strong> ,不然以前的修改就会丢失</p><p>所以根据 <strong>当前读</strong> ,B 在更新 k 的时候,是已经能够拿到 C 的操作,所以 B 写入数据版本 101 的值为 (1,3)</p><p>随后 B 执行 get K 操作,一看当前最新的 <code>undo log</code> 的 trx_id &#x3D; 101 是自己,那当然可以读取到了</p><p>即,一个事务里面,之前发生过的更新操作,之后的查询操作一定能够观察到(自己写的数据自己认)</p><h4 id="两阶段锁协议"><a href="#两阶段锁协议" class="headerlink" title="两阶段锁协议"></a>两阶段锁协议</h4><p>考虑事务 C 修改为如下</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7rohbk3gnj30fc09gdgm.jpg" alt="img_13.png"></p><p>虽然事务 C 在事务 B 之前发起了更新操作,但是并没有立即提交,而是在事务 B 的更新操作之后才提交的</p><p>此时事务 B 会如何处理呢</p><p>由于事务 C 的 <code>update</code> 操作会为当前数据加上写锁,而事务 B 根据当前读原则,要求其更新数据时必须是当前的最新数据</p><p>但是当前数据上的写锁仍然被其他事务持有,所以事务 B 不得不等待事务 C 释放写锁后才能读取到事务 C 的最新改动,从而更新值</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>总结来说</p><p>可重复读的本质就是通过 <strong>视图</strong> 达到 <strong>一致性读</strong></p><p>但是在遇到更新操作是,就必须通过 <strong>当前读</strong> 来保证之前的更新不会丢失</p><p>如果更新的记录被其他事务持有写锁,根据 <strong>当前读</strong> 原则,必须等待其他事务释放写锁后,才允许继续更新记录</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>(一)mysql 日志系统</title>
    <link href="/2022/11/02/mysql/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/"/>
    <url>/2022/11/02/mysql/(%E4%B8%80)mysql%20%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="日志模块-redo-log-和-binlog"><a href="#日志模块-redo-log-和-binlog" class="headerlink" title="日志模块 redo log 和 binlog"></a>日志模块 redo log 和 binlog</h2><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>首先明确一点: mysql 是 <strong>先写日志,再写磁盘</strong>  这个和 redis 的 <strong>先写磁盘,再写日志</strong> 正好相反</p><p>mysql 写 <strong>前日志</strong> ,redis 写 <strong>后日志</strong></p><p>在存储引擎内,任何更新操作都会先记录 <code>redo log</code> 后,并更新内存数据,然后再适当的时候将 <code>redo log</code> 的数据回写到磁盘里</p><p>由此可知 <code>redo log</code> 是存储引擎持有的</p><h3 id="redo-log-组成"><a href="#redo-log-组成" class="headerlink" title="redo log 组成"></a>redo log 组成</h3><p>实际上 <code>redo log</code> 也是由两个部分组成</p><ol><li>redo log buffer</li><li>redo log file</li></ol><p>这也是为了解决内存和磁盘读写速率不一致的问题</p><p>所以 mysql 也需要提供一定的机制,保证将 <code>redo log buffer</code> 缓冲里面的数据,刷新到 <code>redo log file</code> 磁盘里持久化</p><p>mysql 运行在用户态,要想真正写入磁盘,必须通过 <code>os</code> 提供的 <code>os buffer</code> 进入内核态调用 <code>fsync()</code> 才能写入磁盘</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5h2r8mj30ca0a4tau.jpg" alt="img.png"></p><p>mysql 提供 3 种写入 redo log 的配置</p><ol><li>延时写:不会在事务提交时写入 <code>redo log</code>,而是每秒写入 <code>os buffer</code> 后在调用 <code>fsync()</code> 刷盘,发生宕机时会丢失大概 1s 的数据</li><li>实时写,实时刷:事务提交后,写入 <code>os buffer</code> 立即刷新到磁盘,性能低,但是数据可靠性最高,即使宕机也不会丢数据</li><li>实时写,延时刷:事务提交后,写入 <code>os buffer</code> 每隔 1s 中左右刷新磁盘,发生宕机会丢失大概 1s 的数据</li></ol><p>整个 <code>redo log</code> 的数据结构类似以个环形数组,通过两个指针 <code>write_pos</code> 和 <code>check_point</code> 来记录读写进度</p><p><code>write_pos</code> 记录当前已经写入的位置,随着新数据到来, <code>write_pos</code> 指针会不停地往后移动</p><p><code>check_point</code> 记录当前正要落盘的位置,每次将数据落盘之后,<code>check_point</code> 也会往后移动</p><p>如果新数据的写入速度,超过了落盘的速度,导致 <code>write_pos</code> 和 <code>check_point</code> 相遇了</p><p>此时就需要暂停新数据的写入,先将一部分数据落盘后,空出来的 <code>redo log</code> 空间才允许新数据写入</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp577ek3j30ll0cx764.jpg" alt="img_1.png"></p><p>这样,当事务提交后,由于 mysql 写前日志的特性,即使还没来得及完成刷盘操作,也能通过 <code>redo log</code> 的 <code>check_point</code> 之后保存记录来恢复事务</p><h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>在存储引擎有 <code>redo log</code> 的存在,在 Server 层自然也有对应的 <code>binlog</code> 来记录日志</p><p>对比下 <code>redo log</code> 和 <code>binlog</code> 的不同点</p><ol><li><code>redo log</code> 写物理日志, <code>binlog</code> 写逻辑日志<br>物理日志就是记录磁盘页的操作:在第 <code>x</code> 页磁盘,偏移量为 <code>y</code> 的位置,写入 <code>z</code> 个字节</li></ol><p><code>binlog</code> 写逻辑日志,也就是说 <code>binlog</code> 记录的是每一条实际操作的 sql 语句<br>由于 <code>redo log</code> 写的是物理日志,其记录了磁盘操作的本质,在数据恢复上就比逻辑日志的 <code>binlog</code> 快很多</p><ol start="2"><li><code>redo log</code> 是类似环形数组的循环写入,有固定的大小</li></ol><p>而 <code>binlog</code> 则是顺序追加写入文件,这样记录了所有操作过的 sql 语句</p><p><code>redo log</code> 的大小固定,不可能无限制地写入日志,所以 <code>check_point</code> 保证了在其之前的数据都是已经刷入磁盘的</p><p>不会保存历史记录,相对于 <code>binlog</code> 而言,节省了很多空间</p><p>同时由于 <code>binlog</code> 一直追加写,并没有什么标志位能够得知哪条记录之前的 sql 是已经刷入磁盘的,在做数据恢复的时候,难以定位哪些还未刷盘的日志</p><p>而 <code>redo log</code> 通过 <code>check point</code> 可以很方便的找到未刷盘的日志位置,从而进行数据恢复</p><ol start="3"><li><code>redo log</code> 是存储引擎 innoDB 独有的,<code>binlog</code> 是 mysql Server 层持有的,跟存储引擎无关</li></ol><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>以 <code>slq = 为 id = 2 的记录 c 值加 1</code> 为例,看看 mysql 具体的执行过程</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7qp5x282nj30cs0hkdik.jpg" alt="img_2.png"></p><ol><li><p>经过链接器,抛开查询缓存不谈,完成语法分析和分析,经过优化器来到执行器后</p></li><li><p>首先执行器调用存储引擎的接口检索 <code>id=2</code> 的记录,检查记录是否存在于 <code>buffer pool</code> 当中,若命中则直接执行器,否则将会从磁盘里面读出数据所在的 <strong>页</strong> 放入内存当中</p></li><li><p>执行器拿到 <code>id=2</code> 的记录后,对其 <code>c</code> 值完成加 1 操作后,在调用存储引擎的接口将其写入内存</p></li><li><p>存储引擎将更新后的数据写入内存后,立即写入 <code>redo log buffer</code> 当中,此时 <code>redo log</code> 处于 <code>prepare</code> 状态,然后返回到执行器</p></li><li><p>执行器接收到存储引擎完成数据写入后的响应,则记录当前 sql 到 <code>binlog</code> 里面,然后再调用存储引擎提交事务</p></li><li><p>存储引擎接收到执行器提交事务后的请求后,将刚刚 <code>redo log</code> 当中的 <code>prepare</code> 状态更新为 <code>commit</code></p></li></ol><p>可以看到整个过程当中,<code>redo log</code> 分别在不同的时期处于两种不同的状态,这个特性被称作 mysql 的 <code>两阶段提交</code></p><p>为何一个事务在写 <code>redo log</code> 的时候有两次操作,这个需要结合 <code>binlog</code> 解释下当事务提交时发生宕机后,如果通过 <code>binlog</code> 和 <code>redo log</code> 完成数据恢复</p><h4 id="mysql-数据恢复时的规则"><a href="#mysql-数据恢复时的规则" class="headerlink" title="mysql 数据恢复时的规则"></a>mysql 数据恢复时的规则</h4><ol><li>若 <code>redo log</code> 里面有 <code>commit</code> 记录,则直接提交当前事务</li><li>若 <code>redo log</code> 有 <code>prepare</code> 记录,则检查 <code>binlog</code> 是否有事务 <code>commit</code> 记录. 若 <code>binlog</code> 也有,则提交当前事务;若 <code>binlog</code> 没有,则回滚当前事务</li></ol><h4 id="如果先写-redo-log-再写-binlog"><a href="#如果先写-redo-log-再写-binlog" class="headerlink" title="如果先写 redo log 再写 binlog"></a>如果先写 redo log 再写 binlog</h4><p>若数据更新后,<code>redo log</code> 已经完成写入,此时再写入 <code>binlog</code> 发生宕机</p><p>在恢复数据的时候,检查到 <code>redo log</code> 里面已经有事务的 <code>commit</code> 记录,此时应该提交当前事务到数据库</p><p>此时主库完成事务提交, <code>c</code> 值已经被更新为 2</p><p>但是由于 <code>binlog</code> 没有记录,导致通过 <code>binlog</code> 同步到从库时,从库缺少了当前事务,从而导致主备的数据不一致</p><h4 id="如果先写-binlog-再写-redo-log"><a href="#如果先写-binlog-再写-redo-log" class="headerlink" title="如果先写 binlog 再写 redo log"></a>如果先写 binlog 再写 redo log</h4><p>若数据更新后先写入 <code>binlog</code>, 此时再写入 <code>redo log</code> 时发生宕机</p><p>在数据恢复的时候,检查 <code>redo log</code> 没有事务的 <code>commit</code> 的记录,从而主库缺少了当前事务的记录</p><p>而从库因为从 <code>binlog</code> 当中同步到了更新的事务,这也导致了主备的数据不一致</p><h4 id="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"><a href="#两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题" class="headerlink" title="两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题"></a>两阶段提交如何避免发生宕机后数据恢复时主备数据不一致的问题</h4><ol><li><code>redo log prepare</code> 之后,写 <code>binlog</code> 之前宕机</li></ol><p>恢复数据时,检查到 <code>redo log</code> 有 <code>prepare</code> 的事务,再去检查 <code>binlong</code> 的情况,发现 <code>binlog</code> 里面没有记录事务</p><p>此时需要回滚 <code>redo log</code> 里面的事务,即主库回滚未提交的事务</p><p>这样主备之间通过 <code>binlog</code> 同步时,都没有宕机前未提交的事务,保证主备之间的数据一致性</p><ol start="2"><li><code>binlog</code> 完成,写 <code>redo log commit</code> 时宕机</li></ol><p>数据恢复时,检查到 <code>redo log</code> 有 <code>prepare</code> 记录,再去检查 <code>binlog</code> 的情况,发现 <code>binlog</code> 里面也有事务的记录</p><p>此时需要将 <code>redo log prepare</code> 修改为 <code>commit</code>,将 <code>binlog</code> 里面记录的事务提交到主库</p><p>这样从库因为已经从主库同步了 <code>binlog</code> 执行了最新的事务,但是主库由于宕机导致事务没有提交,所以这时候检查后需要将 <code>binlog</code> 里面的时候重新在主库提交一遍,这样保证主备之间的数据一致性</p>]]></content>
    
    
    <categories>
      
      <category>mysql</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 的二次开发</title>
    <link href="/2022/10/31/gin/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/"/>
    <url>/2022/10/31/gin/gin%E7%9A%84%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h3 id="结合业务对-gin-做二次开发"><a href="#结合业务对-gin-做二次开发" class="headerlink" title="结合业务对 gin 做二次开发"></a>结合业务对 gin 做二次开发</h3><p>考虑下 gin 或者 go 原生的 http 包究竟为我们提供了哪些扩展点 <strong>根据开闭原则,对修改关闭,对扩展开放</strong></p><ol><li><p>go http Server</p></li><li><p>go http 包为我们提供了 Handler 接口</p></li></ol><p>其实 go 的 http 处理最终也是交给 <code>Handler</code> 去处理,这里可以通过实现这个接口来扩展自定义 http 框架(因为 go 也是这么做的)</p><ol start="3"><li>gin 的 <code>HandlerFunc</code> 中间函数,这个地方可以扩展的东西太多了,我们可以把各种和业务挂钩的 hook 函数全部添加到 <code>handlerChain</code> 里</li></ol><p>有点 <code>AOP</code> 的感觉嗷</p><h3 id="结合-fx-框架实现自定义启动和结束行为"><a href="#结合-fx-框架实现自定义启动和结束行为" class="headerlink" title="结合 fx 框架实现自定义启动和结束行为"></a>结合 fx 框架实现自定义启动和结束行为</h3><p><code>fx</code> 是 uber 开源的一款依赖注入框架,可以通过 <code>fx</code> 启动一个 <code>app</code> 服务,利用 <code>fx</code> 的 <code>hook</code> 函数,可以轻松地实现类似 <code>Spring</code> 的 <code>AOP</code> 能力</p><p>为 <code>fx</code> 容器注册启动和停止时的 <code>hook</code> 函数</p><p>首先根据前面总结的内容,启动 gin 服务,无非就是创建了一个 <code>http.Server</code> 容器而已</p><p>只不过 gin 通过实现 <code>Handler</code> 接口,实际上启动的是 gin 自定义的 <code>Engine</code> 对象而已</p><p>所以为了对 gin 做满足业务的二次开发,我们也通过同样的接口,定义我们自己的 <code>Server</code> 对象,并且让它配合 <code>fx</code> 框架完成启动和停止的自定义操作</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-comment">// 首先定义我们的自定义 `Server` 对象</span><br><span class="hljs-keyword">type</span> GinxServer <span class="hljs-keyword">struct</span> &#123;<br>server *http.Server<br>proxy  *ProxyGinEngine<br>&#125;<br><br><span class="hljs-keyword">type</span> ProxyGinEngine <span class="hljs-keyword">struct</span> &#123;<br>engine *gin.Engine<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStart() &#123;<br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br>    <span class="hljs-comment">// 注意</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server starting....&quot;</span>)<br>        <span class="hljs-comment">// 这里才是启动 gin 容器的关键代码</span><br>err := s.server.ListenAndServe()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;ginx listen and serve error: %s&quot;</span>, err.Error())<br>&#125;<br>&#125;()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *GinxServer)</span></span> OnStop() &#123;<br>fmt.Println(<span class="hljs-string">&quot;ginx server stoping....&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 使用我们自定义的 Server</span><br>s := &amp;GinxServer&#123;<br>server: &amp;http.Server&#123;<br>Addr: addr,<br>&#125;,<br><span class="hljs-comment">// 底层仍然是 gin 的引擎,不过对它做了一些扩展</span><br>proxy: &amp;ProxyGinEngine&#123;engine: gin.New()&#125;,<br>&#125;<br><br>    <span class="hljs-comment">// 注册我们的路由函数</span><br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/ping&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>,<br>&#125;)<br>&#125;)<br>s.Register(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-string">&quot;/hello&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>c.JSON(http.StatusOK, gin.H&#123;<br><span class="hljs-string">&quot;msg&quot;</span>: <span class="hljs-string">&quot;hello world&quot;</span>,<br>&#125;)<br>&#125;)<br><span class="hljs-keyword">return</span> s<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    ctx := context.Background()<br>app := fx.New(<br>fx.Provide(ginx.NewServer),<br>fx.Invoke(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(lc fx.Lifecycle, server *ginx.GinxServer)</span></span> &#123;<br>lc.Append(fx.Hook&#123;<br>OnStart: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStart()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>OnStop: <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(ctx context.Context)</span></span> <span class="hljs-type">error</span> &#123;<br>server.OnStop()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;,<br>&#125;)<br>&#125;),<br>)<br>    <span class="hljs-comment">// 注意通过 ide 启动 main 函数后,再通过 ide 结束是无法出发 OnStop 事件的</span><br>    <span class="hljs-comment">// 因为 ide 的结束是直接杀死进程,而不是通过信号量的方式结束进程</span><br>    <span class="hljs-comment">// 调用 fx.Stop() 时,会发送信号量来结束进程,这样 OnStop() 函数才能触发</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>time.Sleep(<span class="hljs-number">2</span> * time.Second)<br>app.Stop(ctx)<br>&#125;()<br>app.Run()<br>&#125;<br></code></pre></td></tr></table></figure><p>注意这里有个大坑,在 <code>OnStart()</code> 里一定要用协程去启动这个 gin 的监听函数</p><p>对于 fx 框架来说,所有 <code>hook</code> 函数都必须正常启动,fx 应用才算最终启动</p><p>如果这里没有用协程启动,那么 <code>OnStart()</code> 函数将会一直阻塞下去(因为 <code>ListenAndServe()</code> 阻塞),相当于这个 <code>OnStart()</code> 函数就一直没有返回</p><p>而 fx 框架在执行 hook 函数时,发现某个 hook 超时没有正确返回,就会认为启动 fx.App 失败,从而发出停止的信号量</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nn3ybz8gj30t803rjvk.jpg" alt="img.png"></p><h3 id="添加自定义-HandlerFunc-函数"><a href="#添加自定义-HandlerFunc-函数" class="headerlink" title="添加自定义 HandlerFunc() 函数"></a>添加自定义 HandlerFunc() 函数</h3><p>假如我们要对每个 http 请求统计其请求耗时,以及添加相关的埋点信息,应当如何扩展 gin 的 <code>HandlerFunc</code> 函数</p><p>首先可以知道的是,在 <code>ServeHTTP()</code> 最终会调用到 gin 重写的 <code>ServerHTTP()</code> 方法</p><p>里面 gin 通过遍历路由树,找到请求对应的路由节点,然后顺序执行节点的 <code>[]HanderFunc()</code> 函数列表</p><p>其中有个很关键的函数 <code>c.Next()</code> 就是用来遍历整个 <code>[]HandlerFunc()</code> 中间件函数的</p><p>所以我们的两个目标: 1. 新增请求埋点 2. 统计接口耗时  就需要在这个 <code>c.Next()</code> 函数上动文章</p><p>简单回顾下这个 <code>c.Next()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br>c.index++<br><span class="hljs-keyword">for</span> c.index &lt; <span class="hljs-type">int8</span>(<span class="hljs-built_in">len</span>(c.handlers)) &#123;<br>c.handlers[c.index](c)<br>c.index++<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到,在 gin 的自定义上下文 <code>Context</code> 通过 <code>index</code> 字段记录了当前执行的中间件函数的位置,一旦所有函数执行完成之后,就会返回</p><p>首先记录请求埋点肯定是先于业务函数的,所以在初始化 gin 容器的时候,在其他业务 <code>api</code> 注册之前,就应该先行注册埋点函数</p><p>改造 <code>NewServer()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> ginx<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewServer</span><span class="hljs-params">(addr <span class="hljs-type">string</span>)</span></span> *GinxServer &#123;<br><span class="hljs-comment">// 省略前面的初始化</span><br><br>    <span class="hljs-comment">// 首先添加埋点函数的注册</span><br>    <span class="hljs-comment">// 这样每次遍历 []HandlerFunc 的时候第一个都是 这个埋点函数</span><br>    s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>        <span class="hljs-comment">// req := c.Request</span><br><span class="hljs-comment">// header := c.Request.Header</span><br><span class="hljs-comment">// body := c.Request.Body</span><br><span class="hljs-comment">// do something with req or header or body</span><br>fmt.Printf(<span class="hljs-string">&quot;do something with request&quot;</span>)<br>    &#125;)<br><br>    <span class="hljs-comment">// 接着注册我们的统计耗时的函数</span><br>s.proxy.engine.Use(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>start := time.Now() <span class="hljs-comment">// 计算当前时间</span><br><span class="hljs-comment">// 注意这里调用 c.Next() 很关键</span><br>c.Next()<br>cost := time.Since(start) <span class="hljs-comment">// 计算耗时</span><br>fmt.Printf(<span class="hljs-string">&quot;cost time is %s&quot;</span>, cost.String())<br>&#125;)<br><br>    <span class="hljs-comment">// 省略业务路由的注册</span><br><span class="hljs-keyword">return</span> s<br>&#125;<br></code></pre></td></tr></table></figure><p>这里着重关注统计耗时的函数,在其内部再次调用了 <code>c.Next()</code> 函数</p><p>来看看调用链 :</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nmkujkcsj31240kegus.jpg" alt="1.png"></p><p>看看最终效果</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nqwvrx9zj30te0cowl4.jpg" alt="2.png"></p><p>可以看到埋点函数和统计耗时函数都能正常工作</p><p><strong>发现个很奇怪的地方,没来得及分析</strong></p><p>就是每次 gin 服务启动之后,第一次请求耗费的时间远长于后面的请求</p><p>有些情况下甚至第一次请求耗时是后面的几十倍</p><p>这个还没找到原因,如果有谁知道,可以通过博客的 <strong>About</strong> 页面取得联系方式告知我一下</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (三)</title>
    <link href="/2022/10/30/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/"/>
    <url>/2022/10/30/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%89)/</url>
    
    <content type="html"><![CDATA[<h2 id="http-连接的建立和监听"><a href="#http-连接的建立和监听" class="headerlink" title="http 连接的建立和监听"></a>http 连接的建立和监听</h2><p>前面用了介绍了 <code>engine</code> 容器的初始化, 处理 <code>http</code> 请求的流程, <code>Router</code> 路由树的生成和注册</p><p>接下来将了解下,一个 http 连接究竟是如何建立的,以及如何将流程扭转到 gin 去实际处理一个请求</p><h3 id="http-ListenAndServe-函数"><a href="#http-ListenAndServe-函数" class="headerlink" title="http.ListenAndServe() 函数"></a>http.ListenAndServe() 函数</h3><p>回到 <code>gin.Run()</code> 函数实现,里面有个 <code>http.ListenAndServe(address, engine)</code> 函数</p><p>通过入参和签名,很明显的告诉我们这个函数将监听在 <code>address</code> 的连接, 第二个参数 <code>engine</code> 猜测最终会把请求交给 <code>engine</code> 容器去处理</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfglt6d4j30is06yado.jpg" alt="img.png"></p><p>首先创建一个 <code>Server</code> 对象,将需要监听的地址,和处理器 (和 gin 的中间函数 <code>HandlerFunc</code> 区分下)</p><p>其实这里的处理器,就是我们之前初始化的 <code>engine</code> 容器,不过 <code>engine</code> 实现了 <code>Handler</code> 接口而已</p><p>这里可以充分体现出 gin 在设计上遵循 <strong>依赖接口而不是依赖实现</strong> 的原则</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgu7g3rj30i1088q68.jpg" alt="img_1.png"></p><p>这里的 <code>Serve</code> 对象感觉和 java 的 <code>Socket</code> 套接字很类似,监听并 <strong>阻塞</strong> 等待</p><p>既然是类似套接字,那么自然就能关闭,所以检查当前的套接字是否关闭,已经关闭了就不能再监听地址接受请求了</p><p>后面就是创建 <code>tcp</code> 链接,以及处理事件</p><h4 id="Listen-函数"><a href="#Listen-函数" class="headerlink" title="Listen() 函数"></a>Listen() 函数</h4><p>跟进 <code>net.Listen()</code> 函数和 <code>lc.Listen()</code> 函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>DefaultResolver.resolveAddrList(ctx, <span class="hljs-string">&quot;listen&quot;</span>, network, address, <span class="hljs-literal">nil</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>resolveAddrList()</code> 函数负责解析 <code>address</code> 的监听类型, 通过后面的逻辑可知,大致能够分为两类</p><ol><li>TCP 类型(通过 ip 地址加 port 端口,UDP 也类似)</li><li>UNIX 套接字类型???</li></ol><p>里面都是 go 原生的网络库实现,大致逻辑如下:</p><ol><li>解析 <code>ip</code> 地址,解析是 <code>ipv4</code> 还是 <code>ipv6</code> 的类型</li><li>尝试解析 <code>ip</code> 类型,如果不是一个合法的 <code>ip</code> 地址,就试着当做 <code>DNS</code> 地址解析</li></ol><p>接下来是为解析后的 <code>addr</code> 地址创建对应的的监听者对象 <code>sysListener</code> 这没什么好说的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl := &amp;sysListener&#123;<br>ListenConfig: *lc,<br>network:      network,<br>address:      address,<br>&#125;<br></code></pre></td></tr></table></figure><p>通过这个 <code>sysListener</code> 对象来完成实际的监听行为</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(lc *ListenConfig)</span></span> Listen(ctx context.Context, network, address <span class="hljs-type">string</span>) (Listener, <span class="hljs-type">error</span>) &#123;<br>sl.listenTCP(ctx, la)<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfgz7a1zj30ff04rgo3.jpg" alt="img_2.png"></p><p>这里面都涉及到 <code>unix</code> 底层的套接字编程,得到网络文件描述符 <code>fd</code> 完成后续操作,哎我也看不懂了</p><p>有空还要去拜读下 <code>unix</code> 的 <code>socket</code> 套接字编程,再回头看看这里应该会清晰很多</p><p>最后把创建的套接字对象 <code>fd</code> 注入到 <code>sysListener</code> 里,这样这个监听者就相当于已经就绪了,可以进行监听操作</p><p>返回到 <code>http.ListenerAndServe(ln)</code> 将 <code>listen()</code> 函数创建得到的监听者 <code>ln</code> 当做参数传入</p><h4 id="Serve-函数"><a href="#Serve-函数" class="headerlink" title="Serve() 函数"></a>Serve() 函数</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>origListener := l<br>l = &amp;onceCloseListener&#123;Listener: l&#125;<br><span class="hljs-keyword">defer</span> l.Close()<br>&#125;<br></code></pre></td></tr></table></figure><p>通过 <code>OnceCloseListener</code> 对象包裹原始的 <code>Listener</code> 对象</p><p>从字面意思上来说,就是只允许调用一次 <code>Close()</code> 避免重复关闭一个已经关闭了的 <code>Listener</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">if</span> !srv.trackListener(&amp;l, <span class="hljs-literal">true</span>) &#123;<br><span class="hljs-keyword">return</span> ErrServerClosed<br>&#125;<br><span class="hljs-keyword">defer</span> srv.trackListener(&amp;l, <span class="hljs-literal">false</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>将传入的监听者 <code>ln</code> 注入到 <code>Serve</code> 对象里, defer 保证了回收 <code>Serve</code> 的时候会把 <code>ln</code> 移除掉</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br>baseCtx := context.Background()<br><span class="hljs-comment">// ...</span><br>ctx := context.WithValue(baseCtx, ServerContextKey, srv)<br>&#125;<br></code></pre></td></tr></table></figure><p>创建一个空的 <code>Context</code> 对象,将 <code>Serve</code> 对象注入到上下文里</p><h4 id="阻塞监听"><a href="#阻塞监听" class="headerlink" title="阻塞监听"></a>阻塞监听</h4><p><strong>以上完成了所有准备,接下来开启一个死循环阻塞监听请求</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(srv *Server)</span></span> Serve(l net.Listener) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 调用监听者的 Accept() 函数,这是个同步阻塞函数</span><br><span class="hljs-comment">// 2022-10-30 本人无能,套接字编程,网络文件描述符相关的操作,实在是看不懂啊</span><br>rw, err := l.Accept()<br><br><span class="hljs-comment">// 当 l 监听到时间产生后, Accept() 函数返回,开始后面处理请求</span><br><span class="hljs-comment">// 可以通过启动 gin 的时候注册一个简单的 /ping 心跳路由</span><br><span class="hljs-comment">// curl 请求一下这个 /ping 路由即可</span><br><br><span class="hljs-comment">// 跳过监听得到的异常处理</span><br><br><span class="hljs-comment">// 这个 ConnContext 成员变量可以在初始化 Serve 对象的时候注入进去</span><br><span class="hljs-comment">// 本质是一个 func(ctx context.Context, c net.Conn) context.Context 函数变量</span><br><span class="hljs-comment">// 起作用是在得到一个新的 c 连接的时候,返回一个继承自 ctx 的新的上下文对象</span><br><span class="hljs-comment">// 具体怎么继承,以及要对这个新的上下文对象做什么处理,则有函数自行决定</span><br><br><span class="hljs-comment">// 这里要么使用原始的父 ctx 对象,要么通过 cc 函数得到个继承自 ctx 的新上下文对象</span><br>connCtx := ctx<br><span class="hljs-keyword">if</span> cc := srv.ConnContext; cc != <span class="hljs-literal">nil</span> &#123;<br>connCtx = cc(connCtx, rw)<br><span class="hljs-keyword">if</span> connCtx == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;ConnContext returned nil&quot;</span>)<br>&#125;<br>&#125;<br>tempDelay = <span class="hljs-number">0</span><br><span class="hljs-comment">// 将 http 裸的连接包成 conn 对象</span><br>c := srv.newConn(rw)<br>c.setState(c.rwc, StateNew, runHooks) <span class="hljs-comment">// before Serve can return</span><br><br><span class="hljs-comment">// 启动一个协程去处理接收到的连接 conn</span><br><span class="hljs-keyword">go</span> c.serve(connCtx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>Unix</code> 网络套接字编程是很复杂的,这里因为之前没有充分准备,导致很多 <code>Socket</code> 底层通过 <code>Unix</code> 提供的文件描述符进行网络操作的代码看不懂</p><p>后面补充了 <code>Socket</code> 相关知识后,一定要回来再看看这里</p><p>整个流程总结如下:</p><ol><li>Accept() 函数阻塞监听,直到请求过来返回 net.conn 裸的 http 连接</li><li>如果 Accept() 返回有异常,则处理异常</li><li>如果 Serve 初始化了 ConnContext 函数成员变量,这个函数会继承全局的 ctx 上下文得到一个新的上下文对象</li><li>将裸的 http.conn 包装为 serve 包下面的 conn 结构,新建一个协程,使用第 3 步得到上下文去处理请求</li><li>主协程通过死循环仍然继续阻塞监听 Accept() 函数,直到下一个请求进来 go to 1</li></ol><h4 id="实际的-serve-connCtx-函数"><a href="#实际的-serve-connCtx-函数" class="headerlink" title="实际的 serve(connCtx) 函数"></a>实际的 serve(connCtx) 函数</h4><p>接下来进一步解析这个 <code>serve()</code> 函数如何处理请求的</p><p><code>serve()</code> 函数很长,挑重点解析</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> serve(ctx context.Context) &#123;<br><span class="hljs-comment">// 上下文的设置</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// defer 定义了发生异常后的处理流程</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 检查和处理 tls 协议的链接,即 https 请求</span><br><span class="hljs-comment">// ..</span><br><br><span class="hljs-comment">// 非 tls 协议, http 请求的处理</span><br><span class="hljs-comment">// 创建一个带有</span><br>ctx, cancelCtx := context.WithCancel(ctx)<br>c.cancelCtx = cancelCtx<br><span class="hljs-keyword">defer</span> cancelCtx()<br><br><span class="hljs-comment">// 初始化 buffer reader 和 buffer writer</span><br><span class="hljs-comment">// 为读取连接和向连接发送内容做好准备</span><br>c.r = &amp;connReader&#123;conn: c&#125;<br>c.bufr = newBufioReader(c.r)<br>c.bufw = newBufioWriterSize(checkConnErrorWriter&#123;c&#125;, <span class="hljs-number">4</span>&lt;&lt;<span class="hljs-number">10</span>)<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 解析请求</span><br>w, err := c.readRequest(ctx)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>c.readRequest()</code> 函数将会实际处理 <code>conn</code> 对象的请求</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *conn)</span></span> readRequest(ctx context.Context) (w *response, err <span class="hljs-type">error</span>) &#123;<br><span class="hljs-comment">// 设置超时时间,最长读取时间,缓冲最大读取长度,等等参数</span><br><span class="hljs-comment">// 兼容一些老的客户端在发送 post 请求会后多带上了 /r/n 等换行符,从缓冲区读取的时候去掉这些字节</span><br><span class="hljs-comment">// ...</span><br><br><span class="hljs-comment">// 从缓冲区里读取请求内容</span><br>req, err := readRequest(c.bufr)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>readRequest(c.bufr)</code> 函数就是按照 <code>http 1.0</code> 规范解析请求报文</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfh60d1sj30ne03pwi9.jpg" alt="img_3.png"></p><p>首先解析报文行,得到请求方法,请求的协议和版本</p><p>紧跟着解析报文头,得到 <code>Header</code> 里面的值,处理 <code>Header</code> 里面约束的各种参数</p><p>校验一些协议和版本是否兼容,校验 <code>Header</code> 参数是否合法</p><p>最后通过传入的 <code>reader</code> 构造一个 <code>bufferWriter</code> 当做 <code>response</code> 的操作对象</p><h4 id="通过-ServeHTTP-函数扭转处理流程"><a href="#通过-ServeHTTP-函数扭转处理流程" class="headerlink" title="通过 ServeHTTP 函数扭转处理流程"></a>通过 ServeHTTP 函数扭转处理流程</h4><p>在前面通过 <code>readRequest()</code> 解析请求后,创建对应的 <code>http.response</code></p><p><strong>注意:重点来了,这个时候 go 原生的 net 网络包已经帮忙把一个 http 请求全部解析好; 这个时候就需要通过对外暴露的 ServeHTTP 接口把控制流程交给其实现类去处理; 否则请求将会由 go net 库自行处理掉</strong></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7nfhd792kj30iy0b1dld.jpg" alt="img_4.png"></p><p>跟进这个 <code>ServeHTTP()</code> 方法,在这里面实际上调用的是 <code>server.Handerl.ServeHTTP()</code> 方法</p><p>此时,终于把控制流程交给了 gin 去处理</p><p>回到 gin 框架里面,如果对 gin 的流程有些忘记了的话,可以看看第一张里面关于 <code>gin 如何通过 Handler 接口实现接收和响应请求</code><br>的部分</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img_5.png"></p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (二)</title>
    <link href="/2022/10/29/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/"/>
    <url>/2022/10/29/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%BA%8C)/</url>
    
    <content type="html"><![CDATA[<p>简单回顾: gin 从 <code>Run()</code> 函数启动容器之后</p><p>注册路由,添加路由中间函数的调用链</p><p>到使用 go 底层的 <code>net</code> 库绑定地址和端口,阻塞监听端口上的请求</p><p>到最后通过中间函数的调用链完成请求的处理</p><p>这里来看看 gin 容器是如何初始化的,都分别作了什么</p><h3 id="gin-容器的初始化"><a href="#gin-容器的初始化" class="headerlink" title="gin 容器的初始化"></a>gin 容器的初始化</h3><p>gin 提供了两个最常用的初始化方法</p><ol><li>gin.New()</li><li>gin.Default()</li></ol><p>其中 <code>Default()</code> 就是在 <code>New()</code> 的层面上,多添加了两个中间函数而已</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m78mblrej30ct049dhi.jpg" alt="img.png"></p><p>对于 <code>New()</code> 函数来说,在这里面初始化设置了 <code>engine</code> 对象的各种属性配置</p><p>比较关键的几个列出来单独说明下:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">New</span><span class="hljs-params">()</span></span> *Engine &#123;<br>engine := &amp;Engine&#123;<br>RouteGroup: RouteGroup&#123; <span class="hljs-comment">// 初始化路由组对象</span><br>Handlers: <span class="hljs-literal">nil</span>,<br>basePath: <span class="hljs-string">&quot;/&quot;</span>,<br>root:     <span class="hljs-literal">true</span>, <span class="hljs-comment">// 设置为根节点</span><br>&#125;,<br><span class="hljs-comment">// &#123;省略&#125; </span><br>trees: <span class="hljs-built_in">make</span>(methodTrees, <span class="hljs-number">0</span>, <span class="hljs-number">9</span>) <span class="hljs-comment">// 为 9 种 http 方法初始化路由树</span><br>&#125;<br><span class="hljs-comment">// 初始化 Context 池,减少上下文的频繁创建,提高内存复用率</span><br>engine.RouterGroup.engine = engine<br>engine.pool.New = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-keyword">interface</span>&#123;&#125; &#123;<br><span class="hljs-keyword">return</span> engine.allocateContext()<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="路由组的初始化"><a href="#路由组的初始化" class="headerlink" title="路由组的初始化"></a>路由组的初始化</h3><p>在有了 gin 容器之后,接下来需要做的就是为我们的 api 分类并设置路由组</p><p>就是把具有类似路由 path,隶属于同一个领域的 api 聚合到一个路由组里面,方便快速的查找路由</p><p>使用函数 <code>engine.Group()</code> 可以快速的聚合一组 api 路由</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m794m97bj30o305dn26.jpg" alt="img_1.png"></p><p>继续跟进 <code>engine.combineHandlers()</code> 函数一探究竟</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m799u5raj30mw06eaf6.jpg" alt="img_2.png"></p><p>之前接收到请求后,有个很关键的 <code>Next()</code> 函数,其遍历的所有 <code>handler</code>,都来自于路由组绑定的 <code>handlers</code></p><p>至于计算绝对路径的函数很简单,就是把上一个绝对路径和当前路由的 path 拼接到一块</p><h3 id="具体某个路由如何注册"><a href="#具体某个路由如何注册" class="headerlink" title="具体某个路由如何注册"></a>具体某个路由如何注册</h3><p>以 <code>engine.GET()</code> 函数为例,说一下一个具体的路由是如何注册到对应方法的路由组里去的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79eu2cwj30kt02z76o.jpg" alt="img_3.png"></p><p>调用 <code>engine.handler()</code> 函数完成实际的注册</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79jhejxj30od047q6k.jpg" alt="img_4.png"></p><p>其中 <code>calculateAbsolutePath()</code> 和 <code>combineHandlers()</code> 不在赘述</p><p>着重关注 <code>addRoute()</code> 是如何在路由树上添加路由</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> addRoute(method, path <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-comment">// 省略前置校验</span><br><br><span class="hljs-comment">// 检查当前 method 路由树的 root 节点是否存在,没有的话就创建为 root 节点</span><br>root := engine.trees.get(method)<br><span class="hljs-keyword">if</span> root == <span class="hljs-literal">nil</span> &#123;<br>root = <span class="hljs-built_in">new</span>(node)<br>root.fullPath = <span class="hljs-string">&quot;/&quot;</span><br>engine.trees = <span class="hljs-built_in">append</span>(engine.trees, methodTree&#123;method: method, root: root&#125;)<br>&#125;<br><span class="hljs-comment">// 重中之重,对路由树(前缀树)的处理</span><br>root.addRoute(path, handlers)<br><br><span class="hljs-comment">// 省略不重要的</span><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="addRoute-函数前缀树应用一探究竟"><a href="#addRoute-函数前缀树应用一探究竟" class="headerlink" title="addRoute() 函数前缀树应用一探究竟"></a>addRoute() 函数前缀树应用一探究竟</h3><p>有两个关键分支:</p><ol><li>root 为空创建前缀树根节点</li><li>root 非空,在前缀树上插入节点</li></ol><h4 id="root-为空创建空节点"><a href="#root-为空创建空节点" class="headerlink" title="root 为空创建空节点"></a>root 为空创建空节点</h4><p>以这组 RESTful api 为例说明:</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/:id/children&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/cat/play&quot;</span>)<br>r.<span class="hljs-built_in">GET</span>(<span class="hljs-string">&quot;/dog&quot;</span>)<br></code></pre></td></tr></table></figure><p>第一次添加 <code>method</code> 的路由前缀树时,创建了空的 root 节点,在判断当前节点 <code>path</code> 长度为 0,并且没有 <code>children</code> 子节点时,就需要初始化 root 节点</p><p>直接调用 <code>insertChild()</code> 函数将当前路由插入到 root 节点当中</p><p>首先判断当前 path 是否包含通配符,例如 <code>/cat/:id</code></p><p>首次创建 root 前缀树时,不应该直接使用 <code>/cat/:id</code> 作为 <code>full path</code> 而是需要把通配符 <code>:id</code> 单独切割出来,正确的 <code>full path</code> 应该是 <code>/cat/</code></p><p>函数 <code>findWildcard()</code> 返回通配符 <code>:</code> 或者 <code>*</code> ,以及通配符规则是否符合 <code>valid</code> 和通配符所处的下标</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(n *node)</span></span> insertChild(path <span class="hljs-type">string</span>, fullPath <span class="hljs-type">string</span>, handlers HandlersChain) &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 找到通配符的位置</span><br>wildcard, i, valid := findWildcard(path)<br><span class="hljs-comment">// 省略校验逻辑</span><br><span class="hljs-keyword">if</span> wildcard[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;:&#x27;</span> &#123; <span class="hljs-comment">// param</span><br><span class="hljs-comment">// 如果有通配符,则把通配符前面的 path 当做 root 节点的 path,而不是带有通配符的 path</span><br><span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span> &#123;<br><span class="hljs-comment">// Insert prefix before the current wildcard</span><br>n.path = path[:i]<br>path = path[i:]<br>&#125;<br><span class="hljs-comment">// 为当前 root 节点创建带有通配符的子节点</span><br>child := &amp;node&#123;<br><span class="hljs-comment">// 通配符节点类型为 param,表示在路由树上有个通过参数来区分的路由节点</span><br>nType:    param,<br>path:     wildcard,<br>fullPath: fullPath,<br>&#125;<br><span class="hljs-comment">// 将通配符路由当做子路由添加到当前路由节点 &#x27;/cat/&#x27; 上</span><br>n.addChild(child)<br><span class="hljs-comment">// 设置当前路由节点 &#x27;/cat/&#x27; 带有通配符节点</span><br>n.wildChild = <span class="hljs-literal">true</span><br><span class="hljs-comment">// 更新路由树的指针,继续对通配符节点查找后续的路由树,例如 &#x27;/cat/:id/children`</span><br><span class="hljs-comment">// 表示列出 :id 的 cat 的所有小猫咪 :)</span><br><span class="hljs-comment">// 所以这里需要更新指针指向子节点,继续递归解析</span><br>n = child<br><span class="hljs-comment">// 注意:这里设置的是子节点的 priority 优先级属性</span><br><span class="hljs-comment">// 可以看到在对 root 节点每添加一个子路由,都会让全链路的节点 priority 值 +1</span><br><span class="hljs-comment">// 越靠近根节点的 prioriy 值越大</span><br>n.priority++<br><br><span class="hljs-comment">// 如果当前路径不是以通配符结尾, 例如 `/cat/:id/children` </span><br><span class="hljs-comment">// 那么会继续解析后续的 `/children` 为更深层次的路由子节点</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(wildcard) &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[<span class="hljs-built_in">len</span>(wildcard):]<br><span class="hljs-comment">// 新添加的节点,其 prioriy 值从 1 开始计算,每过一个父节点都比下面的孩子节点大 1</span><br>child := &amp;node&#123;<br>priority: <span class="hljs-number">1</span>,<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n = child<br><span class="hljs-keyword">continue</span><br>&#125;<br><span class="hljs-comment">// 添加中间函数</span><br>n.handlers = handlers<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// 省略</span><br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>对于第一个带有通配符的路由 <code>/cat/:id</code></p><p>在切割 <code>:id</code> 之后,得到路由为 <code>:id</code> 的通配符子节点</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79o3oj4j30bp050gnm.jpg" alt="img_5.png"></p><h4 id="root-节点非空-往路由前缀树继续添加子路由"><a href="#root-节点非空-往路由前缀树继续添加子路由" class="headerlink" title="root 节点非空,往路由前缀树继续添加子路由"></a>root 节点非空,往路由前缀树继续添加子路由</h4><p>回到 <code>addRoute()</code> 函数,继续看 root 非空的情况是如何处理的</p><p>首先一上来就是一个 100 行的无限循环,代码有点长,仔细解读</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">addRoute</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-comment">// 从 root(n) 节点开始查找最长前缀的位置索引 i</span><br><span class="hljs-comment">// 这个函数很简单,双指针遍历比较找到第一个不相等的位置</span><br>i := longestCommonPrefix(path, n.path)<br><br><span class="hljs-comment">// 前面说过 gin 使用的紧凑型的前缀树,而非标准的字典前缀树,节省节点内存分配</span><br><span class="hljs-comment">// 如果当前节点是插入节点的子节点,则需要调整父子节点关系</span><br><span class="hljs-comment">// 例如已经插入 即 n = /cat/play/ball</span><br><span class="hljs-comment">// 现在插入 /cat/play</span><br><span class="hljs-comment">// 最后 n 变成 /cat/play, n.children = /ball</span><br><span class="hljs-comment">// 同理,如果继续添加路由 /cat</span><br><span class="hljs-comment">// n = /cat, n.c = /cat/play, n.c.c = /cat/play/ball</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(n.path) &#123;<br>child := node&#123;<br>path:      n.path[i:],<br>wildChild: n.wildChild,<br>indices:   n.indices,<br>children:  n.children,<br>handlers:  n.handlers,<br>priority:  n.priority - <span class="hljs-number">1</span>,<br>fullPath:  n.fullPath,<br>&#125;<br><br>n.children = []*node&#123;&amp;child&#125;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices = bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;n.path[i]&#125;)<br>n.path = path[:i]<br>n.handlers = <span class="hljs-literal">nil</span><br>n.wildChild = <span class="hljs-literal">false</span><br>n.fullPath = fullPath[:parentFullPathIndex+i]<br>&#125;<br><span class="hljs-comment">// 如果在先后顺序上符合父子关系,可以直接在节点 n 上创建对应的子节点</span><br><span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(path) &#123;<br>path = path[i:]<br>c := path[<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">// 处理参数节点后带有 &#x27;/&#x27; 的情况</span><br><span class="hljs-keyword">if</span> n.nType == param &amp;&amp; c == <span class="hljs-string">&#x27;/&#x27;</span> &amp;&amp; <span class="hljs-built_in">len</span>(n.children) == <span class="hljs-number">1</span> &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>n = n.children[<span class="hljs-number">0</span>]<br>n.priority++<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// 处理带有公共前缀的节点</span><br><span class="hljs-comment">// 解释一下 indices 的作用,这个字符串保存当前节点下所有孩子节点最长公共前缀之后出现的第一个字符</span><br><span class="hljs-comment">// 例如 /cat/run</span><br><span class="hljs-comment">// 添加 /cat/run_with_me</span><br><span class="hljs-comment">// run 和 run_with_me 有着公共前缀 run</span><br><span class="hljs-comment">// 这样 /cat/run_with_me 就会被继续拆分为子节点 _with_me</span><br><span class="hljs-comment">// 父节点为 /cat/run =&gt; _with_me</span><br><br><span class="hljs-comment">// 在举例,若有 /person/eat 和 /person/laugh</span><br><span class="hljs-comment">// 此时 /person 节点有 indince = le</span><br><span class="hljs-comment">// 添加新路由 /person/lying,此时发现 lying 和 l 有公共前缀 l</span><br><span class="hljs-comment">// 就会将 /laugh 节点拆分为 /l 作为父节点,包含两个子节点 augh 和 ying</span><br><span class="hljs-comment">// 最终 /person/ =&gt; eat 和 l</span><br><span class="hljs-comment">// /l =&gt; augh 和 ying ,且 a 的 indince = ay,eat 没有孩子,所以没有 indinces</span><br><span class="hljs-keyword">for</span> i, max := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(n.indices); i &lt; max; i++ &#123;<br><span class="hljs-keyword">if</span> c == n.indices[i] &#123;<br>parentFullPathIndex += <span class="hljs-built_in">len</span>(n.path)<br>i = n.incrementChildPrio(i)<br>n = n.children[i]<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 如果插入节点和当前节点不在同一个父节点上,则直接插入到前缀树里</span><br><span class="hljs-keyword">if</span> c != <span class="hljs-string">&#x27;:&#x27;</span> &amp;&amp; c != <span class="hljs-string">&#x27;*&#x27;</span> &amp;&amp; n.nType != catchAll &#123;<br><span class="hljs-comment">// []byte for proper unicode char conversion, see #65</span><br>n.indices += bytesconv.BytesToString([]<span class="hljs-type">byte</span>&#123;c&#125;)<br>child := &amp;node&#123;<br>fullPath: fullPath,<br>&#125;<br>n.addChild(child)<br>n.incrementChildPrio(<span class="hljs-built_in">len</span>(n.indices) - <span class="hljs-number">1</span>)<br>n = child<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> n.wildChild &#123;<br><span class="hljs-comment">// 如果当前节点是参数节点,往参数节点后面添加子节点</span><br>n = n.children[<span class="hljs-built_in">len</span>(n.children)<span class="hljs-number">-1</span>]<br>n.priority++<br><br><span class="hljs-comment">// Check if the wildcard matches</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(path) &gt;= <span class="hljs-built_in">len</span>(n.path) &amp;&amp; n.path == path[:<span class="hljs-built_in">len</span>(n.path)] &amp;&amp;<br><span class="hljs-comment">// Adding a child to a catchAll is not possible</span><br>n.nType != catchAll &amp;&amp;<br><span class="hljs-comment">// Check for longer wildcard, e.g. :name and :names</span><br>(<span class="hljs-built_in">len</span>(n.path) &gt;= <span class="hljs-built_in">len</span>(path) || path[<span class="hljs-built_in">len</span>(n.path)] == <span class="hljs-string">&#x27;/&#x27;</span>) &#123;<br><span class="hljs-keyword">continue</span> walk<br>&#125;<br><br><span class="hljs-comment">// Wildcard conflict</span><br>pathSeg := path<br><span class="hljs-keyword">if</span> n.nType != catchAll &#123;<br>pathSeg = strings.SplitN(pathSeg, <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-number">2</span>)[<span class="hljs-number">0</span>]<br>&#125;<br>prefix := fullPath[:strings.Index(fullPath, pathSeg)] + n.path<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;&#x27;&quot;</span> + pathSeg +<br><span class="hljs-string">&quot;&#x27; in new path &#x27;&quot;</span> + fullPath +<br><span class="hljs-string">&quot;&#x27; conflicts with existing wildcard &#x27;&quot;</span> + n.path +<br><span class="hljs-string">&quot;&#x27; in existing prefix &#x27;&quot;</span> + prefix +<br><span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br><br>n.insertChild(path, fullPath, handlers)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// Otherwise add handle to current node</span><br><span class="hljs-keyword">if</span> n.handlers != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;handlers are already registered for path &#x27;&quot;</span> + fullPath + <span class="hljs-string">&quot;&#x27;&quot;</span>)<br>&#125;<br>n.handlers = handlers<br>n.fullPath = fullPath<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果后插入的节点在 <strong>关系上</strong> 是先插入节点的父节点,则需要调整父子节点的关系</p><p>原先的父节点 <code>/cat/play/ball</code> ,后插入的节点 <code>/cat/play</code></p><p>从关系上来说,后者应该是前者的前驱 <code>/cat/play</code> ; 前者截断后变为子节点 <code>/ball</code></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m79vblj0j30a4055jsx.jpg" alt="img_6.png"></p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7m7aa05qlj30bb0a8q6w.jpg" alt="img_7.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>gin 使用紧凑前缀树实现路由树,减少树节点的个数,提高查找效率</li><li>gin 对通配符 :xxx 和 *xxx 两种类型的参数有些特殊限制,尤其小心在 *xxx&#x2F;other 这种路由,会导致 &#x2F;other 节点失效,具体原因是因为 *xxx 节点被设置为 cathAll 类型,<br>其后面的路由不再匹配,全部由 *xxx 提供服务</li><li>其中 priority 字段的设计,是为了让出现次数更多的路由前缀尽可能早的匹配到请求上,提升前缀树检索的性能</li><li>其中 indinces 的设计,是为了将路由子节点尽可能多的拆分出公共前缀,这样做的目的也是为了减少路由树中路由节点的个数,提升检索性能</li></ol><p>总之,还是有很多细节没有列举完成,包括对通配符节点的特殊处理和判断,都没有一一解释代码了</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gin 源码解读 (一)</title>
    <link href="/2022/10/28/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/"/>
    <url>/2022/10/28/gin/gin%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB(%E4%B8%80)/</url>
    
    <content type="html"><![CDATA[<h2 id="走进-Gin-的大门"><a href="#走进-Gin-的大门" class="headerlink" title="走进 Gin 的大门"></a>走进 Gin 的大门</h2><h3 id="启动-gin-服务"><a href="#启动-gin-服务" class="headerlink" title="启动 gin 服务"></a>启动 gin 服务</h3><p>启动 gin 服务很简单,代码里面只需要两行</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/gin-gonic/gin&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>r := gin.Default()<br>r.Run() <span class="hljs-comment">// listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)</span><br>&#125;<br></code></pre></td></tr></table></figure><p>跟进 <code>r.Run()</code> 方法一探究竟</p><h3 id="Run-方法"><a href="#Run-方法" class="headerlink" title="Run() 方法"></a>Run() 方法</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvpgnuj30m709ljx3.jpg" alt="img01.png"></p><p>可以看到 <code>Run()</code> 方法大概做了 3 件事</p><ol><li>解析配置的受信任 CIDRs 地址</li><li>如果有在启动时指定监听的地址,就解析对应 <code>addr</code> 地址</li><li>传入解析后的 <code>addr</code> 地址,并监听这个地址上的 http 事件</li></ol><p>通过上面的注释可知,其本质是 <code>http.ListenAndServe(addr, router)</code> 的一个实现</p><p>且 <code>Run()</code> 方法是一个阻塞方法,将会阻塞调用协程,除非异常发生</p><p>了解过 <code>Socket</code> 编程的应该都知道, <code>socket.Accept()</code> 就是一个阻塞方法,它会一直阻塞监听套接字绑定的 ip 和端口,直到收到请求数据才返回</p><p>可见 <code>http.ListenAndServe()</code> 也是一直阻塞并监听端口事件发生的</p><h3 id="http-ListenAndServe"><a href="#http-ListenAndServe" class="headerlink" title="http.ListenAndServe"></a>http.ListenAndServe</h3><p>这是 gin 的核心函数,其依赖于 go 语言内置的 <code>net</code> 库实现</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvnvo2j30ir06ladw.jpg" alt="img02.png"></p><p>注意,外面传入的是 <code>gin.engine</code> 到这里变成了 go 语言 <code>net</code> 库的 <code>Handler</code> 接口对象</p><p>可以看到的是 <code>gin.engine</code> 是实现了 <code>Hanler</code> 接口的</p><p>并且后续所有的 <code>request</code> 请求和 <code>response</code> 响应也都是通过这个 <code>Handler</code> 接口实现的</p><h3 id="gin-如何通过-Handler-接口实现接收和响应请求的"><a href="#gin-如何通过-Handler-接口实现接收和响应请求的" class="headerlink" title="gin 如何通过 Handler 接口实现接收和响应请求的"></a>gin 如何通过 Handler 接口实现接收和响应请求的</h3><p>跟进 <code>Handler</code> 接口,找到对应的 gin 实现 engine 对象</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvra9xj30jf06w42g.jpg" alt="img03.png"></p><p><code>engin.pool.Get()</code> 获取一个 gin 自己封装的 <code>Context</code> 对象,注意这里不是 go 原生的 <code>Context</code> 对象</p><p>可以看到 gin 使用了池化技术,做到内存复用,避免频繁的创建上下文</p><p>初始化 <code>Context</code> 对象时,把接收到的请求 <code>req</code> 也放到上下文里</p><p>进一步跟进 <code>handleHTTPRequest()</code> 函数看看 gin 究竟是如何处理请求的</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(engine *Engine)</span></span> handleHTTPRequest(c *Context) &#123;<br>httpMethod := c.Request.Method <span class="hljs-comment">// 解析 method</span><br>rPath := c.Request.URL.Path    <span class="hljs-comment">// 解析 url path</span><br>unescape := <span class="hljs-literal">false</span><br><span class="hljs-comment">// &#123;一些对 url path 的额外处理&#125;</span><br><br><span class="hljs-comment">// gin 维护了所有 method 的路由树集合</span><br>t := engine.trees<br><span class="hljs-keyword">for</span> i, tl := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(t); i &lt; tl; i++ &#123;<br><span class="hljs-comment">// 遍历路由树集合找到当前 method 对应的的路由树</span><br><span class="hljs-keyword">if</span> t[i].method != httpMethod &#123;<br><span class="hljs-keyword">continue</span><br>&#125;<br>root := t[i].root<br><span class="hljs-comment">// 从 root 节点开始查找路由树,直到查找到 path 对应的路由</span><br>value := root.getValue(rPath, c.params, unescape)<br><span class="hljs-keyword">if</span> value.params != <span class="hljs-literal">nil</span> &#123;<br>c.Params = *value.params<br>&#125;<br><span class="hljs-comment">// 如果路由有配置 handler 函数</span><br><span class="hljs-keyword">if</span> value.handlers != <span class="hljs-literal">nil</span> &#123;<br>c.handlers = value.handlers<br>c.fullPath = value.fullPath<br><span class="hljs-comment">// Next() 函数会依次执行路由配置的所有 handler 函数</span><br>c.Next()<br>c.writermem.WriteHeaderNow()<br><span class="hljs-keyword">return</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br><span class="hljs-comment">// &#123;后续处理&#125;</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这里有两个关键点 <code>engine.trees</code> 路由树 和 <code>Next()</code> 函数</p><h3 id="先来看-Next-函数"><a href="#先来看-Next-函数" class="headerlink" title="先来看 Next() 函数"></a>先来看 Next() 函数</h3><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvsw2xj30io05y0vq.jpg" alt="img04.png"></p><p>还记得之前的 <code>gin.engine</code> 对象吗? <code>engine</code> 实现了 <code>ServeHTTP</code> 接口,在里面封装了 gin 关于 http 请求的处理</p><p>其中 <code>c.reset()</code> 初始化 <code>Context</code> 上下文对象的时候,有设置 index 的值为 -1</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmytfj309203fgm8.jpg" alt="img05.png"></p><p>这说明还没有 <code>handler</code> 函数处理的时候,<code>Context</code> 上下文里面保存的处理索引是从 <code>-1</code> 开始计算</p><p><code>Next()</code> 函数里,一来就让 index 自增 <code>c.index++</code> 后 index &#x3D; 0,说明从第 0 个 <code>handler</code> 函数开始依次执行</p><p>而 <code>handleHTTPRequest()</code> 函数在从路由树当中找到请求对应的路由节点后,如果发现这个路由有配置过 <code>handler</code> 函数,则会把路由配置的 <code>handler</code> 函数全部赋值给 <code>Context</code> 上下文 <code>c</code> 里</p><p>这样就相当于通过上下文 <code>c</code> 依次执行路由配置的 <code>handler</code> 函数处理请求,而每次执行 <code>handler</code> 之后,都会使 <code>index</code> 自增</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gin<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Context)</span></span> Next() &#123;<br><span class="hljs-comment">// 关注核心代码</span><br>c.handlers[c.index](c)<br><span class="hljs-comment">// c.index 表示当前待执行的索引</span><br><span class="hljs-comment">// c.handlers[] 数组</span><br><span class="hljs-comment">// c.handlers[c.index] 相当于取出处于 index 的 handler 函数</span><br><span class="hljs-comment">// 而 handler 函数的签名是 func (c *Context)</span><br><span class="hljs-comment">// 可以理解为 c.handlers[c.index] = func (c *Context)</span><br><span class="hljs-comment">// 所以 c.handlers[c.index](c) 相当于把 c 又当做参数传给了 handler 函数</span><br>&#125;<br></code></pre></td></tr></table></figure><p>除非设置了 <code>AbortIndex</code> 的值终止 <code>handlers</code> 的遍历,否则会执行完所有配置的 <code>handlers</code> 函数才会结束请求的处理</p><h3 id="engine-trees-路由树"><a href="#engine-trees-路由树" class="headerlink" title="engine.trees 路由树"></a>engine.trees 路由树</h3><p>接下来在看看路由树的是怎么实现的</p><p>一路跟进去看源码</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvmodrj308903yq3f.jpg" alt="img06.png"></p><p>可以看到 gin 维护了一个 <code>[]methodTree</code> 数组,数组里面每个元素都是一个路由树节点对象,分别保存了当前路由的方法 <code>method</code> 和当前路由的根节点 <code>root</code></p><p>继续跟进树节点 <code>node</code> 看看怎么实现的</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvxqjkj30m5062q5u.jpg" alt="img07.png"></p><p>其实路由树就是一棵 <strong>紧凑前缀树</strong></p><p>前缀树利用字符串的公共前缀来减少查询时间,而路由则天生符合前缀的特性</p><p>例如有以下几个路由:</p><ol><li>&#x2F;</li><li>&#x2F;order</li><li>&#x2F;order&#x2F;:name</li><li>&#x2F;order&#x2F;:id</li></ol><p>可以看到这些路由都有根节点 <code>/</code> ,同时下面三个路由都有重复节点 <code>/order</code></p><p>普通的前缀树保存每个字符,而 gin 使用 <strong>紧凑前缀树</strong> 保存每个路由节点,减少了内存的使用,提高查询效率</p><p>此时生成的路由前缀树如下:</p><p><img src="https://tva1.sinaimg.cn/large/008vK57jgy1h7kefvvkzyj307007z74p.jpg" alt="img08.png"></p><p>通过路由树可以快速的检索到对应的的路由节点,至于路由如何注册在这里暂且不表</p><h3 id="回到-handleHTTPRequest-方法"><a href="#回到-handleHTTPRequest-方法" class="headerlink" title="回到 handleHTTPRequest() 方法"></a>回到 handleHTTPRequest() 方法</h3><p>在经历了路由检索, <code>handler</code> 函数的处理,此时一笔请求就已经全部执行完毕了</p><p>通过 <code>c.WriteHeaderNow</code> 将 http 状态写回 header 后,当前请求的处理协程结束</p><p>主协程仍然阻塞在 <code>accept()</code> 监听方法上,通过 channel 来启动协程继续处理后续的请求</p><p>至此,一笔请求就被完整的处理完并返回给调用方</p><p>剩余的细节:</p><ol><li>go 内置的 net 网络通信库,如何建立连接,监听请求,前置处理</li><li>gin 注册路由如何生成路由树</li></ol><p>后面再说吧</p>]]></content>
    
    
    <categories>
      
      <category>gin</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/10/27/hello-world/"/>
    <url>/2022/10/27/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
