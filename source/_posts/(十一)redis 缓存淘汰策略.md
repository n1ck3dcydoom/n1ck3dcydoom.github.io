---
title: (十一)redis 缓存淘汰策略
date: 2022-11-12 20:21:06
index_img: /img/redis.png
categories:
  - redis
tags:
  - redis
---

### redis 的缓存淘汰机制

想要淘汰一个缓存,有两步关键的步骤

1. 通过一定的策略,选出 **需要被淘汰** 的缓存
2. 在合适的时机,将这些缓存从内存里删除

一旦 redis 实例配置好整体缓存的大小之后,除非是只读缓存否则总会发生缓存被写满的那一刻

而淘汰缓存就必须要解决上面两个问题:如何选?什么时候删?

### redis 缓存淘汰策略(解决如何选问题)

redis 在 4.0 以后提供了 8 种缓存淘汰策略

1. 不进行缓存淘汰,只有 `noeviction` 这一种 (通常也没有人会选择这种策略)
2. 会进行缓存淘汰的其他 7 种策略还可以按照两类进行划分
   * 设置了过期时间的数据
   * 所有范围内的数据

#### 设置了过期时间数据的淘汰策略

1. volatile-ttl: 在筛选时,针对设置了过期时间的键值对,根据过期时间的先后进行删除,越早过期的数据越早被删除
2. volatile-random: 在筛选时,针对设置了过期时间的键值对,随机选出若干数据进行删除
3. volatile-lru: 在筛选时,针对设置了过期时间的键值对,使用 `LRU` 算法选择需要淘汰的数据
4. volatile-lfu: 在筛选时,针对设置了过期时间的键值对,使用 `LFU` 算法选择需要淘汰的数据

#### 所有数据的淘汰策略

1. allkeys-random: 针对所有数据随机选择并删除
2. allkeys-lru: 针对所有数据,使用 `LRU` 算法选择需要淘汰的数据
3. allkeys-lfu: 针对所有数据,使用 `LFU` 算法选择需要淘汰的数据

需要注意的是,如果 redis 配置的是针对所有数据的淘汰策略; 那么按照策略选出来的数据即使还没有到过期时间,也会被淘汰掉


### LRU 算法

`LRU` 算法即 `最近最少使用` , 可以把一段时间内最不常用的数据筛选出来,而那些频繁被访问的热数据则会继续留在缓存里面

`LRU` 会把所有缓存页组织为一条链表,表头是 `MRU端` 表尾是 `LRU端`

![img.png](https://tva1.sinaimg.cn/large/008vK57jgy1h83ayzqhv2j30ih0iijvw.jpg)

当 `LRU` 缓存里面有数据被命中了,则会被放置到表头; 而那些迟迟没有命中的数据则会随着时间推移慢慢来到表尾

当 `LRU` 被放满,而新的请求数据不在 `LRU` 里面,此时 `LRU` 发生了缺页就会从磁盘里面加载最新的数据页放到表头; 这样处于表尾的冷数据就会被淘汰掉

朴素的 `LRU` 根据局部性原理,认为当前被访问的数据接下来还会访问的概率会很大,所以直接放到表头; 而 `LRU` 当有大量数据被访问时(类似 mysql 全表扫描导致 `buffer pool` 缓冲区污染的问题),会带来很多链表节点的移动操作,此时可能会导致 redis 性能下降

redis 在朴素 `LRU` 算法上进行了一些改良,并没有通过传统的链表组织数据

redis 会记录每个数据的最近一次访问时间戳(由 redis 的抽象数据结构 `redisObject` 记录),这个字段记为 `lru` 值

当 redis 需要淘汰数据时,首次会根据配置一次性选出 `N` 个数据放到一个集合里面; 接下来 redis 会比较这 `N` 个数据的 `lru` 值,把最小 `lru` 值的数据淘汰出去

后续再次需要进行数据淘汰的时候,redis 会把需要淘汰的数据加入到第一次淘汰时的集合里面去; 这里能够进入淘汰集合的要求是: `能进入淘汰集合的数据的 lru 字段必须必集合里面的最小 lru 值还要小`

当淘汰集合放满之后,redis 就会把集合中 `lru` 最小的数据淘汰出去

这样 redis 就不用维护一个所有数据的链表,也不用每次移动链表节点,只需要比较 `redisObject` 的 `lru` 字段即可, 提升了缓存的性能

* 如果系统有明显冷热数据的情况,优先选择 `allkeys-lru` 策略
* 如果系统没有明显的冷热数据区分,选择 `allkeys-random` 进行随机淘汰就可以
* 如果系统有 **置顶** 等要求,则选择 `volatile-lru` 策略,并且将这些置顶的数据设置为永不过期

### 如何删除被淘汰的数据

与 mysql 的 `buffer pool` 淘汰缓存页类似,同样 redis 也将缓存页分为 `干净页` 和 `脏页` 

* 如果需要淘汰的是一张 `干净页` ,那么直接从内存里面出删除即可

* 如果淘汰的是一张 `脏页` ,那么从内存删除前还需要把脏页刷入数据库之后才能删除

### 缓存污染问题

什么是缓存污染,就是在某些场景之下,有些数据被访问的次数非常少,甚至只有一次,但是仍然停留在缓存里面,造成缓存空间的浪费

当缓存污染不严重时,新数据还能继续被加入缓存中使用; 当缓存污染占用了较大的空间后,缓存空间已经被用完之后,新数据页想要进入缓存就必须淘汰掉部分页,这就引入了额外的性能开销

#### 如何解决缓存污染

最直接的想法就是,把那些缓存命中率很低的数据筛选出来并淘汰掉

#### redis 的 8 种缓存淘汰策略

1. noeviction: 不淘汰缓存
2. 针对设置了过期时间的数据:
   * volatile-random: 随机从设置了过期时间的数据中选择部分进行淘汰
   * volatile-ttl: 从设置了过期时间的数据淘汰掉已过期的数据
   * volatile-lru: 使用 `LRU` 算法淘汰部分设置了过期时间的数据
   * volatile-lfu: 使用 `LFU` 算法淘汰部分设置了过期时间的数据
3. 针对所有数据:
   * allkeys-random: 随机从所有数据中选择部分进行淘汰
   * allkeys-ttl: 从所有数据中淘汰掉已过期的数据
   * allkeys-lru: 使用 `LRU` 算法部分淘汰所有数据
   * allkeys-lfu: 使用 `LFU` 算法淘汰部分所有数据

对于两种随机淘汰策略,很难准确选出那些缓存利用率低的数据,所以在解决缓存污染上效果并不好

对于两种判断过期时间的策略,由于过期时间并不能反映出缓存的利用率,很可能存在过期时间很长但是几乎不被命中的数据,,所以在解决缓存污染上效果也不好

除非明确知道有些数据会在什么时候过期,这样当数据不可用之后,自然会被淘汰掉,避免一直留在缓存里面造成污染,但这些数据在真实的服务中,只是很少一部分,绝大多数的数据都无法准确得知其在什么时候应该失效

#### LRU 如何避免缓存污染

简单回顾下 `LRU` 的过程:

1. 首次随机选择 `N` 个数据放入淘汰集合当中,根据 `redisObject` 的 `lru` 字段排序后,最小的将会被淘汰掉
2. 后面每次需要淘汰数据时,都放入淘汰集合当中,然后淘汰掉 `lru` 字段最小的数据; 这里要能进入淘汰集合的要求是小于淘汰集合当中最小的 `lru` 值
3. 重复步骤 2

一般场景下,缓存命中率高的数据会在 `LRU` 里面停留较长的时间,那些命中率低的数据则会在适当的时机呗淘汰掉,对于减轻缓存污染的影响有一定作用

但是对于类似 mysql 的全表扫描场景这时候 `LRU` 的表现就很糟糕; 这种场景下,每个数据记录的 `lru` 值都很大,在进入缓存后很难被 `LRU` 算法淘汰掉,而且这些数据又占用了大量空间

当有新数据需要进入缓存时,因为缓存被大量数据污染,又会进行淘汰,还是会影响 redis 的性能

#### LFU 如何避免单次扫描大量数据导致的缓存污染

在 redis 4.0 之后,引入了新的缓存淘汰算法 `LFU`

`LFU` 即最不经常使用: `LFU` 淘汰那些在一定时间范围内,使用次数最少的数据页
`LRU` 是最近最少使用: `LRU` 淘汰那些最长时间没有被使用过的数据页

为了统计使用次数,`LFU` 在 `LRU` 的基础上将 `redisObject` 的 `lru` 字段稍加改善: `把原来的 24 位长度的字段拆分为前 16 位用于记录时间戳,后 8 位用于记录访问次数`

当进行 `LFU` 淘汰时,会在淘汰集合里面选出访问次数最少的数据进行淘汰; 如果选出来的数据访问次数都相同,再根据 `lru` 值最小的数据进行淘汰

问题点 1: `8bit` 最多只能表示 256 次,但实际上一个数据被访问的次数很可能超过这个次数,这样 `LFU` 在次数到达 256 次之后,就不能新增计数,从而导致 `LFU` 统计不准

redis 为了避免 `8bti` 很快被使用完的问题,引入了对计数的优化,新增了一个计数因子 `lfu_log_factory` 字段,可以简单理解为这个计数因子导致最终的技术并不是 `线性增长` 的

官方给出了不同的计数因子下,达到 `255` 所需要的实际次数

![img.png](https://tva1.sinaimg.cn/large/008vK57jgy1h83lg791zoj30j904pac9.jpg)

问题点 2: 当有些数据在短时间内被大量访问过后,导致其引用计数很大,但是从此以后再也不会被访问了,此时的 `LFU` 该怎样筛选出这些造成污染的数据

为了解决这个问题,redis 还引入了 `lfu_decay_time` 计数衰减因子,简单来说就是数据的引用计数次数,会随着这个 `计数衰减因子` 而不断减少

所以那些短时间内被大量访问的数据,之后由于计数衰减因子的存在,其引用计数次数会不断地减少; 直到最后被 `LFU` 淘汰掉

### 总结

可以看到,在应对缓存污染这个问题上

* 不淘汰缓存 noeviction
* 随机淘汰缓存 volatile-random 和 allkeys-random
* 按照过期时间淘汰缓存 volatile-ttl 和 allkeys-ttl

这几种淘汰策略要么无法避免缓存污染,要么就是对降低缓存污染的效果很小

* `LRU` 在一般场景下,可以很好的避免缓存污染,但是无法处理 `单次扫描式查询`
* `LFU` 则可以很好的解决 `LRU` 无法处理的 `单次扫描式查询` 但是要求 redis 版本在 4.0 以上