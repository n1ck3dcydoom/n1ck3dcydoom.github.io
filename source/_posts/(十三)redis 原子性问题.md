---
title: (十三)redis 原子性问题
date: 2022-11-13 16:56:37
index_img: /img/redis.png
categories:
  - redis
tags:
  - redis
---

### 并发场景下如何保证正确性

并发读取一个数据不需要额外考虑,因为本身读操作之间是共享的

并发写一个数据则需要考虑互斥问题,同一时间对于同一个数据来说只能有一个线程进行写操作,其他线程都必须等待; 不然就会导致严重的并发问题

![img.png](https://tva1.sinaimg.cn/large/008vK57jgy1h83sa17v4wj30iu0bo400.jpg)

例如这个例子,线程 A 和线程 B 同时更新一个库存值,由于并没有任何额外的并发控制,导致最终的数据表现和预期不一致

这是由于线程对库存的可以拆分为 3 个子步骤:

1. 获取当前的库存值
2. 当前库存值-1
3. 将最新的库存值写入缓存

而这 3 个子步骤之间并没有通过任何方式进行并发控制,导致多个线程同时操作,最后出现数据不一致的问题

最简单的解决并发安全问题的手段有两个

1. 加锁使之串行化
2. 使用原子操作

#### 加锁

加锁是解决并发问题的最简单最直接的方式,但是加锁和释放锁会明显的导致系统并发性下降,同时这两个过程也会增大请求的响应耗时

如果是分布式服务,还必须引入分布式锁,这也会加大系统的复杂程度

### redis 提供的原子操作

为了实现并发操作临界区资源,redis 提供了两种方式保证指令的原子性

1. 将多条指令通过一个 `Lua` 脚本的方式提交给 redis 执行
2. 将多条指令合并为 1 条指令执行

#### redis 的单指令操作

因为 redis 的核心线程只有一个,所以当主线程执行一条指令的时候,就无法执行其他指令; 有这个特性就能够保证 redis 在执行单指令的时候一定是一个原子操作

对于数据的加减,有原子增和原子减,即 `INCR/DECR` ,多个线程并发执行原子增/减指令,其最终效果与串行化执行表现一致

还例如使用 redis 作为分布式锁时,通常需要在加锁前先判断锁是否可获取

```
get lock
if (got) {
    set lock
}
// do something with lock
del lock
```

可以看在一次分布式锁的获取过程当中,先判断,在加锁是两个步骤,如果直接提交的话是无法保证原子性的

redis 提供了 `set if not exist` 类似的单指令操作,用于实现最简单的分布式锁

#### redis Lua 脚本

如果一个业务无法使用 redis 提供的单指令完成,又要保证其原子性,就必须使用 `Lua` 脚本

将多条指令放入一个 `Lua` 脚本里面提交给 redis 执行,redis 会把 `Lua` 脚本当做一个整体去执行,在这个执行过程当中不会被其他指令打断,从而保证了 `Lua` 脚本的原子性

### redis 如何实现分布式锁

前面说到,想要保证并发安全问题,除了原子操作以外,还有个最简单解决并发问题的方案,那就是加锁使命令串行化

对于一个分布式系统来说,锁都必须要求是所有其他系统都能访问到的,而不是只属于某个服务的 **本地锁**; 这要求锁必须保存到一个能够被多个客户端共享访问的系统上,redis 正好就是一个共享存储的系统,所以可以使用 redis 来实现分布式锁

#### 单节点 redis 实现分布式锁

最简单的 redis 锁实现就是通过一个变量,来判断这个变量值来决定是上锁还是没有上锁; 例如约定 `锁变量 == 1` 表示已上锁,而 `锁变量 == 0` 表示没有上锁

由于是单节点 redis,而且 redis 的核心线程也只有 1 个,即使线程 A 和 C 同时发出加锁请求,redis 也只能串行化处理; 所以同一时间内最多只能有 1 个线程能够持有锁

![img_1.png](https://tva1.sinaimg.cn/large/008vK57jgy1h83sa6z51vj30hx0e0q5i.jpg)

释放锁的过程也很简单,就是把对应锁变量的值修改为 `0`, 这样其他线程就能继续持有和释放这同一把锁

![img_2.png](https://tva1.sinaimg.cn/large/008vK57jgy1h83sacwjkyj30gt0d6jt1.jpg)

简单分析可以发现,上锁的过程包含好几个步骤:

1. 获取锁变量的值
2. 判断锁变量值是否等于 `0`
3. 如果等于 `0` 则设置锁变量的值为 `1` 表示当前线程已经持有这把锁
4. 如果等于 `1` 则上锁失败,继续等待下一次请求上锁

而这些步骤再实际执行时,因为可能存在并发安全的问题,所以必须保证原子性

redis 对于分布式锁的实现,提供了一条单指令 `SETNX` 其效果等于 `SET key value IF NOT EXIST`: 如果 `key` 不存在的话就设置对应的键值对数据; 如果 `key` 已经存在,则不做任何操作

这里的锁变量不再是某个变量值是否为 `0` 或者 `1` ,而是直接判断某个变量存在与否; 当不再需要锁是,直接 `DEL key` 删掉变量即可

#### SETNX 指令实现的分布式锁的潜在风险

上述方案并不是完美的分布式锁实现, 单单只用一条 `SETNX` 指令还存在其他风险

1. 如果某个线程上锁成功,但是在释放锁之前异常挂掉了,此时这个变量值将会一直存在下去无法被释放; 这会导致其他线程再也无法获取到锁,从而阻塞整个服务的运行

针对这个问题最简单的办法,就是 `给分布式锁添加上一个自动过期时间`

这样一来,即使某个线程持有锁之后异常挂掉了,在经过一段时间后,锁也会自动释放; 不会完全阻塞其他线程

2. 如果某个线程上锁成功,但是其他线程执行了 `DEL key` 指令,这会导致线程的锁被其他线程误释放掉

此时如果有其他线程申请到了锁,这样就会和第一个线程同时操作临界区资源,最后可能导致严重的数据不一致问题

针对锁被其他线程 **误** 释放的问题,可以在加锁的时候,带上一个唯一标识以区分不同的加锁请求

上述加锁方案仅仅通过 `0` 或者 `1`,或者单纯的判断变量是否存在, 这是无法区分出不同的加锁请求的; 这就要求在加锁的时候,在锁变量上带上自己的唯一标识

这个唯一标识的取值并不固定,线程 id,客户端 id 这种有唯一性约束的都可以

最后上锁指令变为 `SETNX key unique_id EX 10` 其中 `EX 或者 PX` 表示带上超时时间单位分别是 `秒` 或者 `毫秒`

这样在释放锁的时候,就不再是简单的 `DEL key` 了,而是先获取锁变量的值,判断其 `value` 是否等于自己的唯一性标识,如果是才删除,否则说明是别人加的锁自己不能删除

这导致释放锁的操作变为多个步骤,还必须通过 `Lua` 脚本保证释放锁也是一个原子性操作

3. 锁过期问题

在经历了上面两个优化之后,还存在另一个问题,那就是如果持有锁的线程在处理业务的时候耗时过长,超过了上锁时设置的自动过期时间; 这也会导致锁被提前释放,可能引起并发安全问题

这里 redis 原生没有提供对应的解决方案,需要通过其他额外的三方提供类似于 `自动续期` 的功能

4. 单机节点宕机

由于 redis 是单节点部署,如果说 redis 发生了宕机,此时整个系统的锁就无法正常提供服务,整个业务相当于不可用

最终,还是需要依靠集群部署的 redis 提供分布式锁,才能有效解决上面提到的所有问题

#### redis 分布式锁

想要实现系统的高可用,单节点明显是不可能的; 一旦引入了分布式,整个系统的复杂度也就远比单机系统更为复杂; 在分布式锁的设计上,就需要按照一定的步骤和规范进行加解锁操作; 否则将会导致非预期的表现

redis 官方提供了基于集群部署下的分布式锁实现 `RedLock 红锁`; 简单来说,就是采用 `过半机制`,即加锁和释放锁的标志为 `在半数以上的节点上操作成功`

这样分布式锁就保存在多个主节点上,即使有主节点发生宕机,其他主节点仍然能够维护这些分布式锁

红锁的主要实现过程如下,假设整个 redis 集群当中有 `N` 个节点:

1. 客户端获取当前时间 `now`
2. 客户端 `依次` 向 `N` 个节点发送加锁请求
  * 加锁的过程与单节点几乎一致,即 `SETNX key unique_id EX expire`
  * 如果在对某个节点请求加锁的过程发生了超时,就继续向下一个节点发起加锁请求; 这里加锁时的超时时间远小于整个锁的超时时间,保证如果能拿到锁,也不至于立马就过期被释放掉
3. 一旦客户端请求完 `N` 个节点后,就需要计算整个加锁过程的 `总耗时 cost`

只有在满足下面两个条件时,才认为最终加锁成功

1. 加锁成功的节点个数过半 `即 >= N/2 + 1`
2. 总耗时小于锁的超时时间,即 `cost < expire`,最终锁的有效时间为 `expire - cost`

**需要注意的是,如果一个客户端最终加锁失败,那么它必须立即向所有节点发送解锁请求**

使用了 `Redlock` 之后,只要保证集群当中有半数以上的实例正常工作,就能保证分布式锁的正常工作